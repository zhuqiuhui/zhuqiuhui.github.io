<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[桃子的博客铭]]></title>
  <subtitle><![CDATA[高性能、高可用服务端开发]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="https://taozj.org/"/>
  <updated>2017-02-28T15:47:25.000Z</updated>
  <id>https://taozj.org/</id>
  
  <author>
    <name><![CDATA[taozj]]></name>
    <email><![CDATA[dEB0YW96ai5vcmcK (base64)]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[后台开发那些常用技术再次小结（五）：消息队列]]></title>
    <link href="https://taozj.org/201702/study-note-of-scalable-backend-(5)-message-queue.html"/>
    <id>https://taozj.org/201702/study-note-of-scalable-backend-(5)-message-queue.html</id>
    <published>2017-02-24T15:46:13.000Z</published>
    <updated>2017-02-28T15:47:25.000Z</updated>
    <content type="html"><![CDATA[<h1 id="一、消息队列简介">一、消息队列简介</h1><p>　　消息队列本质上是一个缓冲并分发请求的组件，消息队列工作的上下文中假定消息为单向流动，拥有着“发射后不用管”的特性。消息由消息生产者产生、消息队列缓冲、消息消费者消费信息执行操作，生产者和消费者之间彼此独立的工作，之间只会通过消息格式和消息队列产生耦合，这样就实现了生产者和消费者业务的解耦和异步化操作：之后生产者和消费者可以独立部署、独立伸缩，并且生产者向队列提交完消息之后就可以立即响应客户的请求。</p>
<h2 id="1-1_消息队列中的角色">1.1 消息队列中的角色</h2><p>　　<strong>消息生产者</strong><br>　　消息生产者也叫作消息发布者，其属于客户端代码的一部分，其只需要负责创建一条合法消息，并发送到消息队列中即可。应用通常有多个生产者，所有发步的消息被排队并异步处理。<br>　　<strong>消息队列</strong><br>　　消息队列本身起着向消费者递交消息的缓冲作用，消息队列可以是一个具有权限控制、路由、持久化、失败恢复等多种职责的独立组件，所以通常也被作为一个独立应用程序提供服务，称作消息代理或者面向消息的中间件。<br>　　<strong>消息消费者</strong><br>　　消息消费者主要从消息队列中接收并处理消息，是实际处理异步请求的组件。消息消费者不应当知道生产者的情况，其应该只依赖于消息队列中的合法消息做出行动。<br>　　消息消费者通常具有周期模式和守护模式进行工作：<strong>周期模式 | 拉模式</strong>，消费者定期连接到消息队列检查队列状况，如果有消息才消费，这种模型在诸如PHP、Perl等动态语言中比较常见，可以用在队列消息较少或者网络不稳定的场景；<strong>守护模式 | 推模式</strong>，消息消费者和消息代理通常用一个持久连接进行无限循环方式运行，消费者阻塞在取消息的操作上，这种模式在持久化应用容器的语言中更常见，比如Java、Nodejs；还有结合两种，采用推拉结合的形式进行工作的。<a id="more"></a><br>　　从消费者向消息队列取消息的不同订阅方法，也派生出了消息的不同路由方法：<br>　　a. 直接工作队列模型<br>　　该模式下队列由生产者和消费者所周知，多个生产者可以在任意时间点向队列的一端发送消息，而另一端可以有一个或者多个消费者竞争消费消息，但每条消息只会被路由到一个消费者。这种情况下消费者是无状态的，因此失效节点的替换、处理性能的可伸缩性将极为的简单。<br>　　b. 发布订阅模型<br>　　该模式实际是设计模式中观察者模式的变体，此模式下消息可能被发送到不止一个消费者。生产者产生的消息不再是发送给一个队列，而是发送到一个主题；消费者使用的时候必须连接到消息代理，并声明自己所感兴趣的主题；消息到达主题后，会被克隆给每个订阅了该主题的消费者，消费者接受一份消息的拷贝并复制到自己的私有队列中。在实现上，如果在发消息的时间点没有消费者订阅到该主题，通常这个消息会被丢弃掉。<br>　　这种模式的一个实例，就是电商在购物操作被确认后，会将购物事件发送给消息队列的某个主题，那么后续对这个主题感兴趣的消费者就可以收到消息后进行相关事务处理，比如通知供货商、消费者风控规则、消费者积分奖励等。<br>　　c. 定制路由规则<br>　　主要是各种消息路由规则的定制，消费者可以选择灵活的方式决定消息如何路由到自己的队列中。比如日志消息可以根据日志错误等级进行特定方式的路由。</p>
<h1 id="二、消息队列的好处">二、消息队列的好处</h1><p>　　<strong>实现异步处理</strong><br>　　使用消息队列可以推迟耗时的操作而不必阻塞客户端，消息添加到队列后就可以返回客户端让客户端继续执行。<br>　　异步处理的另外好处，就是保护系统的核心业务和关键特性，比如下单、产品检索、处理支付，如果将非核心业务同核心业务耦合起来，就会引入新的失效点影响核心业务的可用性，这些非核心业务请求都可以放到消息队列中进行异步处理。同时，对于那些消耗计算资源的操作、低价值的操作类型也都可以隔离到消息队列中处理。<br>　　<strong>更好的伸缩性</strong><br>　　生产者和消费者可以独立进行伸缩操作，理想情况下只需要简单添加机器联系到消息代理就可以完成伸缩。<br>　　<strong>平衡流量峰值</strong><br>　　即便业务流量持续增长，系统仍然可以持续高频接收请求，虽然消息产生的速率比消费速率快，但是可以持续高速的将消息送入队列中。虽然消息生产速率比消费速率会快，会导致整个队列不断增长，消息从发出到处理的延时也会不断变长，但是当峰值过后生产速率比消费速率低，整个系统就会慢慢趋于正常水平。<br>　　<strong>失败隔离和自我修复</strong><br>　　消息队列容许从关键路径上删除一些非核心功能，那么通过生产者、消费者的角色隔离就可以提高系统的健壮性和容错性，消费者系统错误就可以同生产者系统隔离。不仅在消费者遇到问题的时候体现出这样的价值，这也意味着消费者可以在任意时刻停止消息的处理，那么对于消费者端软件的维护、升级都是大有裨益的，只要消息被保存好就可以了。<br>　　<strong>解耦</strong><br>　　通过消息队列可以让生产者和消费者从不互相直接交互，甚至感知不到对方的存在，他们的行为只依赖于事先约定的消息格式。消费者和生产者可以独立开发、独立维护，甚至可以由不同的团队完成，从而在架构上实现了业务的高度解耦。</p>
<h1 id="三、消息队列的挑战">三、消息队列的挑战</h1><p>消息队列在上述描述的好处之外，带来的挑战和代价主要有：<br>　　<strong>消息无序</strong><br>　　在大多数情况下为了实现业务的伸缩性，消息消费者都是并行执行而且没有同步机制的，虽然这样可以最大化消费性能，但是某些情况下会出现消息无序的状况，消息处理的顺序取决于每个消费者处理能力的大小以及本身处理消息所需要的计算量。比如创建账户和发送邮件两个消息，这两个消息是有顺序依赖的，但是可能会被并行执行；某些情况下消息处理失败，消息队列基础架构会让该消息重回队列，然后被发送给其他消费者，那么就有可能出现消息的倒序执行、消息的多次执行问题。  针对上面的问题，可能的解决方式有：<br>　　a. 如果只有一个消费者(单线程)，每次只消费一条消息，那么可以保证消息严格按照入队的顺序进行有序消费，但是这种方式缺乏伸缩性。<br>　　b. 由应用程序保证消息顺序，整个消息系统仍然是不受消息顺序影响的。比如业务只发送创建账户的消息，而等消费者创建完账户后，该消费者负责创建发送Email的消息。<br>　　c. 某些消息代理可以支持部分消息顺序保证，这类组件主要是进行消息组机制，当消息发送的时候带有一个分组ID的标签，该分组ID可以由应用程序定义，消息代理能够保证同一组的所有消息能够按照发布的顺序被消费。其实内部是进行路由映射的策略，将同一个组ID的消息都发送给同一个消费者，这样就能够保证被顺序消费，但是不利于负载均衡。<br>　　<strong>消息重新入队列</strong><br>　　某些失败的场景下可能导致消费的信息被重新入队列。如果这种情况下需要系统健壮，那么就需要保证消费者的操作具有幂等性，但这种幂等性的实现根据业务类型可易可难，通常是在应用程序中增加一个操作跟踪和持久层来解决。<br>　　还有需要注意的是，幂等操作和顺序依赖往往是相互制约的，比如两条消息：一条将价格设置为55美元，一条将价格设置为60美元，那么这样的消息具有幂等性，但是最终结果严格依赖执行顺序；如果改为价格增加5美元，虽然对顺序无依赖，但是操作不具有幂等性。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://tech.meituan.com/mq-design.html" target="_blank" rel="external">消息队列设计精要</a></li>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="一、消息队列简介">一、消息队列简介</h1><p>　　消息队列本质上是一个缓冲并分发请求的组件，消息队列工作的上下文中假定消息为单向流动，拥有着“发射后不用管”的特性。消息由消息生产者产生、消息队列缓冲、消息消费者消费信息执行操作，生产者和消费者之间彼此独立的工作，之间只会通过消息格式和消息队列产生耦合，这样就实现了生产者和消费者业务的解耦和异步化操作：之后生产者和消费者可以独立部署、独立伸缩，并且生产者向队列提交完消息之后就可以立即响应客户的请求。</p>
<h2 id="1-1_消息队列中的角色">1.1 消息队列中的角色</h2><p>　　<strong>消息生产者</strong><br>　　消息生产者也叫作消息发布者，其属于客户端代码的一部分，其只需要负责创建一条合法消息，并发送到消息队列中即可。应用通常有多个生产者，所有发步的消息被排队并异步处理。<br>　　<strong>消息队列</strong><br>　　消息队列本身起着向消费者递交消息的缓冲作用，消息队列可以是一个具有权限控制、路由、持久化、失败恢复等多种职责的独立组件，所以通常也被作为一个独立应用程序提供服务，称作消息代理或者面向消息的中间件。<br>　　<strong>消息消费者</strong><br>　　消息消费者主要从消息队列中接收并处理消息，是实际处理异步请求的组件。消息消费者不应当知道生产者的情况，其应该只依赖于消息队列中的合法消息做出行动。<br>　　消息消费者通常具有周期模式和守护模式进行工作：<strong>周期模式 | 拉模式</strong>，消费者定期连接到消息队列检查队列状况，如果有消息才消费，这种模型在诸如PHP、Perl等动态语言中比较常见，可以用在队列消息较少或者网络不稳定的场景；<strong>守护模式 | 推模式</strong>，消息消费者和消息代理通常用一个持久连接进行无限循环方式运行，消费者阻塞在取消息的操作上，这种模式在持久化应用容器的语言中更常见，比如Java、Nodejs；还有结合两种，采用推拉结合的形式进行工作的。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[后台开发那些常用技术再次小结（四）：缓存部分]]></title>
    <link href="https://taozj.org/201702/study-note-of-scalable-backend-(4)-cache.html"/>
    <id>https://taozj.org/201702/study-note-of-scalable-backend-(4)-cache.html</id>
    <published>2017-02-23T15:21:03.000Z</published>
    <updated>2017-02-24T15:18:04.000Z</updated>
    <content type="html"><![CDATA[<p>　　缓存技术在计算机体系中使用的极为广泛：CPU内部多级缓存、硬盘缓存、Linux文件系统缓存、数据库查询缓存、DNS解析缓存、浏览器和应用APP缓存等，缓存在加快系统响应的同时，也降低了对某些资源的消耗，善用缓存会整个系统的性能将会有极大的改善。<br>　　因为缓存通常可以从源头重建，所以即使被删除或者丢失了也不会产生太大的问题，不过也有一些诸如缓存失败导致服务器雪崩的问题。缓存最主要考量的是命中率，这个指标收到缓存键集合大小、内存空间大小和缓存寿命相互制约。</p>
<h1 id="一、基于HTTP缓存">一、基于HTTP缓存</h1><p>　　HTTP层的缓存一个重要特性就是其为通读缓存，通读缓存通常作为中介(代理)的角色，透明地给HTTP链接添加缓存功能，他可以拦截客户端请求并用缓存对象返回给客户端作为响应，只有当缓存没有合适的数据的生活，才会链接到原始服务器并转发客户端请求给他。因为服务和通读缓存的接口是一样的，这种情况下客户端也可以直接连接到原始服务器而跳过缓存。通读缓存很具有吸引力，因为他的存在对客户端来说是透明的，客户端无法区分响应来自缓存还是原始服务器，所以通读缓存扮演着可插拔的角色，客户端无须因为他的存在与否而做任何修改。</p>
<h2 id="1-1_HTTP规范的缓存头">1.1 HTTP规范的缓存头</h2><p>　　HTTP协议虽然广为使用，而且其可被缓存特性也广受赞誉，不过协议上其相关选项和实现缺较为的混乱。HTTP协议中和缓存相关的参数有：<br>　　<strong>Cache-Control</strong><br>　　private: 指出请求结果对请求用户是特定的，响应不能提供给其他用户。该用法也就意味着只有浏览器可以缓存响应，因为中间缓存无法识别特定用户。<br>　　public: 只要它为过期，指示响应可以在用户间被共享。注意这个选项和private是互斥的。<br>　　no-store: 指示响应不能被任何中间缓存存储到磁盘上，即响应可以被缓存在内存，但是不能持久化到磁盘。当你在响应中包含用户敏感信息的时候应该包含这个选项，使得缓存信息不回存储这些数据到磁盘上。<br>　　no-cache: 指示响应不能被缓存，更精确的意思是针对这个请求，缓存在每次用户请求相同资源的时候都需要询问服务器此时是否仍然合法，其效果和 Cache-Control:max-age=0相当。<a id="more"></a><br>　　max-age: 指示响应在缓存失效前，客户端可以保持缓存多少秒(即响应的TTL)。作者推荐不适用该选项，因为它向后兼容不好，而且还依赖Expires这个HTTP头。<br>　　no-transform: 指示响应不做任何修改直接用缓存提供。比如CDN的提供商可能通过对图片转码来减少大小，降低质量或者改变压缩算法。<br>　　must-revalidate: 指示一旦响应过于陈旧，不重新验证就不能返回给客户端。出现这个参数主要是客户端可以允许返回陈旧信息，此时通过这个参数告知缓存必须停止提供陈旧响应数据，每当客户端请求陈旧对象，缓存会强制向原始服务器请求数据。<br>　　<strong>Expires</strong><br>　　指定一个缓存对象失效的绝对时间点，超过这个时间点缓存对象就“陈旧”了。这个头其实同Cache-Control:max-age有些重复的，参考说Cache-Control 中指定的缓存过期策略优先级会高于Expires，不过同时定义两个变量可能会导致潜在不一致行为，建议只用一个并固定使用它。<br>　　<strong>Vary</strong><br>　　这个头告知缓存你需要基于某些HTTP请求头，生成响应的多个变体。</p>
<p>　　除此之外，还可以在Web页面中使用meta标签控制Web页面缓存，但是书的作者不推荐使用，因为他们不能用来控制中间缓存，而且容易引起混乱，经验不足还是使用HTTP头来控制缓存。</p>
<h2 id="1-2_HTTP的缓存类型">1.2 HTTP的缓存类型</h2><p>　　因为HTTP缓存是通读缓存，在客户端和服务端交互中的任何环节都可以插入中间缓存因而比较灵活。HTTP缓存常见于四种形式：浏览器本地缓存、缓存代理、反向代理和CDN。<br>　　<strong>浏览器缓存</strong><br>　　浏览器缓存和本机的内存、文件系统协同工作，当HTTP请求将要发出的时候，浏览器会检查缓存是否具有该资源的合法版本，如果响应存在于缓存中并且仍然有效，浏览器就可以直接重用之而不用发出一个HTTP请求。<br>　　<strong>缓存代理</strong><br>　　通常由大公司或者ISP作为通读缓存部署，用于加快用户响应的同时降低网络流量。但是近些年本地代理的做法有所限制，一方面是网络带宽变便宜了，二则越来越多的Web站点采用HTTPS部署，客户端和服务器之间的通信无法被识别和拦截，缓存也就无从谈起了(一大批运营商的缓存服务器要吃灰了)。<br>　　<strong>反向代理</strong><br>　　其工作方式和常见的缓存代理差不多，不过是开发者自己部署和控制的，具有极大的灵活性。反向代理本身可以缓存页面缓存，降低对后端Web服务器的请求压力；还可以在反向代理中覆盖HTTP头，更好的控制请求的缓存策略和有效时间。<br>　　<strong>CDN</strong><br>　　CDN在之前也说的比较多了，其是基于智能DNS解析+缓存技术实现的分布式网络加速。<br>　　现在较好的CDN提供商可以通过配置，同时提供网站的静态内容和动态内容，这样客户端就可以不用直接向数据中心或者原始服务器发送请求而直接向CDN的地址请求，动态内容的请求可以穿透CDN缓存服务器回源到原始服务器。即使看似有些麻烦，但是这一方面可以隐藏原始服务器的地址，而且可以减轻DDoS攻击力度，再则某些动态的内容也是可以被CDN缓存的。<br>　　在我之前体验的几家国内的CDN提供商，在提供HTTP服务的同时还提供HTTPS类型的服务，不过后者的费用会高一些。CDN会要求用户提供域名证书，所以相比于缓存代理而言，他们是完全可以缓存HTTPS加密通信的内容的</p>
<h1 id="二、缓存应用对象">二、缓存应用对象</h1><p>　　对象缓存区别于HTTP缓存，其为旁路缓存类型。旁路缓存中，应用需要意识到缓存对象的存在，而不是透明的存在于应用和数据源之间。<br>　　旁路缓存会应用视为一个独立的键值存储服务，应用程序代码会询问需要的对象是否存在，如果存在就获取之，否则(不存在或者已过期)则需要从头构建该对象，并将结果保存在缓存中以便将来使用。使用这种缓存的动机就是节省对象从头构建所化的时间和资源。</p>
<h2 id="2-1_对象的缓存类型">2.1 对象的缓存类型</h2><p>　　<strong>客户端缓存</strong><br>　　主要还是浏览器的，据说用JS玩起来比较溜。<br>　　<strong>本地缓存</strong><br>　　本地缓存是相对于原始服务器而言的，其常见的本地缓存形式有：<br>　　(1) 对象直接缓存在应用内存<br>　　应用可以创建一个缓存对象池并不在释放分配的内存，这种缓存的速度最快，因为是以执行代码相同的格式存储在进程的内存空间中的。<br>　　(2) 对象存储在共享内存<br>　　这种形式主要是方便同一台机器的多个进程可以同时访问的需要。<br>　　(3) 缓存服务器作为独立应用部署在Web服务器上<br>　　这种形式的缓存服务器，需要应用程序使用专门的接口与之交互，而不能直接访问内存。虽然和上面的形式相比有一定的性能消耗，但好处是可以使用统一的访问接口，后续进行伸缩也较为的方便。这里讨论的本地缓存强调的是应用服务和缓存服务服务在同一台机器上，这种样式的缓存也有一定的问题：a. 如果在多个机器组成的应用环境中，各个机器上的缓存没有联系，也就可能同一个缓存对象会被缓存成多个副本；b. 这种分散式的缓存管理起来也比较麻烦，比如要更新或者删除某条缓存记录的话，要通知到所有的缓存服务器将会非常的棘手。<br>　　<strong>分布式缓存</strong><br>　　其实就是相对于上面描述的本地缓存中，将缓存服务器和应用服务器进行分离，通过网络接口的方式进行交互，可为所有的应用服务提供一个集中的缓存服务(变更和删除缓存条目比上面多个本地缓存类型要方便的多)。这样的缓存服务具有很强的伸缩性，管理的方式也多种多样，而且通常也会提供多种语言的访问接口库，是近年来开发和研究的热点，老牌的缓存服务如Memcached和Redis使用非常广泛。</p>
<h2 id="2-2_对象缓存的伸缩">2.2 对象缓存的伸缩</h2><p>　　针对上面描述的对象缓存类型，通常只有分布式缓存才具有伸缩的价值和可行性。常见的Memecached可以采用Ketama一致性hash算法算法的客户端库实现水平伸缩(再次提到last.fm的<a href="http://www.last.fm/zh/user/RJ/journal/2007/04/10/rz_libketama_-_a_consistent_hashing_algo_for_memcache_clients" target="_blank" rel="external">这个C库</a> )，这里强调一下Memcached一致性hash实现的伸缩性是在客户端一侧实现的；而Redis允许进行主从复制部署，对某些高热度的数据可以采用读副本的形式增加并发访问量。</p>
<h1 id="三、缓存使用的经验法则">三、缓存使用的经验法则</h1><p>　　<strong>缓存整个调用栈</strong><br>　　通常一个请求从客户端到最终服务端之间会经历多个角色，在整个调用栈中任意部分都可以考虑插入缓存，而且缓存的调用栈越高，能节省的资源也就越大，响应这个请求的代价也就越小。<br>　　<strong>用户间缓存重用</strong><br>　　缓存使用的另外一个要点就是尽可能多地在不同请求或者用户之间重用相同的缓存对象！<br>　　比如下面的例子，通过经度、维度数据查询某个结果，此时过高精度的参数将导致几乎每个调用都是不相同的，而如果将请求参数进行精度降低，那么很多请求就可以共享结果，也就增加了缓存的命中率。<br>　　<strong>缓存的入手点</strong><br>　　缓存的实施不是凭感觉的，通常的2-8定律也可以用在这里：可以通过日志查看访问量高的页面或者接口，然后从这些位置入手看是否能通过缓存改善性能，在重要、热点页面上的改进带来收益的提升可能性更大。<br>　　<strong>缓存失效的困难</strong><br>　　可以说缓存失效的问题是缓存体系中的大难题，虽然这也同业务类型具有比较大的相关性。<br>　　首先缓存服务可以设置在整个调用栈的任何可能位置，要让整个调用链在最大化缓存命中率的同时还能及时感知缓存失效是比较困难的；再则有些缓存的结果是通过多个数据源进行计算得来的，当最初的某个或者某些数据源变更将会导致该缓存失效，但是怎么样跟踪这种依赖关系是个难点。<br>　　缓存失效简单的方案就是对重要缓存对象上设置一个较短的TTL，这样可以保证数据不会过于的陈旧；为了降低数据库和服务的压力，某些动态数据的展示仍然是可以使用缓存的，只是在最终产生业务的时候进行实际的数据校验操作(虽然体验上不见得多好，比如12306的那种缓存，但至少可以帮助服务器抗住强大的访问压力)。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="http://mp.weixin.qq.com/s/qOMO0LIdA47j3RjhbCWUEQ" target="_blank" rel="external">彻底弄懂 Http 缓存机制 - 基于缓存策略三要素分解法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&amp;mid=2652897955&amp;idx=1&amp;sn=de2d8984f6d0f9e061d1da35df84b182" target="_blank" rel="external">聊聊高并发系统之HTTP缓存</a></li>
<li><a href="http://tech.meituan.com/avalanche-study.html" target="_blank" rel="external">Cache应用中的服务过载案例研究</a></li>
<li><a href="http://mogu.io/cheetah-101" target="_blank" rel="external">静态化技术在蘑菇街的应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=404087915&amp;idx=1&amp;sn=075664193f334874a3fc87fd4f712ebc" target="_blank" rel="external">缓存架构设计细节二三事</a></li>
<li><a href="http://coolshell.cn/articles/17416.html" target="_blank" rel="external">缓存更新的套路</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　缓存技术在计算机体系中使用的极为广泛：CPU内部多级缓存、硬盘缓存、Linux文件系统缓存、数据库查询缓存、DNS解析缓存、浏览器和应用APP缓存等，缓存在加快系统响应的同时，也降低了对某些资源的消耗，善用缓存会整个系统的性能将会有极大的改善。<br>　　因为缓存通常可以从源头重建，所以即使被删除或者丢失了也不会产生太大的问题，不过也有一些诸如缓存失败导致服务器雪崩的问题。缓存最主要考量的是命中率，这个指标收到缓存键集合大小、内存空间大小和缓存寿命相互制约。</p>
<h1 id="一、基于HTTP缓存">一、基于HTTP缓存</h1><p>　　HTTP层的缓存一个重要特性就是其为通读缓存，通读缓存通常作为中介(代理)的角色，透明地给HTTP链接添加缓存功能，他可以拦截客户端请求并用缓存对象返回给客户端作为响应，只有当缓存没有合适的数据的生活，才会链接到原始服务器并转发客户端请求给他。因为服务和通读缓存的接口是一样的，这种情况下客户端也可以直接连接到原始服务器而跳过缓存。通读缓存很具有吸引力，因为他的存在对客户端来说是透明的，客户端无法区分响应来自缓存还是原始服务器，所以通读缓存扮演着可插拔的角色，客户端无须因为他的存在与否而做任何修改。</p>
<h2 id="1-1_HTTP规范的缓存头">1.1 HTTP规范的缓存头</h2><p>　　HTTP协议虽然广为使用，而且其可被缓存特性也广受赞誉，不过协议上其相关选项和实现缺较为的混乱。HTTP协议中和缓存相关的参数有：<br>　　<strong>Cache-Control</strong><br>　　private: 指出请求结果对请求用户是特定的，响应不能提供给其他用户。该用法也就意味着只有浏览器可以缓存响应，因为中间缓存无法识别特定用户。<br>　　public: 只要它为过期，指示响应可以在用户间被共享。注意这个选项和private是互斥的。<br>　　no-store: 指示响应不能被任何中间缓存存储到磁盘上，即响应可以被缓存在内存，但是不能持久化到磁盘。当你在响应中包含用户敏感信息的时候应该包含这个选项，使得缓存信息不回存储这些数据到磁盘上。<br>　　no-cache: 指示响应不能被缓存，更精确的意思是针对这个请求，缓存在每次用户请求相同资源的时候都需要询问服务器此时是否仍然合法，其效果和 Cache-Control:max-age=0相当。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[CMake工具使用手册]]></title>
    <link href="https://taozj.org/201702/cmake-cheatsheet.html"/>
    <id>https://taozj.org/201702/cmake-cheatsheet.html</id>
    <published>2017-02-22T12:31:21.000Z</published>
    <updated>2017-02-23T06:57:24.000Z</updated>
    <content type="html"><![CDATA[<p>　　之前自己的小项目都是直接手动人肉Makefile，因为项目的文件不是很多，发现以前写的那个Makefile模板增增改改还是挺够用的。但现在发现CMake真是越来越流行了，不知道是不是借着QT/KDE等项目的东风，越来越多的C++开源项目开始使用CMake工具来用作管理项目了。此外，著名IDE Clion和CMake也集成的很好，只不过我现在已经不用IDE进行调试了，因为命令行的GDB更方便。<br><img src="/post_images/images/201702/4a3b2635.png" alt="cmake"><br>　　这次在一个项目中使用了CMake，简单直白的几行命令，就可以快速生成Makefile，相比Makefile晦涩的语法和隐暗的规则，可以说是懒人(对我来说主要是弱鸡)用的Makefile。除了辅助生成编译用的Makefile，CMake还集成安装、测试、打包等功能，同时跟Boost库的单元测试框架也很好的集成，Bingo！<br>　　注意：CMake工具的实现主要是由一系列的命令构成，同时还有大量的预定义变量，正是他们的存在使得用户可以用极少的语句生成功能丰富的Makefile文件。现在CMake官方最新发布版本是v3.8，但是在CentOS-7系列的机器上最新的CMake版本仍然是v2.8分支，由于代码的部署环境所限，本篇文档还是针对CMake v2.8.12老版本操作实验的结果，有时候同最新CMake可能会有所差异，建议查看查看老版本的文档。<br>　　CMake中有很多涉及到文件、目录的相关命令或者变量，在作为参数的时候有时可以使用相对路径，有时可以使用绝对路径；在使用相对路径的时候，有时候是相对于项目的源代码路径，有时候是相对于编译路径，还有些时候相对路径参考于某些预制变量，这些东西如果被搞糊涂了还是建议查看相关文档。<br>　　本文档不求最全，够用即可！</p>
<h1 id="一、起步">一、起步</h1><p>　　凡是手动安装过CMake管理的软件的同学，都知道CMake的用法。通常会在项目路径下面建立一个build目录，然后进入build目录使用<code bash="">➜  build git:(master) ✗ cmake ../ </code>命令就可以生成Makefile文件，接下来的操作想必大家就都知道了。额外创建build路径进行项目外编译，就是可以保护你的源代码路径整洁干净。<br>　　所以开发者就是要编写这个CMakeLists.txt文件，方便自己的同时也方便了用户。<a id="more"></a><br>　　CMakeLists.txt文件使用#打头的是注释，项目根目录CMakeLists.txt所必须行如下，前者规定了可以使用该文件的最低版本CMake版本，后者指明了项目名称。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cmake_minimum_required (VERSION 2.8.11)</div><div class="line">project (aimlsrvd)</div></pre></td></tr></table></figure></p>
<p>　　如果你的项目是比较简单的结构，所有源代码都放在source/目录下面，而根目录包含一个main.cpp入口函数，则只需要再添加如下两行，就可以编译产生可执行文件了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">aux_<span class="built_in">source</span>_directory( <span class="built_in">source</span>/ DIR_SRCS )</div><div class="line">add_executable( aimlsrvd main.cpp <span class="variable">$&#123;DIR_SRCS&#125;</span> )</div></pre></td></tr></table></figure></p>
<p>　　aux_source_directory 命令的作用就是将指定目录下的文件名收集起来并保存到指定变量中。这个命令原本不是专门为上面这种情况使用的，因为CMake只会检查CMakeLists.txt文件的时间戳来决定是否执行cmake更新编译环境，那么当你在指定目录下添加了新的源代码文件的时候而没有更新过CMakeLists.txt，那么CMake可能就不能感知到该目录下源文件增删的变化，此时你必须手动执行cmake命令进行刷新。<br>　　add_executable 命令用于指定生成可执行文件，该名字必须在整个项目中相对其他可执行文件必须是全局唯一的。不仅仅是可执行文件，通过add_library还可以生成库类型的目标。</p>
<h1 id="二、自定义库">二、自定义库</h1><p>　　将所有的源代码都丢在一个目录下“扁平化”管理是很糟糕的，现在的软件工程都讲求模块化设计，所以通常的手段是将模块的代码单独放在一个文件夹，将模块编译成库，一方面方便代码(库)的重用，而来对于整个项目的管理、调试都是大有裨益的。<br>　　CMake支持这种递归形式的处理，只需要在项目根目录的CMakeLists.txt通过add_subdirectory命令添加你模块所在的源代码目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">add_subdirectory( <span class="built_in">source</span>/Netd/ )</div></pre></td></tr></table></figure></p>
<p>　　然后调到你模块所在的源代码目录(比如上面例子的source/Netd/)，再新建一个CMakeLists.txt文件，通过上面提到的add_library命令指定所需生成的库名称，生成的库还可以指定生成动态库SHARED还是静态库STATIC的类型。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">aux_<span class="built_in">source</span>_directory(. DIR_LIB_SRCS)</div><div class="line">add_library (Netd SHARED <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</div><div class="line">add_library (Netd_static STATIC <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</div><div class="line">install (TARGETS Netd Netd_static</div><div class="line">            RUNTIME DESTINATION bin</div><div class="line">            LIBRARY DESTINATION lib</div><div class="line">            ARCHIVE DESTINATION lib/static )</div></pre></td></tr></table></figure></p>
<p>　　后面那个install是在安装的时候需要使用到的。因为CMake有个问题，就是安装必须在当前目录下指明，所以该库的安装命令不能在顶层的CMakeLists.txt文件中去设定，虽然麻烦，但是设计如此。<br>　　一旦可执行程序使用了连接库(无论是自己生成的还是其他外部组件的)，都需要在CMakeLists.txt中指明这种依赖关系。如果你想让自己的CMakeLists.txt看得优雅一些，推荐set个变量来慢慢收集，而且有时候你还不得不这么做。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; pthread hiredis iconv)</div><div class="line">set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; boost_system boost_thread boost_date_time boost_log boost_log_setup boost_regex)</div><div class="line">set ( EXTRA_LIBS $&#123;EXTRA_LIBS&#125; Netd )</div><div class="line">target_link_libraries( aimlsrvd $&#123;EXTRA_LIBS&#125; )</div></pre></td></tr></table></figure></p>
<h1 id="三、宏变量和编译选项">三、宏变量和编译选项</h1><h2 id="3-1_编译命令行选项">3.1 编译命令行选项</h2><p>　　通过add_definitions函数可以设置编译时候命令行的宏定义，比如gcc的-D和巨硬的/D。一个常用的例子就是assert的NDEBUG宏开关了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">add_definitions (-DBOOST_LOG_DYN_LINK -DNDEBUG)</div></pre></td></tr></table></figure></p>
<p>　　除了这个，CMake还有很多内置的变量和可以设置，比如Debug/Release便宜版本，编译参数的设置等(比如c++11标准必须显式设定)，在此罗列出来供大家参考。Debug版本和Release版本编译出来的可执行程序的尺寸相差巨大啊！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS <span class="string">"<span class="variable">$&#123;CMAKE_CXX_FLAGS&#125;</span> -std=c++11 "</span> )</div><div class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "-Wall -Wconversion -Woverloaded-virtual -Wpointer-arith -Wshadow -Wwrite-strings -march=native " )</span></div><div class="line"><span class="built_in">set</span>(CMAKE_BUILD_TYPE Debug)</div><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS_DEBUG   <span class="string">"<span class="variable">$ENV</span>&#123;CXXFLAGS&#125; -O0 -g"</span>)</div><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="string">"<span class="variable">$ENV</span>&#123;CXXFLAGS&#125; -O2 "</span>)</div></pre></td></tr></table></figure></p>
<h2 id="3-2_通过文件配置宏定义">3.2 通过文件配置宏定义</h2><p>　　通过configure_file这个命令，CMake可以将输入配置文件进行处理，并转换成可用的C/C++头文件，而且在配置文件模板中使用的@VAR@变量会被在CMakeLists.txt中定义的值所替换，这样就提供了CMakeLists.txt-配置模板-应用程序三者交换数据的通道。对此，在CMake手册中最经典不过的例子就是软件版本号了。下面是在CMakeLists.txt定义的主、次两个版本号信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> (AIMLSRV_VERSION_MAJOR 0)</div><div class="line"><span class="built_in">set</span> (AIMLSRV_VERSION_MINOR 85)</div><div class="line">configure_file ( <span class="string">"include/config.h.in"</span>   <span class="string">"../include/config.h"</span> )</div></pre></td></tr></table></figure></p>
<p>　　然后在模板配置文件config.h.in中定义两个变量，变量的值可以引用之前在CMakeLists.txt中定义的变量：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _CONFIG_H_</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> _CONFIG_H_</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> aimlsrv_VERSION_MAJOR @AIMLSRV_VERSION_MAJOR@</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> aimlsrv_VERSION_MINOR @AIMLSRV_VERSION_MINOR@</span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// _CONFIG_H_</span></span></div></pre></td></tr></table></figure></p>
<p>　　正常使用cmake命令，就会发现可被C/C++引用的指定头文件config.h生成了，其中的两个宏aimlsrv_VERSION_MAJOR、aimlsrv_VERSION_MINOR的值已经被正常替换，在C/C++源代码中可以像普通的宏一样被使用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"      VERSION: "</span>  &lt;&lt; aimlsrv_VERSION_MAJOR &lt;&lt; <span class="string">"."</span> &lt;&lt; aimlsrv_VERSION_MINOR &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div></pre></td></tr></table></figure></p>
<h2 id="3-2_定义选项开关">3.2 定义选项开关</h2><p>　　option命令可以提供类似选项开关(ON、OFF)的效果，而且在使用ccmake的时候可以提供ncurses库支持的图形化选择效果，不过<strong>需要特别注意</strong>使用该命令的时候，其设置结果会被缓存起来，如果你最开始生成CMake的缓存文件之后，如果修改了其取值后直接运行cmake，那么该新值是没有生效的，只有当你删除build目录下缓存文件之后再次生成，才会实际的生效。<br>　　我有个库AiSQLpp在当前的项目中还没有完成调试，所以其选项设置为OFF，该变量会影响到下面的编译和生成过程：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">option(USE_AISQLPP <span class="string">"Currently not work with aisqlpp, so must be disabled!"</span> OFF)</div><div class="line"><span class="keyword">if</span> (USE_AISQLPP)</div><div class="line">  add_subdirectory( <span class="built_in">source</span>/Aisql/ )</div><div class="line">endif (USE_AISQLPP)</div><div class="line"><span class="keyword">if</span> (NOT USE_AISQLPP)</div><div class="line">  <span class="built_in">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> mysqlclient z m ssl crypto dl)</div><div class="line"><span class="keyword">else</span> (NOT USE_AISQLPP)</div><div class="line">  <span class="built_in">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> Aisql mysqlcppconn)</div><div class="line">endif (NOT USE_AISQLPP)</div></pre></td></tr></table></figure></p>
<p>　　上面定义了名称为USE_AISQLPP的开关选项，其ON和OFF的选项值决定了程序是使用AiSQLpp库还是使用原生的mysqlclient来访问数据库。我们在之前的config.h.in配置模板文件中可以使用cmakedefine来声明这个宏：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#cmakedefine USE_AISQLPP</span></div></pre></td></tr></table></figure></p>
<p>　　如果USE_AISQLPP的值是ON，那么在生成的config.h中就会有<code cpp="">#define USE_AISQLPP</code>这个宏定义的存在，如果该选项是OFF，那么就将没有这个宏的定义，因此这个选项的定义还可以控制程序源代码的行为。</p>
<h1 id="四、单元测试">四、单元测试</h1><p>　　CMake自带单元测试工具ctest，更令我高兴的是可以和Boost.Test单元测试框架无缝结合，这样单元测试的代码也可以使用CMakeLists.txt文件进行管理了。当然，根据网上的资料看来，集成gtest和CMake使用也不是难事，不过个人来说还是倾向于喜欢Boost全家桶。<br>　　单元测试的目录的CMakeLists.txt跟项目差不多，只不过需要额外的添加enable_testing()命令，在文件的末尾对于每个测试用例，都要使用add_test()命令添加到测试用例集中去。按照下面的步骤编译测试用例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  <span class="built_in">test</span> git:(master) ✗ mkdir build &amp;&amp; <span class="built_in">cd</span> build</div><div class="line">➜  build git:(master) ✗ cmake ..</div><div class="line">➜  build git:(master) ✗ cmake --build .</div><div class="line">➜  build git:(master) ✗ ctest</div></pre></td></tr></table></figure></p>
<p>　　下面是执行单元测试的效果：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">➜  build git:(master) ✗ ctest </div><div class="line">Test project /home/taozj/remote_build/aimlsrvd/<span class="built_in">test</span>/build</div><div class="line">    Start 1: dividewordtest</div><div class="line">1/3 Test <span class="comment">#1: dividewordtest ...................   Passed    0.20 sec</span></div><div class="line">    Start 2: aisqlpptest</div><div class="line">2/3 Test <span class="comment">#2: aisqlpptest ......................   Passed    0.41 sec</span></div><div class="line">    Start 3: utfgbktest</div><div class="line">3/3 Test <span class="comment">#3: utfgbktest .......................   Passed    0.38 sec</span></div><div class="line"></div><div class="line">100% tests passed, 0 tests failed out of 3</div><div class="line"></div><div class="line">Total Test time (real) =   1.42 sec</div><div class="line">➜  build git:(master) ✗</div></pre></td></tr></table></figure></p>
<p>　　如果想要更详细的输出，比如想在测试的过程中查看测试用例和应用程序代码中的打印信息，可以使用<code bash="">ctest –verbose</code>命令，虽然现实的东西比较多额多，但是总体输出格式还是非常友好第。</p>
<h1 id="五、安装和打包">五、安装和打包</h1><h2 id="5-1_安装">5.1 安装</h2><p>　　通过install命令可以安装编译产物——可执行文件、动态|静态库、头文件、配置文件等，默认情况下CMake还是比较保守的，全部都安装到/usr/local/{bin,lib,include}目录下。对于可执行文件和头文件可以按照下面的方式进行设置，而对于动态和静态库文件，由于CMake的限制必须在当前目录进行安装，所以需要在对应的子文件下进行安装，其代码已经在上面自定义库的段落进行了示范。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">install (TARGETS aimlsrvd DESTINATION bin )</div><div class="line">install (DIRECTORY include/ DESTINATION include/aimlsrvd)</div></pre></td></tr></table></figure></p>
<p>　　设置好之后，使用<code bash="">➜  build git:(master) ✗ sudo make install</code>就可以进行实际的安装。不过，默认情况下CMake不提供uninstall目标，虽然从官方的手册上面可以在配置模板文件中添加uninstall目标的支持，其实安装文件都记录在了install_manifest.txt文件中，只需要执行下面一行命令就可以搞定删除操作：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">➜  build git:(master) ✗ xargs rm &lt; install_manifest.txt</div><div class="line">➜  build git:(master) ✗ cat install_manifest.txt | sudo xargs rm</div></pre></td></tr></table></figure></p>
<h2 id="5-2_软件打包">5.2 软件打包</h2><p>　　如果上面的安装配置好了，那么软件打包也极为的简单，只需要将下面几行代码粘贴到根目录的CMakeLists.txt文件的末尾，然后使用cpack工具就可以进行可执行文件、源代码文件的打包操作。<br>　　不过我个人而言觉得不是很必要，因为：线上的项目基本都是编译玩直接在当前目录启动运行，不会发布给其他人使用，也就没有了软件打包的需要；如果需要打包，各大发行版有更专业的打包工具(比如rpmbuild)，使用cpack打包成一个.sh的安装文件总感觉显得比较的业余。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">include (InstallRequiredSystemLibraries)</div><div class="line"><span class="built_in">set</span> (CPACK_PACKAGE_VERSION_MAJOR <span class="string">"<span class="variable">$&#123;AIMLSRV_VERSION_MAJOR&#125;</span>"</span>)</div><div class="line"><span class="built_in">set</span> (CPACK_PACKAGE_VERSION_MINOR <span class="string">"<span class="variable">$&#123;AIMLSRV_VERSION_MINOR&#125;</span>"</span>)</div><div class="line">include (CPack)</div></pre></td></tr></table></figure></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/25751686/" target="_blank" rel="external">Mastering CMake</a></li>
<li><a href="https://cmake.org/cmake-tutorial/" target="_blank" rel="external">CMake Tutorial</a></li>
<li><a href="https://cmake.org/cmake/help/v2.8.12/cmake.html" target="_blank" rel="external">CMake 2.8.12 Documentation</a></li>
<li><a href="http://www.boost.org/doc/libs/1_63_0/libs/test/doc/html/boost_test/section_faq.html" target="_blank" rel="external">Boost.Test FAQ</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　之前自己的小项目都是直接手动人肉Makefile，因为项目的文件不是很多，发现以前写的那个Makefile模板增增改改还是挺够用的。但现在发现CMake真是越来越流行了，不知道是不是借着QT/KDE等项目的东风，越来越多的C++开源项目开始使用CMake工具来用作管理项目了。此外，著名IDE Clion和CMake也集成的很好，只不过我现在已经不用IDE进行调试了，因为命令行的GDB更方便。<br><img src="/post_images/images/201702/4a3b2635.png" alt="cmake"><br>　　这次在一个项目中使用了CMake，简单直白的几行命令，就可以快速生成Makefile，相比Makefile晦涩的语法和隐暗的规则，可以说是懒人(对我来说主要是弱鸡)用的Makefile。除了辅助生成编译用的Makefile，CMake还集成安装、测试、打包等功能，同时跟Boost库的单元测试框架也很好的集成，Bingo！<br>　　注意：CMake工具的实现主要是由一系列的命令构成，同时还有大量的预定义变量，正是他们的存在使得用户可以用极少的语句生成功能丰富的Makefile文件。现在CMake官方最新发布版本是v3.8，但是在CentOS-7系列的机器上最新的CMake版本仍然是v2.8分支，由于代码的部署环境所限，本篇文档还是针对CMake v2.8.12老版本操作实验的结果，有时候同最新CMake可能会有所差异，建议查看查看老版本的文档。<br>　　CMake中有很多涉及到文件、目录的相关命令或者变量，在作为参数的时候有时可以使用相对路径，有时可以使用绝对路径；在使用相对路径的时候，有时候是相对于项目的源代码路径，有时候是相对于编译路径，还有些时候相对路径参考于某些预制变量，这些东西如果被搞糊涂了还是建议查看相关文档。<br>　　本文档不求最全，够用即可！</p>
<h1 id="一、起步">一、起步</h1><p>　　凡是手动安装过CMake管理的软件的同学，都知道CMake的用法。通常会在项目路径下面建立一个build目录，然后进入build目录使用<code bash>➜  build git:(master) ✗ cmake ../ </code>命令就可以生成Makefile文件，接下来的操作想必大家就都知道了。额外创建build路径进行项目外编译，就是可以保护你的源代码路径整洁干净。<br>　　所以开发者就是要编写这个CMakeLists.txt文件，方便自己的同时也方便了用户。]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="内核" scheme="https://taozj.org/tags/%E5%86%85%E6%A0%B8/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="读书笔记" scheme="https://taozj.org/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[后台开发那些常用技术再次小结（三）：存储部分]]></title>
    <link href="https://taozj.org/201702/study-note-of-scalable-backend-(3)-storage.html"/>
    <id>https://taozj.org/201702/study-note-of-scalable-backend-(3)-storage.html</id>
    <published>2017-02-12T15:12:07.000Z</published>
    <updated>2017-02-28T00:37:12.000Z</updated>
    <content type="html"><![CDATA[<p>　　原书对于存储模块，主要就是描述的数据库的设计和优化，和我通常想到的文件系统的存储有点差异，其实数据库的底层还是放在文件系统上面的(原谅我又不禁想到了GitLab删库事件)，只不过随着数据量增加数据库文件的尺寸会不断的变大(在mysql中查找datadir的变量就可以看见数据文件的位置)。<br>　　互联网公司很多数据都塞在数据库中的，而且数据库这一模块的使用和优化经验也比较的丰富，更加有文章可做吧！</p>
<h1 id="一、文件存储">一、文件存储</h1><p>　　在绝大多数情况下磁盘一直都被诟病是拖慢整个系统的罪魁祸首，现在看来网络速度都会比磁盘要快得多。<br>　　如果是自己的服务器托管，建议尽可能的增加物理内存(云主机就算了，增加内存配置价格贼贵)，因为操作系统的缓存机制，较大的物理内存能减少IO操作，从而改善文件系统访问性能。<br>　　现在优化磁盘效率的方法除了操作系统和文件系统的参数调优之外，最直接的方法就是上SSD。想到前些年很多人对SSD还是持观望态度，时常会有SSD无故掉盘、数据无法恢复的情况，不过从这些年看来随着SSD技术的完善，各大厂商和数据中心都以SSD硬盘作为主机的卖点了，可见SSD还是接受住了现实的考验了(虽然现在随着工艺水平的提高和TLC的推广，据称SSD的寿命甚至还不如之前)，工业上通过SSD将业务性能提高几倍甚至几十倍的案例数见不鲜。其实，现实世界没有什么硬件是绝对可靠的，所谓的可靠性缺陷可以用软件来弥补。想当初我在2012年花了六百多大洋买了Crucial 64GB m-sata接口的固态硬盘，该硬盘作为系统盘现在仍然工作的杠杠地，所以增加内存和上固态硬盘是任何工作或者生产机器实现“垂直扩展“的最佳捷径了。对于固态硬盘如果是SATA3接口，其最高速率是6Gbps，而现在很多SSD的传输速度已经受限于该接口速率了，那么你可以考虑采用PCI-E接口的SSD存储来获取更高的性能了。<br>　　如果你对SSD的可靠性还是不放心的话，将SSD作为一个缓存介质而不做数据持久化的存储，也可以极大增加IOPS的性能指标，对随机化IO密集型的服务优化效果十分明显。虽然某些情况下SSD中的数据没有写回之前挂掉，还是会有丢数据的风险，但是相比之前安全系数已经高了好多。各个大厂针对此种情形的<a href="http://mogu.io/Facebook_flashcache-81" target="_blank" rel="external">解决方案</a>貌似很多啊！<br>　　RAID(独立冗余磁盘阵列)算是一个历史悠久但却极为有用的存储技术了，通过多个廉价独立的磁盘进行组合达到多种组合，将IO操作分散到多个物理磁盘上去，同时具有增加副本备份恢复的功能，让整个存储系统在可靠性、性能、成本之间做出权衡，RAID技术算是在存储最底层层次上所做出的备份和优化操作。RAID的类别可分为几十种，比如：RAID0是把数据切成块，分别存储在两个或者多个磁盘上，虽然读写性能都增加了N倍，但是安全性最低，任何一块磁盘挂掉数据就无法恢复了；RAID1是做的存储冗余镜像，读性能能增加N倍，但是写操作需要在多块磁盘上写出完整副本，性能可能会有所降低，而且磁盘空间利用率最低；RAID5和RAID6也是将数据分块，同时将可恢复的校验数据也作为一个数据块，他们依次分布在不同的磁盘上，这样在增加读写性能的同时，也允许少量磁盘坏掉后可以恢复原来的数据，工业上使用的较多；RAID10和RAID01算是RAID1和RAID0的合体也比较流行(两者镜像和条带操作的顺序不同)，虽然磁盘利用率低，但是大家觉得在可靠性和性能都能达到较好的效果(也不一定，工业上不都是认为3-5份的数据备份才是比较安全的嘛)。<a id="more"></a><br>　　让我印象最深刻的，还是当时在《<a href="https://book.douban.com/subject/24335672/" target="_blank" rel="external">淘宝技术这十年</a>》这本书里面看到的关于淘宝自建存储部分的章节。对于一般规模的公司觉得数据库的问题显得更为突出，而文件存储的需求只有特定业务类型公司才会比较急切。比如淘宝、腾讯、Facebook这类公司对于自身海量级别的数据，基本都不约而同地开发了适合自己的文件系统应对存储问题。<br>　　现在各大云厂商也提供了对象存储技术，除了在可靠性方面达到了99.9999999%的可用性，还提供水平弹性扩充、异地容灾、权限控制、线路优化、冷热存储、标准RESTful接口等各种特色服务，达到了开箱既用的便捷性。其实从硅谷的那些独角兽公司来说，基本初始阶段都使用Amazon这类成熟的云服务，等到自己的业务发展的比较规模后，再考虑自建数据中心节省成本，不过也有失败的案例(请原谅我在此又一次联想到了GitLab)。</p>
<h1 id="二、关系型数据库伸缩性">二、关系型数据库伸缩性</h1><p>　　数据库虽然是一个再常见不过的组件了，但是其中学问大的很。在保证可靠性的同时，其性能直接关系到业务的可用性，同时作为有状态的存储部件也不像较上层的业务容易扩展，更可怕的是如果开始设计不够充分或是没有好好规划，那将会是埋下的一个巨坑，对后续维护、扩展来说后患不已、贻害无穷。</p>
<h2 id="2-1_复制">2.1 复制</h2><p>　　MySQL自带同步机制，在一台主机作为主节点的时候，可以将主节点的修改同步到多台从节点。<br>　　对于数据库的修改命令，都应该在主节点上面操作，主服务器将这些修改操作记录到binlog日志文件中，一旦操作被记录到binlog日志中，那么主节点就可以向从节点发送了。MySQL的同步操作是异步的，所以主服务执行完更改后会立即返回给客户端响应，而不用等待从服务日志复制过程，从服务器可以在任意时刻连接到主服务器上，同时从服务器和主服务器可以快速进行增量更新，同时任何一个新的从服务器都可以连接到主服务器上面去。其好处有：<br>　　(1) 增加副本，那么只读操作就可以分布在多个从服务器上面，进而减轻主库的负载，而且这样的从服务器可以添加多个副本，不仅是水平的，在垂直的方向上海可以进行多层次的同步。<br>　　(2) 可以针对不同类型的查询使用不同的从数据库，比如将过慢的、对数据更新要求不高的查询放到单独的从数据库上面。因为数据库同步的异步性，从服务器的数据副本很可能不是最新的，所以对于数据更新需求强的读请求应该被路由到主库上面以确保得到最新的副本。<br>　　(3) 根据同步的异步性，可以在某个时间将从服务器停止同步，然后就可以对数据库进行完整的冷备份，而主库的对外服务不受影响。这种操作有时候是必须的，因为MySQL不支持从一个空数据库上启动一个从服务器，所以经常对数据库进行完整备份，可以提高下次增加或替换从服务器的速度。<br>　　(4) 如果主服务器失效，MySQL不支持自动失效转移的功能，即不能自动将一台从服务器提升为主服务器。这需要手动更改配置才能生效，而且由于同步的异步性，往往还需要检查将要提升为主服务器的binlog是否是最新的。</p>
<p>　　<strong>主-主同步拓扑</strong><br>　　针对主服务器挂掉，从服务器不能自动提升为主服务器的情况，有提出主-主同步的架构，两个主服务器是对等的角色，在一台挂掉的情况下应用程序可以快速切换到另外一台服务器进行正常工作。因为MySQL的binlog日志会记录执行的主机信息，所以在主-主同步拓扑的情况下，服务器A发送给服务器B的日志不会再由服务器B发送回服务器A，虽然理论上可以同时向两台服务器进行写入操作，但是为了降低数据冲突的风险，通常也都是向一条服务器进行写入。不仅仅是2，还可以有多个主服务器之间进行同步，总体来说就是在增加可用性的同时，数据的一致性和冲突的问题就越严重，所以现实环境下慎重使用。</p>
<p>　　<strong>复制的问题和挑战</strong><br>　　虽然使用副本的方法来进行伸缩的时候，只是对读操作进行了伸缩，其写入能力并没有得到改善(主要是处于数据一致性的考虑)，这对于读操作多的程序是一种很好的伸缩手段，可以大大增加客户端只读的并发读和QPS指标。增加副本对增加数据规模也没有任何帮助，任何一个主、从服务器都包含了完整的数据副本，其存储能力没有得到任何提升。<br>　　再次强调数据库同步是异步操作，正常情况下主-从的同步延时不会超过500ms，但是也有非正常情况。MySQL的复制是从服务器上单线程独立完成的，而主服务器上的更新操作是多线程并发执行的，很有可能从服务器跟不上主服务器的更新步骤，尤其当执行表结构更新等复杂的操作时，会阻塞之后所有的同步请求。解决这种问题的思路有：a.对数据敏感的请求直接发送到主服务器上面；b.尽量降低复制延迟，比如将服务器上更新表结构的操作binlog关闭，这类操作在从服务器上面手动执行，那么更新表结构和数据同步就可以并行完成了。<br>　　MySQL的复制还可能遇到其他问题导致数据不一致，比如使用生成随机数的功能(还有时间函数？)等，导致主服务器和从服务器的数据不一样，一旦主从服务器同步出现差错，后面的更新操作很可能会得到不一致的结果，这种问题就大发了！<br>　　现在想想，终于知道数据库专家的工资那么高了，数据库对于一个产品和公司的发展至关重要，而其相关技术专业性强，需要大量的经验和积累！</p>
<h2 id="2-2_数据分片">2.2 数据分片</h2><p>　　数据分片是将数据通过某种方式进行切分，以便将他们分散存储在多台服务器上，这也是我们通常听到的数据库分表分库，是除了功能分隔、增加副本之外的第三种伸缩性手段。这里说的数据库分片是针对数据库本身不支持分片，在应用层实现的数据分片。<br>　　数据分片首先需要选择分片键，通过分片键和某种映射算法可以快速定位路由对应记录在哪个服务器上，而不需要获取记录时候同所有的服务器进行通信，分片键和映射算法的选择，最好能让各个分片中的记录能够均匀分布。数据分区是突破数据量、并发链接数、服务器IO限制的有效手段。</p>
<p>　　<strong>数据分片的问题挑战</strong><br>　　应用层数据分片的主要假定分片键之间是彼此独立没有联系的，这也就制约了无法执行多个分片的联合查询，如果有这种需求只能在各个分片上执行对应操作后再在应用层进行合并后返回结果。而有些情况这种执行甚至是不可能的，比如按照用户ID分片的数据库，如果要执行销售量最多的产品ID，那甚至要对绝大多数记录进行整理，因为那些分布均匀看似普通的产品，可能累计值是最大的。还有，某些以年月为后缀的分表操作，跨月份查询也是个痛点。<br>　　数据分片还导致数据库的ACID特性难以得到满足。MySQL支持单个数据库的ACID，那么上面的例子对某个用户的所有数据执行更新就是可行的，但是如果针对某个产品进行更新就需要横跨多个数据库操作，MySQL是不支持分布式事务的。<br>　　数据分片还可能涉及到一致性HASH类似的问题，绝大多数情况下通过机器数目取模的方式进行定位的算法是极度不推荐的(不过也不是绝对的，比如可以采用逻辑数据库概念分布，然后将逻辑数据库映射到物理主机上面去)，因为一旦这样定位就意味着接下来没有第二次伸缩的可能性了。在定位算法中可以简单的在数据库或者配置文件中配置定位关系(比如用户ID在哪个区段定位到哪个数据库)，这样不仅不会影响到新增记录，而且数据迁移也十分方便：只需要将对应记录锁住，然后进行实际数据的迁移，接着更改他们的映射关系，最后解锁记录就完成了。映射关系的这种定位还可以增加灵活性，比如把某些活跃用户，或者优质用户映射到配置高、线路好的机器上面去，以实现差异化运营。<br>　　数据分片还有个问题就是生成唯一性键约束。在MySQL有两个变量：auto_increment_offset和auto_increment_increment，数据库在这两个变量上实现的自增的逻辑是：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">auto_increment_offset + N × auto_increment_increment</div></pre></td></tr></table></figure></p>
<p>　　所以分区的数据库通过设置这两个变量就可以产生不重复的唯一性键了；另外的一种方式就是借助外部第三方组件生成唯一性键值，比如Redis。这种唯一性键的特性还常常用在主-主同步的环境中。<br>　　下面这个图是把上面技术都用到的样子。<br><img src="/post_images/images/201702/ec6594c2.jpg" alt="mysql"></p>
<h2 id="2-3_其他">2.3 其他</h2><p>　　<strong>数据的冷热存储</strong><br>　　世界万事万物都是相互制约、相生相克的，在限制成本因素的时候数据存储的性能和容量是相互制约的，因此如果业务模型可以清晰的分离出冷热数据(比如交易类型的数据按照创建日期进行划分)，那么冷热数据分开处理也将是个存储上的优化。冷数据一般来说具有数据量大、通常只有简单的查询操作、对性能要求不高的特点，所以可以对低频数据分配性能、线路较差的机器负责(而且由于其访问和操作少，所以低配的机器响应也不一定会差)。现在的云计算厂商也提供不同特性的存储服务类型，自建数据中心的也可以借鉴之。</p>
<p>　　当然，上面的水平伸缩虽然在系统设计之初的时候就应当考虑，不过也不要忽视各个独立服务器的性能优化，否则就有一种舍本取末的感觉，毕竟数据分区会在运维、业务处理上带来很多的麻烦，常常感觉有那么一种不得已而为之。在独立服务器本身的性能没有被压榨到极限的时候，你集群的规模可能会成为你的谈资，但是你为此所付出的确是白花花的银子。<br>　　所以，一方面还是要对数据库单表、单库优化做到心中有数，比如索引、数据库引擎、缓存；而对于开发人员来说SQL语句的使用也要养成良好的习惯，多看看数据库的慢查询日志再对应做出优化，不要让宝贵的资源被自己的不成熟代码白白吞噬了。建议查看下面两篇文章：<br>　　<a href="https://segmentfault.com/a/1190000006158186" target="_blank" rel="external">《MySQL大表优化方案》</a><br>　　<a href="https://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="external">《Top 20+ MySQL Best Practices》</a></p>
<h1 id="三、NoSQL数据库伸缩性">三、NoSQL数据库伸缩性</h1><p>　　关于NoSQL这里就不多说了，因为没有支持SQL的存储都把自己叫做NoSQL，概念显得比较宽泛和模糊，就像是要有意要和SQL传统数据库划清界限以凸显自己似的。<br>　　觉得大家讲到的NoSQL很多时候都是KV键值类存储(比如Amazon Dynamo)，这类存储设计之初就想到高性能和灵活的扩展性，因此两者最大的差异性就体现在可扩展性上。其实两者对比来说也没有绝对的优劣，毕竟SQL是标准性的，这么悠久的历史大家玩起来更有经验，各种优化和扩展方案也十分丰富；NoSQL是伴随着大数据成长起来的一个新概念，因为其横向扩展性优秀，对于数据量大、数据类型简单的存储需求乃是如鱼得水，因此才得以倍受追捧吧。还是那句话，符合业务需求的技术才是好技术！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://mogu.io/Facebook_flashcache-81" target="_blank" rel="external">Facebook flashcache介绍与使用</a></li>
<li><a href="https://book.douban.com/subject/24335672/" target="_blank" rel="external">淘宝技术这十年</a></li>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="http://www.d1net.com/datacenter/tech/256374.html" target="_blank" rel="external">SQL vs Nosql ：优劣大对比</a></li>
<li><a href="https://segmentfault.com/a/1190000006158186" target="_blank" rel="external">MySQL大表优化方案</a></li>
<li><a href="https://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="external">Top 20+ MySQL Best Practices</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　原书对于存储模块，主要就是描述的数据库的设计和优化，和我通常想到的文件系统的存储有点差异，其实数据库的底层还是放在文件系统上面的(原谅我又不禁想到了GitLab删库事件)，只不过随着数据量增加数据库文件的尺寸会不断的变大(在mysql中查找datadir的变量就可以看见数据文件的位置)。<br>　　互联网公司很多数据都塞在数据库中的，而且数据库这一模块的使用和优化经验也比较的丰富，更加有文章可做吧！</p>
<h1 id="一、文件存储">一、文件存储</h1><p>　　在绝大多数情况下磁盘一直都被诟病是拖慢整个系统的罪魁祸首，现在看来网络速度都会比磁盘要快得多。<br>　　如果是自己的服务器托管，建议尽可能的增加物理内存(云主机就算了，增加内存配置价格贼贵)，因为操作系统的缓存机制，较大的物理内存能减少IO操作，从而改善文件系统访问性能。<br>　　现在优化磁盘效率的方法除了操作系统和文件系统的参数调优之外，最直接的方法就是上SSD。想到前些年很多人对SSD还是持观望态度，时常会有SSD无故掉盘、数据无法恢复的情况，不过从这些年看来随着SSD技术的完善，各大厂商和数据中心都以SSD硬盘作为主机的卖点了，可见SSD还是接受住了现实的考验了(虽然现在随着工艺水平的提高和TLC的推广，据称SSD的寿命甚至还不如之前)，工业上通过SSD将业务性能提高几倍甚至几十倍的案例数见不鲜。其实，现实世界没有什么硬件是绝对可靠的，所谓的可靠性缺陷可以用软件来弥补。想当初我在2012年花了六百多大洋买了Crucial 64GB m-sata接口的固态硬盘，该硬盘作为系统盘现在仍然工作的杠杠地，所以增加内存和上固态硬盘是任何工作或者生产机器实现“垂直扩展“的最佳捷径了。对于固态硬盘如果是SATA3接口，其最高速率是6Gbps，而现在很多SSD的传输速度已经受限于该接口速率了，那么你可以考虑采用PCI-E接口的SSD存储来获取更高的性能了。<br>　　如果你对SSD的可靠性还是不放心的话，将SSD作为一个缓存介质而不做数据持久化的存储，也可以极大增加IOPS的性能指标，对随机化IO密集型的服务优化效果十分明显。虽然某些情况下SSD中的数据没有写回之前挂掉，还是会有丢数据的风险，但是相比之前安全系数已经高了好多。各个大厂针对此种情形的<a href="http://mogu.io/Facebook_flashcache-81">解决方案</a>貌似很多啊！<br>　　RAID(独立冗余磁盘阵列)算是一个历史悠久但却极为有用的存储技术了，通过多个廉价独立的磁盘进行组合达到多种组合，将IO操作分散到多个物理磁盘上去，同时具有增加副本备份恢复的功能，让整个存储系统在可靠性、性能、成本之间做出权衡，RAID技术算是在存储最底层层次上所做出的备份和优化操作。RAID的类别可分为几十种，比如：RAID0是把数据切成块，分别存储在两个或者多个磁盘上，虽然读写性能都增加了N倍，但是安全性最低，任何一块磁盘挂掉数据就无法恢复了；RAID1是做的存储冗余镜像，读性能能增加N倍，但是写操作需要在多块磁盘上写出完整副本，性能可能会有所降低，而且磁盘空间利用率最低；RAID5和RAID6也是将数据分块，同时将可恢复的校验数据也作为一个数据块，他们依次分布在不同的磁盘上，这样在增加读写性能的同时，也允许少量磁盘坏掉后可以恢复原来的数据，工业上使用的较多；RAID10和RAID01算是RAID1和RAID0的合体也比较流行(两者镜像和条带操作的顺序不同)，虽然磁盘利用率低，但是大家觉得在可靠性和性能都能达到较好的效果(也不一定，工业上不都是认为3-5份的数据备份才是比较安全的嘛)。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[后台开发那些常用技术再次小结（二）：Web服务层]]></title>
    <link href="https://taozj.org/201702/study-note-of-scalable-backend-(2)-web-service.html"/>
    <id>https://taozj.org/201702/study-note-of-scalable-backend-(2)-web-service.html</id>
    <published>2017-02-08T12:32:23.000Z</published>
    <updated>2017-02-22T01:37:46.000Z</updated>
    <content type="html"><![CDATA[<p>　　Web服务部分应当算是整个服务端开发中最重要、最复杂、同时也最具可玩性的部分了。业务逻辑的处理主要分布在Web服务层，这样一方面可以让其上层展示层不必关心业务逻辑，只专心负责展示和用户输入部分(也让其具有强大的伸缩性)，而Web服务层本身也可以通过功能分割(增加副本、功能分割和数据分片是实现伸缩性的三大利器)，以及单个服务自身的伸缩设计，最终构建一个功能强大的Web服务层。<br>　　Web服务层采用一定的设计模式为上层提供调用接口，同时这些年来，跟随者移动互联网和与计算的大潮，各大厂商也喜欢将自己的服务通过接口的方式免费或者收费的形式提供给第三方使用，这也就是所谓的Web服务和前端应用平行部署的现象，在这种环境下的服务接口设计就显得会比以往更加的重要，当时那种裸socket之上自定义数据帧的时代显然是跟不上了。尤其这些年来，关于RESTful接口设计风格可谓是如日中天，无论是Google、Amazon这些互联网大佬，还是几个人组成的互联网创业公司，都号称自己开放的服务是符合RESTful风格的接口，但是正如我在V2ex论坛上看到大家所争论(《 <a href="https://www.v2ex.com/t/340607" target="_blank" rel="external">RESTful 有用吗？ HTTP 有 GET POST 就足够了？</a>》)的一样：绝对纯正的RESTful风格接口的设计和实现在当下是不可能实现的，大家开放出来的接口要么就是根据实践情况有所妥协，要么就是封装了一个简易外壳的“伪RESTful接口”而已。<br>　　这里看到一本《<a href="https://book.douban.com/subject/25786076/" target="_blank" rel="external">服务设计模式</a>》，虽然后面的内容看的不是很明白，但是前面对于服务设计的总结还是不错的，在此进行归纳总结！归咎来说，Web服务主要是为集成不同的系统提供相应地方法，并通过HTTP来输出可重用业务功能，他们或者将HTTP作为一种简单的信息传输工具来承载数据传输(比如SOAP/WSDL服务)，或者将HTTP作为一种完整的应用控制协议，将HTTP协议的内容定义服务的各种行为和语义(RESTful服务)，前者被定义为以功能为中心的服务，后者被定义为以资源为中心的服务。<br>　　<strong>以功能为中心的服务</strong>：该种风格的服务是指能够调用远程机器上的功能或者对象方法，而无需知道这些功能或者对象是如果实现的，因此这种框架技术需要处理跨编程语言、跨CPU构架、跨运行时环境的问题，同时对调用参数的约定、变量转换、错误处理还必须进行明确的规范。以功能为中心的服务现在基本是SOAP一枝独秀，其基本使用XML作为服务描述和消息编码方式，通过HTTP在客户端和服务端之间传递请求和响应。<a id="more"></a><br>　　以功能为中心的服务基本不会用在动态语言中，因为这些动态语言和SOAP服务集成会比较困难，基本都是Java、C/C++这类静态语言。此外，由于SOAP请求是通过XML进行发送的，请求参数和方法名都通过XML封装了，URL里面没有远程调用需要的全部信息，所以对于HTTP层面基于URL的缓存就没法实现，使得伸缩性变差。<br>　　<strong>以资源为中心的服务</strong>：以资源为中心的服务作为新一代的服务设计构架，已经成为Web应用集成事实上的标准，这种设计就是以资源为中心代表一类对象，在对象上只能执行有限的操作(比如创建、删除、更新、获取资源等)，将和资源(对象)之间的交互标准化了。跟上面对应，利用HTTP缓存是可伸缩RESTful Web服务的一项重要技术，当设计的方法严格准守HTTP方法语义约束的生活，重要的GET方法的响应就应该是可缓存的，如果确保所有GET方法是只读且不会导致状态变化和数据更新，那么就可以安全的缓存该HTTP GET请求。当然，具体的业务类型可能也不允许这种形式的缓存。</p>
<h1 id="一、Web服务API设计风格">一、Web服务API设计风格</h1><p>　　Web服务API设计风格包含：RPC API、消息API、资源API三种类型。</p>
<h2 id="1-1_RPC_API">1.1 RPC API</h2><p>　　RPC API的核心概念是远程过程调用的思想，通过RPC客户端首先向远程服务器发进程发送消息，再阻塞自己，等待接收响应，请求的消息可以标识要执行的过程，同时也包括一组固定的参数映射作为远程过程的参数；远程服务收到消息时候会进行检查，并根据消息中的过程名称及其参数调用相关过程(服务)；如果需要，服务器将对应的响应结果返回给客户端，客户端提取结果并继续执行。<br>　　这是我们所最熟悉的服务设计风格，因为其历史悠久并被广泛使用，相对容易理解而且使用简单(有大量现成的服务框架可用)。这种风格API通常使用XML定义数据类型和消息，使用WSDL(Web Service Description Language)进行服务描述，用WS-Policy/WS-Security等规范来定义对客户端的授权、加密等规则；当然也可以使用非XML的方法，比如JSON-RPC这类的规范来实现。<br>　　<strong>考虑因素</strong><br>　　(1) 因为RPC和本地方法很相像，所以通常会像声明本地方法签名的方式来创建服务签名，这样的话客户端必须严格按照参数的顺序、类型来发送参数，导致使用不灵活。所以通常建议将服务签名设计为单个参数类型，或者多个可选参数类型的服务。<br>　　(2) RPC API的特点是位置透明性，服务的真实位置应该是完全隐藏的，即客户端开发者调用本地过程和调用远程过程的代码都应该大致相同，这样服务就可以按照需要进行自由移动，然后通过其他方法通知客户端服务的具体位置，比如存储在配置文件或者数据库中供客户端查询。<br>　　(3) 除了默认的请求-响应模式，RPC API还可以使用请求-确认的交互模式。这种情况下服务端收到请求后会将消息转发到一个异步后台进程，并向客户端返回一个简单确认。通常消息首先存储在消息队列或者固化到数据库中，通过这种消息接收和消息处理时间分离，系统就可以更好的处理负荷峰值，控制消息处理速率。<br>　　(4) 使用RPC API的客户端在发送消息后，也可以不需要阻塞，而采用异步响应处理器的方式提高效率。<br>　　(5) RPC API通常使用XML或者JSON进行编码，也可以采用二进制数据编码，从而压缩网络传输、节省带宽、减少延迟，不过副作用就是二进制编码会增加客户端、服务器端的计算量。</p>
<h2 id="1-2_消息API">1.2 消息API</h2><p>　　RPC API的服务端和客户端是强耦合的，无论调用名、调用签名、数据结构发生变化，都需要两方面的协调完成。<br>　　基于消息API(文档API)的服务，会在一个给定的URI上收到一个或者多个自描述的消息，消息体包含主要的数据，同时还可以附加一些标头用于身份验证、请求有效截止日期等信息。消息API通常手法表转化的消息格式(比如SOAP)。当客户端向一个指定URI发送消息后，客户端可以选择阻塞来等待响应，当消息到达服务器时候Web服务执行反序列化处理，检查消息并选择适当的处理器来处理请求，通过将客户端和真正的处理器(远程过程)进行隔离，Web服务提供了一个间接层的作用。<br>　　这种模式意在情调是基于消息设计的，API提供一个接收断点，而Web服务则扮演者分发器的角色，客户端的消息通常包括命令消息、事件消息、文档消息类型。<br>　　<strong>考虑因素</strong><br>　　(1) 消息API通常使用WSDL描述符，依赖框架辅助生成客户端服务连接器代码。具体的消息再通过某种特定的传输协议(比如HTTP)进行绑定，并在指定URI上输出其内容。<br>　　(2) 下次API的服务通常采用请求-确认模式，而不是请求-响应模式。</p>
<h2 id="1-3_资源API">1.3 资源API</h2><p>　　这种方式是对所有资源(比如文本文件、媒体文件、数据库表中的数据、业务过程等)分配一个URI，使用HTTP作为一种完整的应用协议以定义标准的服务行为，采用标准化的媒体类型和可能获得的状态码来交换信息。这样资源API的服务通过使用请求的URI、客户端发起的HTTP方法、一同提交来的请求信息及媒体类型等既可以判断客户端的意图，可以将这个规则表达为表述性状态转移(Representational State Transfer, REST)原则，因为客户端和服务端之间交换消息的生活，资源的状态发生了转变。<br>　　资源API中的URI是一个逻辑意义上的地址，通过向这个URI发送请求就可以调用对应服务或获得相应地资源，而实际的资源和URI可能存在一对多的关系，但是一个URI应该只能用于引用一个逻辑资源。资源API通过如下HTTP标准方法来访问资源：</p>
<ul>
<li>PUT：用于创建或者更新资源；</li>
<li>GET：用于检索资源的表述；</li>
<li>DELETEL：用于删除一个资源；</li>
<li>POST：该行为多样性，作为以上相对而言非标准行为，同时当服务器禁用了PUT、DELETE或者防火墙阻塞了这两种方法时候，可以用POST作为一种替代方法(隧道化执行)。很多REST的倡导者不支持使用POST隧道化的行为，因为这模糊了请求的目的，而且实现上也不利于对结果进行缓存；</li>
<li>OPTIONS：用于发现目标URI所支持的HTTP方法；</li>
<li>HEAD：用于获取URI上交换的与媒体类型有关的元数据，类似于GET只是不返回资源的表述。</li>
</ul>
<p>　　上面最常用的PUT、GET、DELETE基本可以映射为CURD(Create、Update、Retrieve、Delete)操作，而POST可以用于其他无法映射的行为。由于HTTP协议将这些行为预先定义好了，所以客户端不必学习特殊的API，而只需要知道每个URI上面可以使用的方法，以及每种方法使用时机就可以了，服务开发人员会按照标准来实现对应的功能。<br>　　HTTP规范定义了那些方法是安全的(Safe)和幂等(Idempotent)的，如果操作不会产生副作用就被认为是安全的，其不会触发创建、更新、删除操作，GET、HEAD、OPTIONS方法可以实现为安全的操作；幂等性指的无论调用同一个过程多少次，只要参数相同，那么就应该返回相同的结果(出错、超时等情况不考虑)，GET、HEAD、PUT、DELETE、OPTIONS都是幂等的，但是POST不是幂等的。POST方法也可以实现为幂等的，比如在客户端请求中插入一个唯一的标识符，服务在执行它的时候进行逻辑检查，如果已经被处理则拒绝这个请求。<br>　　资源URI会利用标准HTTP状态码，向客户端提供处理结果，通常可以返回最小量的数据表示结果因而优化了网络利用率。不过有时候响应码也会有含糊不清的意义，这也是RESTful在实现中缺陷之所在，否则那些号称符合RESTful风格的开放接口都不会另外列出一大串HTTP错误码对应的实际错误描述了。<br>　　<strong>考虑因素</strong><br>　　(1) 使用不同类型的客户端，这时候资源API是最好的选择，因为HTTP协议的广泛流行使得资源API可以得到最广泛的支持。<br>　　(2) 可寻址能力，因为资源API的设计上，URI通常是有意义的信息(比如账号ID)，那么这些信息很可能被恶意挖掘和使用。可以使用UUID映射将这些信息进行隐藏，或者采用身份验证和逻辑授权机制，确认调用者身份、限制每个调用者可执行的操作，以起到对应保护的作用。<br>　　(3) 客户端一般没有代码自动生成能力，即无法自动产生服务的客户端连接器，客户端必须采用标准的HTTP进行请求。<br>　　(4) 面向资源的服务通常使用请求-响应模式，但也可以使用请求-确认交互模式。服务可以将请求转发到异步后台进程，而向客户端立即返回一个确认消息(HTTP状态202)。<br>　　(5) 资源API通常会为同一个逻辑资源提供多种表现形式，不必为每种表现形式使用不同的URI，这通常使用媒体类型协商来满足客户端的偏好的。<br>　　(6) 资源API风格可以天生有效利用针对HTTP专门设计的缓存技术(比如反向代理缓存)，以减小队原始服务器的压力，资源API尤其适合读操作较多的场景。</p>
<h1 id="二、客户端和服务端之间的交互风格">二、客户端和服务端之间的交互风格</h1><p>　　客户端和Web服务之间基本通信模式是点对点的链接，在连接建立后通常在多次交换数据中采用同一个连接，这样有助于最小化建立和释放连接所带来的延迟。但是在实际上，网络流量在传输的过程中总要通过各种中介，比如防火墙、反向代理等，这些中介一方面可以实现安全功能，过滤或者阻止某些请求，实现负载均衡及周边缓存的功能。</p>
<h2 id="2-1_请求-响应模式">2.1 请求-响应模式</h2><p>　　该模式下客户端发给服务端的请求，会被立即执行处理，并通过同一个客户端链接返回处理结果，是客户端和服务端最常见、最易于理解的交互模式。这种客户端和服务端之间的交互是同步的，会按照严格的顺序发生，通常客户端提交请求后不能继续做其他的操作，直到请求的服务提供了响应，所以要求这种服务没有或者尽小的延迟。<br>　　<strong>考虑因素</strong><br>　　(1) 请求-响应模式是高时间耦合度的交互，因为客户端的请求都需要立即得到处理，所以大量并发的请求可能会耗尽系统的处理能力。服务架构师必须理解服务的典型工作负载，并依据期望的负载来调整服务器、数据库、网络资源的容量，包括“垂直扩展”和“水平扩展”提高性能。通过将服务有请求-响应模式修改为请求-确认-轮训或者请求-确认-回调的模式，在时间上将接收请求、处理请求、发送响应进行分离，前者让客户端空闲时候轮训响应，后者要求客户端提供自己的服务以便接收回调消息，可以缓解服务器峰值压力的风险，但是实现和调试的复杂度较高。<br>　　(2) 默认情况下，请求-响应服务的客户端会阻塞以等待响应，通过异步响应处理器可以改善客户端的性能。<br>　　(3) 请求-响应在客户端和服务端之间可以插入中介者，比如代理服务器可以缓存查询结果，防火墙可以阻止或者过滤网络流量，检查证书等功能。</p>
<h2 id="2-2_请求-确认模式">2.2 请求-确认模式</h2><p>　　请求-确认模式是可以使Web服务免受负载峰值影响，虽然通过异步响应处理器器可以缓解这个问题，但是在总体处理能力有限的情况下，如果请求的处理时间过长，那么客户端连接就会超时，这种情况通常会导致丢失响应。<br>　　传统上可以采用网络可寻址的消息队列技术(面向消息的中间件)，这样无论目标系统的运行状况如何，客户端都可以随时将消息发送给远程系统，即使无法连接远程队列基础构架也可以将消息先保存在本地，然后不断尝试发送直至成功。消息到达远程队列后会慢慢发送到目标系统，中间可以通过节流或控制处理请求速率保护远程系统。<br>　　简单的队列具有发射后不管的特点，服务会接收请求、处理请求，但是不会发送响应，客户端无法感知服务是否被接收、是否被处理、处理的结果如何。解决的方法是对请求生成特定的标识符或者URI以作为唯一性的键值，将来所有参与会话的各方都可以引用这个键值，以形成一个特定请求的上下文处理逻辑。<br>　　<strong>考虑因素</strong><br>　　请求-确认模式的难点是提供更新或者最终处理结果，通常实现的方法有：<br>　　(1) 轮训：该模式实现简单，客户端定期轮训另外一个Web服务以获取更新信息或者最终处理结果。要实现这个功能客户端必须先得到一些轮训的先决条件，资源API通常返回客户端轮序的URI地址，而RPC API和消息API通常提供查询的标识符。<br>　　请求-确认-轮序的缺点是客户端效率不高，如果轮训频率不高那么得到更新、处理结果就会有明显的延时滞后，如果轮序太过频繁也会对Web服务器带来负载，浪费网络流量。<br>　　(2) 回调和转发：这种模式下客户端不会轮训另外一个服务获取结果，而由请求处理器主动将信息推送回客户端或者其他参与者(请求-确认-转发模式)，此时客户端和服务器就互相交换角色了。这种模式下Web服务端必须获得一个回调服务列表，这可以由资源API客户端在请求中包含回调URI，或者RPC API和消息API通过WS-Addressing标识头提供，也可以是通过某种标识在数据库中查询回调信息。<br>　　这种模式实现起来比轮训更具挑战性，但是如果原始客户端不能或者不愿意提供一个可以公开寻址的回调服务，那么该种方式就不能使用。</p>
<h2 id="2-3_媒体类型协商模式">2.3 媒体类型协商模式</h2><p>　　比如在使用资源API服务的不同客户端通常可以有不同的媒体偏好，比如有的喜欢XML而有的客户端好JSON。指明客户端偏好的方法很多，比如可以将媒体类型作为最终URI的一部分或者文件资源的扩展名，这种方式简单直观而且可以被浏览器等客户端支持，但是：客户端必须知道如何对每个资源构造正确的URI，显然增加了客户端和服务端的耦合和复杂度。<br>　　解决的最好方法是使用标准HTTP协议的进行内容协商，客户端可以在HTTP请求头中指定一种或者多种媒体类型首选项，那么服务端可以参考按照预设的格式生成响应。实现的方法有：<br>　　(1) 服务器驱动的协商是最常用的一种协商方式，客户端通过Accept Request标头来提供自己的媒体偏好，可以一次提供多个偏好，也可以指明媒体类型的优先级，没有提供的话服务端可以默认选择一个，常见的媒体类型比如：application/xml、application/json、text/plain、text/html等，这些流行的类型会被自动序列化反序列化，而自定义类型可以需要自己编写对应的序列化器了。<br>　　(2) 客户端驱动的协商方式中，在客户端在发送请求的时候还是通过HTTP的Accept Request标头来携带它的媒体偏好，Web服务端收到请求后在响应中提供一组客户端可以考虑使用的URI，然后客户端根据这个响应来选择特定的URI发起真正的资源请求。<br>　　<strong>考虑因素</strong><br>　　(1) 服务器与客户端驱动的协商中，当服务拥有者期望为客户端提供选择，同时又需要维持对类型选择过程的控制时候，采用服务器驱动的协商比较合适，这有助于简化客户端逻辑，减少往返协商的流量，只是此时如果客户端没有提供明确偏好时，服务器的响应就可能不合适客户端；当期望客户端可以更多控制接收到的类型可以选择客户端驱动的协商，缺点是客户端必须发起两次请求-响应的数据交换，依次用于查询服务地址列表，另一次用于获得最终响应。<br>　　两种方法比较而言，服务端驱动协商因为是同一个URI返回多种类型的资源，不利于中介缓存，而客户端驱动的协商可以最好的利用中介缓存，因为URI和特定的媒体资源存在一对一的关系。<br>　　(2) 请求处理器中的代码应该可能会被复制，这时候应该考虑使用设计模式中的命令模式，可以降低复制代码维护的痛点。</p>
<h2 id="2-4_链接服务">2.4 链接服务</h2><p>　　通过Web服务可以将其他的服务信息输出给客户端，通常只需要发布几个根Web服务的地址作为最初的访问点，此后在每个响应中包含相关服务的地址信息，客户端解析响应之后就可以发现后续服务URI，那么客户端根据服务列表有选择的使用其他服务了。该方式的优点有：<br>　　(1) 响应可以只是提供一组对最近请求有上下文意义的服务地址，对客户端完成正确的工作流转换具有指导意义；<br>　　(2) 由于服务的地址是服务端返回的，可以确保这些地址是有效的，如果依赖客户端构造服务地址通常会出现各种各样的问题；<br>　　(3) 增加、减少、修改服务变得更加容易，只需要在响应中做出相应修改就可以了，客户端需要修改识别新的服务，对于旧的不可用服务服务端返回404就可以了；<br>　　<strong>考虑因素</strong><br>　　(1) 这种模式主要同上述的资源API一起使用；<br>　　(2) 这种服务容易遭受中间人攻击，因为中间人可以截获响应或者构造响应指向一个恶意服务。通常需要采用TLS安全传输，也可以采用数字签名保护消息不被篡改。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="https://book.douban.com/subject/25786076/" target="_blank" rel="external">服务设计模式</a></li>
<li><a href="http://www.drdobbs.com/web-development/restful-web-services-a-tutorial/240169069" target="_blank" rel="external">RESTful Web Services: A Tutorial</a></li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html" target="_blank" rel="external">Amazon S3 REST API Introduction</a></li>
<li><a href="http://blog.igevin.info/posts/restful-architecture-in-general/" target="_blank" rel="external">RESTful 架构风格概述</a></li>
<li><a href="http://blog.igevin.info/posts/restful-api-get-started-to-write/" target="_blank" rel="external">RESTful API 编写指南</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　Web服务部分应当算是整个服务端开发中最重要、最复杂、同时也最具可玩性的部分了。业务逻辑的处理主要分布在Web服务层，这样一方面可以让其上层展示层不必关心业务逻辑，只专心负责展示和用户输入部分(也让其具有强大的伸缩性)，而Web服务层本身也可以通过功能分割(增加副本、功能分割和数据分片是实现伸缩性的三大利器)，以及单个服务自身的伸缩设计，最终构建一个功能强大的Web服务层。<br>　　Web服务层采用一定的设计模式为上层提供调用接口，同时这些年来，跟随者移动互联网和与计算的大潮，各大厂商也喜欢将自己的服务通过接口的方式免费或者收费的形式提供给第三方使用，这也就是所谓的Web服务和前端应用平行部署的现象，在这种环境下的服务接口设计就显得会比以往更加的重要，当时那种裸socket之上自定义数据帧的时代显然是跟不上了。尤其这些年来，关于RESTful接口设计风格可谓是如日中天，无论是Google、Amazon这些互联网大佬，还是几个人组成的互联网创业公司，都号称自己开放的服务是符合RESTful风格的接口，但是正如我在V2ex论坛上看到大家所争论(《 <a href="https://www.v2ex.com/t/340607">RESTful 有用吗？ HTTP 有 GET POST 就足够了？</a>》)的一样：绝对纯正的RESTful风格接口的设计和实现在当下是不可能实现的，大家开放出来的接口要么就是根据实践情况有所妥协，要么就是封装了一个简易外壳的“伪RESTful接口”而已。<br>　　这里看到一本《<a href="https://book.douban.com/subject/25786076/">服务设计模式</a>》，虽然后面的内容看的不是很明白，但是前面对于服务设计的总结还是不错的，在此进行归纳总结！归咎来说，Web服务主要是为集成不同的系统提供相应地方法，并通过HTTP来输出可重用业务功能，他们或者将HTTP作为一种简单的信息传输工具来承载数据传输(比如SOAP/WSDL服务)，或者将HTTP作为一种完整的应用控制协议，将HTTP协议的内容定义服务的各种行为和语义(RESTful服务)，前者被定义为以功能为中心的服务，后者被定义为以资源为中心的服务。<br>　　<strong>以功能为中心的服务</strong>：该种风格的服务是指能够调用远程机器上的功能或者对象方法，而无需知道这些功能或者对象是如果实现的，因此这种框架技术需要处理跨编程语言、跨CPU构架、跨运行时环境的问题，同时对调用参数的约定、变量转换、错误处理还必须进行明确的规范。以功能为中心的服务现在基本是SOAP一枝独秀，其基本使用XML作为服务描述和消息编码方式，通过HTTP在客户端和服务端之间传递请求和响应。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[后台开发那些常用技术再次小结（一）：前端部分]]></title>
    <link href="https://taozj.org/201702/study-note-of-scalable-backend-(1)-front.html"/>
    <id>https://taozj.org/201702/study-note-of-scalable-backend-(1)-front.html</id>
    <published>2017-02-08T12:31:21.000Z</published>
    <updated>2017-02-24T08:35:43.000Z</updated>
    <content type="html"><![CDATA[<p>　　回家的路途上看了一下《<a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a>》这本书，该书是使用开发者头条积分兑换的第二本书，而且出版的时间还比较新。看了之后感觉还是比较有收的，至少感觉有了这个视野之后，再观网上那些所谓的高并发、高性能、高扩展性的网站架构，会有一种豁然开朗的感觉。其实怎么说呢，现在强调的高性能、可扩展系统的各套花样本质上也就那么几种模式，大家都是在实际项目中根据自身的业务规模、业务特点做相应的选型、裁剪、适配、调优而已。<br>　　想想其实也不难理解，毕竟我们已经进入后互联网时代这么久了，大规模互联网系统开发中的各种问题、各种坑点想必大家都遇到过了，解决方案也十分成熟可靠，甚至各大云平台都把你所考虑的东西都帮你做完了，你只需要专注自己的业务开发和运维就可以了！或许真如之前别人所对我所说：这些互联网时代听起来高大上的技术，如果不是作为专家深入研究，而是仅仅当做一个现成的组件使用，那么你所“了解”的这些技术，充其量就是跟别人之间多出来的那几分谈资而已，任何一个程序员在对应的环境下都可以快速掌握的。说说也是，毕竟上面说的那本书俺一天不到的时间就看完了，这么看来，感觉操作系统、数据结构和算法、计算机网络、软件调试和优化等看似不起眼的东西，此时便显得更为地重要！<br>　　不过话又说回来，上面的意思并不是说这类知识不重要，即使你不去做他，但是对他的全局观的理解和把控也会影响到自身的业务设计和实现。于是后面将根据书中内容的主线，总体描述现在互联网系统的开发过程中，为了达到构建高性能、可扩展的架构，从前端层、Web应用层、Web服务层、数据存储层部分，配合缓存、异步这些组件进行设计和实现的相关事项，同时配合其他文献分类别进行整理归纳和扩充，算是做一个自我普及的作用吧。<br><img src="/post_images/images/201702/ae1f1917.jpg" alt="struct"><br><a id="more"></a><br>　　首先开篇是与前端相关的。说实话对上面列出的那些内容，后端部分个人还是在不同程度上比较了解和清楚的，但是前端部分确实接触不多，而且前端本身也有流行的开发模式和开发框架，在此就不再深入挖掘了，此处就关于一些零碎的知识点进行总结吧。<br>　　一般来说，前端部分作为应用栈上的最顶层，包含了直接与用户交互的一些组件，他们不应当包含业务逻辑，可以最大限度的使用CDN、缓存进行优化；在这之下通常还会有Web应用层，他们通常用轻量级的动态语言和框架实现最小的业务逻辑，主要用于帮助生成用户界面，而具体业务逻辑应该放置到下面的Web服务层完成，这一方面是因为该部分通常变更会比较频繁，而且最好设计成无状态的，以方便实现弹性伸缩。</p>
<h1 id="一、状态管理">一、状态管理</h1><p>　　HTTP最早是被设计成无状态、请求-应答模型的协议用于在客户端和服务端传送数据的，这种模式在网站上用于进行文字、图片资源的传输是合适的，在现代互联网的开发中，越来越多的应用场景也都基于HTTP协议进行传输，主要是因为HTTP具有广泛的跨平台、跨网络、多客户端支持，同时传输中的各项细节也都在协议中进行规范明确了，否则如果直接在socket层面上面进行业务开发，就需要处理太多细节方面的东西，而如果重新设计一套协议也不是一件容易的事情。<br>　　可是，HTTP设计之初主要是用于文件资源类传输的，显然不适合当下的各种应用数据的传输，其中最主要的因素是HTTP是无状态(Stateless)模式的，各个请求之间都相互独立，服务器不会保留相关状态信息，所以每个请求都会被认为是一个新的请求；但是现在应用程序的数据大多都是有状态(Stateful)模式，需要维护一种状态来进行相关的业务处理。为此，解决这个问题的方案有:<br>　　<strong>将会话状态存储在cookie中</strong><br>　　Session和Cookie机制是HTTP用于维持状态的主流方式。HTTP的协议是无状态的，所以必须在其之上维护形成一个逻辑上的“有状态”连接，当用户第一次连接到服务端的时候，就会建立一个相关的会话，在会话中可以存储或简单、会复杂的任意的信息。通过Session，服务器就可以识别同一个用户的各个请求，并为这些请求创建一个复杂持久的上下文，以便实现诸如购物车、wizard-style配置等有状态的应用效果了，虽然通信的各个HTTP请求严格上说仍然是无状态的。不过会话有一个时效性的问题，服务端不可能永远维护一个不活跃的会话，否则会严重影响服务端的并发量和处理能力。<br>　　Cookie可以用于处理上面的问题。Cookie是服务端产生的(通过返回头中使用Set-Cookie:添加)，可以被浏览器保存，并在之后的所有HTTP请求中浏览器都会自动发送给服务端(通过Cookie头)的数据。cookie是和域名相关联的，在浏览器向服务端传输数据的时候回自动将对应域名中的cookie数据放入HTTP Header中传输给服务端，所以服务端的开发者可以方便的提取这些cookie数据。在了解Cookied额机制后，几乎现在所有的现代服务端程序都会对新连接生成”session ID”字段并将其作为cookie内容传递给浏览器，浏览器保存了该内容之后，及时该会话结束了，下次重连的时候也可以在服务端查找到对应的session ID，从而实现一种有状态的效果。<br>　　在业务开发过程中，服务端就必须要检查每个请求，看其是否具有会话标识；如果存在会话标识，还必须根据业务检查该会话是否过期；在实际的使用中，还需要根据该会话ID调取其管理的相关资源。如果需要存储的数据比较的少，那么所有的状态数据完全都可以放置在Cookie当中，而如果会话的数据比较的多，通常会话数据需要额外存储在外部存储系统中。<br>　　<strong>将会话数据存储在外部数据存储系统中</strong><br>　　这种情况更为的常见，因为cookie会在每次请求中传输，如果保存的东西太多显然降低了通信的效率和安全性。该情况下cookie中就只需要保存sessionID、会话令牌等简短的数据当做索引，真正会话数据不需要在请求响应之间传递，而是直接从外部存储(比如内存、数据库、文件系统等)直接加载就可以了，常用的外部存储比如Memcached、Redis、DynamoDB，都是根据key-value读写低延迟的优化存储服务。<br>　　<strong>ASP的VIEWSTATE机制</strong><br>　　这个我还不太好归类，主要是之前爬虫的时候，在一些基于Windows/ASP构建的网站中<a href="https://github.com/taozhijiang/dust_repos/blob/master/crawl_laws/chongqing/chongqing_request_law.py" target="_blank" rel="external">遇到</a>的。在第一次使用GET方式请求网站的时候，在返回的页面中会嵌入一些’VIEWSTATE’的字段，后面的页面都是使用POST方法请求的，每次得到的页面都会更新’VIEWSTATE’字段，而且在下一个页面的请求中需要添加这个不断变化的’VIEWSTATE’。<br>　　既然大家都是做基于Linux平台下的开发的，相比这个VIEWSTATE机制遇到的也比较少，其实还真不知道巨硬公司的这个字段是干吗用的。</p>
<p>　　虽然在业务上(而不是协议上)实现有状态逻辑显得比较麻烦，但这反而也是HTTP的优势所在，因为在无状态的情况下客户端可以访问任意事例而不用担心结果会有差异，因此这样的应用具备了强大的可伸缩性。</p>
<h1 id="二、智能DNS、CDN和负载均衡">二、智能DNS、CDN和负载均衡</h1><p>　　前端优化主要有智能DNS、CDN和负载均衡扩充的方式。</p>
<h2 id="2-1_智能DNS和CDN">2.1 智能DNS和CDN</h2><p>　　在国内，电信行业的历史渊源造就了对骨干网南电信、北联通、其他运营商忽略的格局，虽然电信和联通的网络高速互联不会有什么技术上的问题，但实际的效果确实互访的延时很大，于是在买虚拟主机和服务器的时候，双线网络都会作为一个卖点列出来。大家会发现当访问一些老网站、某些下载资源的网站时候，那时候智能DNS解析还没有普及开来，所以网站会给出电信、联通的链接让你去点击，以便让用户有较好的网络体验，不过以我们现在的情商看来，这种让用户手动选择线路的体验真是太差了。<br>　　智能DNS就是把上面手动选择的操作智能化，因为域名的访问最终都是转化成IP地址才能直接使用的，所以智能DNS就会根据用户所在的网络返回适宜的IP地址。因为朋友的信任，自己手头有好几天服务器，前段时间还折腾过<a href="https://www.cloudxns.net/" target="_blank" rel="external">cloudxns</a>的智能解析的，可以细分到各个省份的各个线路解析成什么IP地址，不过国内网络环境复杂，到底某个地区的某个线路访问自己的某个主机比较快，测试起来比较麻烦，最后也作罢了。在书中提的较多的是GeoDNS，其号称是一种基于客户地理位置进行域名解析的DNS服务，其实按照上面的运维方式手动设置各个地区各个线路的DNS记录的话会累趴，如果能做到给出所有目的主机IP列表，服务商自动给予最优化将会是多么美好的事情！书中还提到了Amazon的Route 53解析服务，其解析的结果不是基于地理位置，而是根据响应延迟来决断的，可见这算是非常先进的智能<br>DNS解析了。<br>　　现在的机房也讲求BGP(边界网关协议)，其实际是实现线路的智能路由的功能，其实现成本较高。不过这都是机房和运营商相互合作的，对于我们普通用户可玩性不大。<br>　　CDN从本质上来说就是智能DNS+缓存结合的产物。CDN对网站的优化效果十分显著，当访问静态内容的时候不仅可以加快用户的响应时间，而且可以大大减少后端服务器的压力和带宽/流量消耗(CDN提供商的带宽费用肯定比自己服务器带宽费用便宜很多)，一定程度上还能起到抗攻击的效果。不过CDN的只对静态资源加速效果较好，动态内容很多还是需要访问原始服务器才可以，实践的时候可以根据业务特点将某些动态资源静态化，以此可以享受CDN带来的好处。</p>
<h2 id="2-2_负载均衡">2.2 负载均衡</h2><p>　　通过DNS轮训机制本身就自带负载均衡的效果，比如我们每次PING百度的IP地址都不一样。不过基于DNS的负载均衡问题比较多，比如DNS是一个分布式的系统，在本地主机到各层次的服务器都有缓存效应，这使得服务器的管理和变更时效性很差，所以实践中使用的较少。负载均衡还可以通过硬件实现，这里复杂均衡器性能较好，但是专业性太强，而且售价很高。<br>　　其实，现在各大云计算厂商也提供负载均衡的服务，我查阅了<a href="https://www.qcloud.com/product/clb?idx=2" target="_blank" rel="external">qcloud的CLB服务</a>，其实很多都跟Nginx的负载均衡功能类似，说明负载均衡已经是一项十分成熟的技术了。负载均衡现在比较有意思的东西是和弹性按需计算相结合，比如CLB可以根据业务的负载进行自动的横向扩展，自动的创建和释放CVM实例，而Amazon的ELB也有这样的功能，可以自动增加和删除EC2运算实例。这种方式的确可以自动优化资源利用从而节省成本，但是这样的弹性运算实例不能再上面存储任何数据，至少保证数据是一次性的(比如缓存)，而且删除和销毁实例的时候要保证运算实例是真正空闲的才可以；其次这种弹性机制存在着“预热”的问题，对于网站流量爆发的情况，自动伸缩往往不能立刻响应，从而影响服务的可用性。<br>　　一般的用户使用的都是软件负载均衡，其中最著名的就是Nginx和HAProxy两个开源软件，他们都支持三层负载均衡和七层负载均衡，HAProxy本人没有接触过所以不太了解，Nginx本身就是一个HTTP服务器，所以可以预见对HTTP的七层代理支持会比较完善。负载均衡通常都能实现很大的并发量和很快的数据包处理，但是单机也会有性能极限的时候，水平扩展负载均衡通常采用DNS轮训的方式，因为负载均衡器不会做业务处理，通常服务比较稳定，同时也不会频繁的增加删除负载均衡器实例，而且负载均衡器本身也是无状态的，可以进行随意互换的。<br>　　<strong>负载均衡的好处</strong><br>　　a. 安全性<br>　　负载均衡器像是个卫士一样挡在服务的最前线，所有的流量都会先经过他们，所以可以隐藏后端服务器的IP地址、网络和服务结构等信息。同时负载均衡本身还可以设置各种过滤和规则，对用户的访问进行控制，以对后端整个服务起到保护作用。<br>　　b. 服务器维护<br>　　无论是维护原因还是失效的原因，服务器都可以从负载均衡的转发对象中方便的移除。负载均衡器本身就有健康度检查机制，当请求失败率达到一定程度就认定该服务器失效并停止流量转发；同时正常工作的服务器可以配置负载均衡让其不在接收新的请求，正在服务的连接结束后服务器就可以安全下线了，对于不间断服务滚动更新等各项需求都很容易实现。<br>　　c. 无缝伸缩处理能力：<br>　　和上面说的一样，负载均衡器结合弹性计算，可以优化资源的利用率和节省成本。<br>　　d. 高效的资源管理：<br>　　负载均衡的一大功能就是SSL终结(SSL卸载)，在负载均衡器上处理所有的SSL加密解密工作，而在服务和数据中心全部采用非加密传输方式。SSL是在外网不可信环境下进行数据保护的操作，而经过负载均衡之后就是内网环境，尽早卸载SSL可以最大程度地降低对性能的影响。</p>
<h1 id="三、安全">三、安全</h1><p>　　在HTTP的开发中，会有很多安全性相关的问题，这一方面主要是之前的HTTP协议是明文传输的，可以说上个世纪的协议在当下暴露出各种各样的安全性问题。<br>　　<strong>同源策略和会话劫持</strong><br>　　同源策略(Same-origin policy)是保证同一站点的资源处于一个可信的范围内，他们之间可以相互访问而不受限制，但是会阻止不同站点对文档、资源的访问和操作(同源策略涉及到的是访问内容，比如Cookie、文档内容嵌入等，而连接可以随便插入不受此限制)。同源中相同站点的三要素是：相同的协议、相同的主机名、相同的端口号。<br>　　同源策略是增强了安全性，但是也给开发带来了麻烦，因为在现代互联网开发扩展中，资源和服务拆分到不同的主机上面十分常见，那么根据同源的三要素，这些主机之间资源将不能相互操作。不过当然针对这种情况都有相应的解决方式，对于最常见的Cookie访问和AJAX请求，可以：<br>　　<strong><em>Cookie访问</em></strong>：在相同一级域名下的Cookie共享十分简单，只需要在调用Set-Cookie的时候添加domain=.example.com进行制定就可以，后面其子域名就可以共享Cookie了；<br>　　<strong><em>AJAX请求</em></strong>：同源策略规定AJAX请求只能发给同源的网址，否则就会报错。现在解决这个的方法最常见的是跨源资源共享CORS(Cross-Origin Resource Sharing)，该方式需要浏览器和服务器端同时支持，当支持的浏览器发现AJAX请求跨源后，会自动通过添加Origin附加头信息；服务端通过检查这个字段，判断是否同意这次请求，如果不允许就返回不带Access-Control-Allow-Origin头字段的响应，这时候浏览器就知道出错了，否则返回一些额外的头部信息(Access-Control-XXX)并附带正常响应结果。</p>
<p>　　<strong>跨站脚步攻击(XSS)</strong><br>　　当允许用户输入的HTML和javascript在网站上显示的时候，极容易遭受这种攻击。<br>　　如果服务端对用户输入的内容不做检查和无害处理，这些内容嵌入到网页中进行显示的时候，就会现实和执行这些HTML和javascript代码，后果将会是不可估计的。<br>　　除了对用户的输入进行检查和无害处理外，还建议使用安全的输入格式，比如Markdown格式以提供丰富的输入格式并保证安全，这一点<a href="https://www.v2ex.com" target="_blank" rel="external">v2ex</a>做的就比较好。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="https://f5.com/resources/white-papers/cookies-sessions-and-persistence" target="_blank" rel="external">Cookies, Sessions, and Persistence</a></li>
<li><a href="http://www.kancloud.cn/kancloud/tealeaf-http/43840" target="_blank" rel="external">HTTP 下午茶</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html" target="_blank" rel="external">浏览器同源政策及其规避方法</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2016/04/cors.html" target="_blank" rel="external">跨域资源共享 CORS 详解</a></li>
<li><a href="https://help.aliyun.com/knowledge_detail/40533.html" target="_blank" rel="external">BGP高防是什么？有什么优势？</a></li>
<li><a href="http://www.cloudxns.net/Support/detail/id/2163.html" target="_blank" rel="external">智能DNS和CDN加速功能以及区别介绍</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　回家的路途上看了一下《<a href="https://book.douban.com/subject/26906846/">互联网创业核心技术：构建可伸缩的web应用</a>》这本书，该书是使用开发者头条积分兑换的第二本书，而且出版的时间还比较新。看了之后感觉还是比较有收的，至少感觉有了这个视野之后，再观网上那些所谓的高并发、高性能、高扩展性的网站架构，会有一种豁然开朗的感觉。其实怎么说呢，现在强调的高性能、可扩展系统的各套花样本质上也就那么几种模式，大家都是在实际项目中根据自身的业务规模、业务特点做相应的选型、裁剪、适配、调优而已。<br>　　想想其实也不难理解，毕竟我们已经进入后互联网时代这么久了，大规模互联网系统开发中的各种问题、各种坑点想必大家都遇到过了，解决方案也十分成熟可靠，甚至各大云平台都把你所考虑的东西都帮你做完了，你只需要专注自己的业务开发和运维就可以了！或许真如之前别人所对我所说：这些互联网时代听起来高大上的技术，如果不是作为专家深入研究，而是仅仅当做一个现成的组件使用，那么你所“了解”的这些技术，充其量就是跟别人之间多出来的那几分谈资而已，任何一个程序员在对应的环境下都可以快速掌握的。说说也是，毕竟上面说的那本书俺一天不到的时间就看完了，这么看来，感觉操作系统、数据结构和算法、计算机网络、软件调试和优化等看似不起眼的东西，此时便显得更为地重要！<br>　　不过话又说回来，上面的意思并不是说这类知识不重要，即使你不去做他，但是对他的全局观的理解和把控也会影响到自身的业务设计和实现。于是后面将根据书中内容的主线，总体描述现在互联网系统的开发过程中，为了达到构建高性能、可扩展的架构，从前端层、Web应用层、Web服务层、数据存储层部分，配合缓存、异步这些组件进行设计和实现的相关事项，同时配合其他文献分类别进行整理归纳和扩充，算是做一个自我普及的作用吧。<br><img src="/post_images/images/201702/ae1f1917.jpg" alt="struct"><br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[2017年春节返途中的两三思考]]></title>
    <link href="https://taozj.org/201702/little-thoughts-at-the-begin-of-2017.html"/>
    <id>https://taozj.org/201702/little-thoughts-at-the-begin-of-2017.html</id>
    <published>2017-02-05T13:53:19.000Z</published>
    <updated>2017-02-10T15:21:12.000Z</updated>
    <content type="html"><![CDATA[<p>　　2017年是中国传统农历上的鸡年，而对我来说也是注定不平凡的一年：全家终于搬迁进了久等三年的安置新房，算是终于住上一个看起来像样一点的房子了；这是我结婚后的第一个年头，名义上正式步入人生中新的阶段；这年是我老爸的本命年，我爸六十了，而我也已经三十而立了！<br>　　这是在和老婆走完娘家从汉中回深圳途中立下的提纲，这是一个没有空客320/波音737，也没有时速三百公里和谐号的旅途，我们搭乘的，是从所有南下陕西人记忆中磨灭不掉的K768。我是无座票在这人山人海中度过了漫长的28个小时（当然还是要感谢黄牛帮老婆抢了张卧铺），那种人山人海、水泄不通、吵杂闷浊的环境实在是种炼狱的感觉，而唯一带来的好处就是，没有在安然舒适的环境中看电影、耍手机来消磨时光，而是给了我多些回忆、思考的机会和生活的种种感触（悲剧是吸了好多二手烟，这点确实比较惨）！<br><img src="/post_images/images/201702/d96907d5.jpg" alt="2017-ticket"></p>
<p><strong>父母和亲人老了</strong><br>　　年底在老家办了一场简单的婚礼，算是所有的亲戚都到场了，本身我爸妈都是排行最小的，所以到场的长辈都是老头、老太级别的状态了，最长的姑妈已经84岁高龄了。虽是一眼望去满是凋零，但是堂、表兄弟姐妹的小孩很多，活蹦乱跳的小精灵为整个场地增加了不少生命的气息。在所有我这一辈的亲戚中，我是最后完婚的，不过作为我这代人婚事的收官之作，虽然简陋但也凭空流露出那么一些自豪感。<br>　　让我感到欣慰的是，全家早年虽然多灾多难、命运多舛，而且爸妈也都接近60岁高龄，但是总体来说二老的身体和精神面貌还挺不错的。自从03年上大学直到现在工作，一直未有机会在家尽孝，这点是一直让我心中愧疚不已的，自己是家中的独子，必须承担起这份义不容辞的责任。结婚本是件幸福无比的事情，但是婚后直接面临的就是孩子、房子等各种问题，身边跟我类似情况的朋友还有很多，有时候想想我们这代人活得真是无比的辛苦。<br><a id="more"></a><br><strong>人丁兴旺</strong><br>　　在婚宴上，二舅家和姨夫家的家人就能凑上一桌了，可谓是人丁兴旺、儿孙满堂啊。所以我也会想，在这样一个时代，我们追求的到底是什么？是可以让人满足的物质金钱？还是动物本能的生衍繁衍？<br>　　我把上面两个问题列出来，虽然看似不矛盾，但是放在我们现处的环境下，确实是两个相互对立的问题。我们几个朋友其实很早都可以结婚生孩的，但是一直都拖了下来：想要好一点的工作就必须去北上广深一线城市去打拼，而生小孩会涉及到户口、上学各种问题，这些问题又跟房子问题紧紧绑定，对于没有背景白手起家的我们再怎么努力也几乎这没有希望在一线城市买房，而在我们心灰意冷准备退居二线城市的时候，发现二线城市的房价也被推高到无以承受的价位了，而且同时还伴随着各种政策性的限购。各种情况交织在一起，逼着大家喘不过气来。<br>　　或许大家会觉得我们清高不愿意将就，但是上面的问题不仅是我们搞IT、搞金融所谓的白领人士遇到的问题，那些做外贸、做工厂的人也有着同样的遭遇。他们所能给出的解决方法，就是在老家生完孩子让二老抚养，然后丈夫或者夫妻一起外出打工挣钱，跟我们一样逢年过节回去个一两次。想想看来，是不是我们也会最终沦落到这个地步！<br>　　我们这一代是接收“计划生育”这一“基本国策”光辉照耀的一代，中国人口发展的历史问题再去讨论也是无意，但是作为一个独生子的经历来说，强制生一个孩子对一个家庭来说嫉妒残忍：对孩子来说成长的历程是寂寞的，而父母会穷尽所有去培育这个孩子，往往适得其反创造了一个畸形的成长环境。<br>　　这么看来，或许我们这代，可以放松一下自己的要求：工作不必是那些明星企业、房子不必是那些繁华都市、孩子也不一定要挑最好的学校……我们可以在一个自己可以承受的环境下，生个两三个健康的宝宝，营造一个和谐的家庭环境，培养好他们健全的人格和健康的喜欢，少一分攀比，多一份真切。</p>
<p><strong>男女婚姻问题</strong><br>　　感觉身边跟我同龄的大龄剩男、剩女越发的多了，当然也有可能是之前没有注意到这个问题。关于剩男的问题，中国人口男女比例本来就严重失调，在这个大前提下面就必然有人会被淘汰下来，就像是俄罗斯、乌克兰这样的国家，是个男的就可以娶个美女回家，而且很多男的可以终日酗酒不干活的说。<br>　　在农村几乎没有剩女，偶尔会有些女孩和家长极度挑剔的；剩男大多是经济条件比较弱势，或者有生理缺陷的人。但是围绕在我们身边的剩男、剩女，大多比较优秀：长得靓、工资高、有素养……每年过年都会有大批的人求回家攻略，甚至有人受不了了直接告知父母我是个Gay!(玩笑)<br>　　此时不禁要感慨下自己是多么的幸运：没有成为剩男，而且还有个比较恩爱的老婆，虽然我们彼此不算完美，也让对方遭受过不少罪，但七年的相识相伴至少说明还是可以凑活在一起过的。木讷的我自然解释不了世界上最深奥动物的这一现象，但是大家谈论的比较多的因素无外乎有：经济和生活可以完全独立了，不用找个人抱团取暖了；思想观念开放了，不觉得结婚晚了是件丢脸的事情；事业，或者网络的虚拟世界让人更容易活得存在感，相比感情的经营更容易成功；当然其中也不乏一些恨嫁的人，但是苦于工作、生活、环境方面的原因很难遇到适合的人，我觉得此时是不是可以把锅甩给网络、手机来着，它们让我们越来越不愿意走出去，生活也变得越来越单调了！</p>
<p><strong>亲情和友情</strong><br>　　由于结婚这件事，就必须牵扯到亲戚了，虽然这次没有借钱的问题，但是亲戚之间的相处一直是个热点问题。<br>　　其实平时跟爸妈电话的时候也会说，当前的一点得失不必过于的看重，吃亏也是一种福，但是他们还是为一些问题苦恼抱怨着。这个过程中我也发现了，经常外出、交流较多的人，会显得比较开明大方；而常年蹲守老家的人，思想会变得较为保守僵硬。其实爸妈年轻的时候不是这样的，他们常常教导我在外边别跟人家争利，做人要老实谦让一些，但没想到随着年龄的增长，他们居然成为了自己以前最不喜欢的人了。<br>　　其实有时候会有一种错觉，感觉自己的朋友都比自家亲戚靠谱，比如礼金、借钱啥的都大方的不得了，平时办事要帮忙也随叫随到。但是仔细想想，亲人是通过血缘关系绑定起来必须面对的，而朋友是经过选择剩余下来的，后者的水平自然会高很多。<br>　　当然有人也会说，现在的朋友很多都是利益上的伙伴，大难来个各自飞、该出卖时就出卖。其实呢，人这种动物本来就具备着很大的不确定性，父子都可能会恩断义绝，还有什么不可能的。人啊，往往还就有那么一种犯贱的感觉，越是通过亲戚的纽带绑定在一起，大家就越是嫌隙彼此；而越是天南海北不打紧的人，还越是去亲近巴结去。但是，亲情、友情谁也不能替代谁，在一定程度上只能选择去培养和保护他。想我们这些远在外边的儿女，自然希望远在故乡的父母能得到亲戚的掌故，而独在异乡的自己在巨大的工作、生活压力下，跟自己境遇相似的朋友互相鼓励、互相抱团取暖，大家才能走的更坚强一些！</p>
<p>　　<strong><em>我们到底想成为一个什么样的人？我们所追求的到底是一种什么样的生活？</em></strong><br>　　我感觉自己的优点是，在累、沮丧、无助的时候，我会静下心来去思考这些问题而有所获；但缺点是，得到的结果很难深刻的烙在今后的生活和实践中去。虽然现在某些人会耍些小聪明，但是底层的工薪族们真的很优秀，他们勤劳、质朴、拼搏，为了自己的家庭从无怨言，真心祝愿那些远在他乡的你们今年能满载而归，也希望那些有能力有责任的的人能多多帮助他们，善待这些可爱的人们！<br><img src="/post_images/images/201702/52dac91d.jpg" alt="2017-people"></p>
<p>本文完！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　2017年是中国传统农历上的鸡年，而对我来说也是注定不平凡的一年：全家终于搬迁进了久等三年的安置新房，算是终于住上一个看起来像样一点的房子了；这是我结婚后的第一个年头，名义上正式步入人生中新的阶段；这年是我老爸的本命年，我爸六十了，而我也已经三十而立了！<br>　　这是在和老婆走完娘家从汉中回深圳途中立下的提纲，这是一个没有空客320/波音737，也没有时速三百公里和谐号的旅途，我们搭乘的，是从所有南下陕西人记忆中磨灭不掉的K768。我是无座票在这人山人海中度过了漫长的28个小时（当然还是要感谢黄牛帮老婆抢了张卧铺），那种人山人海、水泄不通、吵杂闷浊的环境实在是种炼狱的感觉，而唯一带来的好处就是，没有在安然舒适的环境中看电影、耍手机来消磨时光，而是给了我多些回忆、思考的机会和生活的种种感触（悲剧是吸了好多二手烟，这点确实比较惨）！<br><img src="/post_images/images/201702/d96907d5.jpg" alt="2017-ticket"></p>
<p><strong>父母和亲人老了</strong><br>　　年底在老家办了一场简单的婚礼，算是所有的亲戚都到场了，本身我爸妈都是排行最小的，所以到场的长辈都是老头、老太级别的状态了，最长的姑妈已经84岁高龄了。虽是一眼望去满是凋零，但是堂、表兄弟姐妹的小孩很多，活蹦乱跳的小精灵为整个场地增加了不少生命的气息。在所有我这一辈的亲戚中，我是最后完婚的，不过作为我这代人婚事的收官之作，虽然简陋但也凭空流露出那么一些自豪感。<br>　　让我感到欣慰的是，全家早年虽然多灾多难、命运多舛，而且爸妈也都接近60岁高龄，但是总体来说二老的身体和精神面貌还挺不错的。自从03年上大学直到现在工作，一直未有机会在家尽孝，这点是一直让我心中愧疚不已的，自己是家中的独子，必须承担起这份义不容辞的责任。结婚本是件幸福无比的事情，但是婚后直接面临的就是孩子、房子等各种问题，身边跟我类似情况的朋友还有很多，有时候想想我们这代人活得真是无比的辛苦。<br>]]>
    
    </summary>
    
      <category term="生活杂感" scheme="https://taozj.org/tags/%E7%94%9F%E6%B4%BB%E6%9D%82%E6%84%9F/"/>
    
      <category term="生活" scheme="https://taozj.org/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[GNU GDB调试手册]]></title>
    <link href="https://taozj.org/201701/gnu-gdb-debug.html"/>
    <id>https://taozj.org/201701/gnu-gdb-debug.html</id>
    <published>2017-01-19T13:03:50.000Z</published>
    <updated>2017-02-15T14:52:25.000Z</updated>
    <content type="html"><![CDATA[<p>　　人家都说Windows平台下的程序员是幸福的，因为Visual Studio实在是太好用了。<br>　　我想一听到上面这句话，绝大多数Linux平台C/C++程序员都将会沉默，至少网上搜Linux平台下C/C++开发调试，很大一部分文章都是介绍搭建IDE的，这也侧面说明了Linux平台下没有一个占绝对主流地位好用的IDE。自己平时写程序是用的SlickEdit，这个IDE很贵，支持代码补全和跳转，调试过程也支持断点、Watch等特性，但是使用过程中还是有这样那样的小问题(比如非英文字串显式、速度比较慢)，但是总体比较而言还是比较优秀的跨平台C/C++ IDE。虽然线下编码调试使用这货当然可以，然则线上环境就无能为力了，再加上自己之前对gdb也只是了解个表明，这次就顺着gdb的文档深挖一下！<br>　　真是一看吓一跳，gdb的命令行调试要远比IDE的功能高级的多，如果只是通常的设置断点，监测变量什么的可能IDE比较方便，但是一旦上升到高级点的调试技巧，反而gdb在命令行的模式下更为的方便和高效。<br>　　前方预警：<strong>这将会是一篇很长很长的文档摘读</strong>。</p>
<h1 id="一、开始使用gdb">一、开始使用gdb</h1><h2 id="1-1_启动gdb">1.1 启动gdb</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ gdb program [core|pid]</div><div class="line">➜  ~ gdb --args g++ -O2 -o main main.cpp</div><div class="line">(gdb) shell <span class="built_in">echo</span> <span class="variable">$SHELL</span></div><div class="line">(gdb) <span class="built_in">set</span> logging on</div></pre></td></tr></table></figure>
<p>　　gdb接需要调试的程序可执行文件，后面可以附加core文件或者pid进程号(调试正在运行的进程)，如果有第三个参数gdb总是先尝试解释他为core文件，然后才是进程号。第二种格式采用–args，待调试的程序执行的时候需要额外的参数，此时可执行程序后面的参数不再被gdb解释。<br>　　组合键Ctrl-D或者输入quit可以退出调试状态，如果之前attach到一个进程上面去了，可以用detach命令释放进程，如果quit有表达式那么表达式就作为gdb的退出状态，否则是被调试的子进程的退出状态。gdb中使用Ctrl-C不会终止gdb，而是会终止gdb正在运行的调试指令返回到gdb命令状态。<br>　　在gdb中可以使用shell或者!做前导来执行shell中的命令而不用退出gdb(gdb的退出和重启动的代价是很大的)，make命令可以用来重新编译程序而不用先导shell|!符号，而gdb自动重新加载符号。<br>　　通过set logging on可以打开日志功能，默认会将日志输出追加到当前目录的gdb.txt文件中。</p>
<h2 id="1-2_gdb中的命令">1.2 gdb中的命令</h2><p>　　gdb是很智能的，所有的命令都可以使用TAB、TAB-TAB进行补齐或者提示，不输入任何命令的空换行(在可能的情况下)表示重新执行前一条指令，这节省了重复输入step|list等指令的劳动。gdb允许指令和参数的缩减输入，没有歧义的时候会运行，而在遇到歧义的时候起会提示出各个歧义的命令列表供参考。<br>　　有些命令参数中可能含有特殊的符号(比如括号)，尤其在C++允许函数重载的时候需要使用参数类型来进行区分，此时参数需要使用 ‘ 单引号来包围，而且在需要的时候gdb也会自动帮你包围并给出候选列表的。</p>
<h2 id="1-3_gdb帮助">1.3 gdb帮助</h2><p>　　gdb本身附带了很多帮助命令，比如：<br>　　<strong>help <em>command</em></strong>：显示名的帮助信息<br>　　<strong>apropos <em>args</em></strong>：会在命令名、文档中搜索指定的表达式<br>　　<strong>info <em>args|registers|breakpoints|…</em></strong>：可以显示很多状态信息，具体可以查看help info<br>　　<strong>set <em>var val</em></strong>：设置环境变量<br>　　<strong>show <em>var</em></strong>：显示环境变量的值</p>
<h2 id="1-4_调试执行程序">1.4 调试执行程序</h2><p>　　对于待调试程序编译时候，总应该使用-g选项生成调试信息。<a id="more"></a></p>
<h3 id="1-4-1_启动调试程序">1.4.1 启动调试程序</h3><p>　　<strong>run/r</strong><br>　　必须在gdb启动的时候指定调试文件，或者启动后再使用exec|exec-file指定调试文件。启动的时候gdb会创建子进程(inferior process)并在子进程中立即运行该程序。run命令后面可以接参数，所有的参数都会被传递给可执行程序，而下次调试如果直接run而不添加参数，上一轮的参数会被继承自动添加(下面的start也是一样)。<br>　　除了在调用run/start的时候指定参数，还可以单独调用set args方法设置参数。参数的展开和shell规则一样，而且支持输入输出重定向(比如&gt;aa.txt)，展开后传递给run/start使用。<br>　　<strong>start</strong><br>　　该命令会在程序入口函数的地方(C/C++默认是main)添加一个临时断点，然后程序立即运行并在入口函数的地方被暂停。<br>　　此处还需要注意，C++程序在执行main之前会创建static和全局变量，他们的构造函数会被调用，所以程序入口函数不一定会被最早执行的程序代码。</p>
<h3 id="1-4-2_调试运行的进程">1.4.2 调试运行的进程</h3><p>　　<strong>attach process-id</strong><br>　　可以用来跟踪一个已经在运行的进程，然后被跟踪的进程会暂停执行，然后可以做任何的调试操作，以及continue让程序继续执行。同时，gdb还会在当前工作路径、源代码搜索路径等地方搜索该进程的可执行文件，当然也可以使用file命令手动加载可执行文件。<br>　　<strong>detach</strong><br>　　一旦detach之后程序会继续执行，而且和gdb再无瓜葛了。如果当前有attach的进程而使用Ctrl-D退出gdb，gdb会提示是否要detach调试的进程。<br>　　<strong>kill</strong><br>　　该命令会kill掉当前调试的进程，无论是run/start创建的还是attach调试的。常用情况是修改代码后需要重新调试，此时可以先kill掉当前调试，然后编译出新的可执行程序，再使用run/start开启调试，此时gdb会发现可执行程序已经修改了，会重新读取符号表信息(但是之前的断点等信息还是得以保留的)。</p>
<h3 id="1-4-4_调试多线程程序">1.4.4 调试多线程程序</h3><p>　　线程除了共享地址空间之外，拥有自己独立的寄存器状态、执行栈和线程存储。gdb可以查看跟踪进程的所有线程的状态信息，但是只能有一个线程处于当前被跟踪的状态。<br>　　<strong>info threads [thread-id-list]</strong><br>　　显示所有(或者指定)线程的信息，带星号标识的是当前跟踪的线程。<br>　　<strong>thread thread-id</strong><br>　　切换thread-id线程为当前跟踪线程。<br>　　<strong>thread apply [thread-id-list | all] command</strong><br>　　在所有(或者指定)线程线程上执行command命令。<br>　　<strong>thread name [name]</strong><br>　　设置线程的名字(info threads中会显示)，如果不带参数，会恢复名字为操作系统默认名字。</p>
<h3 id="1-4-5_调试fork创建的多进程程序">1.4.5 调试fork创建的多进程程序</h3><p>　　GDB对fork产生新进程的调试没有特殊的支持，当使用fork产生子进程的时候，GDB会继续调试父进程，子进程不会被阻碍而是继续执行，而此时如果子进程遇到断点后，子进程会收到SIGTRAP信号，当在非调试模式下默认会导致子进程中止。如果要调试子进程，可以让子进程启动后睡眠一段时间(或者监测某个文件是否创建)，在这个空隙中使用ps查看子进程的进程号，然后再启动gdb去attach到这个进程上面去调试。<br>　　通过catch命令可以让gdb在fork/vfork/exec调用的时候暂停执行。<br>　　影响fork多进程调试还有以下几个变量：<br>　　<strong>follow-fork-mode</strong><br>　　可选值是parent或child，指明当正在被调试的进程fork出子进程的时候，如果该值是parent，那么父进程被调试子进程正常执行，这也是默认行为；而当其为child的时候，则新创建的子进程被调试，父进程正常执行。<br>　　<strong>detach-on-fork</strong><br>　　可选值是on或off，知名当被调试的进程fork出子进程后，是否detach某个进程还是调试他们俩，如果是on，那么子进程(或父进程，取决于上面follow-fork-mode的值)将会被detach正常执行，这是默认行为；否则两个进程都会被gdb控制，其中的一个进程被正常调试，另外一个进程被suspend住。<br>　　<strong>follow-exec-mode</strong><br>　　gdb对于exec调用的反应，其值可以为new或same，当值为new的时候，之前fork的子进程和exec后的进程都会被保留；如果是same，则exec的进程使用之前fork的进程，exec会用新的执行镜像替代原先的可执行程序，这是默认行为。</p>
<h3 id="1-4-6_设置书签保存历史状态">1.4.6 设置书签保存历史状态</h3><p>　　gdb可以在程序执行的过程中保留快照(状态)信息，称之为checkpoint，可以在进来返回到该处再次查看当时的信息，比如内存、寄存器以及部分系统状态。通过设置checkpoint，万一调试的过程中错误发生了但是已经跳过了错误发生的地方，就可以快速返回checkpoint再开始调试，而不用重启程序重新来过。<br>　　<strong>checkpoint</strong><br>　　对当前执行状态保存一个快照，gdb会自动产生一个对应的编号供后续标识使用。从提示信息看来，其实每建立一个checkpoint，都会fork出一个子进程，所以每个checkpoint都有一个唯一的进程ID所对应着。<br>　　<strong>info checkpoints</strong><br>　　查看所有的checkpoint，包括进程ID、代码地址和当时的行号或者符号。<br>　　<strong>restart checkpoint-id</strong><br>　　恢复程序状态到checkpoint-id指明的checkpoint，所有的程序变量、寄存器、栈都会被还原到那个状态，同时gdb还会将时钟信息回退到那个点。恢复过程中程序的状态和系统的部分状态是支持的，比如文件指针等信息，但是写入文件的数据、传输到外部设备的数据都无法被回退。<br>　　<strong>delete checkpoint checkpoint-id</strong><br>　　删除指定的checkpoint。<br>　　此外，checkpoint的作用还在于断点、观测点不是什么情况下都可用的情况下，因为Linux系统有时候为了安全考虑，会随机化新进程的地址空间，这样重启调试程序会导致之前使用绝对地址设置的断点、观测点不可用。</p>
<h1 id="二、中断和继续运行">二、中断和继续运行</h1><h2 id="2-1_断点、监视点和捕获点">2.1 断点、监视点和捕获点</h2><p>　　gdb除了普通断点，还支持检测点(watchpoint)、捕获点(catchpoint)两类特殊的断点类型，他们都能使用enable、disable、delete进行管理。检测点会在检测的变量以及使用运算符组合成的表达式的值发生改变的时候暂停程序的执行；catchpoint是在某个事件发生的时候暂停程序的执行，比如C++抛出异常、加载库的时候。</p>
<h3 id="2-1-1_断点">2.1.1 断点</h3><p>　　<strong>break [location]</strong><br>　　location可以是函数名、行号、指令地址，在程序执行到这些指定位置前会暂停下来(暂停时候这些位置的任何代码都不会被执行)。如果没有location参数，则断点会在下一条执行的指令前设置，在最内帧中gdb会在下次执行到该点的时候暂停，这种情况最常见的是在循环中使用。<br>　　<strong>break … if cond</strong><br>　　每次指定到该点的时候会先计算cond的状态，当cond!=0的时候断点生效，程序执行暂停下来。而且在同一个位置，可以使用不同的条件设置多个条件断点。<br>　　<strong>tbreak args</strong><br>　　只生效一次的临时断点，一旦断点生效程序暂定在这个断点处的时候，该断点会被自动删除掉。<br>　　<strong>rbreak regex</strong><br>　　在所有匹配regex正则表达式的函数名处都设置断点，并打印出这些新设置的断点。正则表达式的元字符含义同grep工具的含义(而同shell有所差别)。这在C++设置重载函数断点的时候十分有效。<br>　　<strong>rbreak file:regex</strong><br>　　通过一个文件名的前缀，可以缩小rbreak设置断点的范围(否则库的头文件也会被搜索并设置断点)。<br>　　<strong>info break|breakpoints</strong><br>　　查看断点(同时还包括watchpoint和catchpoint)，同时如果断点被触发了，还会显示触发的次数信息。</p>
<p>　　在一个位置上设置断点，其本质上可以对应于多个位置，比如：同名重载函数、C++合成的多个构造函数、模板函数和模板类、inline函数。对于这种单个断点多个地址的情况，gdb会自动在需要的位置插入断点，当使用info break显示的时候，会以breakpoint-number.location-number的方式显示，断点管理可以引用breakpoint-number，或者针对某个子地址的断点操作。<br>　　动态库也支持断点，不过其地址需要在加载库的时候才能解析，因此动态库中的断点在未能解析地址前都是pend状态，同时动态库在程序执行的过程中也可能进行多次加载和卸载的操作，gdb在只要有动态库加载和卸载操作的时候，都会重新计算断点的位置信息。</p>
<h3 id="2-1-2_监视点">2.1.2 监视点</h3><p>　　监视点是监视特定表达式的值是否改变而触发程序暂停执行，而不用去关心该值到底在代码的哪个位置被修改的。监视的表达式可以是：某个变量的引用、强制地址解析(比如<em>(int </em>)0x12345678，你无法watch一个地址，因为地址是永远也不会改变的)、合理的表达式(比如a-b+c/d，gdb会检测其中引用的各个变量)。<br>　　<strong>watch [-l|-location] expr [thread thread-id] [mask maskvalue]</strong><br>　　thread-id可以设置特定线程改变expr的时候触发中断，默认情况下针对硬件模式的检测点所有的线程都会检测该表达式；-location会让gdb计算expr的表达式，并将计算的结果作为地址，并探测该地址上的值(数据类型由expr计算结果决定)。<br>　　软件模式的检测点作用有限，只能当前单个线程能侦测其变化，虽然该值也可能会被其他线程修改。<br>　　watch命令还存在两个变体：rwatch当expr被程序读的时候触发中断；awatch会在程序读取或者写入expr的时候被中断。watchpoint支持软件模式和硬件模式的检测点，后者效率会比前者高很多，因为如果不支持硬件模式gdb会每次step并计算检测的表达式，x86构架支持硬件模式。rwatch和awatch只支持硬件模式的检测点。<br>　　<strong>info watchpoints</strong><br>　　查看检测点信息，和短线信息输出格式类似。<br>　　当检测点旧监测的变量或者表达式超过了其作用域的时候，gdb会自动删除失效的观测点，所以当跳出变量的作用域后又进入的话，需要重新创建检测点。尤其当调试程序重启的时候，所有局部变量的观测点都会消失，只有全局变量的检测点会保留。</p>
<h3 id="2-1-3_捕获点">2.1.3 捕获点</h3><p>　　可以让gdb在某些事件发生的时候暂停执行，比如C++异常、加载动态链接库以及某些系统调用的时候，其格式为<code bash="">catch event</code>，还有一个变体<code bash="">tcatch event</code>设置临时捕获点，其中event的参数可以为：<br>　　<strong>throw|rethrow|catch [regex]</strong><br>　　在C++异常抛出、重新抛出、捕获的时候触发，可选使用regex参数限定特定的异常类型(在gcc-4.8开始支持)，内置变量<strong>$_exception</strong>会记录在catchpoint激活时候的异常。<br>　　当异常发生时候，程序通常会停留在libstdc++的异常支持点，此时可以通过使用up命令切换帧跳转到用于异常代码处。<br>　　<strong>syscall [name | number | group:groupname | g:groupname] …</strong><br>　　在进入和/或返回系统调用的时候触发。name可以指明catch的系统调用名(定义在/usr/include/asm/unistd.h，且gdb会帮助智能补全)，group|g:groupname可以用来指定一组类别的系统调用，比如g:network，通过智能补全可以查看支持的group信息。<br>　　<strong>exec|fork|vfork</strong><br>　　<strong>load|unload [regex]</strong><br>　　加载和卸载共享库时候触发，可选regex进行过滤。<br>　　<strong>signal [signal… | ‘all’]</strong><br>　　可以在软件收到信号的时候触发。gdb本身会占用SIGTRAP和SIGINT两个信号，如果不添加额外参数，会catch除了这两个信号之外的所有信号。<br>　　使用info break命令，watchpoint的信息会被展示出来，可以像普通断点一样管理之。</p>
<h3 id="2-1-4_断点管理(删除、禁用)">2.1.4 断点管理(删除、禁用)</h3><p>　　<strong>clear</strong><br>在最内栈中，可以用来删除正在被暂停的这个断点。<br>　　<strong>clear location</strong><br>删除指定位置处的断点，可以是func、file:func、linenum、file:linenum。<br>　　<strong>delete [breakpoints] [range…]</strong><br>参数breakpoints可用可不用，可以指明breackpoints、watchpoints、catchpoints的值或者范围来删除它们，他们的编号在同一编号空间中。<br>　　<strong>disable|enable [breakpoints] [range…]</strong><br>禁用|启用某些断点，如果没有指明范围，则是针对所有的断点。<br>　　<strong>enable [breakpoints] once range…</strong><br>临时启用某些断点，一旦这些断点激活，就会被自动disable。<br>　　<strong>enable [breakpoints] count cnt range…</strong><br>　　这种情况下临时使能的断点，会在每次被激活的时候递减cnt计数，当其值为0的时候，会禁用该断点。这个count还有一个好用的方式是和ignore相结合，可以在循环中跳过cnt个循环。<br>　　<strong>enable [breakpoints] delete range…</strong><br>　　临时启用某些断点，一旦这些断点激活，就会被自动delete，跟通过tbreak设置的断点起始状态一样。</p>
<h3 id="2-1-5_条件断点">2.1.5 条件断点</h3><p>　　当指定的cond为true的时候，断点就会被触发，其可以用于普通断点，也可以用于watchpoint(虽然值一旦改变就会触发，但是可以用cond过滤得到感兴趣的值)。条件断点可以具有side-effect，比如其可以调用函数、写入日志、执行命令等操作，副作用是可控的，除非该条件断点上又设置了别的断点，而别的断点使程序暂停此时该cond可能就没有被检查调用。<br>　　普通断点和检测点可以在命令break/watch的时候使用 if关键字指明条件，但是catch不能识别if关键字；其上所有的断点都可以在创建之后使用condition关键字指明条件来创建和删除条件：<br>　　<strong>condition bnum expr</strong>、<strong>condition bnum</strong>：<br>　　创建和删除断点的条件，在expr为true的时候断点才会被触发，后者删除条件后断点就退化成非条件断点了。<br>　　<strong>ignore bnum cnt</strong>：<br>　　让断点可以忽略cnt次后生效，如果是使用continue命令恢复程序的执行，也可以使用<code bash="">continue cnt</code>的方式代替ignore指令。如果一个断点有ignore和condition两种属性，那么在ignore到达0之前是不会检查condition条件的。</p>
<h3 id="2-1-6_断点命令列表">2.1.6 断点命令列表</h3><p>　　<strong>commands [range…]</strong><br>　　<strong>… command-list …</strong><br>　　<strong>end</strong><br>　　通过command-list的方式，可以让断点(breakpoint、watchpoint、catchpoint)在暂停的时候执行一些命令串(比如用来答应表达式或者寄存器的当前值，使能其他断点等)，如果要删除断点的命令串，可以使用commands紧邻着end就可以了。如果没有range参数，该commands默认作用于最后一个创建的断点(或者命令列表，使用rbreak等条件创建的多个断点)。<br>　　在上面说的命令列表中，在执行指定操作后，可以使用标准的命令来恢复程序的执行，比如continue、step等。可以在命令列表的开头使用silent，就不会打印当前断点的额外信息，对于变量等显示，可以使用echo、output、printf等命令来查看，同时还可以使用set命令，让给部分变量赋上正确的值，然后让程序继续执行。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">break</span> 31</div><div class="line">Breakpoint 4 at 0x434c62: file ./<span class="built_in">source</span>/main.cpp, line 31.</div><div class="line">(gdb) commands</div><div class="line">Type commands <span class="keyword">for</span> breakpoint(s) 4, one per line.</div><div class="line">End with a line saying just <span class="string">"end"</span>.</div><div class="line">&gt;silent</div><div class="line">&gt;<span class="built_in">printf</span> <span class="string">"origin port is %d\n"</span>, srv_port</div><div class="line">&gt;<span class="built_in">set</span> srv_port = srv_port + 100</div><div class="line">&gt;cont</div><div class="line">&gt;end</div><div class="line">(gdb) start</div><div class="line">port number is: 8911</div></pre></td></tr></table></figure></p>
<p>　　如果此时使用info b，可以查看当前断点的命令列表的详情:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(gdb) info b</div><div class="line">Num     Type           Disp Enb Address            What</div><div class="line">4       breakpoint     keep y   0x0000000000434c62 <span class="keyword">in</span> main(int, char**) at ./<span class="built_in">source</span>/main.cpp:31</div><div class="line">        breakpoint already hit 1 time</div><div class="line">        silent</div><div class="line">        <span class="built_in">printf</span> <span class="string">"origin port is %d\n"</span>, srv_port</div><div class="line">        <span class="built_in">set</span> srv_port = srv_port + 100</div><div class="line">        cont</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<h3 id="2-1-7_动态打印">2.1.7 动态打印</h3><p>　　上面的printf可以方便的在gdb的终端界面进行打印操作，此外gdb还允许进行打印的灵活配置，该具就是<strong>dprintf</strong>。<br>　　其通过function配置可以随意调用打印函数，而channel配置可以重定向到任何输出流，dprintf的行号可以on-the-fly的任意位置插入打印语句，其格式化输出也是和上面的printf如出一辙。GDB不会检查设置function和channel的合法性，如果非法值会在调试的过程中报错。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">set</span> dprintf-style call</div><div class="line">(gdb) <span class="built_in">set</span> dprintf-function fprintf</div><div class="line">(gdb) <span class="built_in">set</span> dprintf-channel stderr</div><div class="line">(gdb) dprintf 35,<span class="string">"at line 35, the srv_port is%d\n"</span>, srv_port</div><div class="line">D<span class="built_in">printf</span> 1 at 0x434<span class="built_in">cd</span>4: file ./<span class="built_in">source</span>/main.cpp, line 35.</div><div class="line">(gdb) info b</div><div class="line">Num     Type           Disp Enb Address            What</div><div class="line">1       dprintf        keep y   0x0000000000434<span class="built_in">cd</span>4 <span class="keyword">in</span> main(int, char**) at ./<span class="built_in">source</span>/main.cpp:35</div><div class="line">        breakpoint already hit 1 time</div><div class="line">        call (void) fprintf (stdout,<span class="string">"at line 35, the srv_port is%d\n"</span>, srv_port)</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<h3 id="2-1-8_断点保存">2.1.8 断点保存</h3><p>　　<strong>save breakpoints [filename]</strong><br>　　通过上面的命令，可以将所有当前的断点定义和他们的type、commands、ignore counts等信息保存到文件中去，而source命令可以读取这些保存的结果。需要注意的是，对于引用了局部变量的watchpoints很有可能无法重建，因为无法获取当时创建时候的有效上下文信息。<br>　　保存的结果是纯文本文件，其内部实际是一系列的gdb命令列表，可以方便的编译该文件，比如移除不关心的断定定义。</p>
<h2 id="2-2_继续和单步执行">2.2 继续和单步执行</h2><p>　　<strong>continue|c|fg [ignore-count]</strong><br>　　从程序最后停止的位置继续执行，且该位置上的所有断点将会被bypassed。可选的ignore-count和ignore作用相同，该参数只有在当前停止是由于断点触发的时候才有效，否则该参数将会被忽略。<br>　　如果想从别的地方继续程序的执行(而不是当前暂停的位置)，可以选用<strong>return</strong>到函数的调用位置、<strong>jump</strong>到任意位置开始恢复执行。<br>　　<strong>step|s</strong><br>　　继续执行当前的程序直到达到一个新的代码行号后，停止程序并将控制转给GDB。step只会停留在代码行的第一条指令处，如果在当前行中有调用带有调试符号的函数，那么step会继续停留，即step会进入到带符号的函数中去，否则其行为类似于<strong>next</strong>命令而不会进入到函数中去。<br>　　说到这里，需要注意的是step命令只会停留到带有调试符号的代码中，如果在没有调试符号的函数环境中使用step，那么程序会一直执行直到到达一个含有调试信息的函数；否则，需要stepi命令。<br>　　<strong>step <em>count</em></strong><br>　　持续执行count次的step，如果在这之前遇到一个断点或者和step无关的信号，step将会停止。<br>　　<strong>next|n [count]</strong><br>　　在当前(最内层)的stack frame中执行到下一个代码行，和step不同的是代码行中的函数调用将会被直接执行而不会停止。类似的，next也只会在代码行的首个指令处停止执行。<br>　　<strong>finish|fin</strong><br>　　继续执行直到当前选定的stack frame的函数返回，如果可以打印函数的返回值，简言之就是将当前函数执行完。<br>　　和这个命令对应的是<strong>return [expr]</strong>命令，该命令是取消当前函数的后续执行直接返回，并且可选返回一个表达式作为调用结果。<br>　　<strong>until|u</strong><br>　　继续执行直到在当前stack frame中到达超过当前行号的位置，这个在循环中使用的比较多，非循代码下跟next命令比较相似，而且until命令在退出当前stack frame的时候总是会停止程序的执行。需要注意的是，编译器为了效率可能会重排循环代码，有时候until的行为可能会有些诡异。<br>　　<strong>until|u <em>location</em></strong><br>　　相比不带参数的until效率会更高(采用了临时断点方式实现)，会执行程序直到特定位置或者退出当前stack frame，所以只有location是在当前stack frame内部的时候才会到达，location可以是行号、地址等任意类型的位置信息。<br>　　该until命令的另外一个好处，是可以跳过(skip over)递归函数调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">4</span> <span class="function"><span class="keyword">int</span> <span class="title">factorial</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</div><div class="line"><span class="number">5</span>     <span class="keyword">if</span>( value &gt; <span class="number">1</span>)</div><div class="line"><span class="number">6</span>         value *= factorial(value - <span class="number">1</span>);</div><div class="line"><span class="number">7</span>     <span class="keyword">return</span> value;</div><div class="line"><span class="number">8</span> &#125;</div></pre></td></tr></table></figure></p>
<p>　　如果当前执行点在第5行，<code bash="">until 7</code>命令会持续整个递归调用，直到value=120的时候在第7行暂停。<br>　　<strong>advanced <em>location</em></strong><br>　　和until比较类似，但是不会跳过递归调用，同时location的位置也不需要限定在当前的stack frame。<br>　　<strong>stepi/si <em>count</em></strong><br>　　执行一条(count条)机器指令，在使用这种方式调试的时候，建议使用<code bash="">display/i $pc</code>显示机器指令的汇编代码。<br>　　<strong>nexti/ni <em>count</em></strong><br>　　和上面类似，只是在遇到函数调用指令的时候不会跟踪函数调用，会直接等待函数返回。</p>
<h2 id="2-3_跳过函数和代码文件">2.3 跳过函数和代码文件</h2><p>　　有些时候调试中可能对某个函数、某个文件中的所有函数或者特定文件中的特定函数不感兴趣。<br>　　比如：<code cpp="">foo(boring());</code>如果不想调试boring()函数，方法是先step进入boring()，然后使用finish跳出该函数，再继续调试foo()函数。使用<strong>skip</strong>命令可以设置忽略某些函数的调试达到上述的效果。<br>　　<strong>skip function [linespec]</strong><br>　　执行该命令后，linespec指定的函数名或者linespec行号所在的函数将会被跳过。如果没有指定linespec，那么当前正在被调试的函数名将会被作为参数使用。<br>　　<strong>skip file [filename]</strong><br>　　执行该命令后，所有源代码在filename中实现的函数，都会在stepping的过程中被跳过。如果没有指定filename，那么当前调试焦点所在的源代码文件将作为其参数。<br>　　<strong>skip [options]</strong><br>　　是一个基本更灵活的命令(不过测试发现极大发行版的gdb不支持该模式)，通过-file|-function可以得到上面另个子命令相同的效果，而且可以任意组合使用。更强大的是使用-gfile|-rfunction的正则表达式模式，来指定符合正则表达式的文件后者函数名。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) skip -gfile utils/*.cpp</div><div class="line">(gdb) skip -rfu ^std::(allocator|basic_string)&lt;.*&gt;::~?\1 *\(</div></pre></td></tr></table></figure></p>
<p>　　如果没有任何参数，其效果类似于命令<code bash="">skip function</code>。<br>　　<strong>info skip</strong><br>　　<strong>skip enable/disable/delete [range]</strong><br>　　常规的skip管理命令。</p>
<h2 id="2-4_信号">2.4 信号</h2><p>　　信号是操作系统定义在程序中可以异步发生的事件，有些信号是程序正常执行的一部分(比如SIGALRM)，而有些信号预示着错误甚至是致命的(比如SIGSEGV)，通常会终止程序的执行。很多信号如果没有事先设置好处理handler，默认的处理方式是终止该程序的执行。<br>　　GDB可以感知程序中任何信号的发生，可以设置对特定信号的特定处理方式。正常情况下GDB是让非错误的信号(比如SIGALRM)传递到调试的程序，而让错误信号发生的时候停止程序的执行(具体可以使用info signals查看)，可以通过<strong>handle</strong>命令修改特定信号的行为。<br>　　<strong>catch signal [sig…|’all’]</strong><br>　　给对应信号设置catchpoint。<br>　　<strong>handle <em>sig</em> [keywords…]</strong><br>　　修改GDB对信号的默认处理方式，sig参数可以是SIG打头的信号名、low-high的信号值范围、’all’所有信号；keywords可以是下面的关键字<br>　　nostop、stop：当该信号发生的时候gdb是否要停止程序的执行；stop-&gt;print<br>　　print、noprint：当该信号发生的时候是否打印相关信息；noprint-&gt;nostop<br>　　pass|noignore、nopass|ignore：GDB决定是否让你的应用程序看到该信号，即应用程序消费该信号。对于非错误信号的默认模式是nostop|noprint|pass，对于错误信号的模式是stop|print|pass。<br>　　当一个信号停止了程序的执行，被调试的应用程序在continue之前是觉察不到该信号的，在GDB报告一个信号的发生的时候，可以通过handle命令的pass|nopass来设置是否传送该信号，然后继续程序的执行。<br>　　GDB对于调试中的信号处理做了<strong>一定的优化</strong>：<br>　　如果信号是nostop的，此时使用stepi/step/next进行跟踪调试的时候，将会优先执行信号处理函数，在信号处理函数返回后再执行主线调试代码，即会step over信号处理。不过信号处理函数本身也可能有断点等因素导致执行流过早的停止。<br>　　当使用了stop的时候，并且程序设置了对应信号的信号处理函数，此时程序如果因为信号暂停的话，则使用step/stepi/next将会跳入到信号处理函数中去跟踪。</p>
<h2 id="2-5_多线程程序">2.5 多线程程序</h2><p>　　在多线程程序调试中，具有两种工作模式：all-stop和non-stop。</p>
<h3 id="2-5-1_all-stop_mode">2.5.1 all-stop mode</h3><p>　　当进程中任意线程因为某种原因停止执行的时候，所有其他线程也同时被GDB停止执行。好处是程序停止的时候所有线程的状态都被保留下来了，可以切换线程查看整个程序当时的所有状态(缺点是整个业务全部阻塞暂停了)。<br>　　在默认设置下，当恢复程序执行的时候，所有的线程也都会立即执行，即使是使用step/stepi/next这种单步跟踪的模式也是如此。线程的调度是操作系统控制的，即使单步跟踪的时候很有可能其他的线程执行了更多指令后，当前线程才执行完单步指令并停止；还有可能单步跟踪后发现自己停止在了其他的线程上面，因为任何时候任何线程因为断点、信号、异常的时候都会停止程序的执行，并且GDB会自动选定切换到该线程上面去(同时会打印Switching的切换信息)。<br>　　有些操作系统支持OS调度锁定的支持，就可以修改上述GDB的默认行为。<br>　　<strong>schedule-locking</strong><br>　　off：不会锁定，所有线程可以自由运行；<br>　　on：当程序resume的时候，只有当前线程可以运行；<br>　　step：该模式是为单步模式优化的模式，当跟踪的时候阻止其他线程抢占当前线程。当step的时候其他线程无法运行，而在使用continue、until、finish类似指令的时候其他线程可以自由运行。除非其他线程运行时候触发了断点，否则GDB不会切换当前调试的线程。<br>　　<strong>schedule-multiple</strong><br>　　该设置是针对多进程情况下的调试。<br>　　off：只有当前线程所在的进程的所有线程允许恢复执行，该off为默认值。<br>　　on：所有进程的所有线程都可以执行。</p>
<h3 id="2-5-2_non-stop_mode">2.5.2 non-stop mode</h3><p>　　当进程中任意线程停止时，在跟踪检查停止线程的时候其他的线程任然继续执行，其好处就是对线上系统进行最小化的干扰入侵，整个程序还是可以继续响应外部请求的。<br>　　通过下面的设置可以开启non-stop模式，一般都是在gdb开始的时候或者连接调试目标的时候设置才会生效，且在调试过程中不能切换该模式，不是所有平台都支持non-stop模式，所以即使设置了GDB还是有可能fallback到all-stop模式。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">set</span> pagination off</div><div class="line">(gdb) <span class="built_in">set</span> non-stop on</div></pre></td></tr></table></figure></p>
<p>　　non-stop模式的验证也十分的简单，在一个多线程的网络程序中先设置断点，此时发送一个请求那么处理线程会被停止，接下来删除该断点，再次发送一个请求，看该请求是否得到正常响应。如果non-stop正常开启生效的话，此时的info threads会显示其他线程都是running的状态。<br>　　non-stop模式下的命令默认都是针对当前线程的，如果要针对所有线程，通常需要使用-a参数，比如continue -a。</p>
<h3 id="2-5-3_线程相关的断点">2.5.3 线程相关的断点</h3><p>　　<strong>break <em>location</em> thread <em>thread-id</em> [if …]</strong><br>　　在多线程模式下，可以设置线程相关的断点(而不是默认针对所有线程)，其语法类似，只不过需要使用thread关键字指明GDB分配的线程标识符。当线程退出或者gdb在detach的时候，该线程相关联的断点会被自动删除。</p>
<h3 id="2-5-4_中断的系统调用">2.5.4 中断的系统调用</h3><p>　　使用GDB调试多线程程序的时候有一个副作用，就是当线程因为断点或其他因素暂停的时候，其他线程此时如果阻塞在系统调用上，此时的系统调用可能会过早的退出！因为多线程程序调试的时候线程之间需要可能会用信号等手段来通信。<br>　　对此，应当培养良好的系统调用使用习惯，多做系统调用返回值的判断。</p>
<h1 id="三、程序的执行的回放">三、程序的执行的回放</h1><p>　　GDB提供<em>process record and replay target</em>(后面简称R&amp;RT)的功能，可以记录程序的执行过程(execution log)，并在后续时间上进行正向、逆向的程序运行。在调试目标运行的时候，如果接下来的执行指令在log中存在，就会进入replay mode，该模式下不会真正的执行对应的指令，而是将事件、寄存器值、内存值直接从日志中提取出来；如果接下来的执行指令不在log中，GDB将会在record mode执行，所有的指令将会按照正常方式执行，GDB还会记录log方便将来reply。<br>　　进程的R&amp;RT支持正向和逆向执行，即使对应的平台底层调试不支持reverse exec，但是通过reply mode可能模拟这个功能，而record mode可能由于平台的限制不支持reverse exec。<br>　　<strong>record *method</strong><br>　　开启进程的R&amp;RT模式。默认的方法是使用full recording，其实际是GDB采用软件模拟的方式实现的，该模式支持replay reverse exec，不过不支持non-stop mode和异步执行模式的多线程调试。R&amp;RT只能调试正在执行的进程，所以事先需要先使用run|start命令开启调试进程，然后使用record method进行记录。<br>　　<strong>record stop</strong><br>　　停止进程的R&amp;RT，此时所有的log将会被删除，而调试进程将会被终止挥着保持在其最终状态。<br>　　如果是在record模式下(在log的最末尾)使用该命令，被调试的进程将会在下一个要被记录的指令处停止，即如果record了一段时间后停止record，那么调试进程将会保持在类似record从未发生过的状态；如果在replay模式(就是在log的某个中间位置而非末尾)下执行该命令，那么被调试的进程将会在那个点开始进行live正常调试；如果被调试进程退出，或者被detach，那么R&amp;RT将会自动停止。<br>　　<strong>record goto begin|start|end|<em>n</em></strong><br>　　跳转到指定的log位置，除了特殊的begin|start|end，其中的n是log中的instruction的标号。<br>　　<strong>record save|restore <em>filename</em></strong><br>　　log的保存和恢复。如果不指明文件名将会是默认的’gdb_record.process_id’。<br>　　<strong>set record full insn-number-max <em>limit</em>|unlimited</strong><br>　　设置log记录的指令的数目，默认值是200,000。如果设定的limit值是个正数，记录的指令数目超过这个限制后GDB会依次从最先的指令中删除这些旧指令以在不超过这个限制的条件下保存新指令记录，如果其参数值是0或者unlimited，那么久不会有保存数的限制，最终保存的多少将受内存大小的限制。<br>　　<strong>set record full stop-at-limit on|off</strong><br>　　设置在full方式下当保存指令数目超过限制的生活，如果ON(默认)，则GDB会在首次超过限制的生活停止调试进程，并向用户询问是否继续执行下去；如果是OFF，则GDB会自动进行上面删除最旧记录添加最新记录的行为。<br>　　<strong>info record</strong><br>　　显示record记录相关信息，包括当前是Record mode还是Replay mode、最小最大指令记录、当前保存的指令数目、可记录最大条目数限制值等信息。<br>　　<strong>record delete</strong><br>　　当在reply模式下执行该命令的时候，会删除当前所在所在指令之后的所有log记录，即丢失当前指令之后的所有记录，并开始新的record。</p>
<h1 id="四、栈信息检查和回溯">四、栈信息检查和回溯</h1><p>　　由函数调用的原理，一个运行的程序会有多层的stack frame，当被调试程序停止的时候GDB会默认选中当前执行的stack frame(当然后面可以手动选择在各个stack frame之间选择切换)，后续的操作都隐含针对当前选中的stack frame。</p>
<h2 id="4-1_栈结构">4.1 栈结构</h2><p>　　栈帧(stack frame)包含的是传递给函数的参数、函数中的局部变量、已经函数执行的地址(返回地址)信息。当程序最开始执行的时候，只有main函数的一个frame，称其为initial frame或者outermost frame，frame会在函数调用的时候创建并在函数返回的时候删除，当前正在执行的栈称为innermost frame，其地址由frame pointer register寄存器保存，从而可以方便的访问调用参数和局部变量。<br>　　GDB会从innermost开始upward，由0开始对frame进行编号，以方便对特定的stack frame进行引用。<br>　　某些编译器提供某种方法使得编译出来的函数没有stack frame，比如gcc的-fomit-frame-pointer选项，为了就是让那些大量调用的函数节省frame的建立时间，不过其缺点是栈回溯变得困难了。</p>
<h2 id="4-2_Backtrace">4.2 Backtrace</h2><p>　　从当前执行的frame(innermost, 0)开始，沿着其调用者upward的过程。<br>　　<strong>backtrace|bt [n|-n]</strong><br>　　如果没有参数，会打印整个stack，每一行代表一条frame；如果n表示打印innermost n的frame；如果-n表示只打印最outermost n的frame。<br>　　命令info stack是backtrace的别名。<br>　　<strong>backtrace|bt full [n|-n]</strong><br>　　参数和上面的类似，但是还会同时打印每frame的局部变量(调用参数会直接在frame的那一行显示出来)。<br>　　<br>　　在多线程程序的调试中，GDB默认只对当前选中的线程显示backtrace，如果要对其他的线程同样执行类似的跟踪，需要使用前缀的方式<code bash="">thread apply all backtrace</code>才能达到效果，尤其对于调试多线程程序的coredump十分有效。<br>　　backtrace中的函数参数、变量的值可能显示不完美，对于非标量类型的变量会用…显示，而有限变量可能会被优化掉(比如调用的过程中使用寄存器传参)，此时其值会被用’<optimized out="">‘代替。<br>　　默认栈完全回溯会跟踪到main这个outermost层次，如果需要跟踪启动代码，可以设置<code bash="">set backtrace past-main on</code>变量，不过我想一般都用不着这么个层次吧。<br>　　默认情况下backtrace是没有层次限制的(一直顶到main)，通过<code bash="">set backtrace limite n|0|unlimited</code>可以进行设置。</optimized></p>
<h2 id="4-3_选择栈的frame和查看frame">4.3 选择栈的frame和查看frame</h2><p>　　上面说过，很多命令都是隐含针对当前选定的frame操作的。因为GDB对frame都进行了编号，所以既可以用编号进行引用选择，也可以采用相对的up/down操作进行frame的切换。<br>　　<strong>frame|f n</strong><br>　　使用frame编号进行选择，0代表最innermost(当前正在执行)的栈，最大值就是main frame的编号值。<br>　　<strong>frame|f stack-addr</strong><br>　　在stack-addr处选择frame。这通常在frame因为bug被破坏了，导致GDB无法为frame进行编号的生活，以及当程序具有多个stacks并且在他们之间切换的时候。<br>　　<strong>up|down|up-silently|down-silently n</strong><br>　　相对形式的切换frame，参数n默认为1，其值也可以为正数或者负数。</p>
<p>　　<strong>frame|f</strong><br>　　该命令不会切换当前选择的帧，而是简洁的打印当前帧的一些信息。<br>　　<strong>info frame [addr]</strong><br>　　更加详细的打印当前选中frame的信息。<br>　　<strong>info args|locals</strong><br>　　前者打印当前frame的调用参数，后者显示所有可访问的局部变量(包括static或者automatic声明的)。</p>
<h1 id="五、调试与源代码文件">五、调试与源代码文件</h1><h2 id="5-1_打印源代码">5.1 打印源代码</h2><p>　　通过list命令可以显示源代码信息，默认情况下回显示10行源代码，这个设置可以通过变量listsize进行调整。list可以接受0、1、2个参数，使用起来较为的灵活。<br>　　<strong>list location</strong><br>　　该location参数可以是行号，也可以是函数名，表示以该行号为中心或者以该函数开始位置为中心，进行listsize代码行的打印。<br>　　<strong>list +|-</strong><br>　　向前|向后打印刚刚打印代码的位置。<br>　　<strong>list</strong><br>　　这个list会接着打印而不用理会之前的参数。但是+|-的参数会被保留，维持向前、向后的打印顺序。<br>　　**list [first],[last]<br>　　打印指定范围内的代码。</p>
<h2 id="5-2_指定位置信息">5.2 指定位置信息</h2><h3 id="5-2-1_行表示方法">5.2.1 行表示方法</h3><p>　　<strong>-|+offset</strong><br>　　指定位置是相对于当前行的偏移。不过针对不同的命令，current line的含义也有差异，对于list，表示的是最后一次打印的行，对于breakpoint表示的是在当前stack frame执行停止的位置。<br>　　<strong>filename:linenum</strong><br>　　在文件filename的linenum行，如果filename是相对路径名，那么它将会匹配所有的源代码文件。<br>　　<strong>function</strong><br>　　指代的是函数体的开始位置。<br>　　<strong>function:label</strong><br>　　在function中出现的label。<br>　　<strong>filename:function</strong><br>　　在文件filename中出现的函数体的开始位置，指明文件名主要是用于消除函数的二义性。<br>　　<strong>label</strong><br>　　在当前stack frame的label标签指定的位置，如果没有当前stack frame的环境(比如被调试的进程还没有运行)，则GDB不会去搜索label。</p>
<h3 id="5-2-2_显式的位置表示">5.2.2 显式的位置表示</h3><p>　　允许用户采用key=value的方式指明参数名和参数值，这种使用方法在函数、label、文件等具有相同名字的时候具有很大的区分性，同时准确的位置信息也会让GDB更快的定位目标。<br>　　<strong>-source filename</strong><br>　　通常单独的source没有意义，它是和下面的function、line等结合使用的。为了消除可能的文件名歧义，建议对于常用的文件名增加一些额外的路径前缀。<br>　　<strong>-function function</strong><br>　　<strong>-label label</strong><br>　　<strong>-line number</strong><br>　　这里的line既可以是绝对的行号，也可以是相对的(+|-3)行号位置。比如<code bash="">break -s main.c -li 3</code>。</p>
<h3 id="3-2-3_地址信息位置表示">3.2.3 地址信息位置表示</h3><p>　　通常的地址信息会使用<code bash=""><em>addr</em></code>的形式来表示。<br>　　<strong>expression</strong><br>　　<strong>funcaddr</strong><br>　　<em>*’filename’:funcaddr</em></p>
<h2 id="5-3_修改源代码">5.3 修改源代码</h2><p>　　<strong>edit</strong>命令可以修改源代码文件，其编辑的位置是在调用edit命令时候，调试程序中当前活动的那一行。可以通过给edit命令额外的参数确定位置：number 当前活动文件的行号，function 函数定义的开始位置。<br>　　EDITOR环境变量可以指定修改源代码所使用的编辑器名字，因此通过设置<code bash="">export EDITOR=vim</code>就可以完成默认编辑器的设定。<br>　　打印完是不是可以直接shell make编译啦！</p>
<h2 id="5-4_源代码和机器码的对应及反汇编">5.4 源代码和机器码的对应及反汇编</h2><p>　　通过info line可以建立源代码行号和程序地址之前的对应关系，而disassemble可以显示一段地址中机器指令。GDB还有一个变量’disassemble-next-line’，当打开他的时候会在程序停止的时候自动显示要执行的下一行源代码的第一条汇编代码，而如果下一条执行的指令没有调试信息，就会显示下一条机器指令的反汇编结果。<br>　　<strong>info line <em>location</em></strong><br>　　打印locatin代表的源代码行编译后的其实地址和结束地址。当然也可以进行反方向的隐射查询，通过地址查询其对应源代码的那一行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(gdb) info line 14</div><div class="line">Line 14 of <span class="string">"aa.cpp"</span> starts at address 0x4008d9 &lt;main(int, char**)+47&gt; and ends at 0x4008e2 &lt;main(int, char**)+56&gt;.</div><div class="line">(gdb) info line *0x4008e0</div><div class="line">Line 14 of <span class="string">"aa.cpp"</span> starts at address 0x4008d9 &lt;main(int, char**)+47&gt; and ends at 0x4008e2 &lt;main(int, char**)+56&gt;.</div></pre></td></tr></table></figure></p>
<p>　　<strong>disassemble [/m|/s|/r] [start, end]|[start, +len]</strong><br>　　<strong>disassemble [/m|/s|/r] <em>location</em></strong><br>　　可以显示一段地址范围的反汇编信息，或者函数名等其他代表的地址信息的反汇编结果，如果是跨文件的记住使用<code bash="">disassemble ‘foo.c’::bar</code>这样的形式。/m或者/s参数可以显示源代码和反汇编代码同时交叉显示的效果，/r还会以hex的方式显示机器码，当然这对一般人来说使用较少。<br>　　<strong>set disassembly-flavor intel|att</strong><br>　　反汇编是显示intel还是att的风格，个人比较偏向att的格式，这也是GDB的默认行为。</p>
<h1 id="六、查看数据">六、查看数据　　</h1><p>　　最常用的检查数据的命令就是<strong>print|p|inspect</strong>，其接受一个表达式作为参数，会根据调试的语言对表达式进行求值，并将其结果打印出来。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">print</span> expr</div></pre></td></tr></table></figure></p>
<p>　　一种更加底层检查数据的方式是使用<strong>x</strong>命令，该命令会检查内存中特定地址的数据并通过特定的格式显示出来。<br>　　如果想知道表达式的类型而不是关系其值的话，可以使用<strong>ptype <em>expr</em></strong>命令，就可以显示出struct、class等复杂变量的类型信息。</p>
<h2 id="6-1_表达式">6.1 表达式</h2><p>　　GDB的表达式可以支持普通表达式、条件表达式、函数调用、类型转换、字符串常量、宏等类型，同时使用’{elem1, elem2, …}’这种表达式还可以创数组常量。<br>　　<strong>@</strong> 该操作符用于将一段内存当做数组使用<br>　　<strong>::</strong> 该曹组福用于指明在文件或者函数中的变量<br>　　<strong>{type} addr</strong> addr可以是一个整形或者指针，该表达式用于将指定位置的内存引用为type类型的变量。</p>
<h2 id="6-2_二义性的表达式">6.2 二义性的表达式</h2><p>　　由于重载和模板机制，在C++这类语言中二义性的表达式非常常见，在这种情况下通常需要给出函数的参数签名’function(types)’等信息才能和其他同名对象进行区分。GDB会自动探测二义性的存在，给出所有可能性的选择列表，并最终给出’&gt;’提示符信息让用户选择，固定的选项是’[0] cancel’和’[1] all’，后面的选项是各个明细，比如<code bash="">break String::after</code>这样的命令，用空格分割的选项才会打上断点。<br>　　<strong>set multiple-symbols all|ask|cancel</strong><br>　　默认参数值是all，当某个命令的表达式有多个选项的时候，GDB会自动选择所有可能的选项，但是某些环境下必须有一个选项的时候，GDB会显示出上面所述的菜单供选择；ask表示只要二义性检测到了，就会给出菜单让做出选择；cancel表示当debuger探测到二义性的时候会当做错误，相应的命令被放弃执行。</p>
<h2 id="6-3_程序变量">6.3 程序变量</h2><p>　　程序的变量算是最常被在表达式中使用的，变量是在当前选择的stack frame中可见的，他们可以是：全局变量、file-static变量、根据变成语言语法规则可见的变量。这里有一个例外，就是你可以引用file-scope的变量或者函数，即使当前执行的上下文不在该文件当中。<br>　　各个函数中的变量，以及各个文件中的函数或者变量可能会出现重名的情况，这个时候就需要’::’操作符进行指定<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">file::variable  file::<span class="keyword">function</span></div><div class="line"><span class="keyword">function</span>::variable</div><div class="line">(gdb) p <span class="string">'aa.cpp'</span>::main::b</div></pre></td></tr></table></figure></p>
<p>　　在调试的时候，有时候会出现在函数进入作用域和返回的生活，某些局部变量的值是错误的，尤其是当进行机器指令单步的时候，因为很多机器上stack frame的建立(包括局部变量的定义)和函数返回的时候stack frame的销毁，都不是单个机器指令可以解决的，所以在stack frame完全建立和销毁的时候，检查到的变量值很可能是异常的。<br>　　一些没有被使用的变量也可能被编译器优化掉，这时候价差这些变量的值可以提示他们不存在。</p>
<h2 id="6-4_人工数组">6.4 人工数组</h2><p>　　通常用于需要打印内存中连续对象的时候以及变长数组的时候特别的有用，其语法结构是<code bash="">*addr@len</code>，在@的左边是目标数组的第一个元素，右边的操作数是数组的期望长度，所得到的结果是一个元素跟左操作数类型一样的数组。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *arry = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(len * <span class="keyword">sizeof</span> (<span class="keyword">int</span>));</div><div class="line">p *arry@len</div></pre></td></tr></table></figure></p>
<p>　　另外一种创建人工数组的方式是使用cast类型转换，将一个值重新使用数组去解释，比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(gdb) p/x (short[4])0x123456789AL</div><div class="line"><span class="variable">$4</span> = &#123;0x789a, 0x3456, 0x12, 0x0&#125;</div><div class="line">(gdb) p/x (short[])0x123456789AL</div><div class="line"><span class="variable">$5</span> = &#123;0x789a, 0x3456, 0x12, 0x0&#125;</div></pre></td></tr></table></figure></p>
<p>　　当然如果你不设置数组的长度，而直接使用<code bash="">(type[])value</code>，那么GDB会自动计算数组的长度<code bash="">sizeof(value)/sizeof(type)</code>。<br>　　有时候人工数组也不见得方便，比如存储的元素是有规律的但是在物理上不是连续的，那么上面的方法就没法使用了，这个时候最常用的是用convenience变量，然后直接用RET依次遍历元素：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> <span class="variable">$i</span> = 0</div><div class="line">p dtab[<span class="variable">$i</span>++]-&gt;fv</div><div class="line">RET</div><div class="line">RET...</div></pre></td></tr></table></figure></p>
<h2 id="6-5_输出格式">6.5 输出格式</h2><p>　　print默认是根据表达式的类型自动显示的，在大多数情况下都可以工作的很好，但是在print中可以指定输出格式得到个性化得显示结果。下面的格式参数通过/和print命令相连，比如<code bash="">print/x $pc</code><br>　　x 把表达式当做一个int，并使用hex方式显示该整数<br>　　d|u 作为有符号|无符号十进制整数打印<br>　　o|t 作为八进制|二进制数打印<br>　　a 在打印地址的时候，通过最近符号加偏移的方式解析这个地址，和info symbol得到的结果类似<br>　　c 以十进制和字符的方式显示<br>　　f 以浮点数的形式打印<br>　　s 如果可以以字符串的方式显示。如果只想的目标是单字节的数据，则表示为null结尾的字符串；如果是单字节的数组，则表示为定长度的字符串；其他情况正常方式显示<br>　　z 类似x以十六进制显示数据，但是头部的字符会使用0补齐</p>
<h2 id="6-6_内存检查">6.6 内存检查</h2><p>　　通过命令’x’可以进行内存数据检查。其命名格式为(nfu是控制内存显示的大小、格式等参数信息的)<br>　　<code bash="">x /nfu addr</code><br>　　<strong>n</strong>(显示数目) 默认值是1，指明需要单位内存(u指明)显示的数目。如果n的值是负数，那么将会从addr开始进行反方向的内存显示。<br>　　<strong>f</strong>(显示格式) 显示的格式参数和上面print命令的输出格式相类似(包括：x、d、u、o、t、a、c、f、s)，初次还包括i用于机器指令的显示。默认情况下是使用x进行hex显示，该值会随着x|print命令的操作而更新。<br>　　<strong>u</strong> 显示单位尺寸 b(bytes，1字节)、h(半字，2字节)、w(字，4字节)、g(gaint字，8字节)，同样该参数会随着每次使用x被自动记住并在下次命令中自动应用。对于i显示机器指令该参数会被忽略，而对于s该参数默认是b。<br>　　由于<strong>f</strong>和<strong>u</strong>两个格式参数的空间是不重叠的，所以可以以任意顺序显示，但是n必须在他俩之前。<br>　　<strong><em>addr</em></strong> 指定需要检查的起始地址位置，比如函数名等，其最终会被解析成一个整形的地址值。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) x/20i main</div><div class="line">(gdb) x/4xw <span class="variable">$sp</span></div></pre></td></tr></table></figure></p>
<h2 id="6-7_自动显示">6.7 自动显示</h2><p>　　对于需要经常查看的表达式，可以使用display命令将其添加到自动显示列表中，这样每次程序停止执行的时候，就会自动显示该表达式的值，加入的表达式会自动产生一个递增的整形编号。display也可以使用print|x命令的参数进行格式化输出控制，而且其内部如果发现格式化参数包含i|s或者数字，就会调用x；否则会调用print进行输出。<br>　　<strong>display[/fmt] expr</strong><br>　　<strong>display/fmt addr</strong> 使用’i’、’s’格式，或者指定了数字<br>　　将表达式或者要检查的内存地址添加到自动显示列表中去。<br>　　比如想要自动显示下一条要执行的指令，可以做如下添加：<code bash="">display/i $pc</code>。<br>　　<strong>undisplay dnums…</strong><br>　　将对应编号的表达式或者内存从自动显示列表中删除。列表可以使用逗号’,’进行分割，以及使用2-4这种范围表示。<br>　　<strong>info display</strong><br>　　<strong>enable|disable display dnums…</strong><br>　　查看、禁用或者使能自动显示。<br>　　<strong>display</strong><br>　　进行自动显示列表中表达式值的显示，就像程序刚停止时候自动显示的效果相同。<br>　　如果添加自动显示的表达式引用到了局部变量，GDB会自动考虑其上下文信息，如果执行的上下文中该局部变量没有定义则不会显示其值，而如果下次再次进入定义该变量的上下文，则该表达式变得有意义会再次显示其值。无论如何，info display总会显示该表达式的相关信息。</p>
<h2 id="6-8_数值历史(Value_History)">6.8 数值历史(Value History)</h2><p>　　通过使用print命令显示的值会被自动保存在GDB的数值历史当中，该值会一直被保留直到符号表被重新读取或者放弃的时候(比如使用file或symbol-file)，此时所有的值历史将会被丢弃。在使用print打印值的时候，会将值编以整形的历史编号，然后可以使用<strong>$num</strong>的方式方便的引用，单个的<strong>$</strong>表示最近的数值历史，而<strong>$$</strong>表示第二新的数值历史，<strong>$$n</strong>表示倒数第n新的数值历史(所以可以推断<code bash="">$$0==$; $$1==$$;</code>)。<br>　　比如刚刚打印了一个指向结构体的指针，那么<code bash="">print <em>$</em></code>就可以显示结构体的信息，而命令<code bash="">print $.nex</code>甚至可以显示结构体中的某些字段。</p>
<h2 id="6-9_Convenience变量">6.9 Convenience变量</h2><p>　　GDB允许自由创建便捷变量用于保存值，后续可以方便的引用该值，该类型的变量由GDB管理而与正在调试的程序没有直接的关联。便捷变量也是使用符号<strong>$</strong>打头的，可以使用任意名字(除了GDB使用的寄存器名)。<br>　　在任意时候使用一个便捷变量都会创建他，如果没有提供初始化值那么该变量就是void，直到给其进行赋值操作为止。便捷变量没有固定的类型，可以为普通变量、数组、结构体等，而且其类型可以在赋值过程中改变(为当前值的类型)。<br>　　<strong>show convenience|conv</strong><br>　　显示道目前所有的便捷变量和便捷函数，以及其值。<br>　　<strong>init-if-undefined $variable = expr</strong><br>　　如果该变量还没有被创建或初始化，则创建这个变量。如果该变量已经被创建了，则不会创建和初始化该变量，并且expr表达式也不会被求值，所以这种情况下也不会有expr的副作用发生。<br>　　便捷变量的一种经典用法，就是之前提到的连续查看变量时候用于计数作用：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> <span class="variable">$i</span> = 0</div><div class="line"><span class="built_in">print</span> bar[<span class="variable">$i</span>++]-&gt;contents</div></pre></td></tr></table></figure></p>
<p>　　下面的一些便捷变量是GDB自动创建的：<br>　　<strong>$_exitcode</strong><br>　　当调试程序终止的时候，GDB将会根据程序的退出值自动设置该变量，并且将<strong>$_exitsignal</strong>变量设置为void。<br>　　<strong>$_exitsignal</strong><br>　　当调试中的程序因为一个未捕获信号而终止，此时GDB会自动将变量<strong>$_exitsignal</strong>设置为该信号，同时重置变量<strong>$_exitcode</strong>为void。</p>
<h2 id="6-10_Convenience函数">6.10 Convenience函数</h2><p>　　便捷函数和便捷变量一样使用<strong>$</strong>打头引用，其可以像一个普通函数一样在表达式中使用，便捷函数只被GDB内部使用。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> <span class="variable">$_isvoid</span> (<span class="variable">$_exitsignal</span>)</div></pre></td></tr></table></figure></p>
<p>　　<strong>$_isvoid (expr)</strong><br>　　如果expr是void则返回1，否则返回0。<br>　　GDB还有很多的便捷函数支持，但是需要在编译GDB的时候提供Python的支持才可以使用。下面的这些函数意义显而易见，就不在啰嗦了。<br>　　<strong>$_memeq</strong>(buf1, buf2, length); <strong>$_regex</strong>(str, regex); <strong>$_streq</strong>(str1, str2); <strong>$_strlen</strong>(str)</p>
<h2 id="6-11_寄存器">6.11 寄存器</h2><p>GDB可以像普通变量一样引用机器的寄存器值，通过<strong>$</strong>打头。<br>　　<strong>info registers</strong><br>　　<strong>info all-registers</strong><br>显示机器所有寄存器的名字和其当前值信息。后者比前者会多出浮点寄存器和向量寄存器。</p>
<h2 id="6-12_操作系统信息">6.12 操作系统信息</h2><p>通过直接的info os可以显示出GDB支持的操作系统信息类别。<br>　　<strong>info os infotype</strong><br>　　files 列出目标上面打开的文件信息。<br>　　modules 列出目标上加载的内核模块信息。<br>　　msg 列出目标上所有的Sys V消息队列信息。<br>　　processes 列出目标上所有的进程信息。<br>　　semaphores 列出目标上所有Sys V信号量信息。<br>　　shm 列出目标上所有Sys V共享内存信息。<br>　　sockets 列出目标上所有Internet-domain socket信息。<br>　　threads 列出目标上所有线程信息。</p>
<h2 id="6-13_内存和文件拷贝">6.13 内存和文件拷贝</h2><p>　　通过dump、append、restore命令可以在目标机之间传递数据和内存信息。dump命令和append命令将数据写入(追加)到文件中，而restore会读取文件内容并将其加载到调试进程的指定内存位置中。GDB默认使用binary的文件格式，推荐使用该格式。<br>　　<strong>dump|append memory <em>filename</em> <em>start_addr</em> <em>end_addr</em></strong><br>　　<strong>dump|append value <em>filename</em> <em>expr</em></strong><br>　　<strong>restore <em>filename</em> binary <em>bias</em> <em>start</em> <em>end</em></strong><br>　　其中一个比较重要的参数是bias，如果其值为非0，那么这个值将会作为偏移添加到文件中所有地址值上面。因为二进制文件总是从地址0开始，所以在恢复的时候需要添加这个偏移值。</p>
<h2 id="6-14_产生core文件">6.14 产生core文件</h2><p>　　core文件是运行进程的内存镜像和运行状态信息(比如寄存器等)的集合。通过配置，操作系统可以在程序挂掉的时候自动产生coredump文件，而在GDB调试的时候，也支持使用命令方式手动创建coredump文件，这样就可以快速创建一个程序在当时的快照。<br>　　<strong>generate-core-file|gcore [file]</strong><br>　　如果没有提供名字，那么默认将产生core.pid文件名格式的dump文件。</p>
<h2 id="6-15_内存查找">6.15 内存查找</h2><p>　　使用命令find可以对内存进行序列字节的查找操作。<br>　　<strong>find [/sn] start_addr, +len, val1 [, val2, …]</strong><br>　　<strong>find [/sn] start_addr, end_addr, val1 [, val2, …]</strong><br>　　该命令会在内存中搜索var1、var2…字符序，其范围从start_addr开始，以结束地址或者长度结束。<br>　　参数s表示搜索的大小，可以是b、h、w、g(跟之前的x命令一样)，如果该参数没有指定，GDB会考虑当前调试程序的语言环境确定，比如0x43这种整数就默认为w(4字节)类型；n表示打印最大搜索命中数量，默认行为是全部打印。该命令还可以搜索字符串，字符串使用双引号括住。<br>　　对于查找结果，命中数目保存在变量<strong>$numfound</strong>中，而最后一个值命令的地址保存在<strong>$_</strong>中。</p>
<h1 id="七、跟踪点(Tracepoint)">七、跟踪点(Tracepoint)</h1><p>　　有些情况不适合把线上的业务停下来，进行长时间的跟踪和调试；还有些行为只有在线上实时运行的环境才能重现，延时或者线下环境无法复现的问题，针对这种类型的情况，需要不打断程序的运行去观察程序的行为。<br>　　通过GDB的<strong>trace</strong>和<strong>collect</strong>命令，可以在程序中设置跟踪点，然后在跟踪点到达(命中hit)的时候计算事先构造的表达式的值；接下来，通过<strong>tfind</strong>命令，可以检查这些跟踪点中表达式在当时所记录下来的值。当前跟踪点的功能值在remote target的情况下支持，该功能是在remote stub中实现的，但是当前情况下的GDB还没有实现，目前主要使用的方式是使用文件的方式操作。</p>
<h2 id="7-1_设置跟踪点">7.1 设置跟踪点</h2><p>　　跟踪点实际上是一种特殊的断点，所以可以使用任何标准断点的命令来操作跟踪点，和断点不同的是不支持ignore count、不支持针对特定于线程的跟踪点。对于每一个跟踪点，可以事先指明到达的时候所需要搜集的数据，包括寄存器、局部变量和全局变量，之后可以使用GDB的命令来检查这些在当时收集到的数据值。<br>　　跟踪点是动态跟踪工具，意味着这些跟踪点可以被插入在目标的任何位置。<br>　　静态跟踪点暂且不表。</p>
<h3 id="7-1-1_创建和删除跟踪点">7.1.1 创建和删除跟踪点</h3><p>　　<strong>trace location</strong><br>　　**其中的location可以是和break命令参数一样的任意有效位置，通过trace命令可以创建一个跟踪点，当debuger遇到的时候会暂停，收集完相应地数据后继续执行。GDB还支持pending tracepoint，类似于断点的原理，表示在一些共享库还没有加载的时候地址无法解析。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">trace foo.c:121 trace *0x12322 trace +2</div><div class="line">trace my_<span class="keyword">function</span> //函数的第一行</div><div class="line">trace *my_<span class="keyword">function</span> //函数的准确起始地址</div></pre></td></tr></table></figure></p>
<p>　　<strong>trace location if <em>cond</em><br>　　带有条件的，只有当cond取值为true(非零)的时候，才会进行数据的收集，避免每次到达跟踪点都收集数据导致数据量暴增，而往往很多情况下的数据是没有价值的。<br>　　条件跟踪点既可以在创建的时候使用if进行限定，也可以后续使用类似breakpoint情况下的condition命令进行设定修改。和断点不同的是，GDB不会自己去对条件表达式进行取值，而是将该表达式编码给agent(独立于GDB)。
　　</strong>delete tracepoint [num]<strong><br>　　永久性地删除一个或者所有(不带参数)的跟踪点。
　　</strong>disable|enable tracepoint [num]<strong><br>　　禁用|使能某个或者所有的跟踪点。
　　</strong>info tracepoints [num…]**<br>　　显示某个或者全部跟踪点的信息，使用方法和info breakpoints相同。</p>
<h3 id="7-1-2_跟踪点计数">7.1.2 跟踪点计数</h3><p>　　<strong>passcount [n [num]]</strong><br>　　passcount是一种自动停止trace experiment的方式，当tracepoint被命中n次之后trace experiment会自动停止。<br>　　当使用passcount带有n但是不带num参数的时候，n将会作用于最近添加的跟踪点。如果不适用passcount进行设定，默认行为跟踪点将会一直运行直到被用户显式地停止。</p>
<h3 id="7-1-3_跟踪状态变量">7.1.3 跟踪状态变量</h3><p>　　trace state variable是一种特殊类型的变量，它是在target-side创建和管理的(但是对GDB可见)，和GDB的convenience变量语法相同，必须采用tvariable命令显式创建，并且总是64位的整形。<br>　　虽然trace state variable是被target端管理的，但是可以在GDB中像使用convenience variable一样使用它们，GDB会在trace experiment运行的时候从target端获取该变量的当前值。该变量也是使用符号<strong>$</strong>打头的，和GDB其他变量在同一个名字空间中，所以需要注意不能重名。<br>　　<strong>tvariable $name [ = expr]</strong><br>　　创建名为<strong>$name</strong>的trace state variable，并且可选地给其一个初始值。初始值得表达式expr是在该变量创建的时候就进行取值的，得到的结果将会转换成64位整形类型。后续再使用tvariable接上已经存在的变量名的时候，实际不会进行创建操作，而是将之前的变量进行重新赋值。如果没有提供初始值，默认初始值是0。<br>　　<strong>info tvariable
　　</strong>delete tvariable [ $name … ]**<br>　　如果没有提供额外参数，将会删除所有的变量。</p>
<h3 id="7-1-4_跟踪点行为列表">7.1.4 跟踪点行为列表</h3><p>　　<strong>actions [num]</strong><br>　　用于指明在跟踪点被命中的时候所需要执行的操作，如果没有提供num参数，那么该设置默认针对于最新创建的跟踪点。<br>　　这些行为列表中的命令一行一个，通过单个end标示着结束，当前所支持的行为包括collect、teval和while-stepping，其实使用起来跟command命令十分的类似，只不过其命令的内容只能是上面允许的，而不能是其他的GDB调试命令。要想删除跟踪点的actions，则提供空的end就可以了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">(gdb) trace sum</div><div class="line">Tracepoint 1 at 0x4008a4: file aa.cpp, line 5.</div><div class="line">(gdb) actions</div><div class="line">Enter actions <span class="keyword">for</span> tracepoint 1, one per line.</div><div class="line">End with a line saying just <span class="string">"end"</span>.</div><div class="line">&gt;collect a, b</div><div class="line">&gt;collect <span class="variable">$regs</span></div><div class="line">&gt;<span class="keyword">while</span>-stepping 4  <span class="comment">#single step 4 times, collect data</span></div><div class="line"> &gt;collect c</div><div class="line"> &gt;end</div><div class="line">&gt;end</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<p>　　<strong>collect [/mods] expr1, expr2, …</strong><br>　　收集用逗号分隔的各个表达式的值。收集的对象除了全局变量、静态变量、局部变量，还可以包含：<br>　　<strong>$regs</strong> 所有的寄存器<br>　　<strong>$args</strong> 函数的所有调用参数<br>　　<strong>$locals</strong> 所有局部变量<br>　　<strong>$_ret</strong> 函数的返回地址<br>　　<strong>teval expr1, expr2, …</strong><br>　　当跟踪点被命中的生活，计算表达式的值，该命令接收使用逗号风格的多个表达式。取值表达式的结果将会被丢弃，所以该命令的主要用处是在不添加这些值在trace buffer的同时，将表达式计算并赋值给trace state variable。<br>　　<strong>while-stepping n</strong><br>　　在跟踪点之后进行n步的单步调试，并且在每次单步执行后进行数据的搜集，需要收集的数据在while-stepping后使用collect表示，并使用end结尾。<br>　　<strong>set default-collect expr1, expr2</strong><br>　　该变量可以是使用逗号分隔的一大串表达式表明默认需要收集的值，表明在每个跟踪点默认都要搜集的数据。注意的是这个表达式是在每个跟踪点独立解析的，所以相同的表达式、名字在各个跟踪点可能被解析为不同对象。</p>
<h3 id="7-1-5_开始和停止跟踪执行">7.1.5 开始和停止跟踪执行</h3><p>　　<strong>tstart</strong><br>　　该命令启动trace experiment并且开始搜集数据，该命令的副作用是丢弃所有在trace buffer中的已经存在的历史数据。如果给该命令提供了参数，他们将会被视为note并被存储起来。<br>　　<strong>tstop</strong><br>　　该命令会停止trace experiment，如果<strong>某个跟踪点</strong>已经达到其passcount，或者trace buffer的缓冲区已经满了，那么trace experiment会自动停止。如果给该命令提供了参数，他们将会被视为note并被存储起来。<br>　　<strong>tstatus</strong><br>　　用于显示跟踪和收集到的数据信息。</p>
<h3 id="7-1-6_Tracepoints的限制">7.1.6 Tracepoints的限制</h3><p>　　因为收集数据的行为是在target自动进行的，所以GDB无法做出细致的控制，而且后续检查数据的时候也仅基于已经收集到的历史数据。<br>　　(1) 因为跟踪点的首要目标是收集作值，所以GDB的复杂表达式往往是不可用的。在收集的过程中不能调用函数、进行类型转换、访问convenience变量、修改变量值等操作。</p>
<h2 id="7-2_使用跟踪记录的数据调试">7.2 使用跟踪记录的数据调试</h2><p>　　当trace experiment结束后，可以使用GDB命令来查看已经收集到的数据，这些收集的数据都是每次命令跟踪点收集到数据的快照。所有GDB的命令(比如print、info registors、backtrace等)的请求，都会像当时跟踪点命中时候的状态值进行对应返回，而请求那些没有收集到的数据将会失败。</p>
<h2 id="7-2-1_tfind">7.2.1 tfind</h2><p>　　通过使用命令<strong>tfind <em>n</em></strong>可以查看缓冲区中第n个快照，缓冲区中的快照都是从0开始编号的，如果tfind你没有接参数，将会依次访问下一个快照。<br> 　　<strong>tfind start</strong><br> 　　<strong>tfind none|stop</strong><br> 　　<strong>tfind -</strong><br> 　　<strong>tfind tracepoint num</strong><br> 　　<strong>tfind pc addr</strong><br> 　　<strong>tfind line [file:]n</strong></p>
<h2 id="7-2-2_tdump">7.2.2 tdump</h2><p>　　该命令不接受任何参数，其用于打印当前trace snapshot所收集到的所有数据。tdump通过扫描跟踪点的当前收集行为，然后按照其行为打印对应每个表达式的值。</p>
<h2 id="7-3_使用Trace_Files">7.3 使用Trace Files</h2><p>　　可以将线上收集到的数据保存到文件当中，后续可以通过target tfile进行加载，就像使用原始的trace数据一样访问。<br>　　<strong>tsave [-r] filename</strong><br>　　默认的情况下该命令保存在host的文件系统中，所以GDB将会从target上面拷贝对应的数据到本地保存。如果target支持的话，可以通过’-r’参数，直接将数据保存在target的文件系统上面，这样在收集到的数据量很大的时候会更加的高效。<br>　　<strong>target tfile filename</strong><br>　　加载tfile数据，使后面可以感觉和target在线访问的效果，只不过只能访问历史数据而不能进行任何新的trace experiment。</p>
<h1 id="八、GDB对编程语言的支持">八、GDB对编程语言的支持</h1><h2 id="8-1_GDB对C/C++语言的支持">8.1 GDB对C/C++语言的支持</h2><h3 id="8-1-1_GDB对C/C++语言的支持">8.1.1 GDB对C/C++语言的支持</h3><p>　　因为总所周知的原因，GCC和GDB对C/C++的支持一直很不错，包括在gdb命令行中的表达式、操作符的使用就可见一斑了。C++要比C复杂的多，所以下面罗列了一些GDB和C++调试的一些东西。<br>　　C++成员函数的调用是支持的，形如:<code cpp="">count = aml-&gt;GetOriginal(x, y);</code>；<br>　　当成员函数正在被调试(作为选中的stack frame)的时候，调试的表达式具有和成员函数一样的名字空间；<br>　　在某种程度上支持C++重载函数的调用，GDB会进行解析并指向正确的函数调用。但是限制是：GDB不支持用户定义类型转换所支撑的函数重载，以及调用不纯在的构造函数，没有对应类型实例化的模板函数，也不能处理省略的和默认的函数参数。对于数值类型转换、类型提升都是正常支持的。函数重载默认是使能的，除非使用<code bash="">set overload-resolution off</code>关闭之，然后就可以显式调用重载版本的重载函数了：<code bash="">p’foo(char,int)’(‘x’,13)，自然GDB的补全功能不会让你输的很累的。<br>　　GDB支持C++的::名字解析操作符，正如同函数代码中使用方式一样。</code></p>
<h3 id="8-1-2_针对C++的其他GDB特性">8.1.2 针对C++的其他GDB特性</h3><p>　　针对C++的重载特性，GDB可以自动补全所有的重载版本列表，方便识别和选择；<strong>rbreak <em>regex</em></strong>这种正则形式的断点，可以在所有重载版本的函数上实现添加。<br>　　<strong>catch throw|rethrow|catch</strong> 可以提供C++异常处理的监测支持。<br>　　<strong>ptype <em>typename</em></strong> 可以显示该类型的继承关系，同时其成员变量和成员函数也显示的较为详细。<br>　　<strong>info vtbl <em>expr</em></strong> 对多态机制虚函数表的支持。</p>
<h2 id="8-2_C语言预处理宏">8.2 C语言预处理宏</h2><p>　　宏本身是个比较麻烦的东西，因为可以某些点定义、某些点取消定义、某些点重新定义，GDB支持对含有宏的表达式进行展开并显示展开后结果的功能。如果要让编译后的程序具有宏调试功能，需要额外的编译参数-gdwarf-2和-g3(-g是不够的)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  gdb gcc -gdwarf-2 -g3 sample.c -o sample</div></pre></td></tr></table></figure></p>
<p>　　上面的gdwarf-2具有gdwarf-3、gdwarf-4等版本，推荐支持的情况下使用最新版本的调试格式。<br>　　<strong>macro exp|expand <em>expression</em></strong><br>　　显示expression中所有宏被展开后的结果。因为GDB只会进行宏展开而不会对表达式取值，所以这里的expression不需要是合法的表达式。<br>　　<strong>info macro [-a|-all] [–] <em>macro</em></strong><br>　　显示当前的或者全部的macro宏定义，同时显示该宏定义所在的源代码文件及其所在行号位置信息。其中的–表示参数列表结束，因为C中有些宏是可以使用-开头的，这里用于消除歧义作用。<br>　　<strong>info macros <em>location</em></strong><br>　　显示所有在location位置有效的宏定义及他们的位置信息。(显示结果有点多哦)<br>　　<strong>macro define <em>macro</em> <em>replacement-list</em></strong><br>　　<strong>macro define <em>macro</em>(<em>arglist</em>) <em>replacement-list</em></strong><br>　　自定义宏及其展开式，通过该命令创建的宏会在GDB求值的每个表达式中都会生效(只对GDB本身作用，与代码中使用的宏无关)，直到其显式使用macro undef进行删除，同时该宏还会覆盖程序中同名宏的展开(有点诡异)。<br>　　<strong>macro undef <em>macro</em></strong><br>　　只会删除上面使用macro define定义的宏，而不会删除程序代码中定义的宏。<br>　　<strong>macro list</strong><br>　　显示所有通过macro define定义的宏。<br>　　除了通常在源代码中执行宏定义，还可以在编译的时候在命令行中通过<code bash="">‘-Dname=value’</code>的方式定义，这样的宏也支持使用info macro命令查看，不过其行号信息显示为0。</p>
<h1 id="九_修改调试程序的执行">九 修改调试程序的执行</h1><p>　　例如在程序调试的过程中发现了明显的错误，想要验证修改该简单错误后程序执行会不会得到正确结果的时候，GDB的alter execution功能就会比较的好用，支持比如：修改某个寄存器、变量、内存的值，向程序发送某个信号，从不同的地方重新执行，直接跳出函数执行等操作。</p>
<h2 id="9-1_给变量重新赋值">9.1 给变量重新赋值</h2><p>　　下面都是将变量x修改为新值，区别是使用print会同时打印这个变量的值，同时还会降其放入历史记录中去。在使用set的时候还需注意，因为gdb中有很多变量也是使用set设置更新的(比如width)，此时就应该使用set variable|var而不能使用set简写了，并且使用后者总是一个好习惯，可以防止莫名其妙的修改了环境变量值而不知。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> x=8</div><div class="line">(gdb) <span class="built_in">set</span> x=8</div></pre></td></tr></table></figure></p>
<p>　　GDB中对于变量类型的转换要比C/C++语言宽松的多，比如可以把整数当做指针使用等，也可以直接将值放到指定内存位置上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> &amp;a</div><div class="line"><span class="variable">$2</span> = (int *) 0x7fffffffe1ec</div><div class="line">(gdb) <span class="built_in">set</span> &#123;int&#125;0x7fffffffe1ec = 9789</div><div class="line">(gdb) <span class="built_in">print</span> a</div><div class="line"><span class="variable">$3</span> = 9789</div></pre></td></tr></table></figure></p>
<h2 id="9-2_从不同位置恢复执行">9.2 从不同位置恢复执行</h2><p>　　默认使用continue恢复程序执行的时候，会从之前停止的位置继续执行，而使用jump命令可以指定程序恢复执行的位置。该命令很多时候是调回已经执行的代码，重新设置某些变量，然后再次执行下来。<br>　　<strong>jump|j <em>location</em></strong><br>　　在location的位置恢复执行，如果该处有断点则会立即停止，而且有时候为了达到这个效果会同tbreak组合使用。jump除了修改程序计数器之外，<strong>不会修改</strong>当前stack frame、stack pointer、内存信息和其他的寄存器信息，所以如果使用jump调到别的函数位置开始执行，那么结果将会变得十分离奇，因此如果location的地址不在当前执行函数范围内，GDB会给出信息要求确认。<br>　　将<strong>$pc</strong>直接设置新值，然后运行continue也会得到相同的效果。</p>
<h2 id="9-3_向程序发送信号">9.3 向程序发送信号</h2><p>　　<strong>signal <em>sig</em></strong><br>　　恢复程序的执行并立即给予其sig信号。如果sig为0，程序将不会收到信号并恢复执行，这常常用于程序因为收到某个信号而停下来，该信号原本会传递给应用程序的时候，通过’signal 0’可以让程序不收到该信号而继续执行。注意在多线程的环境下，当恢复执行程序的时候信号会被传送到当前选定的线程(而可能不是最后停止下来的线程)，因此如果要使用’signal 0’屏蔽信号，必须先选中对应正确的线程，否则GDB也会探测并给出确认提示。<br>　　此处的signal发送信号和命令kill发送信号是不同的，后者仍然会通过GDB根据handle觉得过滤处理，而signal会直接将信号传递给调试的应用程序。<br>　　<strong>queue-signal <em>sig</em></strong><br>　　将sig信号排队给当前线程，并在程序恢复执行的时候立即发送，要求sig的handle必须是pass的，否则GDB会报错。<br>　　sig参数还可以是0，起效果是当前线程所有排队的信号将会被清空，程序恢复执行的时候将没有信号发给该线程。该命令和上面signal不同的是signal会导致程序的恢复执行，再则queue-signal发送的信号必须是pass处理的信号。</p>
<h2 id="9-4_函数中返回">9.4 函数中返回　</h2><p>　　<strong>return [expr]</strong><br>　　该命令可以取消一个函数的执行，如果提供了expr表达式，则该表达式的值将会作为函数的返回值。<br>　　当使用了该命令，GDB会放弃当前选定的stack frame及其包含在其内部的所有stack frame，使得该函数的调用者作为最内层stack frame。return命令不会恢复程序的执行，而是使得程序的状态处于函数刚刚返回的状态，与其不同的是finish命令，会恢复函数的执行直到函数函数的正常范围时停止。</p>
<h2 id="9-5_调用程序的函数">9.5 调用程序的函数</h2><p>　　<strong>print <em>expr</em></strong><br>　　对表达式expr求值，并打印显示结果，其表达式可以包含对被调试程序中的函数的调用。<br>　　<strong>call <em>expr</em></strong><br>　　同样对表达式expr求值，但是不显示void返回函数的结果，如果调用的函数本身会返回值，那么该返回的值还是会被打印，并添加到值历史记录中去。</p>
<h1 id="十、调试目标和远程调试">十、调试目标和远程调试</h1><p>　　GDB的调试目标可以是process(进程)、exec file、core file、recording sessions，以及突破单机限制采用串口线、网络相连的remote调试目标。调试目标可以使用target命令进行设置，target+TAB可以查看当前gdb所支持的调试目标的种类。<br>　　<strong>target <em>type</em> <em>parameters</em></strong><br>　　参数<em>type</em>常见的有exec|core，这种方式也可以使用exec-file、core-file方式指定，甚至在gdb启动的时候就作为启动参数附加上去。target工具最常用的，还是在于对远程调试的支持上。远程调试，是主要在于一些运行程序的远程操作系统的限制(比如内核限制、内存限制)导致无法全功能运行gdb调试器的情况下尤为的有用，此外就是gdbsever和gdb规定了一套通信协议，而前者尺寸比后者要小的多，运行起来更轻便的同时，也容易在一个新平台上面进行快速的移植和支持。</p>
<h2 id="10-1_连接到远程调试目标">10.1 连接到远程调试目标</h2><h3 id="10-1-1_两种远程连接模式">10.1.1 两种远程连接模式</h3><p>　　GDB支持两种模式的远程调试连接：remote和extend-remote，两者基本功能相同，但是在处理出错、退出等细节性的方面差异很大。<br>　　<strong>target remote</strong><br>　　当调试的程序退出或者detach后(还比如在gdb中使用kill主动杀死正在调试的进程)，target将会断开连接，当使用了gdbserver的时候，gdbserver也会自动退出。<br>　　gdbserver的启动模式有三种：PROG、–attach、–multi，前两者是在gdbserver启动的时候指定调试的二进制程序或者要attach的调试进程，在remote模式下只能连接这两种模式的gdbserver。<br>　　不支持run命令，连接到远程后被调试程序已经运行了，此时可以使用step、continue等各项调试指令。<br>　　不支持attach命令，必须在启动的时候通过–attach参数指定。<br>　　<strong>target extend-remote</strong><br>　　当调试的程序退出或者detach后，target任然保持着和gdbserver连接(此时只有gdb退出后，gdbserver才会reopen侦听)，即使当前没有调试程序在运行。使用–once参数可以让gdbserver在第一个连接断开后退出，否则如果需要使远程的gdbserver退出，可以使用monitor exit命令。<br>　　extend-remote除了上面PROG、–attach外，还可以连接使用–multi模式启动的gdbserver，连接后在使用命令设置远程调试文件或者远程attach进程。<br>　　支持使用run命令，启动的程序是通过set remote exec-file的方式指定的。如果gdbserver启动的时候指明了调试文件，那么也不需要使用run命令了，可以类似使用step、continue等命令恢复程序执行。<br>　　支持attach命令。</p>
<h3 id="10-1-2_指明Host和Target文件">10.1.2 指明Host和Target文件</h3><p>　　具有调试符号的执行文件才可以用于调试。在远程调试模式下，允许GDB通过建立的调试连接访问远程的程序文件(remote program file access)。<br>　　我们将运行gdb的成为Host，运行gdbserver的称为Target，如果远程程序文件访问是支持的，那么允许Target调试的程序是stripped之后的(确实调试符号)，只需要Host加载的程序是带有调试符号的就可以了，除此之外还需要使用set sysroot的方式指明其他组件和库的调试信息。即使此时Host和Target的程序不一致，但是也必须保证后者是前者strip得到的，否则调试将会有异样的结果。</p>
<h3 id="10-1-3_一些远程调试相关命令">10.1.3 一些远程调试相关命令</h3><p>　　<strong>target remote|extended-remote <em>serial-device</em></strong><br>　　<strong>target remote|extended-remote <em>[tcp:]host:port</em></strong><br>　　host主机可以是主机名或者IP地址，如果host和target运行在同一台主机上，则host字段可以被省略(:占位还是需要保留)。<br>　　<strong>target remote|extended-remote <em>udp:host:port</em></strong><br>　　<strong>target remote|extended-remote | <em>command</em></strong><br>　　在后台运行command，并通过管道与之通信，command必须是shell的命令并使用/bin/sh进行解析。</p>
<p>　　<strong>detach</strong><br>　　当完成调试的时候，可以使用该命令进行对GDB控制的释放，当使用remote模式连接的时候，此时GDB可以自由连接其他的target了；而如果使用extend-remote连接的时候，此时GDB仍然处于和target连接状态。<br>　　<strong>disconnect</strong><br>　　断开和target的连接，此时GDB可以自由连接其他的target了。<br>　　<strong>monitor <em>cmd</em></strong><br>　　允许想远程发送任意命令，被远程monitor所解析。motinor exit可以让gdbserver立即退出，通常在disconnect命令之后使用，而monitor set debug|remote-debug 0|1还可以设置后续描述到的这两个调试参数。</p>
<p>　　gdb允许想远程目标上传、接收、删除文件，这对于嵌入式调试(已占用串口线)十分方便，命令如下：<br>　　<strong>remote put <em>hostfile</em> <em>targetfile</em></strong><br>　　<strong>remote get <em>targetfile</em> <em>hostfile</em></strong><br>　　<strong>remote delete <em>targetfile</em></strong></p>
<h2 id="10-2_gdbserver程序">10.2 gdbserver程序</h2><p>　　如前面所说，gdbserver运行的Target端可以是strip后没有调试符号的运行程序，而在Host端负责符号相关的支持。OPTIONS参数选项比较重要的有–debug，可以显示一些额外的调试信息，而–remote-debug会显示一些远程调试协议相关的信息，主要是gdbserver本身开始调试使用的。<br>　　<strong>gdbserver [OPTIONS] COMM PROG [ARGS …] </strong><br>　　命令中的COMM是串口设备字段或者TCP/IP的网络字段，ARGS是作为给PROG的运行参数使用。<br>　　<strong>gdbserver [OPTIONS] –attach COMM PID </strong><br>　　调试一个运行着的进程的时候，不需要指明运行的二进制程序的位置。在extended-remote模式下还允许使用attach命令进行进程指定。pid可以使用pidof工具辅助查找(有多个同名运行的进程的话会一并全部返回，使用-s可以返回单个PID)。<br>　　<strong>gdbserver [OPTIONS] –multi COMM </strong><br>　　允许gdbserver在不指定调试程序、调试进程的情况下启动，后续通过extended-remote连接后再行设定。</p>
<h1 id="十一、GDB_TUI(Text_User_Interface)调试界面">十一、GDB TUI(Text User Interface)调试界面</h1><p>　　就像之前说到的，Windows下面的程序员是幸福的，因为他们有着号称最好用的IDE——Visual Studio。其实内行看门道，到这里发现GNU GDB也是当之无愧的程序调试利器，只不过像通常Linux平台下的软件一样擅长功能而不善于表达，导致给外人看来一种很难用的“假象”。<br>　　GDB内部集成了一个TUI的用户界面，在启动GDB的时候可以使用<code bash="">gdb -tui</code>参数的方式使能，该模式是使用的curses库实现的一个建议UI界面。这个界面基本只是显示的基本功能，远远达不到IDE效果，不过它的好处是比较的易用(因为他没啥功能……)，只需要在command窗口进行常规的gdb调试，分割出来的其他窗口可以自动显示源代码、反汇编、寄存器等信息，操作要有好许多。<br>　　在Linux下面还有一个十分常用的gdb调试外壳，就是DDD，感兴趣的也可以去了解一下。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.cs.swarthmore.edu/~newhall/unixhelp/howto_gdb.html" target="_blank" rel="external">Debugging C and C++ programs with gdb and ddd</a></li>
<li><a href="https://www.ibm.com/developerworks/library/l-gdb/" target="_blank" rel="external">Linux software debugging with GDB</a></li>
<li><a href="https://chromium.googlesource.com/chromium/src/+/master/docs/linux_debugging.md" target="_blank" rel="external">Tips for debugging on Linux</a></li>
<li><a href="http://www.cprogramming.com/debugging/segfaults.html" target="_blank" rel="external">Debugging Segmentation Faults and Pointer Problems</a></li>
<li><a href="http://www.cprogramming.com/gdb.html" target="_blank" rel="external">A GDB Tutorial with Examples</a></li>
<li><a href="https://blogs.msdn.microsoft.com/vcblog/2015/11/18/announcing-the-vs-gdb-debugger-extension/" target="_blank" rel="external">Announcing the VS GDB Debugger extension</a></li>
<li><a href="https://book.douban.com/subject/4111413/" target="_blank" rel="external">软件调试的艺术</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　人家都说Windows平台下的程序员是幸福的，因为Visual Studio实在是太好用了。<br>　　我想一听到上面这句话，绝大多数Linux平台C/C++程序员都将会沉默，至少网上搜Linux平台下C/C++开发调试，很大一部分文章都是介绍搭建IDE的，这也侧面说明了Linux平台下没有一个占绝对主流地位好用的IDE。自己平时写程序是用的SlickEdit，这个IDE很贵，支持代码补全和跳转，调试过程也支持断点、Watch等特性，但是使用过程中还是有这样那样的小问题(比如非英文字串显式、速度比较慢)，但是总体比较而言还是比较优秀的跨平台C/C++ IDE。虽然线下编码调试使用这货当然可以，然则线上环境就无能为力了，再加上自己之前对gdb也只是了解个表明，这次就顺着gdb的文档深挖一下！<br>　　真是一看吓一跳，gdb的命令行调试要远比IDE的功能高级的多，如果只是通常的设置断点，监测变量什么的可能IDE比较方便，但是一旦上升到高级点的调试技巧，反而gdb在命令行的模式下更为的方便和高效。<br>　　前方预警：<strong>这将会是一篇很长很长的文档摘读</strong>。</p>
<h1 id="一、开始使用gdb">一、开始使用gdb</h1><h2 id="1-1_启动gdb">1.1 启动gdb</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ gdb program [core|pid]</div><div class="line">➜  ~ gdb --args g++ -O2 -o main main.cpp</div><div class="line">(gdb) shell <span class="built_in">echo</span> <span class="variable">$SHELL</span></div><div class="line">(gdb) <span class="built_in">set</span> logging on</div></pre></td></tr></table></figure>
<p>　　gdb接需要调试的程序可执行文件，后面可以附加core文件或者pid进程号(调试正在运行的进程)，如果有第三个参数gdb总是先尝试解释他为core文件，然后才是进程号。第二种格式采用–args，待调试的程序执行的时候需要额外的参数，此时可执行程序后面的参数不再被gdb解释。<br>　　组合键Ctrl-D或者输入quit可以退出调试状态，如果之前attach到一个进程上面去了，可以用detach命令释放进程，如果quit有表达式那么表达式就作为gdb的退出状态，否则是被调试的子进程的退出状态。gdb中使用Ctrl-C不会终止gdb，而是会终止gdb正在运行的调试指令返回到gdb命令状态。<br>　　在gdb中可以使用shell或者!做前导来执行shell中的命令而不用退出gdb(gdb的退出和重启动的代价是很大的)，make命令可以用来重新编译程序而不用先导shell|!符号，而gdb自动重新加载符号。<br>　　通过set logging on可以打开日志功能，默认会将日志输出追加到当前目录的gdb.txt文件中。</p>
<h2 id="1-2_gdb中的命令">1.2 gdb中的命令</h2><p>　　gdb是很智能的，所有的命令都可以使用TAB、TAB-TAB进行补齐或者提示，不输入任何命令的空换行(在可能的情况下)表示重新执行前一条指令，这节省了重复输入step|list等指令的劳动。gdb允许指令和参数的缩减输入，没有歧义的时候会运行，而在遇到歧义的时候起会提示出各个歧义的命令列表供参考。<br>　　有些命令参数中可能含有特殊的符号(比如括号)，尤其在C++允许函数重载的时候需要使用参数类型来进行区分，此时参数需要使用 ‘ 单引号来包围，而且在需要的时候gdb也会自动帮你包围并给出候选列表的。</p>
<h2 id="1-3_gdb帮助">1.3 gdb帮助</h2><p>　　gdb本身附带了很多帮助命令，比如：<br>　　<strong>help <em>command</em></strong>：显示名的帮助信息<br>　　<strong>apropos <em>args</em></strong>：会在命令名、文档中搜索指定的表达式<br>　　<strong>info <em>args|registers|breakpoints|…</em></strong>：可以显示很多状态信息，具体可以查看help info<br>　　<strong>set <em>var val</em></strong>：设置环境变量<br>　　<strong>show <em>var</em></strong>：显示环境变量的值</p>
<h2 id="1-4_调试执行程序">1.4 调试执行程序</h2><p>　　对于待调试程序编译时候，总应该使用-g选项生成调试信息。]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="内核" scheme="https://taozj.org/tags/%E5%86%85%E6%A0%B8/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="读书笔记" scheme="https://taozj.org/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HTTPS原理简单介绍]]></title>
    <link href="https://taozj.org/201701/https-principle.html"/>
    <id>https://taozj.org/201701/https-principle.html</id>
    <published>2017-01-17T16:39:59.000Z</published>
    <updated>2017-01-18T13:15:17.000Z</updated>
    <content type="html"><![CDATA[<p>　　HTTPS在今后的互联网中必将扮演者越来越重要的角色了，国外互联网大佬对https部署也是竭力鼓吹呐喊，HTTP/2协议的推广更是逼着你不上也得上！在HTTPS普及化过程中，必然会损害某些集团的利益，但是这是互联网的趋势，历史的洪流是谁也阻挡不了的！<br>　　这篇文章就是对HTTPS的大概做一个了解，力图宏观上掌握其基本原理和流程，而其中涉及到的具体加密算法的细节之流就留给那些博士title的人研究去吧！<br>　　还是一样，要用Wireshark抓取和分析SSL/TLS的数据包，需要设置电脑的SSLKEYLOGFILE环境变量才可以。在Windows上面搞了好久，发现抓到的数据包还是不能解密，最后在Ubuntu下一次就完成了，看来搞开发的话还要Linux算是神器啊！抓取的数据包和Master-Secret也打包<a href="/upload/taozj.ssl.pcapng.zip">共享</a>给大家了。此外为了简单起见，客户端请求禁用了Diffie Hellman支持，这个算法是为了提高安全性考虑的，好处就是密钥可以独立于服务器的私钥，所以历史数据即使在私钥被窃取的情况下，会话的内容也无法被破解。<br><img src="/post_images/images/201701/538d95ba.png" alt="https"><br>　　上面展现的客户端和服务器整个通信过程尽收眼底：首先三次握手建立TCP连接，然后客户端发起HTTP请求并得到302跳转，客户端进行ACK确认后，转而向443端口进行TCP三次握手连接，接下来就是TLS协商，加密信道建立后采用加密方式进行数据的传输。流程中夹杂着TLS和TCP的数据包，这一点也不奇怪，因为ACK是TCP协议的特性哦！<br><a id="more"></a></p>
<h1 id="一、HTTPS和TLS简介">一、HTTPS和TLS简介</h1><p>　　说到HTTPS，其实他代表着运行在SSL/TLS之上的HTTP，TLS是把SSL标准化之后的产物，因为SSL 3.0有安全漏洞，所以互联网大佬们都提倡禁用SSL 3.0，因此推荐在你的Apache/Nginx等ssl_protocols的配置中，取消对于SSLv3及其更低版本SSLv2的支持。在协议中，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3，这点在抓取的数据包的头部可以看出来。<br>　　TLS协议的一个优势，就是它是与应用层协议独立无关的，他的目的就是在通信双方在不可信的网络之上建立一个加密的通道用来安全地传输数据，因此上层的HTTP、FTP、SMTP和IMAP(使用STARTTLS)等应用层协议都可以透明的建立在TLS之上以满足可信通信的需求。<br>　　互联网是开放的但也是不安全的，尤其是上个世纪设计出来的大量网络应用协议都是text模式的，这让心怀不轨的人随便截获数据包就可以查看分析，作恶的成本十分的低。曾经在以前公司做入职培训作业的时候，发现公司Exchange邮件服务器+Foxmail客户端的通信都是明文的，抓包中可以看到同网段中其他同事的邮箱账户和密码(不相信做网络的公司运维水平会如此之差，或者是某些目的故意而为之吧)。HTTP协议也是text模式的，所以如果你不用HTTPS上网，可能遇到的问题有：<br>　　(1). <strong>上网过程裸奔</strong>：你的上网记录可以被监控，HTTP头部信息和Cookie被一览无余，如果传输的内容没有经过加密处理，那么你的东西也会被别人截获查看，帐号密码啥的全都不保，而且你对此丝毫没有察觉。还有些防火墙样的东西，一旦发现你想看不该让你看到的东西，就可以直接把你的连接掐掉。<br>　　(2). <strong>返回数据被篡改</strong>：不知道这锅该不该甩给运营商，很多时候请求的资源总会弹出些乱七八糟的东西，下载个东西有时候是比葫芦娃还恐怖的木马，这点尤其在移动端更为的猖獗。因为HTTP的协议就这样，你给服务端一个请求，服务端就给你一个返回，而对返回的内容根本无法辨识和校验，就这么个东西爱要不要，这样在网页中插入几段广告，或者把下载的文件中途给换掉，你根本无法辨别。<br>　　不过有一点，HTTP请求的话很方便做缓存，好的缓存对大家都有益处，可以节省带宽，同时也加快访问者的响应速度；还有比如中间传递者可以针对访问用户进行特定的转码优化。不过这一切都基于良性驱动的，恶意插入和推广的行径应当被谴责！<br>　　所以负责任的网站在提供文件的下载连接的同时，还要提供MD5/SHA1散列码给用户验证，甚至对其进行数字签名。<br>　　(3). <strong>中间人攻击</strong>：这个就更恶劣了，你甚至不知道是不是在和真正的主机在通信，你只是发出请求然后接受应答，数据包通过明文不知中转了多少台设备，任何环节中间插入个第三者帮你和服务器之间中间传话，听着是不是就惊悚？<br>　　对此，你能做的就是保护自己，所有的网络通信都要加密：HTTP要加密，邮件本身要加密，邮件的传输也要加密，DNS也要加密……为的不是防君子，而是防小人。</p>
<h1 id="二、TLS认证过程">二、TLS认证过程</h1><p>　　这个过程首先普及一点加密的知识。就像当初在GnuPG中描述的一样，加密机制可以分为非对称加密和对称加密两种：<br>　　<strong>非对称加密</strong>：会产生一对公钥和私钥，公钥公开发布到网上，私钥锁在自己保险柜中，用公钥加密的东西只能由私钥解密，用私钥签名的东西只能用公钥验证，注意我的措辞也概括了公钥和私钥的使用方式。一把非对称密钥只能实现一个方向的加密通信，要想实现双向加密通信，就必须通信的双方分别使用对方的公钥进行加密，然后再由对方用自己的私密接钥来实现。<br>　　<strong>对称加密</strong>：双方拥有相同的密钥，该密钥可以用于加密，也可以用于解密，所以这个密钥是不能被公开或者猜测到的。对称加密又分为块加密和流加密，前者只能对定长的数据块进行加密，所以通常要对待加密数据进行padding操作；流加密可以对任意长的数据进行加密，一般明文和加密结果是一样的长度。两者比较块加密的效率要高得多，可以使用CPU的高级指令高效运算，但是padding就需要记录原始数据的长度，实现起来麻烦一些。<br>　　老实说来，当时我一看完openssl支持的加密种类中，就<a href="https://raw.githubusercontent.com/taozhijiang/st_utils/master/source/st_openssl.c" target="_blank" rel="external">知道</a>先用非对称加密传输对称密钥，后续的通信使用对称加密(AES)的方式进行，后者的运算效率会比前者高很多(在一台每秒可进行千万次对称加密计算的电脑上，只能支持每秒几千次的非对称加密计算)，只要保证在每次会话中产生强随机性的密钥，就能让通信的可靠性大大的增加。如果通信双方都采用非对称加密的方式进行，那么服务端要收集庞大的用户公钥，这显然是不现实的。<br>　　下面这张图是从RFC中拷贝过来的，描述了TLS加密通信建立的过程：<br><img src="/post_images/images/201701/c934edcb.png" alt="https-step"><br>　　(1). <strong>Client Hello</strong><br>　　这个是客户端主动向服务端发送的第一个消息，主要产生的信息：Version、Random、Session ID、Cipher Suites、Compression Methods。<br><img src="/post_images/images/201701/33152673.png" alt="https-step"><br>　　Random由一个4字节的GMT Unix Time和28字节的随机串组成，前者是从Jan 1, 1970, UTC开始到现在所经过的秒数，不过奇怪的是访问我的Apache服务器返回的时间都像是随机的，而Google的服务器返回的值是正常的(不过RFC不强制该时间是准确的)，请忽略图中值，他们共同组成一个32位的随机串供后面使用；如果短时间之前连接过相同服务器，Session ID可以帮助快速恢复连接，或者根据当前连接快速创建新的连接，因为有了之前的基础只需修改会话随机部分就可以了，效率会高很多，但是这个Session ID的传输是没有加密的哦，这里是空的；Cipher Suites列出客户端支持的加密方式，使用4字节进行编码的，如前面说所我把高安全的Diffie Hellman禁用了，所以只支持上面三种方式；Compression基本都是空的。既然这个过程是两者协商的，所以恶意情况下中间人可以进行干扰，让加密通信回退到最差安全协议的情况下进行通信。<br>　　此处还需要注意扩展中有个server_name，SSL在最早的时候需要每个站点有不同的IP，但是在同一个IP下运行多个虚拟主机的情况下显然不合适，所以后面就增加了这个扩展来标识需要访问的主机域名。<br>　　(2). <strong>Server Hello</strong><br>　　服务端收到上述消息后，会进行一个回应，主要是根据客户端的情况，选择合适的协议版本和Cipher Suite。<br><img src="/post_images/images/201701/017b2915.png" alt="https-step"><br>　　上面服务端确认采用TLS 1.2，同时采用TLS_RSA_WITH_AES_128_CBC_SHA；除此之外，服务端跟客户端类似，也产生了一个总共长度32字节的随机串。TLS_RSA_WITH_AES_128_CBC_SHA称之为Cipher Suite，RSA用于签名校验和加密、AES_128_CBC用于对称数据加密解密、SHA用于消息完整性校验，openssl集成了大量的算法支持，所以这里的组合种类可能很多，但最终服务端会和客户端达成某种一致的Cipher Suite，而且往往服务端也不一定决定要用最安全的套件，因为越安全的算法往往对服务器性能消耗越大。<br>　　如果Client Hello的Session ID不为空，此时服务端可以在缓存的会话中进行校验，如果OK会恢复相同的Session ID进行确认；服务器也可以产生一个新的Session ID，表明后续有缓存该对话的意图；或者服务器返回空，表示不会缓存对话。<br>　　(3). <strong>CertificateServer Hello Done</strong><br>　　TLS握手过程中一个过程可能有多条消息构成，在上面的Server Hello发送完后，接下来服务端还会发送自己的数字证书，证书的信息通过浏览器上面的那把锁点击也可以查看详情。<br><img src="/post_images/images/201701/e6719e16.png" alt="https-step"><br>　　证书中包含了颁发者、使用域名、有效时间、公钥等重要信息。然后服务端通过Server Hello Done结束发送。<br><img src="/post_images/images/201701/eb4dc437.png" alt="https-step"><br>　　(4). <strong>Client Key Exchange, Change Cipher Spec, Encrypted Handshake Message</strong><br>　　客户端收到证书后，就开始忙活了：证书有效期限、域名匹配、是否被吊销了比较简单，关键怎么验证服务器传送过来的证书是否有效呢，毕竟这个数字证书中包含了服务端的公钥，涉及到后面的非对称加密数据的传输的？<br>　　在通信的双方不能完全相信彼此的情况下，只能通过引入权威第三方进行协调，就像是支付宝的原理样的。从之前的非对称加密原理可知，密钥可以对消息、文件进行数字签名，所以只要可信机构(CA)确认过我的身份可靠后，使用他们的私钥对我的公钥和附加信息进行数字签名，那么任何相信该可信机构的人，都可以使用可信机构的公钥来对我的证书进行验证以实现对我身份的校验了。<br>　　不过我们如何获得可靠的第三方公钥呢，通过每层结构都用自己的私钥对自己颁发出去的公钥及其拥有者进行签名，可以自上而下形成一个信任层次，但是顶级证书谁来信任呢，这不是个鸡与蛋的问题么？所以第三方可信结构的证书都是预置在浏览器和操作系统里面的，他们的证书是自签名的，对他们的信任是无条件的，所以从WoSign作恶被曝光后，Firefox、Chrome都声称停止相信WoSign的证书了，众目睽睽之下证书颁发机构才能得到有效的监督。还有，证书的等级分为DV、OV、EV，这也体现在签发的时候证书机构对申请者审查的程度不同，DV只要能验证域名所有权就可以签发，而EV还需要很多的书面文件审核才可以颁发的。<br><img src="/post_images/images/201701/fa957bfb.png" alt="https-step"><br>　　证书通过验证后，后面就可以使用其中的公钥来加密敏感消息发送给服务端了。<br>　　在上面两个Hello中总共产生了2个32字节的随机数，并且通过明文的方式发送给了对方，此时Client端再产生一个48字节的pre_master_secret随机数，该随机数通过上面的公钥和协定的加密算法(RSA)加密后发送给服务端，只有持有私钥的服务端才可以解密得到内容。这样，客户端和服务端都共有三个随机数，可以用算法产生一个对称加密密钥了。<br>　　这里只使用服务器的公钥将pre_master_secret加密后就发送出去了，设想黑客记录了通信过程中的所有数据包，那么他可以得到handshake Hello过程中的随机数(明文的)以及加密后的pre_master_secret，如果有一天服务器的私钥被泄露，黑客就可以用私钥解密得到pre_master_secret，采用周知的方法得到session key，后续所有通信的数据内容都可以被解密了，即使此时证书过期了或者被吊销了，也于事无补，所以单纯的RSA handshake是不安全的。而上文中提到被禁用的Diffie Hellman就是为了解决这个问题而被提出来的，该算法被设计出来进行密钥的安全交换，原理上就没深究了。<br>　　接下来Client发送一个Change Cipher Spec消息，该消息只有一个字节，其值为1，后面服务端也会向客户端发送，主要作用是告知对端后续的通信将会使用之前协商的CipherSpec和密钥对进行通信。<br>　　客户端发送的最后一个消息是Encrypted Handshake Message，也叫做Finished消息，其内容是之前所有消息(不包括Hello消息)的内容+handshake_messages(“client finished”)等消息产生verify_data，然后通过各种计算操作产生64字节加密结果发送给服务端，服务端对其解密和校验，这个过程主要就是验证客户端和服务端之前商定的Cipher Spec和密钥是否生效。<br>　　(5). <strong>New Session Ticket, Change Cipher Spec, Encrypted Handshake Message</strong><br><img src="/post_images/images/201701/4e7e2040.png" alt="https-step"><br>　　服务端也会有类似的Change Cipher Spec和Encrypted Handshake Message消息，不过这里还有一个New Session Ticket。<br>　　这又是另外一个RFC5077了，其实跟上面的Session ID起到类似的作用，都是通过历史会话快速生成新会话的功能(Session Resumption)。在HandShake过程中，Server发送一个加密的session ticket(包含session key)给客户端，当恢复一个对话的时候客户端返回该加密的key，服务端解密后就可以在不需要私钥的情况下快速恢复对话了。该特性由Firefox、Chrome主要支持，其他浏览器多使用Session ID的方式恢复对话。<br>　　Session ID是TLS内置的功能，而session ticket是一个扩展，其两者的区别是：前者需要在客户端和服务端都缓存该Session ID，服务端的缓存导致该情况下恢复对话功能不能跨主机；session ticket只会将加密的会话保存在客户端，当客户端需要恢复对话的时候，直接将会话数据发送给服务端，服务端解密就可以了，所以所有能够解密该session ticket的服务器多可以用来恢复对话，在免除服务端缓存Session信息压力的同时，更具有灵活性。采用会话恢复机制，能显著减轻服务端的压力以及客户端的连接速度。<br>　　(6). <strong>Application Data</strong><br>　　自此，TLS handshake完成，后继的通信都采用对称加密方式进行加密保护，尽请放心使用。<br><img src="/post_images/images/201701/f1ded92d.png" alt="https-step"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://stormpath.com/blog/why-http-is-sometimes-better-than-https" target="_blank" rel="external">Why HTTP is Sometimes Better than HTTPS</a></li>
<li><a href="http://www.codecompiled.com/understanding-https-protocol/" target="_blank" rel="external">Understanding HTTPS Protocol</a></li>
<li><a href="https://https.cio.gov/" target="_blank" rel="external">The HTTPS-Only Standard</a></li>
<li><a href="http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html" target="_blank" rel="external">The First Few Milliseconds of an HTTPS Connection</a></li>
<li><a href="http://security.stackexchange.com/questions/20803/how-does-ssl-tls-work" target="_blank" rel="external">How does SSL/TLS work?</a></li>
<li><a href="http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html" target="_blank" rel="external">数字证书原理</a></li>
<li><a href="https://engineeringblog.yelp.com/2016/09/great-https-migration.html" target="_blank" rel="external">The Great HTTPS Migration</a></li>
<li><a href="https://www.v2ex.com/t/255600" target="_blank" rel="external">运营商进行网络劫持的前生今世+劫持的危害</a></li>
<li><a href="https://tools.ietf.org/html/rfc5246" target="_blank" rel="external">The Transport Layer Security (TLS) Protocol Version 1.2</a></li>
<li><a href="https://blog.cloudflare.com/keyless-ssl-the-nitty-gritty-technical-details/" target="_blank" rel="external">Keyless SSL: The Nitty Gritty Technical Details</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　HTTPS在今后的互联网中必将扮演者越来越重要的角色了，国外互联网大佬对https部署也是竭力鼓吹呐喊，HTTP/2协议的推广更是逼着你不上也得上！在HTTPS普及化过程中，必然会损害某些集团的利益，但是这是互联网的趋势，历史的洪流是谁也阻挡不了的！<br>　　这篇文章就是对HTTPS的大概做一个了解，力图宏观上掌握其基本原理和流程，而其中涉及到的具体加密算法的细节之流就留给那些博士title的人研究去吧！<br>　　还是一样，要用Wireshark抓取和分析SSL/TLS的数据包，需要设置电脑的SSLKEYLOGFILE环境变量才可以。在Windows上面搞了好久，发现抓到的数据包还是不能解密，最后在Ubuntu下一次就完成了，看来搞开发的话还要Linux算是神器啊！抓取的数据包和Master-Secret也打包<a href="/upload/taozj.ssl.pcapng.zip">共享</a>给大家了。此外为了简单起见，客户端请求禁用了Diffie Hellman支持，这个算法是为了提高安全性考虑的，好处就是密钥可以独立于服务器的私钥，所以历史数据即使在私钥被窃取的情况下，会话的内容也无法被破解。<br><img src="/post_images/images/201701/538d95ba.png" alt="https"><br>　　上面展现的客户端和服务器整个通信过程尽收眼底：首先三次握手建立TCP连接，然后客户端发起HTTP请求并得到302跳转，客户端进行ACK确认后，转而向443端口进行TCP三次握手连接，接下来就是TLS协商，加密信道建立后采用加密方式进行数据的传输。流程中夹杂着TLS和TCP的数据包，这一点也不奇怪，因为ACK是TCP协议的特性哦！<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="协议" scheme="https://taozj.org/tags/%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RPC设计和使用中的一些杂谈]]></title>
    <link href="https://taozj.org/201701/rpc-principle-and-tips.html"/>
    <id>https://taozj.org/201701/rpc-principle-and-tips.html</id>
    <published>2017-01-15T04:33:03.000Z</published>
    <updated>2017-02-08T08:10:03.000Z</updated>
    <content type="html"><![CDATA[<p>　　RPC当前在大公司的开发中越来越流行了，各大厂的开源RPC框架也呈百花开放的状态。在通过前面的<a href="/201612/learn-note-of-google-grpc.html">文章</a>做了一个对Google出品之gRPC的使用手册，也算是在使用方面有了一个基本的了解。恰巧最近逛别人博客的时候，看到几篇关于RPC原理和设计方面的文章，觉得十分不错，于是这里就将这些文章进行整理，对RPC设计、使用和实现中的那些乱七八糟的问题进行一个归纳总结。</p>
<h1 id="一、RPC的原理和关键点">一、RPC的原理和关键点</h1><h2 id="1-1_RPC的原理">1.1 RPC的原理</h2><p><img src="/post_images/images/201701/796a12cc.png" alt="rpc"><br>　　RPC的原理可以说是再简单不过了，一张图足以说明问题，总体来说会经历以下的步骤：<br>　　(1). client代码像普通函数调用一样调用client stub函数，这个调用是本地调用，调用参数会和平常函数调用一样进行返回地址和调用参数压栈操作；<br>　　(2). client stub会把调用参数和其它信息(比如调用方法名、调用属性等，可以称为metadata)进行打包封装成message，然后通过系统调用发送该message，这个打包的过程是个序列化的过程；<br>　　(3). client寻求到服务端的地址，然后通过本地操作系统经由某种协议，将上述message发送给server端；<br>　　(4). server端的操作系统接收message后将其传递给server stub；<a id="more"></a><br>　　(5). server stub将message解包，得到原始传递过来的各项调用参数，解包的过程是反序列化的过程；<br>　　(6). server stub调用server端的本地函数，然后将得到的结果按照上述类似的步骤反向传递给client作为结果返回。当然整个过程也可能不那么顺利，那么也应该产生合适的状态码、异常信息作为返回。<br>　　所以RPC实际是通过client stub和server stub起到一个代理的作用，将client的请求转发到server端去操作，并将操作得到的结果回传，因为传递是跨进程、跨主机的，所以必须进行序列化和反序列化的过程来保证消息的正确性。</p>
<h2 id="1-2_RPC设计中的要点">1.2 RPC设计中的要点</h2><p>　　相比于当前流行的HTTP/JSON开发，RPC等同于在实现相同功能的前提下将服务和传输等细节封装好，实现一种业务代码对特定服务开箱即用的效果。针对上面的RPC工作的流程看来，下面的几点是RPC设计实现中的几点要素：<br>　　(1). <strong>调用接口设计</strong><br>　　调用接口是客户端和服务端的一种约定，接触到的RPC框架大多都是服务于C/C++的，这类静态语言需要在编译期间确定调用接口，而且现在许多主流的编程语言都没有内置stub生成的支持，所以通常的解决方式都是用一种IDL(Interface Definition Language)的方式来描述调用接口，然后通过对应的功能辅助生成stub代码，这一点无论是上个世纪的Sun RPC(rpcgen)还是当下的gRPC(protobuf)、Thrift(thrift)都是这么干的。同时，想做到客户端和服务端跨语言的支持，也可以通过IDL然后生成特定语言种类的辅助代码来屏蔽差别性。<br><img src="/post_images/images/201701/780cf908.png" alt="idl"><br>　　(2). <strong>序列化和网络传输</strong><br>　　序列化的技术当前十分成熟了(json、msgpack、protobuf、xml……)，而且大多序列化库能够保证序列化和反序列化后能够生成特定于语言、字节序、架构的数据正确表示，现在序列化库所最求的极致，除了立志于多平台多语言支持外，就是序列化和反序列过程的速度和数据压缩效率，从这一点说Google的protobuf有着很明显的优势，看看其流行程度就知道了。<br>　　还值得一提的是，序列化还可以对数据结构进行序列化，比如C的结构体、指针等信息，感兴趣的可以参看这个小库<a href="http://www.happyponyland.net/cserialization/readme.html" target="_blank" rel="external">C serialization library</a>！但是在RPC中要实现调用参数Call-by-ref一定要谨慎，通常不要这么干。<br>　　RPC的好处就是对底层传输协议没有任何细节要求，承载client-server主机的通信协议可以选用诸如UDP、TCP、HTTP、MessageQueue甚至自设计协议，当然这也跟业务需求密切相关的，通用的RPC库通常会提供多个传输协议可供自由选择使用。<br>　　(3). <strong>RPC服务发布</strong><br>　　<strong>rpcbind</strong>：最初的Sun RPC就是这么干的，RPC服务提供者启动后将自己绑定到随机端口上，然后向rpcbind注册告知自己提供的服务和侦听的端口，而当客户端发起RPC调用的时候会首先联系rpcbind服务(周知111端口)以寻求提供服务的主机端口，然后再向这个地址发起真正的RPC请求。不过观当前流行的RPC框架，都是服务端直接绑定到某个约定的端口上面～<br>　　<strong>名字服务</strong>：这个就厉害了，前面的<a href="/201701/learn-note-of-distributed-system-%286%29-application.html">文章</a>介绍了zookeeper可以做很多事情，其中RPC服务可以方便的采用zookeeper进行发布：RPC的名字可以定义为ZNode，然后在其子节点上创建提供服务的主机信息，就可以实现诸如负载均衡、地址变更、主备冗余切换等功能。<br>　　(4). <strong>错误和异常处理</strong><br>　　RPC过程涉及到的过程和细节众多，客户端、服务端、网络传输都有可能出问题，为此gRPC为可能的情况都定义了对应的出错码，但是除了OK之外感觉其他提示都是不可靠，针对这种问题，会有一种<em>调用语义</em>的概念。<br>　　<strong>调用语义</strong>：诸如RPC这种跨网络的服务，要达到像本地函数调用那种exactly once semantic是理想化而不可能实现的，通常只能实现at least once和at most once两种调用语义，这之中的权衡一方面需要考虑具体业务的特点和需求，再则需要查看RPC所执行的任务是否是幂等(idempotent)的。</p>
<h1 id="二、RPC和MessageQueue的联系区别">二、RPC和MessageQueue的联系区别</h1><p>　　这两种方式都是企业用来进行业务解耦的重要手段，比如在经历多个项目后，发现有些服务或者功能可以独立出来给大家分享，这种情况就派上了用场了。RPC和MessageQueue虽然功能类似，但是使用手法还是有所区别的：<br>　　<strong>同步和异步</strong>：RPC模拟远程函数作为一个本地函数调用，所以函数调用上特别适合于Request/Response同步交互方式的使用场景，业务开发使用起来也更为的简单和直观；MessageQueue会将发送的消息进行排队处理，所以天然支持异步的工作模式，反而在需要同步返回结果的情况下MessageAQueue会比较麻烦。<br>　　同步方式使用的最大痛点就是并发量无法做的很高(针对那些使用线程处理请求的模式，协程另说)，而这一点MessageQueue可以将请求放入队列中，起到了错峰流控的作用。虽然gRPC、Thrift等开源RPC框架也提供异步使用方式，但是又额外多出来了CompleteQueue、CallBack之类的东西，每个调用还需要使用requestID/tag之类的东西进行标识，增加了RPC框架使用的复杂度，有违RPC简化业务实现的初衷，尤其是那种原本本地调用的业务代码向RPC迁移的时候，异步化过程中大动干戈的修改代码是比较忌讳的。<br>　　大家对这样的使用如此的一致，以至于默认就认为RPC是同步类型的调用，消息队列是异步类型的调用了。<br>　　<strong>固化</strong>：MessageQueue的一个好处就是可以将收到的消息立即固化到磁盘上，然后再进行消息的处理和应答工作，所以即使这个过程中有意外情况发生，消息也不会丢失，从某中程度上提供了一种更可靠的通信，此外这种固化还起到生产者和消费者长时间间隔完全解耦、接收端不可用的情况下针对发送端的可用性、备份等作用。这点对RPC的方式来说是很难实现的，RPC一般不会暂存请求。<br>　　<strong>消费模式</strong>：RPC只是Client和Server之间的一对一的关系，而MessageQueue通常采用Sender-Broker-Receiver的方式构成，这三者的联系可以出演化出各种各样的消费模式，尤其对于类似于“一对多”的使用场景只有MessageQueue才能支持。<br>　　<strong>静态语言的接口限制</strong>：对于C/C++这类强制性静态语言来说，调用接口需要在编译期间确定，基于Protobuf实现的RPC需要修改proto接口定义文件然后重新生成特定语言的辅助代码，对于客户端和服务端这种频繁升级都将是灾难性的。通过MessageQueue的方式就没有这么多的问题，MessageQueue的主体是消息，而Protobuf就是用于定义消息格式的，Google对Protobuf消息的向后兼容性是着重考虑的，所以软件的平滑升级是可行的。<br>　　不过也有大侠指出，一般开发环境都不会这么裸露地直接使用RPC开发业务的，通常会在业务层和RPC层中间做个隔离层，让变化性强的代码不侵入到业务当中，减少RPC频繁变动对业务代码的影响。<br>　　<strong>易用性</strong>：上面比较起来RPC对比于MessageQueue性能低、资源占用多、灵活性和扩展性不太方便，似乎是一无是处。我感觉RPC的最大优势就是简单易用(所以常常这点会作为RPC框架评价的重要指标)，程序开发充斥着无数函数调用，能把远程服务作为像函数调用一样使用真是让程序员再开心不过了。还有，比如RPC-&gt;RPC-&gt;RPC这样的嵌套调用场景，其中任何一个步骤发生了问题，调用过程都可以失败方式返回，业务上的错误处理和回滚等操作也直接明了一些吧，但是如果在异步模式下的开发，除非记录相关状态，否则这种回溯是很麻烦的！</p>
<p>　　当然，本文还是恪守于传统的RPC，所以只需要定位到函数名就可以了；对于支持面向对象的编程来说，还有RMI(Remote Method Invoke)远程方法调用，使用过程中还要找到特定的对象然后再调用该对象上的方法，通常可以通过url、名字服务等方式定位远程对象，不知道现在用的多不多，就没深究下去了。<br>　　RPC的使用的话，PhxSQL项目里面有个PhxRPC，而Raft协议实现中，各个节点的消息传递也是采用的RPC的方式进行的。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="external">Remote procedure call</a></li>
<li><a href="https://www.qcloud.com/community/article/164816001481011874" target="_blank" rel="external">如何设计一个RPC系统</a></li>
<li><a href="https://yq.aliyun.com/articles/3229?spm=5176.100239.bloglist.84.IZX9xy" target="_blank" rel="external">你应该知道的RPC原理</a></li>
<li><a href="http://www.cnblogs.com/metoy/p/4321311.html" target="_blank" rel="external">RPC原理详解</a></li>
<li><a href="http://ternarysearch.blogspot.com/2013/01/message-queues-and-rpc.html" target="_blank" rel="external">Message Queues and RPC</a></li>
<li><a href="http://www.happyponyland.net/cserialization/readme.html" target="_blank" rel="external">C serialization library</a></li>
<li><a href="https://www.cs.rutgers.edu/~pxk/417/notes/08-rpc.html" target="_blank" rel="external">Remote Procedure Calls</a></li>
<li><a href="http://www.grpc.io/docs/guides/error.html" target="_blank" rel="external">gRPC Error Handling</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　RPC当前在大公司的开发中越来越流行了，各大厂的开源RPC框架也呈百花开放的状态。在通过前面的<a href="/201612/learn-note-of-google-grpc.html">文章</a>做了一个对Google出品之gRPC的使用手册，也算是在使用方面有了一个基本的了解。恰巧最近逛别人博客的时候，看到几篇关于RPC原理和设计方面的文章，觉得十分不错，于是这里就将这些文章进行整理，对RPC设计、使用和实现中的那些乱七八糟的问题进行一个归纳总结。</p>
<h1 id="一、RPC的原理和关键点">一、RPC的原理和关键点</h1><h2 id="1-1_RPC的原理">1.1 RPC的原理</h2><p><img src="/post_images/images/201701/796a12cc.png" alt="rpc"><br>　　RPC的原理可以说是再简单不过了，一张图足以说明问题，总体来说会经历以下的步骤：<br>　　(1). client代码像普通函数调用一样调用client stub函数，这个调用是本地调用，调用参数会和平常函数调用一样进行返回地址和调用参数压栈操作；<br>　　(2). client stub会把调用参数和其它信息(比如调用方法名、调用属性等，可以称为metadata)进行打包封装成message，然后通过系统调用发送该message，这个打包的过程是个序列化的过程；<br>　　(3). client寻求到服务端的地址，然后通过本地操作系统经由某种协议，将上述message发送给server端；<br>　　(4). server端的操作系统接收message后将其传递给server stub；]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（六）：基于ZooKeeper的分布式系统的应用场景]]></title>
    <link href="https://taozj.org/201701/learn-note-of-distributed-system-(6)-application.html"/>
    <id>https://taozj.org/201701/learn-note-of-distributed-system-(6)-application.html</id>
    <published>2017-01-14T04:16:15.000Z</published>
    <updated>2017-01-14T15:57:20.000Z</updated>
    <content type="html"><![CDATA[<p>　　至此，Paxos、Raft、ZAB代表着分布式系统中最常见的一致性协议都有所了解，但是除了PaxSql之外，对于分布式系统一致性原理的实际应用还处于一脸懵逼的状态中。此处于是主要借着<a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">《从Paxos到Zookeeper:分布式一致性原理与实践》</a>中的案例，依靠ZooKeeper分布式系统组建，对分布式系统的使用情境做一个简单的了解。毕竟嘛，我又不是做学术的，了解原理后不知道现实有什么用处又有啥意义…<br>　　ZooKeeper扮演者分布式系统的管理和协调框架的作用，通过前面对ZAB和ZooKeeper的了解，ZooKeeper通过ZNode数据模型和序列号、持久和临时节点分类，以及Watcher事件通知机制，可以快速构建分布式应用的核心功能，看看Apache旗下那么多基于ZooKeeper的分布式项目就可晓而知了。ZooKeeper的集群达到3台就可以正常工作了，但是工业上通常认为至少达到5台才是合适的，一方面机器增多集群的可靠性增加了，再次集群工作过程中常常会有机器下线维护的情况，这样在一台机器下线的时候集群还可以容易一台机器宕机而不停止服务。<br><img src="/post_images/images/201701/3ac72ee6.jpg" alt="zookeeper"><br>　　再次说明，个人没什么分布式系统的经验，这些都是查阅资料摘抄得来，如果错误尽请指正，被我误导概不负责！</p>
<p><strong>一、数据发布/订阅(配置中心)</strong> - Publish/Subscribe<br>　　发布/订阅模式不仅仅会出现在这里，通常消息队列的设计中会更加常用到这种模式。发布/订阅模式功能可以分为这几种模式：<br>　　(1). Push模式是服务器主动将数据更新发送给所有订阅的客户端，优点是实时性好，但是服务端的工作比较繁重，常常需要记录各个客户端的状态信息，甚至要考虑消费者的消费能力实现流量控制工作；<br>　　(2). Pull模式则是由客户端主动发起请求来获取最新数据，通常采用定时机制轮训拉取的方式进行，所以实时性较差，但好处是实现简单；<br>　　(3). 还有就是结合两者进行推拉相结合的方式，客户端向服务端注册自己关心的主题，一旦主题数据有所更新，服务端会向对应订阅的客户端发送事件通知，客户端接收到事件通知后主动向服务器拉取最新的数据。<a id="more"></a><br>　　在系统开发中通常会遇到机器列表信息、运行时开关配置、数据库配置等信息，这些数据的特点是<strong>数据规模比较小</strong>、<strong>数据内容在运行时候常常发生动态变更</strong>、<strong>相同的数据在多个机器中共享</strong>。在单机的情况下，可以通过共享内存，或者统一配置文件(可以使用文件系统的特性监测文件变更iNotify)来满足这个需求，但是如果配置需要跨主机，尤其机器规模大且成员会发生变动的情况下共享这些动态信息就较为困难。<br>　　基于ZooKeeper的配置中心方案可以这样设计：首先运行一个ZooKeeper服务器集群，然后在其上面创建周知路径的ZNode；专用的配置管理程序可以修改ZNode上的配置信息，作为用户更新配置的操作接口；关心这些配置的分布式应用启动时候主动获取配置信息一次，然后对ZNode注册Watcher监听，那么当ZNode的数据内容发生变化后，ZooKeeper就可以将这个变更通知发送给所有的客户端，客户端得知这个变更通知后就可以请求获取最新数据。通过这种手段，就可以实现配置信息的集中式管理和动态更新部署的功能了。</p>
<p><strong>二、负载均衡</strong> - Load Balance<br>　　负载均衡在前面的Nginx中也介绍过了，Nginx支持3层和7层软件负载均衡，对用户看来这实际上是实现的基于服务端的负载均衡操作。其实负载均衡还可以在客户端实现，之前介绍的memcached的负载均衡基本都是在客户端通过一致性hash原理实现的。<br>　　通过ZooKeeper实现的负载均衡也是通过客户端来实现的：ZooKeeper创建一个周知路径的ZNode，其数据内容包含了可以提供服务的服务器地址信息，接收服务的客户端在该ZNode上注册Watcher以侦听它的改变。在工作的时候客户端获取提供服务的服务器列表，在接收到修改事前之前可以缓存该列表提高性能，然后服务调用者可以采用自己某种特定负载均衡算法(比如Round Robin、HASH、响应时间、最少连接等算法)选取机器获取服务。<br>　　为了使用方便，服务机器列表的配置可以采用全自动的方式，这也涉及到机器健康度检测问题。可以设计一个健康度探测服务端，并负责更新ZNode中的机器列表：健康度探测服务端可以同机器中的列表建立TCP长连接，健康度探测服务端采用Ping-Pong心跳监测的方式进行健康度监测；也可以机器每隔一定的时间向这个健康度探测服务端发送数据包，如果健康度探测在某个超时时间后仍未收到某机器的数据包，就认定其不可用而将其从机器列表中进行删除。(呃，后面想想，每个服务端机器把自己作为临时ZNode创建在某个路径下，这样的侦测操作不是更加的方便？和集群管理重了)</p>
<p><strong>三、命名服务</strong> - Name Service<br>　　命名服务其实是指明了一种映射关系，在分布式开发中有很多的资源需要命名，比如主机地址，RPC服务列表等，客户端根据名字可以获取资源的实体、服务地址和提供者等信息。<br>　　ZooKeeper提供了方便的API，可以轻松的创建全局唯一的path，这个path就可以作为名称使用，所以ZooKeeper的Name Service是开箱即用的。而且ZNode支持SEQUENTIAL属性，通过创建顺序节点的手法就可以创建具有相同名字但带顺序后缀的这样很具有规则性的名字，这样的命名服务显然在保证命名唯一性的同时更具有解释意义。</p>
<p><strong>四、分布式协调/通知</strong> - Coordinator<br>　　得益于ZooKeeper特有的Watcher注册和异步通知的机制，可以实现分布式环境下不同机器，甚至是不同系统之间的通知和协调工作，以应对于数据变更的实时快速处理，这是和观察者类似的工作模式。而且通过ZooKeepr作为一个事件的中介者，也起到了业务之间解除耦合的效果。</p>
<p><strong>五、集群管理</strong> - Management<br>　　用于对集群中的机器进行监控的情况，主要包括对集群运行状态的收集，以及对集群和集群成员进行操作和控制。<br>　　传统的运维都是基于Agent的分布式集群管理模式，通过在集群成员上部署该类服务软件，该软件负责主动向集群控制中心汇报机器的状态信息。这种方式虽然直接，但是具有着固有的缺陷：很难实现跟业务相关的细化监控，通常都是对CPU、负载等通用信息进行监测；如果整个集群环境一致还可以，否则就必须面对集群中的异构成员进行兼容和适配的问题。<br>　　如果运行一个ZooKeeper集群，不仅通过临时节点在会话结束后会自动消失的特性，可以快速侦测机器的上下线，而且可以通过创建特定的ZNode，集群中的机器就可以向控制中心报告更多主机相关甚至业务相关的信息，而且这一切操作都极为便利，只需要在业务端和控制中心进行适配就可以了。</p>
<p><strong>六、Master选举</strong> - Election<br>　　可以应用于那些只需要一个主节点做特殊的工作，其他节点做普通的工作或者候命作为冗余节点的情况，比如数据库的读写分离可以让Master处理所有的写任务，而剩余的读请求由其他机器负载均衡完成，借此提供整个数据库性能；类似的Master可以单独处理一些复杂的逻辑或者计算，而将计算结果同步共享给集群中的其他主机使用，以此减少重复劳动提高资源利用率。<br>　　传统情况下的选主可以使用数据库唯一性索引简单实现，在此约束下所有的机器创建同一条记录时候只能有一个机器成功，那么可以让这个独一无二的机器作为Master，但是这种方法只是解决了竞争冲突问题，无法解决Master单点故障后整个系统不可用的问题，即不能实现高效快速的动态Master选举功能。<br>　　对此，ZooKeeper的强一致性可以天然解决Master选举的问题(注意这里的选主是客户端的Master，和ZAB协议中的Leader没有关系)：首先ZooKeeper保证在多个客户端请求创建同一路径描述的ZNode的情况下，只会有一个客户端的请求成功；其次创建ZNode可以是临时ZNode，那么一旦创建这个临时ZNode的Master挂掉后会导致会话结束，这个临时ZNode就会自动消失；在之前竞争Master失败的客户端，可以注册该ZNode的Watcher侦听，一旦接收到节点的变更事件，就表示Master不可用了，此时大家就可以即刻再次发起Master选举操作了，以实现了一种高可用的automatic fail-over机制，满足了机器在线率有较高要求的应用场景。<br>　　除了上面的方式，各个主机还可以通过创建临时顺序ZNode的方式，每个主机会具有不同的后缀，一旦当前的Master宕机之后自动轮训下一个可用机器，而下线的机器也可以随时再次上线创建新序列号的临时顺序节点。</p>
<p><strong>七、分布式锁</strong> - Lock<br>　　主要用来进行分布式系统之间的访问资源的同步手段。在使用中分布式锁可以支持这些服务：保持独占、共享使用和时序访问。虽然关系数据库在更新的时候，数据库系统会根据隔离等级自动使用行锁、表锁机制保证数据的完整性，但是数据库通常都是大型系统的性能瓶颈之所在，所以如果使用分布式锁可以起到一定的协调作用，那么可以期待增加系统的运行效率。<br>　　<strong>保持独占</strong>，就是当多个客户端试图获取这把锁的时候，只能有一个可以成功获得该锁，跟上面的Master选举比较类似，当多个竞争者同时尝试创建某个path(例如”_locknode_/guid-lock-“)的ZNode时候，ZooKeeper的一致性能够保证只有一个客户端成功，创建成功的客户端也就拥有了这把互斥锁，此时其他客户端可以在这个ZNode上面注册Watcher侦听，以便得到锁变更(如持锁客户端宕机、主动解锁)的情况采取接下来的操作。<br>　　<strong>共享使用</strong>类似于读写锁的功能，多个读锁可以同时对一个事务可见，但是读锁和写锁以及写锁和写锁之间是互斥的。锁的名字按照类似”/share_lock/[Host]-R/W-SN”的形式创建临时顺序节点，在创建锁的同时读取/share_lock节点下的所有子节点，并注册对/share_lock/节点的Watcher侦听，然后依据读写所的兼容法则检查比自己序号小的节点看是否可以满足当前操作请求，如果不满足就执行等待。当持有锁的节点崩溃或者释放锁之后，所有处于等待状态的节点就都得到了通知，实际中这会产生一个“惊群效应”，所以可以在上面注册/share_lock/的Watcher事件进行细化，只注册比自己小的那个子节点的Watcher侦听就可以了，以避免不必要的唤醒。<br>　　<strong>时序访问</strong>的方式，则是在这个时候每个请求锁的客户端都可以创建临时顺序ZNode的子节点，他们维系着一个带有序列号的后缀，同时添加对锁节点(或者像上面类似优化，只注册序列号比自己小的那个子节点)的Watcher侦听，这样前面的客户端释放锁之后，后面的客户端会得到事件通知，然后按照一定顺序接下来的一个客户端获得锁。该模式能够保证每个客户端都具有访问的机会，但是其是按照创建临时顺序子节点的顺序按次序依次访问的。</p>
<p><strong>八、分布式队列</strong> - Queue<br>　　说到分布式队列，目前已有相当多的成熟消息中间件了。在ZooKeeper的基础上，可以方便地创建先进先出队列，以及对数据进行聚集之后再统一安排处理的Barrier的工作模式。<br>　　先入先出之FIFO队列算是最常见使用的数据模型了，类似于一个生产者-消费者的工作模型。生产者会创建顺序ZNode，这些顺序ZNode的后缀表明了创建的顺序，消费者获得这些顺序ZNode后挑出序列号最小的进行消费，就简单的实现了FIFO的数据类型。<br>　　对于另外一种Barrier(叫做屏障)工作模式，是需要把数据集聚之后再做统一处理，通常在大规模并行计算的场景上会使用到。这种队列实现也很简单，就是在创建顺序ZNode的时候记录队列当前已经拥有的事务数目，如果达到了Barrier的数目，就表示条件就绪了于是创建类似“/synchronizing/start”的ZNode，而等待处理的消费者之前就侦听该ZNode是否被创建，如果侦测到一旦创建了就表明事务的数目满足需求了，于是可以启动处理工作。</p>
<p><strong>小结</strong><br>　　其实，通过上面的查看，基于ZooKeeper实现特定需要的分布式应用是比较方便的，而且更可贵的是，上面的应用都是反反复复基于ZooKeeper的那几条性质实现的！ZooKeeper真是个好东西！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="http://www.ibm.com/developerworks/library/bd-zookeeper/" target="_blank" rel="external">ZooKeeper fundamentals, deployment, and applications</a></li>
<li><a href="http://zookeeper.apache.org/doc/trunk/recipes.html" target="_blank" rel="external">ZooKeeper Recipes and Solutions</a></li>
<li><a href="https://my.oschina.net/galenz/blog/315240" target="_blank" rel="external">ZooKeeper典型应用场</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/" target="_blank" rel="external">分布式服务框架 Zookeeper – 管理分布式环境中的数据</a> </li>
<li><a href="https://www.nginx.com/blog/nginx-and-zookeeper-dynamic-load-balancing-and-deployments/" target="_blank" rel="external">NGINX and ZooKeeper, Dynamic Load Balancing and Deployments</a></li>
<li><a href="http://www.kuqin.com/system-analysis/20111120/315148.html" target="_blank" rel="external">ZooKeeper典型使用场景一览</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　至此，Paxos、Raft、ZAB代表着分布式系统中最常见的一致性协议都有所了解，但是除了PaxSql之外，对于分布式系统一致性原理的实际应用还处于一脸懵逼的状态中。此处于是主要借着<a href="https://book.douban.com/subject/26292004/">《从Paxos到Zookeeper:分布式一致性原理与实践》</a>中的案例，依靠ZooKeeper分布式系统组建，对分布式系统的使用情境做一个简单的了解。毕竟嘛，我又不是做学术的，了解原理后不知道现实有什么用处又有啥意义…<br>　　ZooKeeper扮演者分布式系统的管理和协调框架的作用，通过前面对ZAB和ZooKeeper的了解，ZooKeeper通过ZNode数据模型和序列号、持久和临时节点分类，以及Watcher事件通知机制，可以快速构建分布式应用的核心功能，看看Apache旗下那么多基于ZooKeeper的分布式项目就可晓而知了。ZooKeeper的集群达到3台就可以正常工作了，但是工业上通常认为至少达到5台才是合适的，一方面机器增多集群的可靠性增加了，再次集群工作过程中常常会有机器下线维护的情况，这样在一台机器下线的时候集群还可以容易一台机器宕机而不停止服务。<br><img src="/post_images/images/201701/3ac72ee6.jpg" alt="zookeeper"><br>　　再次说明，个人没什么分布式系统的经验，这些都是查阅资料摘抄得来，如果错误尽请指正，被我误导概不负责！</p>
<p><strong>一、数据发布/订阅(配置中心)</strong> - Publish/Subscribe<br>　　发布/订阅模式不仅仅会出现在这里，通常消息队列的设计中会更加常用到这种模式。发布/订阅模式功能可以分为这几种模式：<br>　　(1). Push模式是服务器主动将数据更新发送给所有订阅的客户端，优点是实时性好，但是服务端的工作比较繁重，常常需要记录各个客户端的状态信息，甚至要考虑消费者的消费能力实现流量控制工作；<br>　　(2). Pull模式则是由客户端主动发起请求来获取最新数据，通常采用定时机制轮训拉取的方式进行，所以实时性较差，但好处是实现简单；<br>　　(3). 还有就是结合两者进行推拉相结合的方式，客户端向服务端注册自己关心的主题，一旦主题数据有所更新，服务端会向对应订阅的客户端发送事件通知，客户端接收到事件通知后主动向服务器拉取最新的数据。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（五）：ZooKeeper之ZAB一致性协议]]></title>
    <link href="https://taozj.org/201701/learn-note-of-distributed-system-(5)-zab-consensus.html"/>
    <id>https://taozj.org/201701/learn-note-of-distributed-system-(5)-zab-consensus.html</id>
    <published>2017-01-13T14:25:15.000Z</published>
    <updated>2017-01-14T06:26:28.000Z</updated>
    <content type="html"><![CDATA[<p>　　得益于Zookeeper在生产环境的广为使用，ZAB(ZooKeeper Atomic Broadcast，ZooKeeper原子消息广播协议)可算是最广泛应用的分布式一致性协议了，其是对Paxos算法进行了大量的改进后形成的分布式系统数据一致性协议。当之前了解Paxos和Raft算法后，落下ZAB总觉得欠缺了那么点什么。查看资料发现ZooKeeper是2007年开始开发的，而Raft算法2013年才正式发布，所以Raft中的一些设计难免会借鉴ZAB，两者存在了很多相似之处，不过多了解多掌握，想必对于分布式系统原理的融汇贯通还是会大有裨益的！</p>
<h1 id="一、前言">一、前言</h1><p>　　首先强调一点，无论是ZAB还是Raft，作为生产环境都极度强调了事务严格按照客户端请求的顺序提交，这一点在<a href="https://cwiki.apache.org/confluence/display/ZooKeeper/Zab+vs.+Paxos" target="_blank" rel="external">Zab+vs.+Paxos</a>中解释的很清楚：<br>　　Paxos注重的是一个状态机模型，一致性协议保证所有的状态机副本以相同的顺序执行相同的指令，那么所有状态机可以保证以相同的状态变化进行转移。而为了性能方面的考虑，一致性算法都允许客户端提出多个提议，当客户端并行或者重叠地提出多个决议的情况。在MultiPaxos就有了提交窗口的概念，但是在某个时刻点Leader发生崩溃后，对应的提交窗口中的提案可能有的提案被提交，有提案未被提交，那么新选出来的Leader可以按照任何顺序重新组织这些提案的表决和提交顺序，甚至也有可能会被丢弃掉。所以，Paxos算法没能够保证严格的因果一致性。<br>　　ZAB和Raft注重的是主备(primary-backup)工作模式，各个副本节点会严格按照Leader接收到客户端请求的顺序进行提交，所以可以描述为一种可靠的增量状态更新。客户端可以提出多个决议，这些决议保证会按照FIFO的顺序被提交，即便在Leader崩溃后发生Leader选取的情况下也会有此保证。虽然，Paxos可以不开启提交窗口的功能，任何时候都只允许有一个未提交的决议，那么就可以得到严格序列化的状态转移，但是相比ZAB和Raft这种专门设计优化过的一致性协议，性能会大打折扣；还有就是Paxos算法可以通过将多个提案封包成batch模式，然后整体显露作为一个提案来表决处理(PhxPaxos有这么一个特性)以提高性能，但是按照Paper所述这些改进措施不见得性能会有多大的提高。<br><a id="more"></a><br>　　可能是我看的文献比较旧吧，没有介绍到ZooKeeper成员的自动变更，只能通过重启集群的方式才能变更成员。后面看手册知道3.5.0开始支持动态成员变更，不过该版本目前仍然处于alpha状态，所以生产环境目前暂且还是持观望态度吧。所以这点来说，Raft算法通过产生一个过渡一致性状态，可以在不停服务进行动态成员变更，算是做的比较好的。<br>　　从ZooKeeper官方的项目列表观来，其已经扮演者一个通用分布式系统的库或者框架的角色了，通过将分布式系统中一致性这个最复杂、最本质的问题进行实现和封装，同时向上提供简洁统一的数据模型和操作接口，就可以在该基础之上快速构建分布式应用了。</p>
<h1 id="二、ZAB协议的基本知识">二、ZAB协议的基本知识</h1><p>　　ZooKeeper对外展现的是一颗类似Unix文件系统的树形数据模型(形如/foo/path1)，其基本元素称之为数据节点(ZNode)，ZNode并不是用来存储实际的数据，而是代表着一种状态信息。ZNode可以分为持久节点和临时节点两种类型：持久节点是一旦创建后，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存；临时节点的生命周期和客户端会话相绑定的，一旦客户端会话失效，那么这个临时节点将会被自动移除。同时，ZAB还可选对每个ZNode附加一个SEQUENTIAL属性，具有这样属性的节点在创建的时候，ZooKeeper会在其尾部追加一个递增的整形数字，这样不仅可以用于创建多个ZNode，而且某种形式上保留了一种次序信息。然后通过提供ZNode的创建、删除、侦听(Watcher)等接口，加上ZNode持久性和临时性的特点，就可以实现集群选主、消息队列等各种分布式服务和模型。<br>　　ZAB也是在协议中，规定集群中只有唯一的Leader，负责处理所有客户端的变更事务请求，通过广播的形式将事务传输到其他Fellower节点上形成副本，每当Fellower接收到事务后首先将其以事务日志的形式固化保存到本地，并向Leader返回Ack确认信息；当Leader一旦收到超过半数的Fellower节点的Ack反馈后，Leader就会再次向所有的Fellower节点发送Commit消息进行事务提交。这种主备的工作形式和2PC十分相像，但是两者还是有着本质的差异。还有，ZAB保证会按照客户端的事务请求顺序执行事务提交的，因此保证了严格的因果一致性。<br>　　从Client的角度上，Client可以向集群的任何一台机器发送请求，如果该请求会引发状态机的改变(非只读请求)，就会被转发到Leader节点；而任何节点都可以直接处理Client的只读类请求，这样一定程度上保证了系统的高可用性，而Client如果想要保证只读请求事务得到的副本是最新的，可以向其直接连接的服务器发送sync请求。在ZAB中，所有更新事务都会由一个64位的事务编号ZXID来标示，这也是实现前面严格提交顺序的基础，ZXID的高32位代表了Leader的周期epoch编号而低32位是一个简单连续单调递增的计数器，Leader接收到客户端的每一个请求，在产生新事务的时候都会对该计数值+1；每当选举产生一个新的Leader的时候，就会从这个Leader服务器上取出本地日志最大事务Proposal的ZXID，并提取出周期epoch进行+1，然后低32位置零从新开始计数。<br><img src="/post_images/images/201701/f29a71e6.png" alt="p-a-c"><br>　　在工作过程中，任意时刻集群中的任意节点都可能随时崩溃退出，ZAB保证了在大多数集群成员正常工作的情况下，整个集群也能够正常工作。</p>
<h1 id="三、ZAB协议中四个Phase介绍">三、ZAB协议中四个Phase介绍</h1><p>　　ZAB协议规定了整个集群所有节点具有4个Phase阶段：在Phase0会进行Leader Election选主操作，后面会依次经历Discovery、Synchronization、Broadcast状态的迭代。集群稳定工作的时候节点会一直处于Phase Broadcast响应客户端的请求，该阶段下集群的工作模式类似于2PC两阶段提交，但是没有2PC中的中断事务的情况，即没有事务回滚情况的发生，同时ZAB也不必等待所有成员的Ack响应，只要过半服务器回复Ack应答之后就可以进行事务提交了，从而允许少部分Fellower非正常的情况下整个集群仍然工作。集群的Leader和Fellower会通过心跳信息保持相互感知，Fellower会向Leader发送心跳消息，如果Leader在指定的超时时间内不能够得到过半数目Fellower的消息，其就会终止当前任期的Leader角色，所有的Fellower也会放弃该Leader，进入到Phase 0阶段重新进行选主；而Fellower如果在超时之后没有收到Leader的消息，也会切换到Phase 0选主的状态。<br>　　对于每个节点，需要关注以下几个持久化变量的状体，他们跟节点的工作和Phase阶段的切换密切相关：<br>　　<em>history</em>：已经被接收的提案的日志信息<br>　　<em>acceptedEpoch</em>：接受到的最后一个NEWEPOCH消息的epoch<br>　　<em>currentEpoch</em>：接受到的最后一个NEWLEADER消息的epoch<br>　　<em>lastZxid</em>：history中最后一个提案的ZXID编号</p>
<h2 id="3-1_阶段0:_Leader_Election">3.1 阶段0: Leader Election</h2><p>　在ZAB中并没有强制某种Leader选取算法，只需要能够得到集群中过半数的vote选票，该节点就可以成为Leader。后面我们会看到，ZooKeeper实现了一个FLE快速选主算法。要注意，只有进入Phase3阶段，Leader的身份才真正的确定，在此之前都是每个节点记录自己所投的prospective Leader，后面要进行一个恢复状态(数据同步)的过程。</p>
<h2 id="3-2_阶段1:_Discovery">3.2 阶段1: Discovery</h2><p>　　在这个阶段，虽然prospective leader只是一种一对一的关系，但是候选Leader肯定是集群中过半数机器的prospective leader。此时所有节点会把自己的F:acceptedEpoch通过FOLLOWERINFO发送给自己的prospective leader，当那个候选Leader得到过半的FOLLOWERINFO消息时候，会在收到消息中取出所见最大的epoch并将其递增，这样之前的Leader就不能再提交新的提案了，然后该候选Leader再将这个新epoch通过NEWEPOCH消息发回给这些节点并等待确认。<br>　　在Fellower节点收到候选Leader发送NEWEPOCH后，将其与自己本地的<em>acceptedEpoch</em>对比，如果比他们大就更新自己<em>acceptedEpoch</em>，并返回ACKEPOCH消息后进入Phase 2，否则切换会Phase 0状态。候选Leader也只能在收到过半数目的ACKEPOCH才会进入Phase 2。需要注意的是这里Fellower发送的ACKEPOCH包含了额外的重要信息——自己最新提交日志，这样候选Leader在收集ACKEPOCH的同时就知道哪个Fellower具有最新提交了，选定到这个具有最新提交的Fellower后向其同步日志。<br><img src="/post_images/images/201701/82529f2f.png" alt="discovery"><br>　　可见，这个Discovery就是要在过半机器中发现最大提案，使得候选Leader在创建一个新epoch周期的同时，也向具有最新提交的Fellower节点同步得到最新提交日志，方便了下一步向其他Fellower同步日志信息。</p>
<h2 id="3-3_阶段2:_Synchronization">3.3 阶段2: Synchronization</h2><p>　　进入这个阶段后，候选Leader已经确立了最新任期号和最新提交日志，然后他会把自己的<em>history</em>通过新epoch作为NEWLEADER消息发送给所有的集群成员，集群成员更新自己<em>currentEpoch</em> 并按需同步<em>history</em>信息。完成这个步骤后候选Fellower向Leader发送ACKNEWLEADER消息，而候选Leader得到过半数目的ACKNEWLEADER消息后，会向所有的Fellower发送COMMIT并进入Phase 3，而Fellower接收到COMMIT命令而完成提交后，也会切换到Phase 3。<br><img src="/post_images/images/201701/a9bc7cc4.png" alt="sync"></p>
<h2 id="3-4_阶段3:_Broadcast">3.4 阶段3: Broadcast</h2><p>　　到达这个阶段后，所有节点检查自己的prospective leader，如果发现它是自己，就切换到正式Leader的状态，不是这种情况的节点切换到正式Fellower的状态，而一致性协议保证此时只可能会有一个Leader。这是整个集群稳定工作状态，其基本流程也类似于上面提到的Propose-ACK-COMMIT的伪2PC操作，只要。<br><img src="/post_images/images/201701/f57029c1.png" alt="broadcast"><br>　　因为只需要得到集群中过半机器的支持，Leader就可以通过上面Phase的迭代而成为新epoch的正式Leader。那些落后的Fellower也允许加入到这个新epoch中来，我们看见Leader仍然保持接受FOLLOWERINFO消息的请求，然后直接返回NEWEPOCH和NEWLEADER消息，接收到该消息的Fellower更新epoch并同步日志后ACKNEWLEADER，接着Leader发送COMMIT命令让其提交。<br>　　在这个阶段，还有一点需要额外注意的是当某个Fellower因为某种原因错过了某些提交，而当前接收到的Leader的提案和自己提交历史之间存在空洞的情况。在图上我们看到存在outstanding transaction的时候Fellower的处理的方式就是<em>Do nothing(wait)</em>，我还没看到具体的实现是什么意思，难道是要阻塞自己到超时，然后通过上面的机制进入Phase 2 Synchronization进行提交事务同步么？</p>
<h1 id="四、ZooKeeper中的FLE选主约束">四、ZooKeeper中的FLE选主约束</h1><h2 id="4-1_一致性算法的选主要求">4.1 一致性算法的选主要求</h2><p>　　分布式系统一致性协议中的重点和难点，就是在Leader崩溃后集群选举出新的Leader，在这种临界情况下对于未完成的提案的正确处理。安全的一致性协议应当保证：<br>　　(1). 确保那些已经在Leader服务器提交的事务，最终都会被所有的服务器提交。<br>　　其临界情况就是当Leader获得绝大多数Ack反馈，但是在其将Commit消息发送给所有Fellower之前崩溃了(已经发出但是Fellower没有收到)；<br>　　(2). 确保丢弃那些只在Leader服务器上仅被提出的事务。<br>　　其临界情况比如Leader在提出一个事务之后就崩溃退出了，而后来该Leader复活后再次加入集群中时候，ZAB协议需要确保丢弃这个事务；<br>　　如果集群中任意一个Fellower都可以被选取成为候选Leader，那么候选Leader就需要通过上面Phase 1 Discovery的方式搜集所有Fellower的提交信息以寻找得到具有最新提案的Fellower并与其进行同步，然后在Phase 2阶段候选Leader以自己作为标杆再将最新提交信息发送给那些落后的Fellower。而如果让选主算法能够保证新选举出来的候选Leader拥有集群中所有机器最高事务编号(ZXID)的事务，那么就可以保证新选举出来的Leader一定具有所有已经提交的提案了，则Phase 1的工作就可以被省略掉了！</p>
<h2 id="4-2_FLE选主算法下的Phase转化">4.2 FLE选主算法下的Phase转化</h2><p>　　ZAB协议没有对Phase 0选主协议具体化，通过任何方式获得绝大多数Fellower的vote都可以成为候选Leader进而进入Phase 1阶段，而由上面可知Phase 1的主要职责就是产生新的epoch，同时发现具有最新提交日志的Fellower并向其同步提交日志。在ZooKeeper的实现中，设计了一种叫做FLE的选主算法，在要求候选Leader获得绝大多数vote的同时增加了一条额外的约束：<strong>候选Leader必须在绝大多数成员中具有最新的提交历史</strong>，这种约束条件下产生Leader后就可以直接忽略Phase 1阶段的操作了(看看，这个跟Raft的选主约束是何其的相似啊！)。然后，论文中将Phase 1和Phase 2结合起来称之为Phase Recovery。<br>　　Phase Recovery的工作过程和Phase 2的情况很不相同，此时选举出来的Leader成为了正式的标杆。同样在这个阶段开始的时候，Fellower会向自己的prospective leader发送自己最新提案号<em>lastZxid</em>，候选Leader接收到该消息后同自己的<em>lastCommittedZxid</em>进行比对，并根据比对结果反馈响应的消息类型：<br>　　(1). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要大，则Leader向其发送TRUNC消息，使该Fellower中不应当被提交的议案被丢弃掉；<br>　　(2). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要小，但是比<em>oldThreshold</em>要大，则发送两者的差异DIFF消息完成同步；<br>　　(3). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要小，而且比<em>oldThreshold</em>还要小，说明该Fellower已经太过于落后了，候选Leader直接发送完整SNAP快照给Fellower使其进行更新；<br>　　当Fellower接收到上面的消息后，根据消息类型对自己的提交进行同步更新，然后向候选Leader发送ACKNEWLEADER确认信息，自己进入Phase 3；而当候选Leader接收到过半的ACKNEWLEADER信息后，自己也进入Phase 3成为正式Leader。<br><img src="/post_images/images/201701/3939446f.png" alt="broadcast"></p>
<h2 id="4-3_ZooKeeper中FLE算法简介">4.3 ZooKeeper中FLE算法简介</h2><p>　　FLE的算法流程还是比较复杂的，这里先不细究了，后面可以找个时间单独理一下，这里先描述一下大概的思路。<br>　　使用FLE算法的目的，就是要选出具有最大提交历史的节点作为候选Leader，这样后续的日志就只需要考虑候选Leader到其他Fellower节点的单向同步就可以保证一致性了。在FLE算法中通过筛选具有最大<em>lastZxid</em>的节点作为候选Leader，因为具有最大<em>lastZxid</em>的节点肯定具有最全的提交历史。<br>　　在FLE算法中，每个节点都只能投一张选票，只有这样才能确定过半选票的统计值，其思路就是在投票的过程中，节点之间互相交换信息，然后节点根据自己获得的信息(发现更好的候选者)不断地更新自己手中的选票，更新的标准就是具有更新的提案号：要么具有更新的epoch，或者在相同epoch下具有更大的编号。那么这个迭代更新的过程什么时候结束呢？<br>　　首先，每一轮的选取会有一个递增的round number作为标识，这个值越高优先级越高；其次，每一个节点都有一个状态标识自己：election和leading/fellowing，同时每个节点都知道集群中其他节点的个数，以及和他们通信的方式。选举刚刚开始的时候，每个节点在没有先验信息的情况下都把选票投向自己，并把这个消息发送给所有的节点，然后等待其他节点们的响应，节点再收到这个消息的时候：<br>　　(1). 如果选票的round number比较旧，则忽略之；<br>　　(2). 如果选票的round number比自己新，则更新自己的round number，并清空上一轮相关的陈旧信息，开始广播自己新的选票；<br>　　(3). 如果是在同一轮投票中：如果接收到的选票的角色是election，并且该消息附带更新的提案号，则更新自己的选票并继续广播自己的选票；如果收到的选票角色是election，但是消息的提案号比自己旧或者跟自己一样，则记录这张选票，而检查发现自己得到针对某个节点超过集群半数的选票，自己切换为leading/fellowing状态，并转入Phase Recovery；<br>　　(4). 任何时候一旦收到leading/fellowing的选票，都指明当前集群中已有有效的候选Leader了，直接更新自己切换入Phase Recovery阶段；<br>　　千言万语，还是伪代码图比较的清晰明了：<br><img src="/post_images/images/201701/80a7b6ef.png" alt="FLE"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到ZooKeeper:分布式一致性原理与实践</a></li>
<li><a href="http://www.ibm.com/developerworks/library/bd-zookeeper/" target="_blank" rel="external">ZooKeeper fundamentals, deployment, and applications</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos" target="_blank" rel="external">Zab+vs.+Paxos</a></li>
<li><a href="http://www.tcs.hut.fi/Studies/T-79.5001/reports/2012-deSouzaMedeiros.pdf" target="_blank" rel="external">ZooKeeper’s atomic broadcast protocol: Theory and practice</a></li>
<li><a href="https://distributedalgorithm.wordpress.com/2015/06/20/architecture-of-zab-zookeeper-atomic-broadcast-protocol/" target="_blank" rel="external">Architecture of ZAB – ZooKeeper Atomic Broadcast protocol</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　得益于Zookeeper在生产环境的广为使用，ZAB(ZooKeeper Atomic Broadcast，ZooKeeper原子消息广播协议)可算是最广泛应用的分布式一致性协议了，其是对Paxos算法进行了大量的改进后形成的分布式系统数据一致性协议。当之前了解Paxos和Raft算法后，落下ZAB总觉得欠缺了那么点什么。查看资料发现ZooKeeper是2007年开始开发的，而Raft算法2013年才正式发布，所以Raft中的一些设计难免会借鉴ZAB，两者存在了很多相似之处，不过多了解多掌握，想必对于分布式系统原理的融汇贯通还是会大有裨益的！</p>
<h1 id="一、前言">一、前言</h1><p>　　首先强调一点，无论是ZAB还是Raft，作为生产环境都极度强调了事务严格按照客户端请求的顺序提交，这一点在<a href="https://cwiki.apache.org/confluence/display/ZooKeeper/Zab+vs.+Paxos">Zab+vs.+Paxos</a>中解释的很清楚：<br>　　Paxos注重的是一个状态机模型，一致性协议保证所有的状态机副本以相同的顺序执行相同的指令，那么所有状态机可以保证以相同的状态变化进行转移。而为了性能方面的考虑，一致性算法都允许客户端提出多个提议，当客户端并行或者重叠地提出多个决议的情况。在MultiPaxos就有了提交窗口的概念，但是在某个时刻点Leader发生崩溃后，对应的提交窗口中的提案可能有的提案被提交，有提案未被提交，那么新选出来的Leader可以按照任何顺序重新组织这些提案的表决和提交顺序，甚至也有可能会被丢弃掉。所以，Paxos算法没能够保证严格的因果一致性。<br>　　ZAB和Raft注重的是主备(primary-backup)工作模式，各个副本节点会严格按照Leader接收到客户端请求的顺序进行提交，所以可以描述为一种可靠的增量状态更新。客户端可以提出多个决议，这些决议保证会按照FIFO的顺序被提交，即便在Leader崩溃后发生Leader选取的情况下也会有此保证。虽然，Paxos可以不开启提交窗口的功能，任何时候都只允许有一个未提交的决议，那么就可以得到严格序列化的状态转移，但是相比ZAB和Raft这种专门设计优化过的一致性协议，性能会大打折扣；还有就是Paxos算法可以通过将多个提案封包成batch模式，然后整体显露作为一个提案来表决处理(PhxPaxos有这么一个特性)以提高性能，但是按照Paper所述这些改进措施不见得性能会有多大的提高。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[【置顶】博客资源收录大全]]></title>
    <link href="https://taozj.org/201701/blog-collection.html"/>
    <id>https://taozj.org/201701/blog-collection.html</id>
    <published>2017-01-09T14:40:48.000Z</published>
    <updated>2017-02-24T10:14:09.000Z</updated>
    <content type="html"><![CDATA[<p>　　虽然当下微信公众号席卷自媒体之势如火如荼，但是文章展示个人还是偏向于独立博客的方式，主要是因为个人可以控制的东西比较多。我想，对于我来说，这个时代没有什么比个性和自由更为重要的了吧。<br>　　下面是一些网络知名人士的博客，以及在搜索资料过程中遇到的好站点。除了不感兴趣的前端、移动端外，过于Java/Nodejs等语言化的博客也被KO了，希望平时没事多看看吧！<br><a id="more"></a></p>
<h1 id="一、技术大拿">一、技术大拿</h1><ol>
<li><a href="http://coolshell.cn" target="_blank" rel="external">Coolshell</a></li>
<li><a href="https://timyang.net/" target="_blank" rel="external">后端技术 by Tim Yang</a></li>
<li><a href="http://blog.codingnow.com/" target="_blank" rel="external">云风的 BLOG</a></li>
<li><a href="http://blog.csdn.net/solstice" target="_blank" rel="external">陈硕的Blog</a></li>
<li><a href="http://www.ruanyifeng.com/blog/" target="_blank" rel="external">阮一峰的网络日志</a></li>
<li><a href="http://calvin1978.blogcn.com/" target="_blank" rel="external">花钱的年华</a></li>
<li><a href="http://blog.csdn.net/myan" target="_blank" rel="external">孟岩</a></li>
<li><a href="http://purecpp.org/" target="_blank" rel="external">知行一</a></li>
<li><a href="http://www.yanmingming.net/" target="_blank" rel="external">心静志远</a></li>
<li><a href="http://jinnianshilongnian.iteye.com/" target="_blank" rel="external">开涛的博客</a></li>
<li><a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">廖雪峰的官方网站</a></li>
</ol>
<h1 id="二、团队博客">二、团队博客</h1><ol>
<li><a href="https://yq.aliyun.com/" target="_blank" rel="external">云栖</a></li>
<li><a href="http://tech.meituan.com/" target="_blank" rel="external">美团技术团队</a></li>
<li><a href="http://mogu.io/" target="_blank" rel="external">蘑菇街技术博客</a></li>
<li><a href="http://jm.taobao.org/" target="_blank" rel="external">阿里中间件团队博客</a></li>
<li><a href="http://wetest.qq.com/lab" target="_blank" rel="external">腾讯质量开放平台</a></li>
<li><a href="http://kernel.taobao.org/index.php" target="_blank" rel="external">淘宝内核组</a></li>
<li><a href="https://www.oschina.net/translate/list?type=2&amp;p=57" target="_blank" rel="external">oschina 翻译</a></li>
<li><a href="https://theboostcpplibraries.com/" target="_blank" rel="external">The Boost C++ Libraries</a></li>
<li><a href="http://githubengineering.com/" target="_blank" rel="external">GitHub Engineering</a></li>
<li><a href="https://blogs.dropbox.com/tech/" target="_blank" rel="external">Dropbox Tech Blog</a></li>
<li><a href="http://aosabook.org/en/index.html" target="_blank" rel="external">The Architecture of Open Source Applications</a></li>
</ol>
<h1 id="三、博客推荐">三、博客推荐</h1><ol>
<li><a href="https://akrzemi1.wordpress.com/" target="_blank" rel="external">Andrzej’s C++ blog</a></li>
<li><a href="http://www.lenky.info/" target="_blank" rel="external">Lenky个人站点</a></li>
<li><a href="https://imququ.com" target="_blank" rel="external">Jerry Qu的小站</a></li>
<li><a href="http://www.lenky.info/" target="_blank" rel="external">Dev Articles - C++</a></li>
<li><a href="http://natsys-lab.blogspot.com/" target="_blank" rel="external">High Performance Linux</a></li>
<li><a href="http://blog.csdn.net/hsly_support" target="_blank" rel="external">白水煮鸡蛋</a></li>
<li><a href="http://microcai.org/" target="_blank" rel="external">菜菜博士 - 博士在网络的家</a></li>
<li><a href="http://aosabook.org/en/index.html" target="_blank" rel="external">The Architecture of Open Source Applications</a></li>
<li><a href="http://proprogramming.org/category/cpp-codes/" target="_blank" rel="external">Pro Programming - C++</a></li>
<li><a href="http://blog.brucefeng.info/" target="_blank" rel="external">brucefeng</a></li>
<li><a href="http://www.ideawu.net/" target="_blank" rel="external">idea’s blog</a></li>
</ol>
<h1 id="四、友情链接">四、友情链接</h1><ol>
<li><a href="http://www.lxy520.net/" target="_blank" rel="external">东方星痕</a></li>
<li><a href="https://wujunze.com/" target="_blank" rel="external">吴钧泽博客</a></li>
<li><a href="http://www.vitah.net/" target="_blank" rel="external">Vitah’s Blog</a></li>
<li><a href="http://littlewin.info/" target="_blank" rel="external">LITTLEWIN’S BLOG</a></li>
<li><a href="https://www.liurongxing.com/" target="_blank" rel="external">刘荣星的博客</a></li>
<li><a href="http://littlewin.info/" target="_blank" rel="external">LITTLEWIN’S BLOG</a></li>
</ol>
<p>持续更新中，同时欢迎投递收录……</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　虽然当下微信公众号席卷自媒体之势如火如荼，但是文章展示个人还是偏向于独立博客的方式，主要是因为个人可以控制的东西比较多。我想，对于我来说，这个时代没有什么比个性和自由更为重要的了吧。<br>　　下面是一些网络知名人士的博客，以及在搜索资料过程中遇到的好站点。除了不感兴趣的前端、移动端外，过于Java/Nodejs等语言化的博客也被KO了，希望平时没事多看看吧！<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="博客" scheme="https://taozj.org/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="杂七杂八" scheme="https://taozj.org/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Linux服务器的那些性能参数指标]]></title>
    <link href="https://taozj.org/201701/linux-performance-basic.html"/>
    <id>https://taozj.org/201701/linux-performance-basic.html</id>
    <published>2017-01-03T15:24:43.000Z</published>
    <updated>2017-02-24T08:39:30.000Z</updated>
    <content type="html"><![CDATA[<p>　　一个基于Linux操作系统的服务器运行的同时，也会表征出各种各样参数信息。通常来说运维人员、系统管理员会对这些数据会极为敏感，但是这些参数对于开发者来说也十分重要，尤其当你的程序非正常工作的时候，这些蛛丝马迹往往会帮助快速定位跟踪问题。<br>　　这里只是一些简单的工具查看系统的相关参数，当然很多工具也是通过分析加工/proc、/sys下的数据来工作的，而那些更加细致、专业的性能监测和调优，可能还需要更加专业的工具(perf、systemtap等)和技术才能完成哦。毕竟来说，系统性能监控本身就是个大学问。<br><img src="/post_images/images/201701/76667dfc.png" alt="linux-performance"></p>
<h1 id="一、CPU和内存类">一、CPU和内存类</h1><h2 id="1-1_top">1.1 top</h2><p>　　<code bash="">➜  ~ top</code><br><img src="/post_images/images/201701/bbbd0eb3.png" alt="linux-top"><br>　　第一行后面的三个值是系统在之前1、5、15的平均负载，也可以看出系统负载是上升、平稳、下降的趋势，当这个值超过CPU可执行单元的数目，则表示CPU的性能已经饱和成为瓶颈了。</p>
<p>　　第二行统计了系统的任务状态信息。running很自然不必多说，包括正在CPU上运行的和将要被调度运行的；sleeping通常是等待事件(比如IO操作)完成的任务，细分可以包括interruptible和uninterruptible的类型；stopped是一些被暂停的任务，通常发送SIGSTOP或者对一个前台任务操作Ctrl-Z可以将其暂停；zombie僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的task descriptor需要父进程访问后才能释放，这种进程显示为defunct状态，无论是因为父进程提前退出还是未wait调用，出现这种进程都应该格外注意程序是否设计有误。<br><a id="more"></a><br>　　第三行CPU占用率根据类型有以下几种情况：<br>　　(us) user: CPU在低nice值(高优先级)用户态所占用的时间(nice&lt;=0)。正常情况下只要服务器不是很闲，那么大部分的CPU时间应该都在此执行这类程序<br>　　(sy) system: CPU处于内核态所占用的时间，操作系统通过系统调用(system call)从用户态陷入内核态，以执行特定的服务；通常情况下该值会比较小，但是当服务器执行的IO比较密集的时候，该值会比较大<br>　　(ni) nice: CPU在高nice值(低优先级)用户态以低优先级运行占用的时间(nice&gt;0)。默认新启动的进程nice=0，是不会计入这里的，除非手动通过renice或者setpriority()的方式修改程序的nice值<br>　　(id) idle: CPU在空闲状态(执行kernel idle handler)所占用的时间<br>　　(wa) iowait: 等待IO完成做占用的时间<br>　　(hi) irq: 系统处理硬件中断所消耗的时间<br>　　(si) softirq: 系统处理软中断所消耗的时间，记住软中断分为softirqs、tasklets(其实是前者的特例)、work queues，不知道这里是统计的是哪些的时间，毕竟work queues的执行已经不是中断上下文了<br>　　(st) steal: 在虚拟机情况下才有意义，因为虚拟机下CPU也是共享物理CPU的，所以这段时间表明虚拟机等待hypervisor调度CPU的时间，也意味着这段时间hypervisor将CPU调度给别的CPU执行，这个时段的CPU资源被”stolen”了。这个值在我KVM的VPS机器上是不为0的，但也只有0.1这个数量级，是不是可以用来判断VPS超售的情况？<br>　　CPU占用率高很多情况下意味着一些东西，这也给服务器CPU使用率过高情况下指明了相应地排查思路：<br>　　(a) 当user占用率过高的时候，通常是某些个别的进程占用了大量的CPU，这时候很容易通过top找到该程序；此时如果怀疑程序异常，可以通过perf等思路找出热点调用函数来进一步排查；<br>　　(b) 当system占用率过高的时候，如果IO操作(包括终端IO)比较多，可能会造成这部分的CPU占用率高，比如在file server、database server等类型的服务器上，否则(比如&gt;20%)很可能有些部分的内核、驱动模块有问题；<br>　　(c) 当nice占用率过高的时候，通常是有意行为，当进程的发起者知道某些进程占用较高的CPU，会设置其nice值确保不会淹没其他进程对CPU的使用请求；<br>　　(d) 当iowait占用率过高的时候，通常意味着某些程序的IO操作效率很低，或者IO对应设备的性能很低以至于读写操作需要很长的时间来完成；<br>　　(e) 当irq/softirq占用率过高的时候，很可能某些外设出现问题，导致产生大量的irq请求，这时候通过检查/proc/interrupts文件来深究问题所在；<br>　　(f) 当steal占用率过高的时候，黑心厂商虚拟机超售了吧！</p>
<p>　　第四行和第五行是物理内存和虚拟内存(交换分区)的信息:<br>　　total = free + used + buff/cache，现在buffers和cached Mem信息总和到一起了，但是buffers和cached<br>Mem的关系很多地方都没说清楚。其实通过对比数据，这两个值就是/proc/meminfo中的Buffers和Cached字段：Buffers是针对raw disk的块缓存，主要是以raw block的方式缓存文件系统的元数据(比如超级块信息等)，这个值一般比较小(20M左右)；而Cached是针对于某些具体的文件进行读缓存，以增加文件的访问效率而使用的，可以说是用于文件系统中文件缓存使用。<br>　　而avail Mem是一个新的参数值，用于指示在不进行交换的情况下，可以给新开启的程序多少内存空间，大致和free + buff/cached相当，而这也印证了上面的说法，free + buffers + cached Mem才是真正可用的物理内存。并且，使用交换分区不见得是坏事情，所以交换分区使用率不是什么严重的参数，但是频繁的swap in/out就不是好事情了，这种情况需要注意，通常表示物理内存紧缺的情况。</p>
<p>　　最后是每个程序的资源占用列表，其中CPU的使用率是所有CPU core占用率的总和。通常执行top的时候，本身该程序会大量的读取/proc操作，所以基本该top程序本身也会是名列前茅的。<br>　　top虽然非常强大，但是通常用于控制台实时监测系统信息，不适合长时间(几天、几个月)监测系统的负载信息，同时对于短命的进程也会遗漏无法给出统计信息。</p>
<h2 id="1-2_vmstat">1.2 vmstat</h2><p>　　vmstat是除top之外另一个常用的系统检测工具，下面截图是我用-j4编译boost的系统负载。<br><img src="/post_images/images/201701/86dda451.png" alt="linux-vmstat"><br>　　r表示可运行进程数目，数据大致相符；而b表示的是uninterruptible睡眠的进程数目；swpd表示使用到的虚拟内存数量，跟top-Swap-used的数值是一个含义，而如手册所说，通常情况下buffers数目要比cached Mem小的多，buffers一般20M这么个数量级；io域的bi、bo表明每秒钟向磁盘接收和发送的块数目(blocks/s)；system域的in表明每秒钟的系统中断数(包括时钟中断)，cs表明因为进程切换导致上下文切换的数目。<br>　　说到这里，想到以前很多人纠结编译linux kernel的时候-j参数究竟是CPU Core还是CPU Core+1？通过上面修改-j参数值编译boost和linux kernel的同时开启vmstat监控，发现两种情况下context switch基本没有变化，且也只有显著增加-j值后context switch才会有显著的增加，看来不必过于纠结这个参数了，虽然具体编译时间长度我还没有测试。资料说如果不是在系统启动或者benchmark的状态，参数context switch&gt;100000程序肯定有问题。</p>
<h2 id="1-3_pidstat">1.3 <strong>pidstat</strong></h2><p>　　如果想对某个进程进行全面具体的追踪，没有什么比pidstat更合适的了——栈空间、缺页情况、主被动切换等信息尽收眼底。这个命令最有用的参数是-t，可以将进程中各个线程的详细信息罗列出来。<br>　　-r： 显示缺页错误和内存使用状况，缺页错误是程序需要访问映射在虚拟内存空间中但是还尚未被加载到物理内存中的一个分页，缺页错误两个主要类型是<br>　　(a). minflt/s 指的minor faults，当需要访问的物理页面因为某些原因(比如共享页面、缓存机制等)已经存在于物理内存中了，只是在当前进程的页表中没有引用之，这种情况下MMU只需要设置对应的entry就可以了，这个代价是相当小的；<br>　　(b). majflt/s 指的major faults(hard page fault)，MMU需要在当前可用物理内存中申请一块空闲的物理页面(如果没有可用的空闲页面，则需要将别的物理页面切换到交换空间去以释放得到空闲物理页面)，然后从外部低速设备加载数据到该物理页面中，并设置好对应的entry，这个代价是相当高的，和前者有几个数据级的差异；如果发生较多的major faults，虽然可以将交换分区建立在高速设备(比如PCI-E SSD)上改善性能，但主要是提示你缺物理内存了；<br>　　(c). 还有一种情况有人也归结进来，就是invalid fault，指的进程要访问的地址不在其虚拟空间内部，属于越界访问。这是比较严重的错误，通常会报段错误并终止程序的执行。<br>　　-s：栈使用状况，包括StkSize为线程保留的栈空间，以及StkRef实际使用的栈空间。使用ulimit -s发现CentOS 6.x上面默认栈空间是10240K，而CentOS 7.x、Ubuntu系列默认栈空间大小为8196K<br><img src="/post_images/images/201701/e41c6480.png" alt="pidstat"><br>　　-u：CPU使用率情况，参数同前面类似<br>　　-w：线程上下文切换的数目，还细分为cswch/s因为等待资源等因素导致的主动切换，以及nvcswch/s线程CPU时间导致的被动切换的统计<br>　　如果每次都先ps得到程序的pid后再操作pidstat会显得很麻烦，所以这个杀手锏的-C可以指定某个字符串，然后Command中如果包含这个字符串，那么该程序的信息就会被打印统计出来，-l可以显示完整的程序名和参数<br><code bash="">➜  ~  pidstat -w  -t -C “ailaw”  -l </code><br>　　这么看来，如果查看单个尤其是多线程的任务时候，pidstat比常用的ps更好使！</p>
<h2 id="1-4_其他">1.4 <strong>其他</strong></h2><p>　　当需要单独监测单个CPU情况的时候，除了htop还可以使用mpstat，查看在SMP处理器上各个Core的工作量是否负载均衡，是否有某些热点线程占用Core。Linux中还有一个工具taskset，可以设置后面运行的命令的CPU affinity。<br><code bash="">➜  ~ mpstat -P ALL 1</code><br>　　如果想直接监测某个进程占用的资源，既可以使用<code bash="">top -u taozj</code>的方式过滤掉其他用户无关进程，也可以采用下面的方式进行选择，ps命令可以自定义需要打印的条目信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> :; <span class="keyword">do</span> ps -eo user,pid,ni,pri,pcpu,psr,comm | grep <span class="string">'ailawd'</span>; sleep 1; <span class="keyword">done</span></div></pre></td></tr></table></figure></p>
<p>　　如想理清继承关系，下面一个常用的参数可以用于显示进程树结构，显示效果比pstree详细美观的多<br><code bash="">➜  ~ ps axjf</code></p>
<h1 id="二、磁盘IO类">二、磁盘IO类</h1><p>　　iotop可以直观的显示各个进程、线程的磁盘读取实时速率；lsof不仅可以显示普通文件的打开信息(使用者)，还可以操作/dev/sda1这类设备文件的打开信息，那么比如当分区无法umount的时候，就可以通过lsof找出磁盘该分区的使用状态了，而且添加+fg参数还可以额外显示文件打开flag标记。</p>
<h2 id="2-1_iostat">2.1 iostat</h2><p><code bash="">➜  ~ iostat -xz 1</code><br>　　其实无论使用<code bash="">iostat -xz 1</code>还是使用<code bash="">sar -d 1</code>，对于磁盘重要的参数是：<br>　　avgqu-sz: 发送给设备I/O请求的等待队列平均长度，对于单个磁盘如果值&gt;1表明设备饱和，对于多个磁盘阵列的逻辑磁盘情况除外；<br>　　await(r_await、w_await): 平均每次设备I/O请求操作的等待时间(ms)，包含请求排列在队列中和被服务的时间之和；<br>　　svctm: 发送给设备I/O请求的平均服务时间(ms)，如果svctm与await很接近，表示几乎没有I/O等待，磁盘性能很好，否则磁盘队列等待时间较长，磁盘响应较差；<br>　　%util: 设备的使用率，表明每秒中用于I/O工作时间的占比，单个磁盘当%util&gt;60%的时候性能就会下降(体现在await也会增加)，当接近100%时候就设备饱和了，但对于有多个磁盘阵列的逻辑磁盘情况除外；<br>　　还有，虽然监测到的磁盘性能比较差，但是不一定会对应用程序的响应造成影响，内核通常使用I/O asynchronously技术，使用读写缓存技术来改善性能，不过这又跟上面的物理内存的限制相制约了。<br>　　上面的这些参数，对网络文件系统也是受用的。</p>
<h1 id="三、网络类">三、网络类</h1><p>　　网络性能对于服务器的重要性不言而喻，工具iptraf可以直观的现实网卡的收发速度信息，比较的简洁方便通过<code bash="">sar -n DEV 1</code>也可以得到类似的吞吐量信息，而网卡都标配了最大速率信息，比如百兆网卡千兆网卡，很容易查看设备的利用率。<br>　　通常，网卡的传输速率并不是网络开发中最为关切的，而是针对特定的UDP、TCP连接的丢包率、重传率，以及网络延时等信息。</p>
<h2 id="3-1_netstat">3.1 netstat</h2><p><code bash="">➜  ~ netstat -s</code><br>　　显示自从系统启动以来，各个协议的总体数据信息。虽然参数信息比较丰富有用，但是累计值，除非两次运行做差才能得出当前系统的网络状态信息，亦或者使用watch眼睛直观其数值变化趋势。所以netstat通常用来检测端口和连接信息的：</p>
<blockquote>
<p>netstat –all(a) –numeric(n) –tcp(t) –udp(u) –timers(o) –listening(l) –program(p)</p>
</blockquote>
<p>　　–timers可以取消域名反向查询，加快显示速度；比较常用的有<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">➜  ~ netstat -antp  <span class="comment">#列出所有TCP的连接</span></div><div class="line">➜  ~ netstat -nltp   <span class="comment">#列出本地所有TCP侦听套接字，不要加-a参数</span></div></pre></td></tr></table></figure></p>
<h2 id="3-2_sar">3.2 sar</h2><p>　　sar这个工具太强大了，什么CPU、磁盘、页面交换啥都管，这里使用-n主要用来分析网络活动，虽然网络中它还给细分了NFS、IP、ICMP、SOCK等各种层次各种协议的数据信息，我们只关心TCP和UDP。下面的命令除了显示常规情况下段、数据报的收发情况，还包括<br>　　<strong>TCP</strong><br>　　<code bash="">➜  ~ sudo sar -n TCP,ETCP 1 </code><br><img src="/post_images/images/201701/3df5f810.png" alt="tcpstat"><br>　　active/s：本地发起的TCP连接，比如通过connect()，TCP的状态从CLOSED -&gt; SYN-SENT<br>　　passive/s：由远程发起的TCP连接，比如通过accept()，TCP的状态从LISTEN -&gt; SYN-RCVD<br>　　retrans/s(tcpRetransSegs)：每秒钟TCP重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据TCP的确认重传机制会发生重传操作<br>　　isegerr/s(tcpInErrs)：每秒钟接收到出错的数据包(比如checksum失败)<br>　　<strong>UDP</strong><br>　　<code bash="">➜  ~ sudo sar -n UDP 1 </code><br>　　noport/s(udpNoPorts)：每秒钟接收到的但是却没有应用程序在指定目的端口的数据报个数<br>　　idgmerr/s(udpInErrors)：除了上面原因之外的本机接收到但却无法派发的数据报个数<br>　　当然，这些数据一定程度上可以说明网络可靠性，但也只有同具体的业务需求场景结合起来才具有意义。</p>
<h2 id="3-3_tcpdump">3.3 tcpdump</h2><p>　　tcpdump不得不说是个好东西。大家都知道本地调试的时候喜欢使用wireshark，但是线上服务端出现问题怎么弄呢？附录的参考文献给出了思路：复原环境，使用tcpdump进行抓包，当之前的问题复现(比如通过观察日志显示或者某个状态显现)的时候，就可以结束抓包了。而且tcpdump本身带有-C/-W参数，可以限制抓取包存储文件的大小，当达到这个这个限制的时候保存的包数据自动rotate，所以抓取的数据包的数量总体还是可控的。此后将线上数据包拿下线来，用wireshark想怎么看就怎么看，岂不乐哉！tcpdump虽然没有GUI界面，但是抓包的功能丝毫不弱，线上服务器的流量可能会很大，但是通过指定网卡、主机、端口、协议等各项过滤参数，抓下来的包完整又带有时间戳，可以结合时间点进行推测就可以大大缩小可疑数据包的范围，所以线上程序的数据包分析也可以这么简单。<br>　　下面就是一个小的测试，可见Chrome启动时候自动向Webserver发起建立了三条连接，由于这里限制了dst port参数，所以服务端的应答包被过滤掉了，拿下来用wireshark打开，SYNC、ACK建立连接的过程还是很明显的！在使用tcpdump的时候，需要尽可能的配置抓取的过滤条件，一方面便于接下来的分析，二则tcpdump开启后对网卡和系统的性能会有影响，进而会影响到在线业务的性能。<br><img src="/post_images/images/201701/e123717e.jpg" alt="tcpdump"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html" target="_blank" rel="external">Linux Performance Analysis in 60,000 Milliseconds</a></li>
<li><a href="http://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="external">Linux Programmer’s Manual PROC-5 </a></li>
<li><a href="http://www.tecmint.com/command-line-tools-to-monitor-linux-performance/" target="_blank" rel="external">20 Command Line Tools to Monitor Linux Performance</a></li>
<li><a href="http://books.gigatux.nl/mirror/linuxperformanceguide/0131486829/" target="_blank" rel="external">linuxperformanceguide</a></li>
<li><a href="http://blog.scoutapp.com/articles/2015/02/24/understanding-linuxs-cpu-stats" target="_blank" rel="external">Understanding Linux CPU stats</a></li>
<li><a href="https://www.qcloud.com/community/article/164816001481011819" target="_blank" rel="external">Linux性能监控——CPU,Memory,IO,Network</a></li>
<li><a href="https://yq.aliyun.com/articles/6047" target="_blank" rel="external">Linux系统性能指标</a></li>
<li><a href="https://wiki.mikejung.biz/Performance_Analysis" target="_blank" rel="external">Performance Analysis</a></li>
<li><a href="https://www.socallinuxexpo.org/scale11x-supporting/default/files/presentations/scalelinuxperformance-130224171331-phpapp01.pdf" target="_blank" rel="external">Linux Performance Analysis and Tools</a></li>
<li><a href="https://www.linux.com/learn/uncover-meaning-tops-statistics" target="_blank" rel="external">Uncover the Meaning of top’s Statistics</a></li>
<li><a href="https://yq.aliyun.com/articles/27461" target="_blank" rel="external">tcpdump 和 wireshark组合拳，揪出有问题的机器</a></li>
<li><a href="http://www.cnblogs.com/maifengqiang/p/3863168.html" target="_blank" rel="external">超级详细Tcpdump 的用法</a></li>
<li><a href="http://www-05.ibm.com/de/events/linux-on-system-z/downloads/Tools-MK2-V7-Web.pdf" target="_blank" rel="external">How to surprise by being a Linux-performance “know-it-all”</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　一个基于Linux操作系统的服务器运行的同时，也会表征出各种各样参数信息。通常来说运维人员、系统管理员会对这些数据会极为敏感，但是这些参数对于开发者来说也十分重要，尤其当你的程序非正常工作的时候，这些蛛丝马迹往往会帮助快速定位跟踪问题。<br>　　这里只是一些简单的工具查看系统的相关参数，当然很多工具也是通过分析加工/proc、/sys下的数据来工作的，而那些更加细致、专业的性能监测和调优，可能还需要更加专业的工具(perf、systemtap等)和技术才能完成哦。毕竟来说，系统性能监控本身就是个大学问。<br><img src="/post_images/images/201701/76667dfc.png" alt="linux-performance"></p>
<h1 id="一、CPU和内存类">一、CPU和内存类</h1><h2 id="1-1_top">1.1 top</h2><p>　　<code bash>➜  ~ top</code><br><img src="/post_images/images/201701/bbbd0eb3.png" alt="linux-top"><br>　　第一行后面的三个值是系统在之前1、5、15的平均负载，也可以看出系统负载是上升、平稳、下降的趋势，当这个值超过CPU可执行单元的数目，则表示CPU的性能已经饱和成为瓶颈了。</p>
<p>　　第二行统计了系统的任务状态信息。running很自然不必多说，包括正在CPU上运行的和将要被调度运行的；sleeping通常是等待事件(比如IO操作)完成的任务，细分可以包括interruptible和uninterruptible的类型；stopped是一些被暂停的任务，通常发送SIGSTOP或者对一个前台任务操作Ctrl-Z可以将其暂停；zombie僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的task descriptor需要父进程访问后才能释放，这种进程显示为defunct状态，无论是因为父进程提前退出还是未wait调用，出现这种进程都应该格外注意程序是否设计有误。<br>]]>
    
    </summary>
    
      <category term="软件" scheme="https://taozj.org/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="内核" scheme="https://taozj.org/tags/%E5%86%85%E6%A0%B8/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="运维" scheme="https://taozj.org/categories/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[文本处理利器sed与awk使用总结]]></title>
    <link href="https://taozj.org/201612/cmd-tools-sed-awk.html"/>
    <id>https://taozj.org/201612/cmd-tools-sed-awk.html</id>
    <published>2016-12-28T14:34:39.000Z</published>
    <updated>2016-12-30T08:57:50.000Z</updated>
    <content type="html"><![CDATA[<p>　　 在整理为知笔记的时候，发现很久以前写的awk、sed学习笔记，这不禁然让我回想起自己最开始接触Linux的情形。那时候还在江安校区东五宿舍，一天晚上打开水瞄到了一张海报——“你想了解让微软感到畏惧的操作系统么？”虽然这个讲座最后我也没听成，但也自从那时起Linux就在我心中烙下了深深的印记。上学的时候家里真的很穷，学费也是申请的助学贷款，自认自己从小开始还是比较懂事的，也不知道那时什么勇气让我跟父母开口要四千多块钱买电脑的，但父母还是爽快地支持了我，放假前入手了当时乞丐版ThinkPad R60e，这台电脑用的Celeron处理器(后面手动升级成了Core Solo单核处理器)，1024x768的LCD显示器，80G的硬盘居然也装了双系统，虽然烂但是陪我度过了好几个年头，直到我研究生实习后用自己的实习工资换了另外一台联想笔记本(现在还在给我老婆用)它才下岗，当然这已是后话了！<br>　　 做的这个笔记，是在放暑假前从图书馆借的那本蓝皮《Unix Shells by Example》，暑假过程中自己折腾的产物，其实当时根本不知道学习这个有什么用。sed、awk当然不会用来单独开发程序，但是在命令行处中理文本，字段切割，分析日志，写一些shell脚本(比如数据库patch)的时候，还有就是在自动化做软件、服务配置文件更新的时候，还是非常好用的。</p>
<h1 id="一、sed_-_stream_editor_for_filtering_and_transforming_text">一、sed - stream editor for filtering and transforming text</h1><p>　　 <strong>sed的操作格式</strong></p>
<blockquote>
<p>➜  ~ sed -opts ‘command’ filename(s)<br>➜  ~ … | sed -opts ‘command’  # 管道输入</p>
</blockquote>
<p>　　 <strong>sed的opts选项</strong></p>
<blockquote>
<p>-n 取消默认打印。默认情况下会全文打印，因此会重复打印匹配的记录，而这个选项用来只打印匹配记录<br>-e 多个command可以用这个连接，比如 sed -n -e ‘cmd1’ -e ‘cmd2’ files<br>-i 使sed的编辑保存。默认sed操作没有破坏性(不会对原文件修改)，但是确实要编辑原文件时候可以加上该参数</p>
</blockquote>
<p>　　 这里实验使用《UNIX shell by example》里面的datafile文件作为数据集。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"> ➜  ~ cat datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15</div><div class="line">southeast       SE      Patricia Hemenway       4.0     .7      4       17</div><div class="line">eastern         EA      TB Savage               4.4     .84     5       20</div><div class="line">northeast       NE      AM Main Jr.             5.1     .94     3       13</div><div class="line">north           NO      Margot Weber            4.5     .89     5        9</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line"> ➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="1-1_删除_d">1.1 删除 d</h2><p>注意，和通常的法则不一样，下面的行号都是从1开始计数的。<br>(a) <code> ➜  ~ sed ‘3d’ datafile</code><br>删除第3行，其余行打印到屏幕上。再次强调sed默认没有破坏性，原文件datafile没有改变。<br>(b) <code> ➜  ~ sed ‘3,$d’ datafile</code><br>删除第3行到文件的末尾记录，只打印剩余的第1,2两行。$代表文件或者记录的最后一行<br>(c) <code> ➜  ~ sed ‘$d’ datafile </code><br>删除最后一行。<br>(d) <code> ➜  ~ sed ‘/north/d’ datafile</code><br>删除匹配north的行，其余记录都被打印。<br> <a id="more"></a></p>
<h2 id="1-2_替换_s">1.2 替换 s</h2><p>标志g表示是对行内所有匹配记录都进行替换，否则只对行内首次出现的记录进行替换<br>(a) <code> ➜  ~ sed -n ‘s/^west/north/p’ datafile</code><br>替换所有west打头记录，这里用了-n选项和p命令，只打印替换的记录<br>(b) <code> ➜  ~ sed ‘s/[0-9][0-9]$/&amp;.5/‘ datafile</code><br>符号$表示行末尾，符号&amp;在替换中用于表示前面匹配的内容，上面表示行结尾为2位数的数字，添加.5成为xx.5。如果要用到&amp;的字面意思，需要使用\&amp;转意方可。<br><code>  ➜  ~ sed -n ‘s/[0-9][0-9]$/&amp;.5\&amp;/p’ datafile</code><br>(c) 标记符号()，可以复用前面的内容<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="string">'s/\(Mar\)go\(t\)/\1ianne\2/p'</span> datafile</div><div class="line">north           NO      Mariannet Weber            4.5     .89     5        9</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里\1复用了前面标记的Mar，而\2复用了t。<br>(d)　默认的替换分隔符是/，其实sed可以使用任何分隔符，就是紧跟着s的那个符号。使用自定义的符号对于操作日期、路径等特殊记录很有效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  nginx <span class="built_in">pwd</span></div><div class="line">/home/v5kf/nginx</div><div class="line">➜  nginx <span class="built_in">pwd</span> | sed <span class="string">'s#v5kf/nginx#ztao#g'</span></div><div class="line">/home/ztao</div><div class="line">➜  nginx</div></pre></td></tr></table></figure></p>
<h2 id="1-3_行范围_,">1.3 行范围 ,</h2><p>行范围的表示是双闭合的，就是包含匹配开始的行、匹配结束的行，以及两者之间的所有行: 5,10  /Dick/,/Joe/  /north/,$<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="string">'/south/,/theast/s/$/**TTT**/p'</span> datafile</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18**TTT**</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15**TTT**</div><div class="line">southeast       SE      Patricia Hemenway       4.0     .7      4       17**TTT**</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里将从south匹配行，到第一个theast匹配行结束，将每条匹配记录的$结尾替换(实际追加)成<strong>TTT</strong>。如果出现south，但是没有出现theast，就默认匹配到文件结尾的地方</p>
<h2 id="1-4_多次编辑_-e">1.4 多次编辑 -e</h2><p><code> ➜  ~ sed -e ‘1,3d’ -e ‘s/north/NORTH/‘ datafile</code><br>多个-e其操作是依次进行的，所以顺序还是有讲究的，不同的顺序对最终的结果可能会有影响<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="_">-e</span> <span class="string">'s/thw/THW/p'</span> <span class="_">-e</span> <span class="string">'s/west/WEST/p'</span> datafile </div><div class="line">norTHWest       NW      Charles Main            3.0     .98     3       34</div><div class="line">WESTern         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">souTHWest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">➜  ~ sed -n <span class="_">-e</span> <span class="string">'s/west/WEST/p'</span> <span class="_">-e</span> <span class="string">'s/thw/THW/p'</span> datafile     </div><div class="line">northWEST       NW      Charles Main            3.0     .98     3       34</div><div class="line">WESTern         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southWEST       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="1-5_文件操作">1.5 文件操作</h2><p>(a) 读文件 r<br>将一个文件的内容加到当前的位置上实际就是在所有匹配行的下面插入文件内容<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> <span class="string">"---newfile info---"</span> &gt; newfile</div><div class="line">➜  ~ sed <span class="string">'/west/r newfile'</span> datafile    </div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">---newfile info---</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">---newfile info---</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">---newfile info---</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(b) 写文件 w<br>把所有匹配到的记录都写入到指定的文件当中<br><code> ➜  ~ sed ‘/south/w newfile1’ datafile</code><br>(c) 追加文本 a<br>该命令是在匹配的记录后面直接追加提供的文本内容，感觉追加的内容有strip的效果，开始的空字符会被删除<br><code> ➜  ~ sed ‘/south/a    This is the message’ datafile</code><br>(d) 插入文本 i<br>跟上面的a命令类似，只不过这个i是插在匹配记录的前面<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'/western/i   - This is the message'</span> datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">- This is the message</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(e) 替换文本 c<br>用该字符替换匹配到的整个记录行<br><code> ➜  ~ sed ‘/north/c This is the message’ datafile </code><br>(f) 下一行 n<br>对匹配到的记录，对其下一行做某些相应的操作<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'/northwest/&#123;n; s/^\&lt;[a-z]*/XXTTZZF/; &#125;'</span> datafile </div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">XXTTZZF         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(g) 替换、转换操作 y<br>下面对第1,2两行记录中的字符做大写化转换<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'1,2y/abcdefghigklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/'</span> datafile</div><div class="line">NORTHWEST       NW      CHARLES MAIN            3.0     .98     3       34</div><div class="line">WESTERN         WE      SHARON GRAY             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(h) 退出<br>直接退出，不做接下来记录的继续处理<br><code> ➜  ~ sed ‘5q’ datafile </code><br><code> ➜  ~ sed ‘/north/{ s/north/NORTH/; q; }’ datafile </code></p>
<h2 id="1-6_sed正则表达式的元字符">1.6 sed正则表达式的元字符</h2><p>Linux平台下很多工具(sed、awk、bash、python…)，其正则表达式虽然在大体上约定类似，但是很多细节方面的东西还是有所差异，使用不确定最好事先查询一下！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">^         行首定位符</div><div class="line">$         行尾定位符</div><div class="line">.         匹配除换行之外的单个字符</div><div class="line">*         匹配0个或者多个前导字符(这里是前导字符0或者多个，任意一个或多个字符，使用 .* )</div><div class="line">[]        指定字符中的任意一个字符，比如[Ll] [a-z]</div><div class="line">[^]       上面一样，不匹配的字符</div><div class="line">\(..\)    保存匹配的字符，后面使用\1 \2..来引用，最多使用9个标签</div><div class="line">&amp;         保存查找匹配到的串，可以用在后面的替换中 s/love/**&amp;**/</div><div class="line">\&lt;        词首定位符，单词的开头</div><div class="line">\&gt;        词尾定位符</div><div class="line">x\&#123;m\&#125;    连续m个</div><div class="line">x\&#123;m,\&#125;   至少m个</div><div class="line">x\&#123;m,n\&#125;  m-n个,sed -n <span class="string">'s/[0-9]\&#123;2\&#125;$/&amp;.5/p'</span> datafile</div></pre></td></tr></table></figure></p>
<h1 id="二、awk_-_pattern_scanning_and_text_processing_language">二、awk - pattern scanning and text processing language</h1><p>注意，下面的操作都是针对gawk的。刚开始发现下面有些例程走不通，原来是Ubuntu上面默认装的个mawk，换成gawk就正常了，话说这个awk就那三个人发明的么，居然还有版本差异？<br>awk比上面的sed要复杂的多，支持运算符、逻辑判断、循环等基本操作，难怪在解释上面已经定位为一个language了。<br><strong>awk的操作格式</strong></p>
<blockquote>
<p>➜  ~ awk -opts ‘cmd’ filenames<br>➜  ~ … | awk -opts ‘cmd’  # 管道输入</p>
</blockquote>
<p>下面的实验操作默认使用《UNIX shell by example》里面的employees文件，也有很多是沿用上面的datafile。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> ➜  ~ cat employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">Sally Chang     1654      7/22/54     650000</div><div class="line">Billy Black     1683      9/23/44     336500</div><div class="line"> ➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-1_简介">2.1 简介</h2><p>awk将输入的每行作为一条记录，默认的行分隔符就是换行符。$0指代每行的整条记录，而NR将每条记录所对应的行号保存在其中。<br><code> ➜  ~ awk ‘{print NR,$0}’ employees </code><br>每条记录都是由多个字段组成的，这些字段的分隔符默认是空白字符(空格或者制表符，如果想要改变这个默认设置，可以使用-F这个参数)，每条字段都是用$1,$2…开始标号表示，而每行的字段个数保存在NF这个特殊的字段当中。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk -F: <span class="string">'&#123;print NR, $1,$7&#125;'</span> /etc/passwd </div><div class="line">1 root /bin/bash</div><div class="line">2 daemon /usr/sbin/nologin</div><div class="line">3 bin /usr/sbin/nologin</div><div class="line">...</div></pre></td></tr></table></figure></p>
<h2 id="2-2_模式和操作">2.2 模式和操作</h2><p>awk的行为可以是花括号包起来的多个操作：<br><code>{action1; action2; … ;}</code><br>默认的模式匹配中就已经包含了if的意思了，表明当该模式满足时候就进行操作，如果没指定默认操作就是打印出这些满足要求的整行记录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/Tom/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">➜  ~ awk <span class="string">'$3&lt;3000'</span> employees</div><div class="line">Sally Chang     1654      7/22/54     650000</div><div class="line">Billy Black     1683      9/23/44     336500</div><div class="line">➜  ~ awk <span class="string">'$0 ~ /Tom/&#123;print&#125;'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">➜  ~ awk <span class="string">'$0 ~ /Tom/&#123;print "NAMEINFO-&gt;" $1, "~"  ,$2&#125;'</span> employees</div><div class="line">NAMEINFO-&gt;Tom ~ Jones</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-3_模式匹配">2.3 模式匹配</h2><p>(a) 整行所有字段匹配<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/[TM]/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">➜  ~ awk <span class="string">'/To|Mar/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) ~ 特定字段匹配操作符，而使用符号!可以表示取反的意思<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$2 ~ /Ch/ &#123;print NR,$1,$2&#125;'</span> employees  </div><div class="line">3 Sally Chang</div><div class="line">➜  ~ awk <span class="string">'$2 !~ /Ch/ &#123;print NR,$1,$2&#125;'</span> employees  </div><div class="line">1 Tom Jones</div><div class="line">2 Mary Adams</div><div class="line">4 Billy Black</div><div class="line">➜  ~ awk <span class="string">' $4 ~ /^Gr/'</span> datafile     </div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 其他的匹配例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">' $5 ~ /\.[4-6]+/'</span> datafile</div><div class="line">eastern         EA      TB Savage               4.4     .84     5       20</div><div class="line">north           NO      Margot Weber            4.5     .89     5        9</div></pre></td></tr></table></figure></p>
<p>这个起到匹配作用的是4.4和4.5代表的字段哦，英文名字中有空格，占用了两个字段位</p>
<h2 id="2-4_关系运算符和条件表达式">2.4 关系运算符和条件表达式</h2><p>(a) &lt; &lt;= &gt; &gt;= != == ~ !~ 前面是一般的比较关系运算符，后面是用于字符串或者正则表达式是否匹配<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$5 &gt;= 5.3'</span> datafile                       </div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">northeast       NE      AM Main Jr.             5.1     .94     3       13</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面我们看到一条有问题的数据，就是第二条记录。其实看看前面的姓名有三个字段…<br>(b) 算书运算 + - * / % ^<br>前面是正常的四则运算，而后面分别是除法、取余和取冪运算符。awk支持浮点运算，而且会按照浮点方式执行运算(比如下面的9/2=4.5)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/centr/ &#123;print NR,$1,$2,$5+3,7+8&#125;'</span> datafile </div><div class="line">9 central CT 8.7 15</div><div class="line">➜  ~ <span class="built_in">echo</span> 9 | awk <span class="string">'&#123;print $1%2, $1/2&#125;'</span></div><div class="line">1 4.5</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 逻辑运算 &amp;&amp; || !<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$5 &gt; 5.5 &amp;&amp; $1 ~ /cen/'</span> datafile</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) 条件表达式<br>类似于C/C++的?运算符，格式为：条件表达式1 ? 表达式2 : 表达式3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'NR&lt;3 &#123; print ( NF==8 ? "valid" : "invalid" ),"NF=",NF&#125;'</span> datafile</div><div class="line">valid NF= 8</div><div class="line">valid NF= 8</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(e) 范围模式 ,<br>awk的范围模式也是封闭范围。在所有记录中他们会顺序进行多次匹配，第一次匹配完后还可以进行下面接下来的第二次、第三次可能的匹配范围。如果开头匹配到了，但是没有结尾的话，会把整个文件记录的末尾当作是这次匹配的结尾作为范围<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/,/south/ &#123;print NR, $1, $2&#125;'</span> datafile</div><div class="line">1 northwest NW</div><div class="line">2 western WE</div><div class="line">3 southwest SW</div><div class="line">7 northeast NE</div><div class="line">8 north NO</div><div class="line">9 central CT</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面例子的第二次匹配没有匹配到结尾，就默认到文件的结尾<br>(f) 赋值运算 = += -= *= /= %=<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/ &#123;$1="NORTH" ; print NR,$1,$2,$3&#125;'</span> datafile</div><div class="line">1 NORTH NW Charles</div><div class="line">7 NORTH NE AM</div><div class="line">8 NORTH NO Margot</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-5_变量">2.5 变量</h2><p>(a) awk的内置变量<br>如上面例子中使用到的NR、NF，这些是awk内置的变量，可以使用$直接取值和设置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">ARGC          命令行参数个数</div><div class="line">ARGV          命令行参数构成胡数组</div><div class="line">FILENAME  当前输入文件的文件名</div><div class="line">FNR　         当前文件的记录数</div><div class="line">FS　            输入分割符，默认是空格字符</div><div class="line">NF               当前记录的字段数</div><div class="line">NR               当前的记录编号</div><div class="line">OFS             输出字段分割符</div><div class="line">ORS            记录分割符</div><div class="line">IGNORECASE  是否忽略大小写</div></pre></td></tr></table></figure></p>
<p>上面的FS、OFS看似都是空字符。其他使用例子：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> <span class="_">-ne</span> <span class="string">"123\n346\n"</span> | awk <span class="string">'&#123; print $0,ARGC,ARGV[0],FILENAME,FNR,FS,NF,NR,OFS &#125;'</span></div><div class="line">123 1 awk - 1   1 1 </div><div class="line">346 1 awk - 2   1 2 </div><div class="line">➜  ~ awk <span class="string">' &#123;IGNORECASE=1&#125;; $1=="North" &#123;print NR,$1,$2,$3&#125; '</span> datafile</div><div class="line">8 north NO Margot</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 一般变量<br>变量类型: 数值类型(默认值0)，字符串类型(默认值””)<br>强制转化: name+0 name+””<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> 123 | awk <span class="string">'&#123; x = $1; y = ++x; print "x="x,"y="y&#125;'</span></div><div class="line">x=124 y=124</div><div class="line">➜  ~ <span class="built_in">echo</span> 123 | awk <span class="string">'&#123; x = $1; y = x++; print "x="x,"y="y&#125;'</span></div><div class="line">x=124 y=123</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-6_BEGIN、END模式">2.6 BEGIN、END模式</h2><p>BEGIN是在对输入文件进行任何处理之前进行的操作块，而实际上不需要任何输入文件，也能执行BEGIN测试，所以后面有很多同输入无关的测试，这样就可以把这些代码写道BEGIN的语句块里面。使用过程中，通常在BEGIN中设置OFS、RS、FS等参数值，以及用户定义输入格式、变量定义初始化等操作。<br>END模式也不匹配任何输入，awk是在处理完毕所有输入行之后才处理END模式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">' BEGIN&#123;IGNORECASE=1; count=0&#125;; $1 ~ /North/ &#123;count++&#125; ; END&#123; print "Found",count&#125;  '</span> datafile</div><div class="line">Found 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-7_重定向和管道">2.7 重定向和管道</h2><p>(a) 支持 &gt; &gt;&gt;　重定向符号<br>使用的时候作为文件名参数需要使用””括起来，getline可以用于输入重定向来获得输入信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; "date" | getline date; print "The date is",date &gt; "date.file"&#125;'</span></div><div class="line">➜  ~ cat date.file</div><div class="line">The date is Wed Dec 28 18:43:39 HKT 2016</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 管道 |<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/ &#123; print $0 | "grep Charles" &#125;'</span> datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) system 函数。可以进行系统命令调用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; system("whoami") &#125;'</span></div><div class="line">v5kf</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) printf　格式化输出信息，跟C语言的类似<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; printf "Hello, %s, you are %d years old.\n","Nicol TAO","23"&#125;'</span></div><div class="line">Hello, Nicol TAO, you are 23 years old.</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-8_条件语句和循环">2.8 条件语句和循环</h2><p>(a) if<br>在条件模式中，if是隐含的模式了，而条件语句if也可以按照需要直接声明出来的<br>句式类似于if () {} else if () {} else {}<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123; if( $1 ~ /north/) &#123; print "north related."&#125; else if ( $1 ~ /south/ ) &#123; print "south related."&#125; else &#123; print "wield..."&#125; &#125;'</span> datafile</div><div class="line">north related.</div><div class="line">wield...</div><div class="line">south related.</div><div class="line">south related.</div><div class="line">south related.</div><div class="line">wield...</div><div class="line">north related.</div><div class="line">north related.</div><div class="line">wield...</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) while<br>句法 while () {}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk &apos;BEGIN &#123; i = 0; count = 0; &#125; &#123; while ( i &lt; NR ) &#123; i ++; if ( $1 ~ /north/ ) &#123; count++; print NR,$1 $2 &#125; &#125; &#125; END &#123; print &quot;Count:&quot;,count &#125;&apos; datafile</div><div class="line">1 northwestNW</div><div class="line">7 northeastNE</div><div class="line">8 northNO</div><div class="line">Count: 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) for<br>普通for循环，句法for( ; ; ){}<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; i = 0;&#125; &#123; for(;i&lt;NR;i++) &#123; if( $1 ~ /north/ )&#123; print NR,$1,$2,"~~" &#125; &#125;&#125;'</span> datafile</div><div class="line">1 northwest NW ~~</div><div class="line">7 northeast NE ~~</div><div class="line">8 north NO ~~</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) break continue<br>同C/C++语言一样，是作用于跳出循环体和跳出本次循环的关键字。</p>
<h2 id="2-9_程序控制语句">2.9 程序控制语句</h2><p>(a) next<br>从文件中读取下一行输入，然后从awk脚本顶部开始重新执行。同continue效果也有点相似，只不过这里是作用于awk工具在对每行操作的自动“循环”中的<br>(b) exit<br>中断记录的处理，但是不能够跳过END语句块。exit可以带一个范围为0~255的退出参数，约定0表示成功，这个退出参数实际就传递给了$?表示执行的结果<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;  if ( $1 ~ /north/ ) &#123; print NR,$1,$2,"skip"; next; &#125; if ( $2 ~ /SO/ ) &#123; print NR,$1,$2,"exit will"; exit 3; &#125; print NR,$1,$2,"after if..."; &#125; END &#123; print "Fininal should be called here..." &#125;'</span> datafile</div><div class="line">1 northwest NW skip</div><div class="line">2 western WE after if...</div><div class="line">3 southwest SW after if...</div><div class="line">4 southern SO <span class="built_in">exit</span> will</div><div class="line">Fininal should be called here...</div><div class="line">➜  ~ <span class="built_in">echo</span> $?</div><div class="line">3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-10_数组">2.10 数组</h2><p>(a) awk中的数组也可以称为键值对，因为数组的下标可以是字符串<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123;x=0;i=0;&#125; &#123;name[x++]=$2;&#125; END &#123; for(;i&lt;NR;i++)&#123; print "name["i"] is",name[i]&#125; &#125;'</span> employees</div><div class="line">name[0] is Jones</div><div class="line">name[1] is Adams</div><div class="line">name[2] is Chang</div><div class="line">name[3] is Black</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 上面是使用的普通for循环结构，而如果数组的下标不是数字类型时候，使用新的for遍历循环就很方便<br><code>for( item in array) { …array[item]…}</code><br>item会自动依次提取array中的索引值，实际数组元素可以通过array[item]来访问。awk中的数组是通过hash来存贮的，所以这里的便利理论上来说顺序是不确定的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;name[$1]=$2;&#125; END &#123; for(item in name ) &#123; print "Family name for",item,"is",name[item];&#125; &#125;'</span> employees</div><div class="line">Family name <span class="keyword">for</span> Tom is Jones</div><div class="line">Family name <span class="keyword">for</span> Sally is Chang</div><div class="line">Family name <span class="keyword">for</span> Mary is Adams</div><div class="line">Family name <span class="keyword">for</span> Billy is Black</div><div class="line">➜  ~ awk <span class="string">'&#123; if ($1 ~ /north/)&#123; count["north"] ++;&#125; else if ( $1 ~ /east/) count["east"]++; else count["other"]++;&#125; END&#123; for(item in count) &#123; print item,"related count:",count[item]; &#125; &#125;'</span> datafile</div><div class="line">other related count: 4</div><div class="line">east related count: 2</div><div class="line">north related count: 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 数组的其他部分<br>splite可以分割字符串，构造形成数组<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; str="/etc/samba/smb.conf"; split(str,name,"/"); for (item in name) print name[item]":";&#125;'</span></div><div class="line">:</div><div class="line">etc:</div><div class="line">samba:</div><div class="line">smb.conf:</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里的开头/被分割出来产生了一个空串哈…</p>
<h1 id="2-11_内置函数">2.11 内置函数</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sub               (/reg/,替换串[,目标串])</div><div class="line">gsub             (/reg/,替换串[,目标串])</div><div class="line">index(str,sub_str)　返回sub_str第一次在str中出现的位置(偏移量从1开始)</div><div class="line">length(str)     返回字符串的字符个数</div><div class="line">substr(str,start_pos[,length])　返回子串，如果没有length，就到串的末尾</div><div class="line">match(str,/reg/)     返回正则匹配在字符串中的位置，同时设置RSTART和RLENGTH的值</div><div class="line">split(str,arr_name[,split_sig])</div></pre></td></tr></table></figure>
<p>上面两个内置函数sub和gsub的区别是，sub只进行第一次替换，而gsub会对所有串进行替换(相当于s添加了g参数吧)。下面是操作例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;sub(/[Ee]ast/,"EAST",$1); print $1,index($1,"EAST"),"length",length($1);&#125;'</span> datafile</div><div class="line">northwest 0 length 9</div><div class="line">western 0 length 7</div><div class="line">southwest 0 length 9</div><div class="line">southern 0 length 8</div><div class="line">southEAST 6 length 9</div><div class="line">EASTern 1 length 7</div><div class="line">northEAST 6 length 9</div><div class="line">north 0 length 5</div><div class="line">central 0 length 7</div><div class="line">➜  ~ awk <span class="string">'&#123; sub(/lly/,"--&amp;**",$1); print $1 &#125;'</span> employees</div><div class="line">Tom</div><div class="line">Mary</div><div class="line">Sa--lly**</div><div class="line">Bi--lly**</div><div class="line">➜  ~ awk <span class="string">'&#123;if ( match($1,/[Ee]ast/) != 0) &#123; print RSTART,RLENGTH,$1; &#125;&#125;'</span> datafile</div><div class="line">6 4 southeast</div><div class="line">1 4 eastern</div><div class="line">6 4 northeast</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面可以看见&amp;的用法哈</p>
<h2 id="2-12_算数函数">2.12 算数函数</h2><p>atan2(x,y) cos(x) exp(x) log(x) sin(x) sqrt(x)<br>int(x)直接舍去小数，保留整数部分<br>rand() 产生随机数(0~1) srand(x) 初始化随机数种子<br>默认情况下每次调用rand()，结果都会产生相同的随机数，这时候需要调用srand()重新产生一个种子，后面的随机数才不同<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.215969 0.629868</div><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.556348 0.749557</div><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.0931369 0.835396</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-13_awk正则表达式元字符">2.13 awk正则表达式元字符</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">^      行首定位符</div><div class="line">$      行尾定位符</div><div class="line">.      匹配除换行之外的单个字符</div><div class="line">*      匹配0个或者多个前导字符(这里是前导字符0或者多个，任意一个或多个字符，使用 .* )</div><div class="line">+      匹配一个或者多个前导字符</div><div class="line">?      匹配0个或者1个前导字符</div><div class="line">[]     指定字符中的任意一个字符，比如[Ll] [a-z]</div><div class="line">[^]    上面一样，不匹配的字符</div><div class="line">AA|BB  匹配AA或者BB</div><div class="line">(AB)+  匹配一个或者多个AB组合，比如AB,ABAB,ABABAB...</div><div class="line">\*     匹配*本身</div><div class="line">&amp;      保存查找匹配到的串，可以用在后面的替换中 s/love/**&amp;**/</div></pre></td></tr></table></figure>
<p>同第一部分sed工具相比，awk不支持的正则模式有<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">\(..\)   \&lt;        \&gt;    x\&#123;m\&#125;  x\&#123;m,\&#125;　x\&#123;m,n\&#125;</div></pre></td></tr></table></figure></p>
<p>从上面看来awk比较的复杂，已经具备了算数运算、逻辑、循环等一个脚本语言需要的大多数基本元素(貌似还缺函数)了。其实觉得单独用awk写脚本的不是很多，大多都是和sed一块，夹杂到shell<br>script里面用的。比如当时我工作时候用的例子：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PRIMSAM=`cat /etc/hosts | /usr/xpg4/bin/grep <span class="string">"OAM_PRIMARY_IF_A"</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</div><div class="line">SEDSAM=`cat /etc/hosts | /usr/xpg4/bin/grep <span class="string">"OAM_SECONDARY_IF_A"</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</div><div class="line">count1=`ttsys -v 1 <span class="_">-e</span> <span class="string">"select count(*) from CONFIGPARAMS where NODENAME='CPSNodes' and SUBSYSTEMNAME='Call Processing' and MANAGERNAME='Call Manager' and PARAMNAME='LocNumMapFeature';quit"</span>|sed <span class="_">-e</span> <span class="string">'s/&lt; //g'</span> <span class="_">-e</span> <span class="string">'s/ &gt;//g'</span>|awk <span class="string">'&#123;print $1&#125;'</span>`</div></pre></td></tr></table></figure></p>
<p>还比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SMBPRINC=`klist -k | grep <span class="string">"\&lt;root@"</span> | uniq | awk <span class="string">'&#123;print $2;&#125;'</span>`</div><div class="line">TMPDIR=<span class="string">"/"</span>`date +%N | md5sum | awk <span class="string">'&#123;print $1&#125;'</span>`</div><div class="line">TMPFILE=`date +%N | md5sum | awk <span class="string">'&#123;print $1&#125;'</span>`</div><div class="line">sed <span class="_">-e</span> <span class="string">"s/^MOUNTD_NFS_V2=.*$//g"</span> /etc/sysconfig/nfs -i 2&gt;&amp;1 &gt;/dev/null</div><div class="line">sed <span class="_">-e</span> &#123;s/REALM/$( <span class="built_in">echo</span> `hostname <span class="_">-d</span>` | tr [:lower:] [:upper:] )/&#125; <span class="variable">$TESTCONFIGFILE</span> -i</div></pre></td></tr></table></figure></p>
<p>看吧，当时做的笔记还是多认真的，那时的学习是多么单纯的一件事！<br>本文完！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　 在整理为知笔记的时候，发现很久以前写的awk、sed学习笔记，这不禁然让我回想起自己最开始接触Linux的情形。那时候还在江安校区东五宿舍，一天晚上打开水瞄到了一张海报——“你想了解让微软感到畏惧的操作系统么？”虽然这个讲座最后我也没听成，但也自从那时起Linux就在我心中烙下了深深的印记。上学的时候家里真的很穷，学费也是申请的助学贷款，自认自己从小开始还是比较懂事的，也不知道那时什么勇气让我跟父母开口要四千多块钱买电脑的，但父母还是爽快地支持了我，放假前入手了当时乞丐版ThinkPad R60e，这台电脑用的Celeron处理器(后面手动升级成了Core Solo单核处理器)，1024x768的LCD显示器，80G的硬盘居然也装了双系统，虽然烂但是陪我度过了好几个年头，直到我研究生实习后用自己的实习工资换了另外一台联想笔记本(现在还在给我老婆用)它才下岗，当然这已是后话了！<br>　　 做的这个笔记，是在放暑假前从图书馆借的那本蓝皮《Unix Shells by Example》，暑假过程中自己折腾的产物，其实当时根本不知道学习这个有什么用。sed、awk当然不会用来单独开发程序，但是在命令行处中理文本，字段切割，分析日志，写一些shell脚本(比如数据库patch)的时候，还有就是在自动化做软件、服务配置文件更新的时候，还是非常好用的。</p>
<h1 id="一、sed_-_stream_editor_for_filtering_and_transforming_text">一、sed - stream editor for filtering and transforming text</h1><p>　　 <strong>sed的操作格式</strong></p>
<blockquote>
<p>➜  ~ sed -opts ‘command’ filename(s)<br>➜  ~ … | sed -opts ‘command’  # 管道输入</p>
</blockquote>
<p>　　 <strong>sed的opts选项</strong></p>
<blockquote>
<p>-n 取消默认打印。默认情况下会全文打印，因此会重复打印匹配的记录，而这个选项用来只打印匹配记录<br>-e 多个command可以用这个连接，比如 sed -n -e ‘cmd1’ -e ‘cmd2’ files<br>-i 使sed的编辑保存。默认sed操作没有破坏性(不会对原文件修改)，但是确实要编辑原文件时候可以加上该参数</p>
</blockquote>
<p>　　 这里实验使用《UNIX shell by example》里面的datafile文件作为数据集。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"> ➜  ~ cat datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15</div><div class="line">southeast       SE      Patricia Hemenway       4.0     .7      4       17</div><div class="line">eastern         EA      TB Savage               4.4     .84     5       20</div><div class="line">northeast       NE      AM Main Jr.             5.1     .94     3       13</div><div class="line">north           NO      Margot Weber            4.5     .89     5        9</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line"> ➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="1-1_删除_d">1.1 删除 d</h2><p>注意，和通常的法则不一样，下面的行号都是从1开始计数的。<br>(a) <code> ➜  ~ sed ‘3d’ datafile</code><br>删除第3行，其余行打印到屏幕上。再次强调sed默认没有破坏性，原文件datafile没有改变。<br>(b) <code> ➜  ~ sed ‘3,$d’ datafile</code><br>删除第3行到文件的末尾记录，只打印剩余的第1,2两行。$代表文件或者记录的最后一行<br>(c) <code> ➜  ~ sed ‘$d’ datafile </code><br>删除最后一行。<br>(d) <code> ➜  ~ sed ‘/north/d’ datafile</code><br>删除匹配north的行，其余记录都被打印。<br>]]>
    
    </summary>
    
      <category term="软件" scheme="https://taozj.org/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[MacbookPro上基于ZFS的Gentoo双系统安装]]></title>
    <link href="https://taozj.org/201612/install-gentoo-root-zfs-on-macbookpro-2015-early.html"/>
    <id>https://taozj.org/201612/install-gentoo-root-zfs-on-macbookpro-2015-early.html</id>
    <published>2016-12-25T04:55:00.000Z</published>
    <updated>2016-12-31T16:09:34.000Z</updated>
    <content type="html"><![CDATA[<p>　　实在没想到，买了Macbook Pro还是避免不了折腾的命，原本很大程度买Macbook Pro就是不想折腾滴。<br>　　或许上层开发程序员无所谓，但无奈对于对做Linux底层开发者来说，涉及到macOS和Linux操作系统的差异性太大了；即使macOS命令行程序无比丰富，但是BSD风格和Linux那一套相比有时候差异还挺大的；8G内存用虚拟机太吃力了——总之，这种情况唯有双系统可解～<br>　　至于发行版，自从遇到Gentoo之后，就对其他发行版无爱了，而文件系统也一直坚持着ZFS装系统，XFS保存数据。这次是macOS+Gentoo了，原理和步骤差异不大，这里总结一下，给需要的人做个参考吧！<br><img src="/post_images/images/201612/11bbad51.jpg" alt="gentoo"></p>
<ol>
<li><strong>EFI启动引导rEFInd</strong><br>　　因为macOS系统使用GPT分区和EFI引导模式，所以要安装的Gentoo也必须使用这种引导模式。rEFInd是一个优秀的EFI引导器，支持Windows/macOS/Linux平台，所以这里需要使用rEFInd来接管，然后用来引导macOS和Gentoo。<br>　　安装rEFInd的方式十分简单，按照<a href="http://www.rodsbooks.com/refind/sip.html" target="_blank" rel="external">教程</a>几步就可以了。从EI Capitan开始，macOS启用了SIP特性，所以必须在恢复模式下安装rEFInd。<a id="more"></a></li>
<li><p><strong>Linux引导盘准备</strong><br>　　Gentoo的安装和其他系统很不一样，必须先用一个LiveCD/DVD首先启动，然后通过chroot模式安装。<br>　　之前自己都是使用带有zfs支持的<a href="http://ftp.osuosl.org/pub/funtoo/distfiles/sysresccd/" target="_blank" rel="external">system-rescue-cd</a>来安装的，但这次funtoo的示例教程用了Ubuntu。我也采用了Ubuntu LiveCD的方式，主要是考虑到Ubuntu一直对各种硬件支持良好(主要是考虑到MacbookPro没有有线网络支持)。通过dd if=ubuntu-16.04.1-desktop-amd64.iso of=/dev/sdb bs=4K写入U盘后，就可以用rEFInd来引导它了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ubuntu@ubuntu:~$ sudo -i</div><div class="line">root@ubuntu:~<span class="comment"># apt-add-repository universe</span></div><div class="line">root@ubuntu:~<span class="comment"># apt update</span></div><div class="line">root@ubuntu:~<span class="comment"># apt install --yes debootstrap zfs-initramfs</span></div><div class="line">root@ubuntu:~<span class="comment"># dmesg | grep ZFS</span></div><div class="line">[  377.595348] ZFS: Loaded module v0.6.5.6-0ubuntu10, ZFS pool version 5000, ZFS filesystem version 5</div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统分区</strong><br>　　幸亏当时买了个次乞丐版的256GB的硬盘，把160GB留给了macOS，剩下的就丢给了Gentoo。<br>　　因为采用了EFI引导方式且ESP分区已经存在，所以只需要创建root、swap和数据分区就可以了。大家都是在macOS下使用磁盘工具释放了部分的空闲空间的，而macOS默认已经把硬盘的空闲部分创建了一个分区了，所以在parted中需要首先rm 4那个分区。<br>　　至于分区的大小，首先交换分区需要大于物理内存8G的大小，因为休眠suspend to disk需要使用它；rootfs需要大一些，主要是zfs后面快照备份的时候也会占用空间；这里对于数据是创建了store不是创建home分区，主要是考虑到后面很多软件和系统的设置都会保留在用户的home分区，如果把home放到rootfs备份会方便些，而真正的数据放到store分区，软连接到home目录下面就可以。最终的分区结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># parted -a optimal /dev/sda</span></div><div class="line">GNU Parted 3.2</div><div class="line">Using /dev/sda</div><div class="line">Welcome to GNU Parted! Type <span class="string">'help'</span> to view a list of commands.</div><div class="line">(parted) <span class="built_in">print</span>                                                            </div><div class="line">Model: ATA APPLE SSD SM0256 (scsi)</div><div class="line">Disk /dev/sda: 251GB</div><div class="line">Sector size (logical/physical): 512B/4096B</div><div class="line">Partition Table: gpt</div><div class="line">Disk Flags: </div><div class="line"></div><div class="line">Number  Start   End    Size    File system     Name                  Flags</div><div class="line"> 1      20.5kB  210MB  210MB   fat32           EFI System Partition  boot, esp</div><div class="line"> 2      210MB   161GB  160GB   hfs+            Customer</div><div class="line"> 3      161GB   161GB  650MB   hfs+            Recovery HD</div><div class="line"> 4      161GB   172GB  10.7GB  linux-swap(v1)  swap</div><div class="line"> 5      172GB   220GB  48.3GB  zfs             rootfs</div><div class="line"> 6      220GB   250GB  29.6GB  xfs             store</div></pre></td></tr></table></figure>
</li>
<li><p><strong>创建zfs分区</strong><br>　　以前自己都是这么做的，主要是参考Richard Yao的<a href="https://github.com/ryao/zfs-overlay/blob/master/zfs-install" target="_blank" rel="external">zfs-install</a>操作，他是gentoo中zfs部分的开发和维护者。关注他之前有段时间沉寂了，gentoo的zfs好久没更新，但最近又再次活跃起来了。<br>　　Richard Yao的那篇文章引导和启动使用的是grub和openrc，而本文用的是EFI和systemd，所以会有一些细微的差异。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># mkdir /mnt/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool create -f -o ashift=12 -o cachefile=/tmp/zpool.cache -O normalization=formD -O atime=off -m none -R /mnt/gentoo zroot /dev/sda5</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool status</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=none -o canmount=off zroot/ROOT</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/ zroot/ROOT/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/usr/portage -o atime=off zroot/ROOT/portage</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/usr/portage/distfiles zroot/ROOT/distfiles</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/var/tmp/portage -o sync=disabled -o compression=lz4 zroot/ROOT/build-dir</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs list -t all</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool set bootfs=zroot/ROOT/gentoo zroot</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统安装准备</strong><br>　　上面的步骤已经为新系统创建好了rootfs，并且挂在了/mnt/gentoo的目录下面。下面就是将基系统stage解压到这个分区上面去，并做出一些配置更新后，chroot到这个新系统中去。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># wget http://mirrors.ustc.edu.cn/gentoo/releases/amd64/autobuilds/current-stage3-amd64/stage3-amd64-20161215.tar.bz2</span></div><div class="line">root@ubuntu:~<span class="comment"># tar -xvjpf stage3-amd64-*.tar.bz2 -C /mnt/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># mkdir -p /mnt/gentoo/etc/zfs</span></div><div class="line">root@ubuntu:~<span class="comment"># cp /tmp/zpool.cache /mnt/gentoo/etc/zfs/zpool.cache</span></div><div class="line">root@ubuntu:~<span class="comment"># cp -L /etc/resolv.conf /mnt/gentoo/etc/resolv.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># mount -t proc none /mnt/gentoo/proc  </span></div><div class="line">root@ubuntu:~<span class="comment"># mount --rbind /dev /mnt/gentoo/dev &amp;&amp; mount --rbind /sys /mnt/gentoo/sys</span></div><div class="line">root@ubuntu:~<span class="comment"># mount --make-rslave /mnt/gentoo/dev &amp;&amp; mount --make-rslave /mnt/gentoo/sys</span></div><div class="line">root@ubuntu:~<span class="comment"># chroot /mnt/gentoo /bin/bash</span></div><div class="line">root@ubuntu:~<span class="comment"># env-update; source /etc/profile; export PS1="(chroot) $PS1"; cd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment">#</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统基础安装</strong><br>　　到了这里已经chroot到目标系统中了，所做的任何操作都会保留在新系统中。不过基本系统组件，很多都没有，包含内核。<br>　　首先需要更新portage，设置profile，更新make.conf。敝人用的<a href="/upload/make.conf">make.conf</a>已经共享了，大家可以借鉴使用，酌情修改相关USE。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge-webrsync</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --sync</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile list</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile set 12 #default/linux/amd64/13.0/systemd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --info | grep ^USE</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># nano -w /etc/portage/make.conf</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge -auDN @world</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>编译kernel和zfs模块</strong><br>　　到这里，系统关键的kernel还没有产生，一般来说gentoo-sources都是比较稳定的，可以安心开启~amd64。<br>　　虽然自4.9内核发布后，各位基佬吵扰着要升级内核尝试TCP BBR拥塞控制算法，但是看了zfs目前只支持4.8的内核分支，所以这里就只用了4.8.15版本内核。内核配置是个细心活，既要支持硬件的驱动，又要删除不必要的部分精简内核(尤其对有洁癖的人来说)，还需要根据使用情况调测相应地参数。个人的<a href="/upload/kernel_4.8.15">内核配置</a>也贴出来了，虽然还没细调，但是可以工作使用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-kernel/genkernel-next</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-kernel/gentoo-sources:4.8.15</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># genkernel kernel --no-clean --no-mountboot --makeopts=-j4 --menuconfig</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-kernel/spl ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-fs/zfs-kmod ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-fs/zfs ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-fs/zfs</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl preset zfs-import-cache zfs-import-scan zfs-mount zfs-share zfs-zed zfs.target</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo 1 &gt; /proc/sys/vm/drop_caches</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># genkernel all --no-clean --no-mountboot --makeopts=-j4 --zfs --callback="emerge @module-rebuild" --menuconfig</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置rEFInd引导</strong><br>　　由于使用EFI引导，这里就不需要安装grub类似的软件了。由于macOS已经有了ESP分区了，这里就只需要将内核和initramfs拷贝到ESP分区中新建的gentoo目录就可以了，不过要注意内核名字的修改，否则可能不能被识别。而且后面有其他版本的内核，也可以用相同的方式拷贝进多个内核和initramfs，rEFInd会自动识别并在引导的时候给出启动内核的选项。<br>　　此外，还需要增加refind_linux.conf文件，设置如下参数以供内核启动的生活使用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># mkdir tmp</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># mount /dev/sda1 tmp</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cp /boot/kernel-genkernel-x86_64-4.8.15-gentoonicol tmp/EFI/gentoo/vmlinuz-genkernel-x86_64-4.8.15-gentoonicol </span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cp /boot/initramfs-genkernel-x86_64-4.8.15-gentoonicol /tmp/EFI/gentoo/initramfs-genkernel-x86_64-4.8.15-gentoonicol </span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cat /mnt/EFI/gentoo/refind_linux.conf </span></div><div class="line"><span class="string">"Default"</span>       <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro quiet"</span></div><div class="line"><span class="string">"Console"</span>       <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro quiet nox"</span></div><div class="line"><span class="string">"Emergency"</span>     <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro 1"</span></div><div class="line">(chroot) ubuntu ~ <span class="comment">#</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>安装gnome桌面环境</strong><br>　　如果直接使用emerge gnome会安装上gnome全家桶，这里可以使用gnome-light安装简洁的gnome环境，然后再根据自己的需要安装其他的gnome应用程序和组件。<br>　　重启之后就可以看见gdm的登录窗口了，而且对于retina高清屏gnome本身适配的很好，这确实超过了我的预期啊。<br>　　人家在苹果本上安装Linux后，据说调测好了，电池的续航是能够和macOS不相上下的。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># useradd -m -G users,wheel,audio -s /bin/bash taozj</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># passwd taozj</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile set 5 #default/linux/amd64/13.0/desktop/gnome/systemd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge -auDN @world</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --ask x11-base/xorg-drivers</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --ask gnome-light</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl enable gdm.service</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl enable NetworkManager</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>备份和优化</strong><br>　　这里主要是ZFS的一些参数调优、备份、迁移、挂载等操作，作为记录后续查找方便的目的，请<strong>不要操作之！！！</strong>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># echo "options zfs zfs_arc_max=536870912" &gt;&gt; /etc/modprobe.d/zfs.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># echo PORTAGE_NICENESS=19 &gt;&gt; /etc/make.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs set compression=lz4 zroot/GENTOO/build-dir</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs snapshot -r zroot@20161223_install</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs list -t snapshot</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs send -Rv zroot@20161223_install | gzip &gt; /mnt/20161223_install.snap.gz</span></div><div class="line">root@ubuntu:~<span class="comment"># gzcat /mnt/20161223_install.snap.gz | zfs receive -Fv zroot</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool import -f -o cachefile= -R /mnt/gentoo zroot</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>　　MacbookPro是Retina高清屏，默认在Gentoo安装后dpi自动翻倍成96*2=192，整体的Gnome显示效果不很理想，而且还有很多的程序不兼容(比如wiznote)，字体显示的十分小。最简单的方式是放弃retina，将显示分辨率降低:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ cat /etc/X11/xorg.conf.d/40-monitor.conf  </div><div class="line">Section <span class="string">"Monitor"</span></div><div class="line">  Identifier  <span class="string">"eDP1"</span></div><div class="line">  Option      <span class="string">"PreferredMode"</span> <span class="string">"1680x1050"</span></div><div class="line">EndSection</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>　　经过上面的设定，再加上之前的<a href="/201601/gentoo-overlay-and-software-recommend.html">文章</a>中使用infinitely进行字体显示和优化设置，最终的效果还是十分的清晰可人的。安装后还有一个问题就是键盘的~键无法使用，fn键默认是功能键盘，对此的纠正方法是对hd_apple模块参数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">echo</span> 0 &gt; /sys/module/hid_apple/parameters/iso_layout</div><div class="line"><span class="built_in">echo</span> 2 &gt; /sys/module/hid_apple/parameters/fnmode</div></pre></td></tr></table></figure></p>
<p>　　为了避免每次这么操作麻烦，可以将其写成一个systemd service，每次开机自动设置就可以了。</p>
<ol>
<li><strong>其他软件安装</strong><br>　　关于其他软件、插件的推荐，请参考之前整理的文档《<a href="/201601/gentoo-overlay-and-software-recommend.html">我的Gentoo Overlay和Linux软件推荐</a>》。因为gentoo是滚动更新版，而又有ZFS保驾护航，希望这个系统能战上几年！！！<br><img src="/post_images/images/201612/2312e6e7.png" alt="系统桌面"></li>
</ol>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.funtoo.org/ZFS_Install_Guide" target="_blank" rel="external">ZFS_Install_Guide</a></li>
<li><a href="https://github.com/ryao/zfs-overlay/blob/master/zfs-install" target="_blank" rel="external">zfs-install</a></li>
<li><a href="https://wiki.gentoo.org/wiki/Apple_Macbook_Pro_Retina" target="_blank" rel="external">Apple Macbook Pro Retina</a></li>
<li><a href="http://cloud-atlas.huatai.me/os/linux/gentoo/install_gentoo_on_macbook.html" target="_blank" rel="external">install_gentoo_on_macbook</a></li>
<li><a href="http://www.rodsbooks.com/refind/sip.html" target="_blank" rel="external">The rEFInd Boot Manager: rEFInd and System Integrity Protection</a></li>
<li><a href="https://github.com/coldnew/macbookpro-2015-config" target="_blank" rel="external">macbookpro-2015-config</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　实在没想到，买了Macbook Pro还是避免不了折腾的命，原本很大程度买Macbook Pro就是不想折腾滴。<br>　　或许上层开发程序员无所谓，但无奈对于对做Linux底层开发者来说，涉及到macOS和Linux操作系统的差异性太大了；即使macOS命令行程序无比丰富，但是BSD风格和Linux那一套相比有时候差异还挺大的；8G内存用虚拟机太吃力了——总之，这种情况唯有双系统可解～<br>　　至于发行版，自从遇到Gentoo之后，就对其他发行版无爱了，而文件系统也一直坚持着ZFS装系统，XFS保存数据。这次是macOS+Gentoo了，原理和步骤差异不大，这里总结一下，给需要的人做个参考吧！<br><img src="/post_images/images/201612/11bbad51.jpg" alt="gentoo"></p>
<ol>
<li><strong>EFI启动引导rEFInd</strong><br>　　因为macOS系统使用GPT分区和EFI引导模式，所以要安装的Gentoo也必须使用这种引导模式。rEFInd是一个优秀的EFI引导器，支持Windows/macOS/Linux平台，所以这里需要使用rEFInd来接管，然后用来引导macOS和Gentoo。<br>　　安装rEFInd的方式十分简单，按照<a href="http://www.rodsbooks.com/refind/sip.html">教程</a>几步就可以了。从EI Capitan开始，macOS启用了SIP特性，所以必须在恢复模式下安装rEFInd。]]>
    
    </summary>
    
      <category term="软件" scheme="https://taozj.org/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="生活" scheme="https://taozj.org/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（四）：Raft一致性算法]]></title>
    <link href="https://taozj.org/201612/learn-note-of-distributed-system-(4)-raft-consensus.html"/>
    <id>https://taozj.org/201612/learn-note-of-distributed-system-(4)-raft-consensus.html</id>
    <published>2016-12-19T12:46:55.000Z</published>
    <updated>2016-12-29T07:55:35.000Z</updated>
    <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　Paxos在分布式系统中地位是不容置疑的，现代分布式系统的实现基本都直接或者间接依赖于Paxos算法。不过Paxos算法有着固有的缺陷：原始的BasicPaxos原理还是比较容易理解的，整个算法无非被分为Prepare和Accept两个阶段，但是要把这种算法工程化实现，各个节点的角色是对等的，系统的效率(可用性)将会非常的低，所以常用的也就是MultiPaxos变体版本以提高性能，这也就隐含的包含了leader的概念了，然后MultiPaxos还允许一个提交窗口，窗口中允许发起多个提案，但是这种情况下考虑到服务器随时可能崩溃的情况，算法将会变得极端复杂。Lamport爷爷就此也是简明说了几句不清不楚的优化，没有具体的实现细节，算是挖了一个巨坑吧。所以说了解BasicPaxos只是一个皮毛，将其推送到工程化可不是件容易的事情。<br>　　Raft算法是斯坦福两位博士生提出的分布式一致性系统，从其论文的题目《<a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">In Search of an Understandable Consensus Algorithm</a>》可以看出，作者以Paxos过于复杂为出发点，力求得到一个正常智商的大学生都能看懂，且工程上也容易实现的分布式系统一致性算法为目标。Raft算法借鉴了Paxos的原理，但最大不同是显式强化了Leader这个角色(虽然很多Paxos算法的实现也会产生Leader角色，但这不是Paxos算法本身所必须的)，并添加了各种约束条件(比如日志的连续性)，让算法更加容易理解和实现。虽然吾等草根屁民尚且不能从理论上审视这个算法的正确性，不过短短时间内美国很多著名大学分布式教学都将Raft算法列入教学课程，且基于Raft协议的项目也越来越多，这些事实已经足以证明一切了。<br>　　学习Raft算法，一篇<a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">普通论文</a>和一篇<a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="external">博士学位论文</a>算是不得不读的经典，而前者网上发现了翻译好的中文版本，简单对比了一下原文，发现翻译的质量还是挺高的，很值得参考，但有些原理中文理解困难的话可以对比英文方便理解。作为正规论文，按照论文八股需求难免有些啰嗦拖沓，本文就是按照前面论文阅读摘抄一些重点要点出来，而后面那篇两百多页的博士论文，后面可以慢慢评鉴一下作为补充吧，当然最好的方式还是——一言不合就读<a href="https://github.com/logcabin/liblogcabin" target="_blank" rel="external">代码</a>，毕竟作者说就两千多行！<br>　　还有，论文对状态机的描述比较的好，算是归纳了分布式系统的本质——复制状态机的基础是通过复制日志来实现的：当每个副本的初始状态相同，只要保证各个副本得到的日志都是顺序且一致的，那么按照相同的顺序执行这些日志中的指令，所有副本必然可以进行相同的状态转移得到相同的结果。所以分布式系统解决的根本问题，就是一致性问题，具体就是日志一致性问题，在这个基础上，上层就可以方便实现分布式日志、分布式数据库(bin log)、分布式存储等具体业务了。<br><img src="/post_images/images/201612/b0c484d0.jpg" alt="raft-stat"></p>
<h1 id="二、Raft算法">二、Raft算法</h1><h2 id="2-1_Raft算法基础">2.1 Raft算法基础</h2><p>　　Raft算法保证和Paxos算法具有相同的安全性，当集群中绝大多数服务器是正常的，则集群即可以正常工作，比如5个节点的集群，允许2个节点的失效。Raft算共有三种角色、需要处理三个问题，三个角色分别是Leader、Candidate、Follower，三个问题是Leader选举、日志复制和安全性，三个问题将会在后面详细阐述。<br>　　任何服务器只能处于上述三种角色中的一种，正常工作的集群具有一个Leader，剩余的节点都是Fellower，系统保证任何时候至多只有一个Leader，也有可能在选举的过程中尚未产生Leader，而在选举新Leader的时候会产生Candidate这个角色。<br><a id="more"></a><br>　　a. <strong>Leader</strong><br>　　Raft算法强化了一个领导者(Leader)的角色。一旦被选举成为Leader，就会发送空的AppendEntries RPC作为心跳给所有其他服务器，并且这个心跳会在一定空余时间后不停的发送，这样可以阻止选取超时而阻止其他服务器重新发起选举操作；<br>　　Leader负责接收客户端的请求(如果客户端和Fellower联系，那么这个请求会被重新定向给Leader)，然后附加entry到本地日志存储中，并负责把日志<em>安全地</em>复制到其他服务器上面，entry被用于Leader本地状态机后给客户端发送响应；<br>　　对于任何一个Fellower，如果已存储的日志比较旧，还会向Leader不断减小nextIndex要求发送之前的日志条目；<br>　　如果日志被安全地复制到了大多数节点上面，则增加提交索引号commitIndex，表明日志已经被安全复制；<br>　　b. <strong>Follower</strong><br>　　通常的服务器角色状态，只响应来自Candidate和Leader的请求；<br>　　如果在选举超时到达后还没收到Leader的心跳消息，或者是候选人发起投票请求，则自己变成Candidate；<br>　　c. <strong>Candidate</strong><br>　　当转变成Candidate后就立即开始选举过程——增加当前term、给自己投票、重置选举超时定时器、发送RequestVote给所有的服务器；<br>　　如果在超时之前收到绝大多数服务器的投票，就成为Leader；当一个节点收到RequestVote RPC的时候，如果请求投票节点的term不比自己旧，其日志也不比自己少，则投票给他；<br>　　如果收到来自新Leader的AppendEntries RPC，则退变成Fellower；<br>　　如果选举过程超时，则再次发起新一轮选举；</p>
<p>　　Raft中使用term表示Leader的任期，使用连续递增的整数来标记区分，在Raft中充当了逻辑时钟的作用，很多操作和记录会打上这个“逻辑时间戳”；每个服务器存储自己的term，服务器之间通信也会交换各自当前term，通过比较term可以确定哪些信息已经过期；当Candidate或Leader发现自己的term过期之后，会立即退变成Fellower的角色；如果服务器收到包含过期term的请求，就会直接拒绝这个请求返回false。<br>　　Raft算法中节点之间的通信使用RPC的方式，主要包括RequestVote、AppendEntries以及InstallSnapshot三种，RPC可以并行的被发起，而当没有及时收到响应的时候会进行重试，同时RPC只需要在绝大多数快速的节点上完成就可以了，少部分比较慢的节点不会影响到系统的整体性能。
　　</p>
<h2 id="2-2_Leader选举">2.2 Leader选举</h2><p>　　很显然以Leader为中心可以大大简化系统的设计和实现，但是分布式系统中任何一个服务器都可能随时崩溃不可用，那么必须使用选举机制来解决Leader出错导致的单点故障。<br>　　Raft中Leader地位的维持和心跳机制密切相关。集群中所有服务器默认都是Fellower的角色，如果Fellower在一段时间中没有收到任何消息(无论是正常消息还是心跳消息)，就会触发选举超时，从而认为系统中没有可用的领导者，进而开始进行选举。选举开始的时候，Fellower会增加当前term并切换为Candidate角色，然后并行向集群中所有其他服务器节点发送RequestVote RPC来给自己投票，候选人等待直到三种情况之一发生：<br>　　a. <strong>该Candidate赢得该次选举成为新Leader</strong><br>　　当某个Candidate从集群中绝大多数服务器获得针对该term的选票，则其赢得该次选举成为Leader，因为按照先来先得的原则，每个服务器最多会对一个term投出一张选票，获得绝大多数选票确保了至多只有一个候选人赢得该次选举。<br>　　一旦Candidate成为Leader，就会向其他服务器发送心跳消息维护自己Leader的地位，并且阻止产生新的Leader。<br>　　b. <strong>其他服务器成为新Leader</strong><br>　　Candidate在收集选票的时候，很可能收到其他服务器发送的声明自己是Leader的AppendEntries RPC消息，此时如果收到的AppendEntries RPC的term不小于该Candidate当前的term，则Candidate承认发送该AppendEntries RPC的服务器的Leader合法地位，自己退化为Fellower角色。否则会拒绝这个RPC并维持自己Candidate的角色。<br>　　c. <strong>一段时间后没有任何Candidate胜出</strong><br>　　一般出现在多个Fellower变成Candidate，然后同时发出RequestVote RPC请求，导致选票被瓜分后，没有任何一个Candidate获得绝大多数选票。此时Candidate会增加term并开始新一轮的Leader选举。<br>　　通常情况下这种选票瓜分的恶性竞争会持续下去。Raft采用随机选举超时的机制来减少这种情况的发生，选举超时设置为某个固定时间区域中的随机值(比如150-300ms)，这样当现有Leader挂掉之后，通常也只有一个Fellower会首先超时，然后迅速切换为Candidate、发出RequestVote RPC并赢得选举，然后快速发送心跳包；同时在发生选票瓜分的情况下，每次在Candidate开始新一轮的选举时候，会重置一个随机的选举超时时间。通过这机制，发生选票瓜分的几率被大大降低了。</p>
<h2 id="2-3_日志复制">2.3 日志复制</h2><p>　　一旦Leader的角色被确定，就可以接受客户端的请求并提供服务了。客户端的每一个请求都包含状态机的执行指令，Leader负责刚其作为一个entry追加到自己本地日志中，然后并行的向其他服务器发送附含执行指令的AppendEntries RPC，使其他服务器都复制这个日志entry。当该条日志被安全的复制后(即通过AppendEntries RPC调用的结果得知，该日志被安全地复制到绝大多数服务器上面了)，Leader会应用这条日志到自己的状态机中，并将执行的结果返回给客户端。如果(少部分)Fellower崩溃或者运行缓慢，或者因为网络等问题，即使Leader已经回复了客户端，Leader仍然会不断的重试AppendEntries RPC直到所有的Fellower都最终存储了所有的日志条目。<br>　　在Raft算法中，日志是有序序号标记的entry组成的，每个entry包含该创建时候的term、状态机需要执行的指令、在所有日志中的位置索引组成。Raft保证当日志条目被复制到绝大多数服务器上面的时候，该日志entry就会被提交，即更新commitIndex，Raft算法同时也保证所有已提交的日志都是持久化的并且最终会被所有的可用状态机执行。<br><img src="/post_images/images/201612/978287ea.jpg" alt="raft-log"><br>　　Leader跟踪了最大将会被提交日志entry的索引，并且该索引值会被包含在未来所有的AppendEntries RPC中(包含附加日志内容为空的心跳包)，这可以方便的让其他服务器知道Leader的提交位置，一旦Fellower知道一条日志已经被提交，就会按照日志的顺序将其应用到本地的状态机中去执行。<br>　　和Paxos不同的是，Raft的日志约束为连续的、中间不允许有空洞，而且相同索引的日志在各个服务器上面指令完全相同，这样的设计可以减少很多不必要的麻烦，具体来说：<br>　　(1) 如果在不同服务器的日志中拥有相同的索引和Term，那么他们存储了相同的指令；<br>　　(2) 如果不同服务器中两个日志具有相同的索引和Term，那么他们之前所有的日志条目也都全部相同。<br>　　对于上面第二点，通过每次RPC简单一致性检查就可以确保。每当Leader发送AppendEntries RPC的时候，会包含新entry紧接之前条目的索引位置和term附加在里面，当Fellower接收到的时候会进行一致性检查，如果发现索引及term指定的日志找不到，就会拒绝接收该AppendEntries RPC请求。这种一致性通过强制Fellower复制Leader日志的方式来解决，领导者对每一个Fellower都维护了一个nextIndex，表示下一个需要发送给Fellower日志条目的索引位置，Leader通过不断减少nextIndex后退的方式尝试最终会找到和Fellower日志不一致位置开始的地方，然后从这个地方开始Leader将自己的日志同步给Fellower就可以了。不过这种大规模的日志不一致性通常在服务器接连崩溃的情况下更容易产生，当新选出了Leader之后，该Leader也会强制所有服务器的nextIndex为自己本地最后一条日志索引值+1，这样在后续正常发送AppendEntries RPC请求后，所有的Fellower就会自动进行本地日志一致性检查并在必要情况下进行同步操作了。<br>　　通过这种方式，只需Leader向Fellower单方面同步日志就可以完成，而且只需要Leader正常发送AppendEntries RPC请求，Fellower自己进行一致性检查，Leader得到失败的反馈信息后，再同Fellower进行不断交互以使得两者日志最终趋于一致，而且这种操作不会影响到其他的Fellower，因而也不会影响到系统整体的性能。</p>
<h2 id="2-4_安全性">2.4 安全性</h2><p>　　上面的内容都比较的理想化，但是在现实环境中Leader、Fellower各个服务器随时都可能崩溃不可用，如果没有额外的约束整个系统的工作是不安全的，比如当只有少量日志的Fellower被选取成了新Leader的情况。<br>　　简单来说，此处就是要实现即使发生了Leader重新选取，也要让任何新Leader对于给定的term，都必须有前任Leader所有已经被提交的日志条目，那么上面的机制就仍然可以正常工作。</p>
<h3 id="2-4-1_增加选举限制">2.4.1 增加选举限制</h3><p>　　如果任何的Fellower都可以成为新人Leader，那么这个新Leader很有可能缺失前Leader的部分提交日志，很多一致性算法确实是这样的，然后通过某些方法识别出新Leader缺失日志，并在选举阶段或者成为新Leader之后快速的将这些缺失日志补齐，这些方法实现起来比较复杂。Raft算法通过很简单的限制解决了这个问题：<strong><em>在RequestVote RPC 中包含了Candidate的日志信息，然后投票人会拒绝掉那些日志没有自己新的请求</em></strong>。<br>　　上面的这条约束肯定是有效的：对于一个被提交的日志，那么这个日志肯定是被大多数服务器所见而被存储的，而一个Candidate要想成为Leader就必须和集群中的大多数服务器所通信，这样一来新Leader肯定会遇到至少一个记录着最新提交日志的服务器。再加上上面的限制条件，那么一个新当选的Leader至少会和大多数的服务器节点一样新，其肯定持有了所有已经提交了的日志条目。</p>
<h3 id="2-4-2_提交前term内的日志条目">2.4.2 提交前term内的日志条目</h3><p>　　在Raft算法中，当一个日志被安全的复制到绝大多数的机器上面，即AppendEntries RPC在绝大多数服务器正确返回了，那么这个日志就是被提交了，然后Leader会更新commitIndex。<br>　　这里书中描述的比较复杂，其实本质就是通过上面的选举机制和提交限制，让Raft算法是安全的，即使是针对前term的日志：如果日志被复制到绝大多数服务器上面，那么含有较少日志的S5服务器就不会被选举成Leader，也就不会发生描述的entry-2日志即使被复制到绝大多数服务器上面，也最终被覆盖的情况；而当含有被复制的绝大多数日志entry-2的服务器被选为新节点的时候，提交entry-4也会让前面的entry-2被隐式提交。</p>
<h3 id="2-4-3_Candidate和Fellower崩溃">2.4.3 Candidate和Fellower崩溃</h3><p>　　Candidate和Fellower崩溃的情况处理要简单的多。如果这类角色崩溃了，那么后续发送给他们的 RequestVote和AppendEntries的所有RCP都会失败，Raft算法中处理这类失败就是简单的无限重试的方式。<br>　　如果这些服务器重新可用，那么这些RPC就会成功返回。如果一个服务器完成了一个RPC，但是在响应Leader前崩溃了，那么当他再次可用的时候还会收到相同的RPC请求，此时接收服务器负责检查，比如如果收到了已经包含该条日志的RPC请求，可以直接忽略这个请求，确保对系统是无害的。</p>
<h1 id="三、集群成员变更">三、集群成员变更</h1><p>　　集群成员的变更和成员的宕机与重启不同，因为前者会修改成员个数进而影响到Leader的选取和决议过程，因为在分布式系统这对于majority这个集群中成员大多数的概念是极为重要的。<br>　　在集群中成员变更的NEW配置不可能立即在所有成员中生效，所以必须采用两阶段的方式来保证安全性，传统方式是将集群暂停工作，让其不再接受新客户的请求，更新配置完成后在让集群继续正常运行。<br>　　Raft中集群成员的变更是全自动的，通过产生一个“共同一致状态”来过渡传播NEW配置，并且做到在集群成员变更过程中仍然支持客户端请求，依靠在临界状态下达成一致的操作(针对选取和提交)需要分别在新旧两种配置上都获得绝大多数服务器投票才可以。成员变更请求在日志中以特殊的configuration entry来存储和通信，主要通过C-old,new和C-new这两个特殊日志entry来实现。<br>　　在Leader接收到成员变更请求后，会创建C-old,new日志entry，然后Leader会首先将其添加到自己本地日志中，并通过之前描述的普通日志复制提交流程，确保在OLD、NEW两个配置下的在绝大多数服务器上复制成功并提交；接下来Leader会创建一个C-new并在NEW配置下的绝大多数机器上复制成功并提交，创建C-new之后NEW配置就可以单独做出决议了。此外，这里还有一个关键性的约定——所有的服务器一旦存储了C-old,new日志条目后(实际就是见到NEW配置后)，就总是会用NEW配置而无论这个配置日志条目是否已经被提交，通过这种方式实现NEW配置在集群成员中快速传播。一旦C-old,new被提交后，OLD和NEW配置都不能单方面的产生决议(只能在新旧两个配置下都完成绝大多数投票)以保证安全，直到NEW配置下的C-new日志条目被产生，NEW配置就可以单独决议了。<br><img src="/post_images/images/201612/d255f8d6.jpg" alt="raft-member"><br>　　至于在C-old,new提交和C-new创建之间为什么会有间隙，原文没有说清楚。其实也很容易理解：在C-old,new日志entry的创建和提交之间，Leader还可能有其他新的决议发起(比如客户端请求)，按照日志顺序一旦C-old,new被提交，那么集群中绝大多数主机都更新成NEW配置了，但是在NEW配置传播的过程中，为了保证安全在这个期间产生的所有日志都必须在新老配置中都得到绝大多数投票才允许真正被提交。至于C-new的产生，是为了表明Leader承诺从这个时候起所有的日志都不再会发给OLD配置主机，所以这个点之后NEW配置就可以独立工作了，由于Raft序列化日志的特性，一旦这个C-new日志条目被提交，集群配置中被删除的服务器就可以安全下线了。<br>　　新加入的机器日志都是空白的，起始阶段都在进行日志追赶(catch up)，Raft算法为了减少可能的性能损耗，对新加入的机器都是以旁观者的状态一直追赶旧日志而不会追加新日志参与投票，只有到了追赶日志和Leader对齐了，再参与新日志追加投票以行使正常集群成员的职能。还有NEW配置可能会把现任Leader删除掉，那么当C-new被提交后，该Leader将会卸任并退化成Fellower的角色，此时在NEW配置下会发生新Leader的选举，选举得到的新Leader一定是NEW配置下的主机，而在这之前由于一致性状态的约束，如果发生Leader选举那么选出来只可能是OLD配置中的服务器，因为一致性状态选举操作必须在新旧配置中都得到绝大多数选票才行。</p>
<h1 id="四、日志压缩">四、日志压缩</h1><p>　　日志会随着系统的不断运行会无限制的增长，这会给存储带来压力，几乎所有的分布式系统(Chubby、ZooKeeper)都采用快照的方式进行日志压缩，做完快照之后快照会在稳定持久存储中保存，而快照之前的日志和快照就可以丢弃掉。<br>　　Raft算法中快照所需保存的数据有：快照点时候状态机的状态信息；最后被快照所取代的日志条目在日志中的索引值；上面被取代条目所属的任期term，此外为了支持成员更新，快照还会将当前最新的成员配置写入上面描述的那个日志索引中。<br>　　Raft采用让服务器独立创建快照，而不是只让Leader负责创建快照，主要考虑到在所有服务器本地已经具有了创建快照所需的全部信息，而且本地创建快照代替Leader创建快照，就免除了Leader要向各个节点传输快照的额外任务、带宽和性能损耗，而且在Leader负责客户端响应、发送RPC的任务外如果还需维护快照的任务，其角色就会更加复杂。<br>　　在Raft中快照都是各个服务器独立创建的，但是有时候需要Leader向其他服务器发送快照，比如某些服务器跟随的速度缓慢，或者新加入集群的服务器，此时需要向Leader同步日志的时候，如果Leader创建了快照并将之前的日志都删除掉了，那么此时就必须通过快照的方式发送了。<br>　　Raft中采用一个额外的InstallSpanshot RPC的调用来实现日志传输，虽然名曰快照，其实也就算是一个特殊的日志entry。当接收到快照的时候，通常情况下快照会包含接受者中没有的信息，即快照代表的日志entry会比接受者当前本地含有的日志要新，此时接收者会丢弃掉自己所有的日志，并在指定位置写入该快照作为最新状态；如果因为网络或其他因素，接收者含有比快照更新的日志，那么接收者负责把快照位置之前的数据全部删除，同时比快照新的数据需要保留下来。</p>
<h1 id="五、Client交互">五、Client交互</h1><p>　　Client只向Leader发送请求，当Client开始的时候会随机向集群中的任何一个服务器发送请求，如果Client挑中的恰巧不是Leader，那么该服务器会拒绝Client的请求，并将其最近获得的Leader信息(包括通信用的IP:Port)返回给Client，接下来Client根据这个信息直接向Leader重新发送请求；如果此时Leader恰巧崩溃了，那么Client的请求就会超时出错，Client会再次重新随机挑选服务器再次发送请求。<br>　　Raft算法要求Client的请求是线性化语义的，即每次请求会被立即执行，在请求和响应中只会被执行一次(也就是RESTful中的等幂性，同一个请求发起一次或者多次，最终的效果是相同的)，而要确保这个效果的方式是客户端负责对每条指令都赋予一个唯一的序列号，然后状态机跟踪每条指令最新序列号和其响应结果，如果后面收到一条指令具有相同的序列号但是该序列号已经被执行了，那么就直接返回结果而不重新执行该指令。<br>　　对于只读操作可以直接处理而不需要记录日志，但是会有读取脏数据的风险。在Leader稳定运行的时态，Leader肯定知道当前已经提交的entry，但是在新Leader选取刚上任的时候，虽然肯定是含有最完整的日志信息的，但是还不知道提交到哪条entry了(可以参看上面提交前term日志条目的情况)，所以在新Leader上任的时候会发起一个no-op的entry来刷新得到最新commit信息。然后，Leader在响应只读请求的时候，需要向绝大多数服务器发送一个心跳信息，确保当前自己还是合法的Leader。</p>
<h1 id="总结">总结</h1><p>　　如果在工程化的水平上考虑，Raft算法的确比MultiPaxos要简单容易的多，而且对比PhxPaxos中做出的诸如Master选举与心跳、Master负责所有客户端请求(允许普通节点响应脏数据除外)、日志压缩与快照等等操作，在这里看来也是那么的熟悉，只不过Raft对于整个分布式的设计和实现要更清晰、更系统，而不会让人感觉是在MultiPaxos的基础上缝缝补补拼凑出来的一个怪物吧。<br>　　眼观这么多论文，大家对Paxos的工程化实现，感觉都是相互借鉴啊，哈哈！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">In Search of an Understandable Consensus Algorithm</a></li>
<li><a href="https://raft.github.io/" target="_blank" rel="external">raft.github.io</a></li>
<li><a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="external">找一种易于理解的一致性算法（扩展版）</a></li>
<li><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="external">CONSENSUS: BRIDGING THEORY AND PRACTICE</a></li>
<li><a href="https://raft.github.io/slides/raftuserstudy2013.pdf" target="_blank" rel="external">Raft: A Consensus Algorithm for Replicated Logs</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="一、前言">一、前言</h1><p>　　Paxos在分布式系统中地位是不容置疑的，现代分布式系统的实现基本都直接或者间接依赖于Paxos算法。不过Paxos算法有着固有的缺陷：原始的BasicPaxos原理还是比较容易理解的，整个算法无非被分为Prepare和Accept两个阶段，但是要把这种算法工程化实现，各个节点的角色是对等的，系统的效率(可用性)将会非常的低，所以常用的也就是MultiPaxos变体版本以提高性能，这也就隐含的包含了leader的概念了，然后MultiPaxos还允许一个提交窗口，窗口中允许发起多个提案，但是这种情况下考虑到服务器随时可能崩溃的情况，算法将会变得极端复杂。Lamport爷爷就此也是简明说了几句不清不楚的优化，没有具体的实现细节，算是挖了一个巨坑吧。所以说了解BasicPaxos只是一个皮毛，将其推送到工程化可不是件容易的事情。<br>　　Raft算法是斯坦福两位博士生提出的分布式一致性系统，从其论文的题目《<a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm</a>》可以看出，作者以Paxos过于复杂为出发点，力求得到一个正常智商的大学生都能看懂，且工程上也容易实现的分布式系统一致性算法为目标。Raft算法借鉴了Paxos的原理，但最大不同是显式强化了Leader这个角色(虽然很多Paxos算法的实现也会产生Leader角色，但这不是Paxos算法本身所必须的)，并添加了各种约束条件(比如日志的连续性)，让算法更加容易理解和实现。虽然吾等草根屁民尚且不能从理论上审视这个算法的正确性，不过短短时间内美国很多著名大学分布式教学都将Raft算法列入教学课程，且基于Raft协议的项目也越来越多，这些事实已经足以证明一切了。<br>　　学习Raft算法，一篇<a href="https://raft.github.io/raft.pdf">普通论文</a>和一篇<a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf">博士学位论文</a>算是不得不读的经典，而前者网上发现了翻译好的中文版本，简单对比了一下原文，发现翻译的质量还是挺高的，很值得参考，但有些原理中文理解困难的话可以对比英文方便理解。作为正规论文，按照论文八股需求难免有些啰嗦拖沓，本文就是按照前面论文阅读摘抄一些重点要点出来，而后面那篇两百多页的博士论文，后面可以慢慢评鉴一下作为补充吧，当然最好的方式还是——一言不合就读<a href="https://github.com/logcabin/liblogcabin">代码</a>，毕竟作者说就两千多行！<br>　　还有，论文对状态机的描述比较的好，算是归纳了分布式系统的本质——复制状态机的基础是通过复制日志来实现的：当每个副本的初始状态相同，只要保证各个副本得到的日志都是顺序且一致的，那么按照相同的顺序执行这些日志中的指令，所有副本必然可以进行相同的状态转移得到相同的结果。所以分布式系统解决的根本问题，就是一致性问题，具体就是日志一致性问题，在这个基础上，上层就可以方便实现分布式日志、分布式数据库(bin log)、分布式存储等具体业务了。<br><img src="/post_images/images/201612/b0c484d0.jpg" alt="raft-stat"></p>
<h1 id="二、Raft算法">二、Raft算法</h1><h2 id="2-1_Raft算法基础">2.1 Raft算法基础</h2><p>　　Raft算法保证和Paxos算法具有相同的安全性，当集群中绝大多数服务器是正常的，则集群即可以正常工作，比如5个节点的集群，允许2个节点的失效。Raft算共有三种角色、需要处理三个问题，三个角色分别是Leader、Candidate、Follower，三个问题是Leader选举、日志复制和安全性，三个问题将会在后面详细阐述。<br>　　任何服务器只能处于上述三种角色中的一种，正常工作的集群具有一个Leader，剩余的节点都是Fellower，系统保证任何时候至多只有一个Leader，也有可能在选举的过程中尚未产生Leader，而在选举新Leader的时候会产生Candidate这个角色。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Amazon Dynamo论文阅读笔记]]></title>
    <link href="https://taozj.org/201612/read-note-of-amazon-dynamo.html"/>
    <id>https://taozj.org/201612/read-note-of-amazon-dynamo.html</id>
    <published>2016-12-16T14:15:34.000Z</published>
    <updated>2016-12-18T08:00:18.000Z</updated>
    <content type="html"><![CDATA[<p>　　其实个人一直比较喜欢读Google、Amazon、Facebook这类科技公司工程化的paper，一方面是这类文章通常不会夹杂着让人看着眼花缭乱的数学公式(而且很多文章往往很简单的道理也会被装饰的神神叨叨滴)；二来这些系统用到的技术都比较的大众成熟，可以很容易的在网上搜到相关资料，让你在短短时间就知道大概是个什么意思；还有最主要的是这些论文是进行实实在在工程化并用于生产环境了，方案可行性自然不用多说，在实现的过程中遇到的各种现实、细节问题也是很值得学习揣摩和借鉴的。比如，接下来要说的<a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">《Dynamo: Amazon’s Highly Available Key-value Store》</a>这篇论文要算是分布式系统设计实现中的必读经典了，虽然该套系统没有开源，而且由于商业机密部分内容没能够详细阐述，但丝毫没有影响到它对分布式系统设计实现的重要指导作用。<br><img src="/post_images/images/201612/3a93058f.png" alt="aws"></p>
<h1 id="一、前言">一、前言</h1><p>　　Amazon Dynamo系统的设计和实现从最开始就比较的实用主义：首先Amazon作为全球最领先的电商企业，其丰富的经验让其可以洞悉到绝大多数互联网公司的需求点和关切点，其次Dynamo是作为服务出售的，所以其并没有设计实现成一个至臻完美的分布式存储模型，它只支持K-V非关系型键值存储，就像是一个巨大的dict/map结构，只支持get()、put()两种简单访问方式，优化成高可写入性要求，存储的对象尺寸大多小于1M，成本考虑上支持99.9%级别的可用性(百毫秒读写响应)，但依据Amazon在云计算领域的强大实力，该系统在性能、可靠性、效能、伸缩性等方面没有丝毫的妥协。<br>　　和绝大多数分布式系统一样，Dynamo使用最终一致性获取性能从而保证可用性的，然后通过现有各项成熟的技术手段解决项目中的各种问题：数据使用一致性hashing进行分区，同时提供数据副本保证安全；通过NWR和对象vector lock版本机制有限的解决冲突并实现最终一致性；Merkle tree数据结构可以实现节点间数据的高效同步；整个系统完全去中心化，采用Gossip协议实现成员变更的同步。</p>
<h1 id="二、背景知识">二、背景知识</h1><h2 id="2-1_系统假设和设计需求">2.1 系统假设和设计需求</h2><p>　　a. 访问模式：数据项通过key唯一确定，且只提供读、写两个操作接口，对象采用二进制方式存储。这种K-V的存储符合绝大多数互联网海量对象的存储需求，对象的读取写入只支持单个对象的操作，任何多对象、关系性的操作都不支持；<br>　　b. ACID：就是分布式系统中的原子性、一致性、隔离性和持久性，强一致性模型虽然实现简单，但是可用性的最大杀手，所以该系统只提供最终一致性保证；同时也不支持隔离性，只提供单个元素的更新操作。<br>　　c. 有效性：服务必须提供稳定可靠的延时和吞吐量，根据在性能、价格、可用性和持久化各个因素的考量和妥协中，提供99.9%的可访问性；<br>　　由于在内部使用，所以不用考虑授权、鉴权操作，整个假设在一个可信环境的内网中执行的，不考虑拜占庭通信模型。<a id="more"></a></p>
<h2 id="2-2_设计考虑的问题">2.2 设计考虑的问题</h2><p>　　在商业系统领域，传统方式都是采用强一致性的数据访问，数据会在各个节点之间进行同步，在数据不确定是否正确的情况下通常设置该数据将是不可用的状态。这种模型虽然从编程角度很容易实现，但是这种情况下一旦出现问题(比如脑裂)，整个系统的可用性就必然会受到影响甚至处于不可用状态。<br>　　对于易于出现主机和网络系统的情况，可以通过优化同步操作来提高系统的可用性，比如后台异步化、并行传输，只要实现最终一致性就可以，但是异步化之后很容易导致修改和访问冲突和失败的情况，这时就需要确定何时、何人负责解决冲突问题(背锅问题)了，针对这个问题：<br>　　a. 很多传统的系统是在写阶段解决冲突和失败，这样读的时候操作会很简单，而如果比如因为冲突而不能顺利写入，写入操作就会被驳回返回失败。而Dynamo设计就是最强的可写入性，比如文中反复出现的购物车情形，即使网络不可用的情况下也不会驳回客户的请求，否则会很影响用户体验，为了保证这样高的可写入性，就必须在读阶段承担起这个解决冲突和失败的任务。<br>　　b. 解决冲突的角色可以是数据中心也可以是用户应用程序，前者是自动化解决冲突，通常只能用简单的机制来解决，比如“使用最新写入值(last write win)”，而用户程序处理会更加的灵活，比如多个版本共同求交集结果等方式。<br>　　除此之外，Dynamo还需要考虑：系统的高伸缩性；节点的对称性，所有的节点都一视同仁；去中心化，采用P2P的发现和同步技术，这一直是分布式系统追求的目标(比如避免单点故障)。</p>
<h1 id="三、系统架构">三、系统架构</h1><p>　　系统的工程化会涉及到相当多的细节，比如：数据持久性存储、可伸缩性、负载均衡、成员管理和错误探测、错误恢复、复制备份同步、过载处理、状态迁移、并发和任务调度、请求安排、请求路由、系统监测和报警、配置管理。篇幅限制，这篇论文没有对上面所有内容都展开论述。</p>
<h2 id="3-1_系统接口">3.1 系统接口</h2><p>　　Dynamo的数据类型是K-V，只支持最简单的get()和put()读和更新接口。Dynamo的底层会将key进行MD5 hash处理得到128bit的索引值，通过其确定底层实际的存储节点。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">get(key);</div><div class="line">put(key, context, object);</div></pre></td></tr></table></figure></p>
<p>　　get(key)正常情况下会返回key锁关联的object，而如果发生冲突(且底层无法解决冲突)的话，会返回一个列表，包含各个冲突的版本和context信息，用户可以用自己的机制解决这些冲突，并将结果写回更新成最新版本；put(key, context, object)会进行存储更新操作，其context参数通常是之前get读返回的。</p>
<h2 id="3-2_分区算法">3.2 分区算法</h2><p>　　对于节点出错和删除，以及添加节点的时候，必须采用一致性hashing的方式保证对其他节点最小影响。一致性hashing的知识在<a href="/201612/consistent-hashing.html">《一致性hash原理》</a>已经详细描述过了，主要也是基于hash环分区的方式实现的，而且相似地，为了让存储节点均匀分布、实现负载均衡，采用了虚拟节点的改进方式，这样不仅在平常访问的时候，而且在增加和删除节点的时候，都会将影像平均分布到其他节点上去，而不会对少数节点造成加大影响。</p>
<h2 id="3-3_副本">3.3 副本</h2><p>　　因为Dynamo实现的是存储系统，而不是前面介绍到的缓存系统，所以为了数据的安全必须使用产生多副本(Replication)机制。Dynamo会让每个数据产生N个副本，关于这些副本的分布，是用到前面通过一致性hash根据key计算出该数据属于哪个虚节点，然后沿着顺时针的方向在接下来的N-1个节点上产生该数据的额外副本。<br>　　上面负责存储key的节点和副本节点共同组成了preference list列表。考虑到有些节点会出错不能访问的情况，这个列表的长度通常会大于N。而且在使用了虚拟节点机制后，物理节点会在hash环中出现多次，所以如果不加挑选的话，很有可能N个虚拟节点会映射到底层少于N个实际的物理存储节点上，显然这样的话单个物理节点可能会出现多个虚拟节点副本的丢失，所以系统在选择节点组成preference list的时候，都是采用跳跃的方式，确保列表中保存的都是物理节点各不相同的虚拟节点。</p>
<h2 id="3-4_数据版本机制">3.4 数据版本机制</h2><p>　　Dynamo只保证最终一致性，采用异步的机制进行读写操作。<br>　　Dynamo采用vector clocks的机制，vector clock记录了某节点对该key更改的版本记录，是一个(node, counter)的结构，那么所有节点对该对象的修改将可以组成一个vector clock的列表。系统可以根据检查两个节点上某个对象的vector clock列表，而判断该对象在各节点上的副本，是序列化的因果关系还是并行分支的关系：如果是前者(大多数正常情况)，系统就可以自动进行语法冲突合并(syntactic reconciliation)，新版本的数据覆盖旧版本的数据；后者冲突情况则需要返回包含所有冲突版本等信息的context，然后由client端负责解决这个冲突，并最后用context更新写会最新结果，称为语义冲突合并(semantic reconciliation)。<br><img src="/post_images/images/201612/e2821ae0.png" alt="aws-1"><br>　　比如上图的过程，D1[(Sx, 1)]、D2[(Sx, 2)]都是由同一个节点X做的修改，所以不可能产生版本冲突，而当因为节点出错、前端负载均衡等因素影响，后面的更新都基于D2但发生在了Y、Z两个节点上，接下来客户读取的时候会发现D3、D4之间没有因果关系，因此将所有结果都罗列返回给客户端，client负责合并后并通过X节点更新写入，且相应地增加Sx的版本号。<br>　　看到这里可能会想到，如果所有的写请求都发向某个固定的节点，难么版本冲突的概率不就会大大降低了么？如果该节点一直可用，那么这种序列化的修改肯定是可以大大降低冲突的概率的，但是论文指出这样的操作负载是不均衡的，那么不均衡的节点请求会导致可用性降低。实际上，通常的写都是紧跟在读操作之后(难道是必须的？put需要一个context啊)，通常写会发送到读响应最快的那个节点上面去，这样的优化就可以保证较好的写入性能，同时也间接实现了”READ-YOUR-WRITE”这读己之所写级别的一致性。<br>　　如果记录每个节点的更新版本的话，通常情况不会产生问题，因为更新都是在preference list的前N个节点，但是在发生脑裂或某些节点出错后，后续节点会依次代替不可用节点响应写入请求，那么这个vector clock列表长度必然会不断增加。为了防止这种情况，实践中的vector clock会加上时间戳以记录该节点最后修改的时间，当vector list列表的长度超过固定长度(比如10)的时候，将时间戳最旧的节点版本信息剔除出去。</p>
<h2 id="3-5_get()和put()操作">3.5 get()和put()操作</h2><p>　　用户的请求都是在HTTP层之上发起的，将用户请求分派到特定节点，分派的方式有两种：<br>　　a. 通用的负载均衡分配，这时分配是通用的基于后端节点的负载信息确定的；<br>　　b. 通过将客户端链接上节点发现(partition-aware)程序库，那么客户端就知道分布式节点的信息，请求会直接瞄准到对应的节点上面去。<br>　　两者各有优缺点，第一种方式应用程序不用链接额外的库，第二种方式更加的高效，会跳过一些无畏的请求转发，所以大多情况下请求会有更小的延迟。<br>　　通过客户端方式定位节点，客户端会以10s周期性的随机从一个节点下载集群的节点成员列表(这个列表是通过Gossip协议方式同步，并保证所有节点最终一致性的)，有了这些信息客户端就直接可以向目标节点发送请求，而不会产生一次可能的请求转发了。这里成员列表更新是客户端主动pull模式，而不是节点主动push模式，很显然前者模型更简单方便，但是可能得到的列表是旧的，此时客户端如果请求失败的话，会立即请求刷新成员列表。<br>　　通常的读写操作都会在preference list的前top-N节点上操作的，如果是以客户端链接节点发现库的方式，负载均衡可能会将请求随机分配到任意节点，如果分配的节点不在该key的preference list的top-N中，那么该请求会自动转发到top-N的第一个节点(任何节点本地都含有整个系统完整的成员列表)。这里所说的top-N节点都是指健康可用的节点，系统会自动跳过那些出错或者不可访问节点，使用排在后面的低rank节点替补上来。<br>　　Dynamo采用NWR的机制来维护多个节点上数据副本的一致性，R和W表示读、写请求最少完成节点数目就可以表示本次操作成功，因而读写请求的延迟由最后一个完成读写操作的节点所决定，配置上要求R+W&gt;N就形成了一个Quorum的机制，而R/W两者相对大小也代表了这个系统读/写性能之间的权衡。所以对于put()请求，当接收到请求的那个节点首先产生新版本的vector clock，本且本地写入该更新值，同时将新版本的值连同新vector clock发送给top-N的其他节点，当最后一个第(W-1)节点完成写入后，该更新操作被认为成功；对于get()请求，收到请求的节点会向top-N的所有节点发送读请求，然后等待收到R个响应后，如果节点收到的R个请求中会有多个版本的数据且无法因果合并冲突，则返回所有版本，冲突合并后的数据会更新并写回节点上去，如果超时后还没返回R个响应，则会做出错处理。</p>
<h2 id="3-6_出错处理：Hinted_Handoff">3.6 出错处理：Hinted Handoff</h2><p>　　Dynamo中的Quorum成员不是固定的。之前说道为了考虑节点会出错的情况，preference list的长度通常会大于N，而top-N通常都是在hash环中按照顺时针方向依次选取的N-1个在不同物理节点上的虚拟节点，当出现脑裂或者部分节点宕机、不可访问的时候，就会依序访问接下来preference list中的接下来的节点。<br><img src="/post_images/images/201612/e5241d11.png" alt="dynamo-2"><br>　　对于上图中，假设N=3且preference list成员依次包含A、B、C、D节点，此时节点A临时不可访问，那么发送到A的数据将会被发送给D，同时会在元数据中标明hint信息，指明这个消息本来是要发送给A节点的。当D收到带有hint消息的数据时候，会在本地单独开辟一个数据库用于存储该类信息，在代替A节点响应请求的同时，还会周期性的检查节点A是否已经恢复，如果恢复了将会把这些副本同步给A节点，然后D节点再把这些本地存储给删除掉。<br>　　现实中，可能因为供电、网络、制冷系统、自然灾害等因素导致整个数据中心挂掉，Dynamo会配置成每个key的preference list会夸数据中心存储，数据中心之间采用高速网络连接，以保证在单个数据中心无法访问的时候整个系统仍然可用。</p>
<h2 id="3-7_永久出错处理：同步恢复">3.7 永久出错处理：同步恢复</h2><p>　　上面的情况主要用于临时性、短暂性的节点不可访问的情况，对于其他永久性出错的情况，Dynamo采用副本同步(replica synchronization)的机制来处理。<br>　　Dynamo使用了Merkle trees的方式，该数据结构是个hash tree，这种数据结构的叶子节点都是单独key对应value的hash值，而父节点都是子节点的hash值，这样的好处是两个父节点的hash值一致，那么就不用逐个比较他们的子树了。当比较两个根节点的hash值的时候如果不一致，就需要不断的交换比较子节点的hash值，一直查找到不相等的叶子节点从而查找到需要同步的key，然后同步更新之。虽然这样操作麻烦一些，但是不需要在节点之间同步整个树结构或者整个数据集，减少了传输量从而增加了同步效率。<br>　　在Dynamo中，每个节点都为其所承担的hash virtual node的key范围建立一个Merkle树，那么当任意两个节点存储了相同数据(副本)的时候，这两个节点交换root节点的hash值看两者是否是已同步的状态，如果不相同采用树遍历的方式检查到未同步的部分。麻烦的是，当新加入节点的生活，需要重新建立Merkle树结构。</p>
<h2 id="3-8_成员管理和错误探测">3.8 成员管理和错误探测</h2><h3 id="3-8-1_Ring_Membership">3.8.1 Ring Membership</h3><p>　　管理员可以通过命令行或者浏览器的方式连接到某个节点上面去，然后发送添加、删除节点的指令，接受处理请求的节点会把这个成员变更事件和时间记录固化下来，然后通过Gossip协议不断地传播这个事件(就是每个节点每秒会随机地选择peer节点，然后两者通信交换自己的本地的全局节点成员信息，并合更新并两者的成员列表)，虽然没有具体时间的保证，但是Gossip协议会保证最后某个时间集群中，所有node都会就成员列表达成最终一致性。<br>　　当一个新的节点添加进来的时候，根据一致性hash和虚拟节点的原理，会产生多个虚拟节点和其hash space的对应关系(tokens)，并固化到本地磁盘上面，虽然新加入的节点起始只含有自己的token信息，然后根据前面相同Gossip协议传播机制，最终所有节点都会在本地存储这种虚拟节点的分区信息，所以这种本地存储也使得任何一个节点都可以快速的将目的key的读写请求进行精准转发。</p>
<h3 id="3-8-2_External_Discovery">3.8.2 External Discovery</h3><p>　　论文描述了逻辑分区的Dynamo环的情况，但是我想主要可能考虑新加入多个节点不能快速互相发现和传播吧。Dynamo会选择一些节点作为种子(seed)的角色，这些种子是通过配置或者其他服务方式产生的，对所有的节点都可见，那么新加入的节点就可以快速的和这些种子节点进行交互和同步，传播的效率大大提高了。</p>
<h3 id="3-8-3_Failure_Detection">3.8.3 Failure Detection</h3><p>　　错误检测主要是防止节点尝试和不能访问的节点进行交互，尽量避免通信失败的情况。其实只要B节点不响应A节点的消息，那么A节点就认为B节点出错了，此时A节点就会选择和B节点具有相同数据副本的节点发送请求，同时A节点还会周期性地探测B节点是否恢复可用了。<br>　　最初的Dynamo设计使用去中心化的方式，维护一个全局的最终一致性的节点失败状态信息，后来发现这种设计是多余的：通过前面的增加或者删除节点的操作，然后通过Gossip协议节点的存在性会达到最终一致性，而临时性的节点不可用直接根据请求是否响应就可以探测出来，候选的节点会自动接替之用于响应服务。</p>
<h2 id="3-9_存储节点(物理节点)的添加和删除">3.9 存储节点(物理节点)的添加和删除</h2><p>　　当一个节点加入到hash环中的时候，比如节点X，考虑到上面的分区问题外，还会涉及到数据副本的问题，会有至多N个节点会和这个变动的hash区间相关联。在这个分区划分出来之后，一些节点不需要再负责这部分区域的keys的时候，会把这部分keys的数据传输到这个新加入的节点上来。<br>　　比如对于上面的图，当节点X加入到节点A-节点B中间的时候且N=3的时候，节点X就需要存储(F,G]、(G,A]、(A,X]区域的数据，而对应的节点B、C、D就不需要保存对应部分的数据副本，因此他们会将这部分数据传输给节点X。</p>
<h1 id="四、后言">四、后言</h1><p>　　Dynamo的基本实现算是理解完了。说到这里，之前看到腾讯微信后台出了PaxosStore的分布式存储，用以替代之前的QuorumKV存储，而后者恰巧是基于NWR(N为3，W/R为2)协议实现的分布式存储系统。他们给出的最终测试结数据看来，QuorumKV和PaxosStore两者的性能(延迟)差距并不大，而是在请求失败率的指标上有较大的改进。<br>　　没有QuorumKV的实现细节，Dynamo和PaxosStore也没有过正面PK，所以这里也不好乱喷。只不过从原理上来说，NWR只是保证异步修改多个副本，协议本身并没有保证最终一致性，那么冲突肯定是更容易发生的；而Paxos协议在更新的时候就需要多个Acceptor进行表决，并达成最终一致性(如果此轮表决没有达成一致还会继续Propose再表决)，这种情况下冲突的概率肯定是很低的，所以得到他们的测试结果也是情理之中的事情，毫无悬念。<br>　　Paxos的论文过于的理论，工业实现确实不容易，坑点很多。感觉Raft虽然添加了一些假设，但是将整个系统实现会方便一大截，有机会要好好拜读一下那篇著名的斯坦福博士论文，你懂得！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2650994526&amp;idx=1&amp;sn=255dd87bd8601919bda3d597c65439f3" target="_blank" rel="external">微信PaxosStore内存云揭秘：十亿Paxos/分钟的挑战</a></li>
<li><a href="http://the-paper-trail.org/blog/consistency-and-availability-in-amazons-dynamo/" target="_blank" rel="external">Consistency and availability in Amazon’s Dynamo</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　其实个人一直比较喜欢读Google、Amazon、Facebook这类科技公司工程化的paper，一方面是这类文章通常不会夹杂着让人看着眼花缭乱的数学公式(而且很多文章往往很简单的道理也会被装饰的神神叨叨滴)；二来这些系统用到的技术都比较的大众成熟，可以很容易的在网上搜到相关资料，让你在短短时间就知道大概是个什么意思；还有最主要的是这些论文是进行实实在在工程化并用于生产环境了，方案可行性自然不用多说，在实现的过程中遇到的各种现实、细节问题也是很值得学习揣摩和借鉴的。比如，接下来要说的<a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf">《Dynamo: Amazon’s Highly Available Key-value Store》</a>这篇论文要算是分布式系统设计实现中的必读经典了，虽然该套系统没有开源，而且由于商业机密部分内容没能够详细阐述，但丝毫没有影响到它对分布式系统设计实现的重要指导作用。<br><img src="/post_images/images/201612/3a93058f.png" alt="aws"></p>
<h1 id="一、前言">一、前言</h1><p>　　Amazon Dynamo系统的设计和实现从最开始就比较的实用主义：首先Amazon作为全球最领先的电商企业，其丰富的经验让其可以洞悉到绝大多数互联网公司的需求点和关切点，其次Dynamo是作为服务出售的，所以其并没有设计实现成一个至臻完美的分布式存储模型，它只支持K-V非关系型键值存储，就像是一个巨大的dict/map结构，只支持get()、put()两种简单访问方式，优化成高可写入性要求，存储的对象尺寸大多小于1M，成本考虑上支持99.9%级别的可用性(百毫秒读写响应)，但依据Amazon在云计算领域的强大实力，该系统在性能、可靠性、效能、伸缩性等方面没有丝毫的妥协。<br>　　和绝大多数分布式系统一样，Dynamo使用最终一致性获取性能从而保证可用性的，然后通过现有各项成熟的技术手段解决项目中的各种问题：数据使用一致性hashing进行分区，同时提供数据副本保证安全；通过NWR和对象vector lock版本机制有限的解决冲突并实现最终一致性；Merkle tree数据结构可以实现节点间数据的高效同步；整个系统完全去中心化，采用Gossip协议实现成员变更的同步。</p>
<h1 id="二、背景知识">二、背景知识</h1><h2 id="2-1_系统假设和设计需求">2.1 系统假设和设计需求</h2><p>　　a. 访问模式：数据项通过key唯一确定，且只提供读、写两个操作接口，对象采用二进制方式存储。这种K-V的存储符合绝大多数互联网海量对象的存储需求，对象的读取写入只支持单个对象的操作，任何多对象、关系性的操作都不支持；<br>　　b. ACID：就是分布式系统中的原子性、一致性、隔离性和持久性，强一致性模型虽然实现简单，但是可用性的最大杀手，所以该系统只提供最终一致性保证；同时也不支持隔离性，只提供单个元素的更新操作。<br>　　c. 有效性：服务必须提供稳定可靠的延时和吞吐量，根据在性能、价格、可用性和持久化各个因素的考量和妥协中，提供99.9%的可访问性；<br>　　由于在内部使用，所以不用考虑授权、鉴权操作，整个假设在一个可信环境的内网中执行的，不考虑拜占庭通信模型。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="读书笔记" scheme="https://taozj.org/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[一致性hashing的原理解析]]></title>
    <link href="https://taozj.org/201612/consistent-hashing.html"/>
    <id>https://taozj.org/201612/consistent-hashing.html</id>
    <published>2016-12-14T12:59:18.000Z</published>
    <updated>2016-12-18T07:45:47.000Z</updated>
    <content type="html"><![CDATA[<p>　　一致性hash最常见的应用情形就是缓存，其实只要涉及到hash和多台主机请求路由的情况，都可能涉及到一致性hash问题。一致性hash主要是考虑到集群中节点挂掉或新增节点的时候，要对已有节点的影响降到最小，传统hash值取余方式肯定不能满足这个要求，交换节点位置影响还有限，但是新增节点、删除节点会让绝大多数的缓存失效，除了导致性能骤降外很有可能会压垮后台服务器。对于日常使用的情况，节点挂掉算是小概率事件，但是对于像Amazon Dynamo这种规模的分布式集群来说，节点挂掉是必然事件——甚至每天都会有集群中的主机或者硬盘出问题。<br>　　一致性hash的解决思路，就是对缓存的object和Node使用同一个hash函数(实际不需要完全一致，但至少保证产生的hash空间相同)，让他们映射到同一个hash空间中去，当然这很容易实现，因为大多数的hash函数都是返回uint32类型，其空间即为1~$2^{32}$-1。然后各个Node就将整个hash空间分割成多个interval空间，然后对于每个缓存对象object，都按照顺时针方向遇到的第一个Node负责缓存它。通过这种方法，在新增加Node和删除Node的时候，只会对顺时针方向遇到的第一个Node负责的空间造成影响，其余的空间都仍然有效。<br><img src="/post_images/images/201612/58d63a48.png" alt="c-hash-add-remove"><br>　　假设有Object A、Object B、Object C、Object D四个对象，以及Node A、Node B、Node C、Node D四个节点。根据上面的一致性hash原理，如果Node C挂掉了，那么Node C掌管的区域(包括Object C)都将会由Node D所接管；而如果增加节点Node X，那么原先Node C掌管的空间将会被分割，导致Node X之前的对象Object C由Node X所接管；针对节点之间交换顺序的情况，也可以预见也只有交换的那两个节点对应的区间会被影响。<a id="more"></a><br>　　当然，上图各个节点的均匀分布是理想状态，实践中通常采用节点的IP地址或者主机名来计算hash值，在整个hash空间不太可能分布的这么均匀，而且即使当前比较均匀的话后面也会由于增加和删除节点打破这种状态。因为通常Node数目不会非常大，导致这种分布不会很均匀，所以采用虚拟节点(virtual nodes)的技术来增加节点的数目，这些虚拟节点再由底层实体Node来承载，当虚拟节点足够多的时候，他们趋向于将整个hash空间均匀成各个区间了。<br><img src="/post_images/images/201612/49f1526a.png" alt="c-hash-vip"></p>
<p>　　MySQL的文档指出一致性hash算法有Ketama和Wheel两种，但是后者Wheel算法的相关资料没有找到。因为Memcached的服务端是设计成单机模式的，如果需要达到多节点协同的效果，就必须在客户端支持负载均衡和一致性hash算法。目前开源流传的主要是last.fm实现的<a href="https://github.com/RJ/ketama" target="_blank" rel="external">libketama</a>，作者声称已经在Last.fm的生产环境稳定运行十几年，用C语言实现，而且提供了各种语言的接口，不过这个项目貌似也开始长草了，作者正在寻找maintainer。<br>　　这个库十分的小，代码没有多少。同时在作者的博客也给出了具体的实现步骤：<br>　　a. 确定主机列表，比如 1.2.3.4:11211, 5.6.7.8:11211, 9.8.7.6:11211；<br>　　b. 对上面的每个主机”ip:port-%d”字符串计算MD5散列值，因为每个MD5是128位，所以可以产生4个unsigned int散列值，每个主机循环40次，即每个主机产生160个虚拟节点，这里每个虚拟机点都保存了实体节点的地址，可以直接取出给客户端访问使用；<br>　　c. 把这些散列值进行排序，然后想象它们分布在0~$2^{32}$-1的散列空间中去；<br>　　d. 当存取一个key的时候，先计算出unsigned int的散列值，然后通过二分查找的方式，快速定位到满足条件的虚节点，并从中取出响应的物理节点的地址信息；<br>　　e. 关于节点的添加和删除，我查看到估计只有ketama_roll这个函数相关，其会判断文件修改时间戳，如果修改了就使用信号量锁住系统，然后重新读取配置重新建立虚拟节点。因为虚拟机点的建立方式是固定规则的，所以对于那些没有修改的主机，其得到的虚拟节点仍然存在，hash一致性得到维持。</p>
<p>　　从上面的描述看来，一致性hash的原理和实现其实还是挺简单明了的。此外，还需要提到无意中观察到的一个案例，就是Google在其Maglev系统中，并没有直接采用通常的一致性hash解决方案，而是改进成了一个Maglev hashing。因为对于一致性hash，通常考量的有两个方面：<br>　　a. load balancing: 对于backend group中的节点，他们所承担的负载应该是大致均匀的；<br>　　b. minimal disruption: 当backend group中的节点发生增删变化时候，没有变化的节点应当受到最小的影响。<br>　　虽然通过虚拟节点和hash盘的手段，上面的两个需求都可以得到一定的满足，但是Google的这个Maglev系统后台会有上千台的服务器集群，所以对负载均衡和最小扰动需求要高的多：要想负载均衡就需要添加更多的虚拟节点以平均单个物理节点的影响，虚拟节点数目增加后会对查找key到虚拟节点映射操作负担增加。<br>　　Maglev hashing的最主要步骤，就是以不同的方式产生每个entry(其实这个entry也有虚拟节点等价的意义)的lookup table。假设backend的节点数目为N，entry的条目数为M(通常M为大于100×N的质数)，使用两个hash函数h1、h2计算产生offset和skip，首先第一步初始化得到permutation表。<br><img src="/post_images/images/201612/775090a1.png" alt="c-hash-p"><br>　　上图是假设h1和h2计算得到的三个backend的(offset, skip)分别为(3,4)、(0,2)、(3,1)情况下所产生的结果，原文中算法伪代码写的十分详细了，可以轻易进行工程化实现。通过permutation表，就可以得到entry和backend节点的映射关系lookup table，不过生成lookup table的步骤原文没有说，看了半天是这个意思：首先产生长度为N的数组，然后把permutation表按照从左到右、从上到下的顺序遍历，如果发现该数字代表的entry还没有backend节点就将其所在的节点填进去，如果已经有了就直接跳过，直到lookup table填满了完成。<br><img src="/post_images/images/201612/0e1b7bea.png" alt="c-hash-table"><br>　　从上图中可以看出，原始生成的lookup table中三个节点的分别比较均匀，而如果将B1节点移除，新生成的lookup table中剩余的B0、B2节点分配还是比较均匀的，而且改动的条目都是原始B1节点的entry，而B0和B2的条目都没有更改。在后文的测试中也发现，当在1000台backend节点下以0%~2.5%的比例并发撤出节点模式故障的情况下，查找表的改动率相比传统一致性hash比率也是相当低的，而且在有限entry数目下各个节点的负载均衡也得到了保证。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
<li><a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" target="_blank" rel="external">The Simple Magic of Consistent Hashing</a></li>
<li><a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/" target="_blank" rel="external">Programmer’s Toolbox Part 3: Consistent Hashing</a></li>
<li><a href="https://www.metabrew.com/article/libketama-consistent-hashing-algo-memcached-clients" target="_blank" rel="external">libketama: Consistent Hashing library for memcached clients</a></li>
<li><a href="https://github.com/RJ/ketama" target="_blank" rel="external">GitHub ketama</a></li>
<li><a href="http://www.tom-e-white.com/2007/11/consistent-hashing.html" target="_blank" rel="external">Consistent Hashing</a></li>
<li><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44824.pdf" target="_blank" rel="external">Maglev: A Fast and Reliable Software Network Load Balancer</a></li>
<li><a href="https://www.evanlin.com/maglev/" target="_blank" rel="external">Maglev : A Fast and Reliable Software Network Load Balancer</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　一致性hash最常见的应用情形就是缓存，其实只要涉及到hash和多台主机请求路由的情况，都可能涉及到一致性hash问题。一致性hash主要是考虑到集群中节点挂掉或新增节点的时候，要对已有节点的影响降到最小，传统hash值取余方式肯定不能满足这个要求，交换节点位置影响还有限，但是新增节点、删除节点会让绝大多数的缓存失效，除了导致性能骤降外很有可能会压垮后台服务器。对于日常使用的情况，节点挂掉算是小概率事件，但是对于像Amazon Dynamo这种规模的分布式集群来说，节点挂掉是必然事件——甚至每天都会有集群中的主机或者硬盘出问题。<br>　　一致性hash的解决思路，就是对缓存的object和Node使用同一个hash函数(实际不需要完全一致，但至少保证产生的hash空间相同)，让他们映射到同一个hash空间中去，当然这很容易实现，因为大多数的hash函数都是返回uint32类型，其空间即为1~$2^{32}$-1。然后各个Node就将整个hash空间分割成多个interval空间，然后对于每个缓存对象object，都按照顺时针方向遇到的第一个Node负责缓存它。通过这种方法，在新增加Node和删除Node的时候，只会对顺时针方向遇到的第一个Node负责的空间造成影响，其余的空间都仍然有效。<br><img src="/post_images/images/201612/58d63a48.png" alt="c-hash-add-remove"><br>　　假设有Object A、Object B、Object C、Object D四个对象，以及Node A、Node B、Node C、Node D四个节点。根据上面的一致性hash原理，如果Node C挂掉了，那么Node C掌管的区域(包括Object C)都将会由Node D所接管；而如果增加节点Node X，那么原先Node C掌管的空间将会被分割，导致Node X之前的对象Object C由Node X所接管；针对节点之间交换顺序的情况，也可以预见也只有交换的那两个节点对应的区间会被影响。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="架构" scheme="https://taozj.org/categories/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[基于Nginx的软件负载均衡实现解读]]></title>
    <link href="https://taozj.org/201612/nginx-load-balancing.html"/>
    <id>https://taozj.org/201612/nginx-load-balancing.html</id>
    <published>2016-12-13T16:08:26.000Z</published>
    <updated>2016-12-26T01:46:42.000Z</updated>
    <content type="html"><![CDATA[<p>　　负载均衡在服务端开发中算是一个比较重要的特性。因为Nginx除了作为常规的Web服务器外，还会被大规模的用于反向代理前端，因为Nginx的异步框架可以处理很大的并发请求，把这些并发请求hold住之后就可以分发给后台服务端(backend servers，也叫做服务池， 后面简称backend)来做复杂的计算、处理和响应，这种模式的好处是相当多的：隐藏业务主机更安全，节约了公网IP地址，并且在业务量增加的时候可以方便地扩容后台服务器。<br>　　负载均衡可以分为硬件负载均衡和软件负载均衡，前者一般是专用的软件和硬件相结合的设备，设备商会提供完整成熟的解决方案，通常也会更加昂贵。软件的复杂均衡以Nginx占据绝大多数，本文也是基于其手册做相应的学习研究的。据介绍除了Nginx，常用的基于反向代理的负载均衡软件还包括：HAProxy、Apache(mod_proxy)、Squid。<br><img src="/post_images/images/201612/ac230f42.png" alt="load-balancing"></p>
<h1 id="一、基本简介">一、基本简介</h1><p>　　负载均衡涉及到以下的基础知识。<br>　　(1) <strong>负载均衡算法</strong><br>　　a. Round Robin: 对所有的backend轮训发送请求，算是最简单的方式了，也是默认的分配方式；<br>　　b. Least Connections(least_conn): 跟踪和backend当前的活跃连接数目，最少的连接数目说明这个backend负载最轻，将请求分配给他，这种方式会考虑到配置中给每个upstream分配的weight权重信息；<br>　　c. Least Time(least_time): 请求会分配给响应最快和活跃连接数最少的backend；<br>　　d. IP Hash(ip_hash): 对请求来源IP地址计算hash值，IPv4会考虑前3个octet，IPv6会考虑所有的地址位，然后根据得到的hash值通过某种映射分配到backend；<br>　　e. Generic Hash(hash): 以用户自定义资源(比如URL)的方式计算hash值完成分配，其可选consistent关键字支持一致性hash特性；<br>　　(2) <strong>会话一致性</strong><br>　　用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session  ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。<br>　　(3) <strong>后台服务端的动态配置</strong><br>　　出问题的backend要能被及时探测并剔除出分配群，而当业务增长的时候可以灵活的添加backend数目。此外当前风靡的Elastic Compute云计算服务，服务商也应当根据当前负载自动添加和减少backend主机。<br>　　(4) <strong>基于DNS的负载均衡</strong><br>　　通常现代的网络服务者一个域名会关连到多个主机，在进行DNS查询的时候，默认情况下DNS服务器会以round-robin形式以不同的顺序返回IP地址列表，因此天然将客户请求分配到不同的主机上去。不过这种方式含有固有的缺陷：DNS不会检查主机和IP地址的可访问性，所以分配给客户端的IP不确保是可用的(Google 404)；DNS的解析结果会在客户端、多个中间DNS服务器不断的缓存，所以backend的分配不会那么的理想。</p>
<h1 id="二、Nginx中的负载均衡">二、Nginx中的负载均衡</h1><p>　　Nginx中的负载均衡配置在<a href="https://www.nginx.com/resources/admin-guide/load-balancer/" target="_blank" rel="external">手册</a>中描述的极为细致，此处就不流水帐了。对于常用的HTTP负载均衡，主要先定义一个upstream作为backend group，然后通过proxy_pass/fastcgi_pass等方式进行转发操作，其中fastcgi_pass几乎算是Nginx+PHP站点的标配了。</p>
<h3 id="2-1_会话一致性">2.1 会话一致性</h3><p>　　Nginx中的会话一致性是通过sticky开启的，会话一致性和之前的负载均衡算法之间并不冲突，只是需要在第一次分配之后，该会话的所有请求都分配到那个相同的backend上面。目前支持三种模式的会话一致性：<a id="more"></a><br>　　(1). <strong>Cookie Insertion</strong><br>　　在backend第一次response之后，会在其头部添加一个session cookie，即由负载均衡器向客户端植入 cookie，之后客户端接下来的请求都会带有这个cookie值，Nginx可以根据这个cookie判断需要转发给哪个backend了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sticky cookie srv_id expires=1h domain=.example.com path=/;</div></pre></td></tr></table></figure></p>
<p>　　上面的srv_id代表了cookie的名字，而后面的参数expires、domain、path都是可选的。<br>　　(2). <strong>Sticky Routes</strong><br>　　也是在backend第一次response之后，会产生一个route信息，route信息通常会从cookie/URI信息中提取。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sticky route <span class="variable">$route_cookie</span> <span class="variable">$route_uri</span>;</div></pre></td></tr></table></figure></p>
<p>　　这样Nginx会按照顺序搜索$route_cookie、$route_uri参数并选择第一个非空的参数用作route，而如果所有的参数都是空的，就使用上面默认的负载均衡算法决定请求分发给哪个backend。<br>　　(3). <strong>Learn</strong><br>　　较为的复杂也较为的智能，Nginx会自动监测request和response中的session信息，而且通常需要回话一致性的请求、应答中都会带有session信息，这和第一种方式相比是不用增加cookie，而是动态学习已有的session。<br>　　这种方式需要使用到zone结构，在Nginx中zone都是共享内存，可以在多个worker process中共享数据用的。(不过其他的会话一致性怎么没用到共享内存区域呢？)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sticky learn </div><div class="line">   create=<span class="variable">$upstream_cookie_examplecookie</span></div><div class="line">   lookup=<span class="variable">$cookie_examplecookie</span></div><div class="line">   zone=client_sessions:1m</div><div class="line">   timeout=1h;</div></pre></td></tr></table></figure></p>
<h3 id="2-2_Session_Draining">2.2 Session Draining</h3><p>　　主要是有需要关闭某些backend以便维护或者升级，这些关键性的服务都讲求gracefully处理的：就是新的请求不会发送到这个backend上面，而之前分配到这个backend的会话的后续请求还会继续发送给他，直到这个会话最终完成。<br>　　让某个backend进入draining的状态，既可以直接修改配置文件，然后按照之前的方式通过向master process发送信号重新加载配置，也可以采用Nginx的on-the-fly配置方式。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ curl http://localhost/upstream_conf?upstream=backend</div><div class="line">$ curl http://localhost/upstream_conf?upstream=backend\&amp;id=1\&amp;drain=1</div></pre></td></tr></table></figure></p>
<p>　　通过上面的方式，先列出各个bacnkend的ID号，然后drain指定ID的backend。通过在线观测backend的所有session都完成后，该backend就可以下线了。</p>
<h3 id="2-3_backend健康监测">2.3 backend健康监测</h3><p>　　backend出错会涉及到两个参数，max_fails=1 fail_timeout=10s;意味着只要Nginx向backend发送一个请求失败或者没有收到一个响应，就认为该backend在接下来的10s是不可用的状态。<br>　　通过周期性地向backend发送特殊的请求，并期盼收到特殊的响应，可以用以确认backend是健康可用的状态。通过health_check可以做出这个配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">match server_ok &#123;</div><div class="line">    status 200-399;</div><div class="line">    header Content-Type = text/html;</div><div class="line">    body !~ <span class="string">"maintenance mode"</span>;</div><div class="line">&#125;</div><div class="line">server &#123;</div><div class="line">    location / &#123;</div><div class="line">        proxy_pass http://backend;</div><div class="line">        health_check interval=10 fails=3 passes=2 match=server_ok;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面的health_check是必须的，后面的参数都是可选的。尤其是后面的match参数，可以自定义服务器健康的条件，包括返回状态码、头部信息、返回body等，这些条件是&amp;&amp;与关系。默认情况下Nginx会相隔interval的间隔向backend group发送一个”/“的请求，如果超时或者返回非2xx/3xx的响应码，则认为对应的backend是unhealthy的，那么Nginx会停止向其发送request直到下次改backend再次通过检查。<br>　　在使用了health_check功能的时候，一般都需要在backend group开辟一个zone，在共享backend group配置的同时，所有backend的状态就可以在所有的worker process所共享了，否则每个worker process独立保存自己的状态检查计数和结果，两种情况会有很大的差异哦。</p>
<h3 id="2-4_通过DNS设置HTTP负载均衡">2.4 通过DNS设置HTTP负载均衡</h3><p>　　Nginx的backend group中的主机可以配置成域名的形式，如果在域名的后面添加resolve参数，那么Nginx会周期性的解析这个域名，当域名解析的结果发生变化的时候会自动生效而不用重启。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">http &#123;</div><div class="line">    resolver 10.0.0.1 valid=300s ipv6=off;</div><div class="line">    resolver_timeout 10s;</div><div class="line"></div><div class="line">    server &#123;</div><div class="line">        location / &#123;</div><div class="line">            proxy_pass http://backend;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">   </div><div class="line">    upstream backend &#123;</div><div class="line">        zone backend 32k;</div><div class="line">        least_conn;</div><div class="line">        ...</div><div class="line">        server backend1.example.com resolve;</div><div class="line">        server backend2.example.com resolve;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　如果域名解析的结果含有多个IP地址，这些IP地址都会保存到配置文件中去，并且这些IP都参与到自动负载均衡。</p>
<h3 id="2-5_TCP/UDP流量的负载均衡">2.5 TCP/UDP流量的负载均衡</h3><p>　　通常，HTTP和HTTPS的负载均衡叫做七层负载均衡，而TCP和UDP协议的负载均衡叫做四层负载均衡。因为七层负载均衡通常都是HTTP和HTTPS协议，所以这种负载均衡相当于是四层负载均衡的特例化，均衡器可以根据HTTP/HTTPS协议的头部(User-Agent、Language等)、响应码甚至是响应内容做额外的规则，达到特定条件特定目的的backend转发的需求。<br>　　除了Nginx所专长的HTTP负载均衡，Nginx还支持TCP和UDP流量的负载均衡，适用于LDAP/MySQL/RTMP和DNS/syslog/RADIUS各种应用场景。这类情况的负载均衡使用stream来配置，Nginx编译的时候需要支持–with-stream选项。查看<a href="https://www.nginx.com/resources/admin-guide/tcp-load-balancing/" target="_blank" rel="external">手册</a>，其配置原理和参数和HTTP负载均衡差不多。<br>　　因为TCP、UDP的负载均衡都是针对通用程序的，所以之前HTTP协议支持的match条件(status、header、body)是没法使用的。TCP和UDP的程序可以根据特定的程序，采用send、expect的方式来进行动态健康检测。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">match http &#123;</div><div class="line">    send      <span class="string">"GET / HTTP/1.0\r\nHost: localhost\r\n\r\n"</span>;</div><div class="line">    expect ~* <span class="string">"200 OK"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-6_其他特性">2.6 其他特性</h3><p>　　slow_start=30s：防止新添加/恢复的主机被突然增加的请求所压垮，通过这个参数可以让该主机的weight从0开始慢慢增加到设定值，让其负载有一个缓慢增加的过程。<br>　　max_conns=30：可以设置backend的最大连接数目，当超过这个数目的时候会被放到queue队列中，同时队列的大小和超时参数也可以设置，当队列中的请求数大于设定值，或者超过了timeout但是backend还不能处理请求，则客户端将会收到一个错误返回。通常来说这还是一个比较重要的参数，因为Nginx作为反向代理的时候，通常就是用于抗住并发量的，如果给backend过多的并发请求，很可能会占用后端过多的资源(比如线程、进程非事件驱动)，最终反而会影响backend的处理能力。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.nginx.com/resources/glossary/load-balancing/" target="_blank" rel="external">WHAT IS LOAD BALANCING?</a></li>
<li><a href="https://www.nginx.com/resources/admin-guide/load-balancer/" target="_blank" rel="external">NGINX LOAD BALANCING – HTTP LOAD BALANCER</a></li>
<li><a href="https://www.nginx.com/resources/admin-guide/tcp-load-balancing/" target="_blank" rel="external">NGINX LOAD BALANCING – TCP AND UDP LOAD BALANCER</a></li>
<li><a href="https://www.nginx.com/products/session-persistence/" target="_blank" rel="external">SESSION PERSISTENCE WITH NGINX PLUS</a></li>
<li><a href="https://www.nginx.com/resources/glossary/dns-load-balancing/" target="_blank" rel="external">WHAT IS DNS LOAD BALANCING?</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/understanding-nginx-http-proxying-load-balancing-buffering-and-caching" target="_blank" rel="external">Understanding Nginx HTTP Proxying, Load Balancing, Buffering, and Caching</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1_%28%E8%AE%A1%E7%AE%97%E6%9C%BA%29" target="_blank" rel="external">负载均衡</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　负载均衡在服务端开发中算是一个比较重要的特性。因为Nginx除了作为常规的Web服务器外，还会被大规模的用于反向代理前端，因为Nginx的异步框架可以处理很大的并发请求，把这些并发请求hold住之后就可以分发给后台服务端(backend servers，也叫做服务池， 后面简称backend)来做复杂的计算、处理和响应，这种模式的好处是相当多的：隐藏业务主机更安全，节约了公网IP地址，并且在业务量增加的时候可以方便地扩容后台服务器。<br>　　负载均衡可以分为硬件负载均衡和软件负载均衡，前者一般是专用的软件和硬件相结合的设备，设备商会提供完整成熟的解决方案，通常也会更加昂贵。软件的复杂均衡以Nginx占据绝大多数，本文也是基于其手册做相应的学习研究的。据介绍除了Nginx，常用的基于反向代理的负载均衡软件还包括：HAProxy、Apache(mod_proxy)、Squid。<br><img src="/post_images/images/201612/ac230f42.png" alt="load-balancing"></p>
<h1 id="一、基本简介">一、基本简介</h1><p>　　负载均衡涉及到以下的基础知识。<br>　　(1) <strong>负载均衡算法</strong><br>　　a. Round Robin: 对所有的backend轮训发送请求，算是最简单的方式了，也是默认的分配方式；<br>　　b. Least Connections(least_conn): 跟踪和backend当前的活跃连接数目，最少的连接数目说明这个backend负载最轻，将请求分配给他，这种方式会考虑到配置中给每个upstream分配的weight权重信息；<br>　　c. Least Time(least_time): 请求会分配给响应最快和活跃连接数最少的backend；<br>　　d. IP Hash(ip_hash): 对请求来源IP地址计算hash值，IPv4会考虑前3个octet，IPv6会考虑所有的地址位，然后根据得到的hash值通过某种映射分配到backend；<br>　　e. Generic Hash(hash): 以用户自定义资源(比如URL)的方式计算hash值完成分配，其可选consistent关键字支持一致性hash特性；<br>　　(2) <strong>会话一致性</strong><br>　　用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session  ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。<br>　　(3) <strong>后台服务端的动态配置</strong><br>　　出问题的backend要能被及时探测并剔除出分配群，而当业务增长的时候可以灵活的添加backend数目。此外当前风靡的Elastic Compute云计算服务，服务商也应当根据当前负载自动添加和减少backend主机。<br>　　(4) <strong>基于DNS的负载均衡</strong><br>　　通常现代的网络服务者一个域名会关连到多个主机，在进行DNS查询的时候，默认情况下DNS服务器会以round-robin形式以不同的顺序返回IP地址列表，因此天然将客户请求分配到不同的主机上去。不过这种方式含有固有的缺陷：DNS不会检查主机和IP地址的可访问性，所以分配给客户端的IP不确保是可用的(Google 404)；DNS的解析结果会在客户端、多个中间DNS服务器不断的缓存，所以backend的分配不会那么的理想。</p>
<h1 id="二、Nginx中的负载均衡">二、Nginx中的负载均衡</h1><p>　　Nginx中的负载均衡配置在<a href="https://www.nginx.com/resources/admin-guide/load-balancer/">手册</a>中描述的极为细致，此处就不流水帐了。对于常用的HTTP负载均衡，主要先定义一个upstream作为backend group，然后通过proxy_pass/fastcgi_pass等方式进行转发操作，其中fastcgi_pass几乎算是Nginx+PHP站点的标配了。</p>
<h3 id="2-1_会话一致性">2.1 会话一致性</h3><p>　　Nginx中的会话一致性是通过sticky开启的，会话一致性和之前的负载均衡算法之间并不冲突，只是需要在第一次分配之后，该会话的所有请求都分配到那个相同的backend上面。目前支持三种模式的会话一致性：]]>
    
    </summary>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[【置顶】个人阶段性学习和规划总结(技能树)]]></title>
    <link href="https://taozj.org/201612/study-conclusion-stage.html"/>
    <id>https://taozj.org/201612/study-conclusion-stage.html</id>
    <published>2016-12-12T11:48:05.000Z</published>
    <updated>2017-02-24T15:49:48.000Z</updated>
    <content type="html"><![CDATA[<p>　　专注后台服务端开发也好久了，自我感觉经验增加了很多，接触到的东西确实不少，博文也批量更新了很多。表面看似很多很杂，但个人心中思路计划感觉还是比较明确的，此处做一阶段性整理和总结吧。<br>　　其实不仅仅是后台服务端开发，就整个软件开发的知识构成也是有所层次的。个人毕竟不是正规计算机科班出身，也就是大家所说的半路出道的野程序员，很多时候感觉自己的知识构成还是有所缺陷。长痛不如短痛，晚补不如早补，该学的终究跑不掉！<br><a id="more"></a><br>　　语言就不说了，主流将会是C/C++系，偶尔会用些Python。其实到了这个阶段，个人已经看透语言了，因为软件开发的思路，手段万变不离其宗，如果不是为了研究语言完全没必要学习那么多语言，基础夯实了接触新语言也是分分钟的事(不过，不得不说C++是个例外)。后面试着啃啃《深度探索C++对象模型 》，虽然书已经买了，不过翻开几页感觉十分吃力，不知道后面能不能够看得懂。C++的另外一个高级方向是模板元编程，不过个人估计至少近两年不打算去涉及，应为一方面感觉自己C++的还没那么深厚，同时模板元编程在实用性工程中使用较少，如果现阶段对C++了解还没那么深刻，而把太多的时间放在这上面有点舍本取末的感觉。<br>　　后台服务端开发技能树就整理如下：</p>
<p><strong>基础知识类</strong></p>
<ul>
<li>C/C++语言和Boost库<ul>
<li><a href="/201607/learn-note-of-boost-%281%29-smart-ptr-memory-pool.html">《基于Boost库的C++学习笔记（一）：智能指针和内存池》</a></li>
<li><a href="/201608/feeling-of-cpp-11-and-two-ticks.html">《关于C++11新标准的学习心得及两个小轮子分享》</a></li>
<li><a href="/201609/cpp11-atomic-and-memory-model.html">《C++11新标准中的Atomic原子操作和内存模型》</a></li>
</ul>
</li>
<li>数据结构和算法<ul>
<li><a href="/201611/data-structure-and-algorithm-%281%29-hash.html">《数据结构和算法（一）：hash散列容器》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%282%29-avl.html">《数据结构和算法（二）：AVL自平衡二叉树》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%283%29-rbtree.html">《数据结构和算法（三）：红黑二叉树》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%284%29-sort.html">《数据结构和算法（四）：主流内排序算法》</a></li>
</ul>
</li>
<li>计算机网络<ul>
<li><a href="/201607/construct-running-close-of-tcp.html">《TCP链接建立和关闭过程》</a></li>
<li><a href="/201612/tcp-connection-keep-alive.html">《网络开发中客户端连接保鲜机制实现方法》</a></li>
</ul>
</li>
<li>操作系统</li>
<li>设计模式<ul>
<li><a href="/201610/talk-about-singleton.html">《说说设计模式中的单例》</a></li>
<li><a href="/201611/design-patterns-%281%29-creational.html">《设计模式整理总结（一）：创建型模式》</a></li>
<li><a href="/201612/design-patterns-%282%29-structural.html">《设计模式整理总结（二）：结构型模式》</a></li>
<li><a href="/201612/design-patterns-%283%29-behavioral.html">《设计模式整理总结（三）：行为型模式》</a></li>
</ul>
</li>
</ul>
<p><strong>后台开发基础类</strong></p>
<ul>
<li>进程，线程<ul>
<li><a href="/201609/read-%28linux-mulit-thread-server-develop%29.html">《Linux多线程服务端编程 读摘》</a></li>
<li><a href="/201609/lockless-in-multi-thread.html">《多线程中无锁队列的学习心得》</a></li>
<li><a href="/201611/about-multi-process-thread-dev-manage.html">《浅谈多进程程序的控制和管理》</a></li>
<li><a href="/201611/forkp-mulit-process-manage-framework.html">《forkp多进程程序管理库的轮子》</a></li>
</ul>
</li>
<li>异步框架<ul>
<li><a href="/201604/linux-env-program-%281%29-async-blocking-io-model.html">《Linux环境开发（一）：同异步、阻塞的IO模型相关的问题》</a></li>
<li><a href="/201604/linux-env-program-%282%29-difference-select-poll-epoll.html">《Linux环境开发（二）：Linux IO复用之select/poll/epoll的差异分析》</a></li>
<li><a href="/201605/learn-note-of-libevent-%281%29-basic-usage.html">《Libevent学习笔记（一）：基本使用》</a></li>
<li><a href="/201605/learn-note-of-libevent-%282%29-thread-pool-in-memcached.html">《Libevent学习笔记（二）：Memcached中Libevent和线程池使用初探》</a></li>
<li><a href="/201606/learn-note-of-libevent-%283%29-internel-impl-and-framework.html">《Libevent学习笔记（三）：内部实现原理初探》</a></li>
<li><a href="/201609/basics-of-boost-asio-%281%29-read-the%20docs.html">《Boost.Asio开发的相关基础知识（一）：读读文档》</a></li>
<li><a href="/201609/basics-of-boost-asio-%282%29-overview-of-the%20async-framework.html">《Boost.Asio开发的相关基础知识（二）：异步框架总览》</a></li>
<li><a href="/201609/basics-of-boost-asio-%283%29-strand.html">《Boost-Asio开发的相关基础知识（三）：Strand序列化执行用户回调》</a></li>
</ul>
</li>
<li>协程<ul>
<li><a href="/201609/usage-of-coroutine-in-boost-asio.html">《Boost.Asio中Coroutine协程库之使用》</a></li>
<li><a href="/201611/introduction-of-boost-context-and-new-coroutine-library.html">《Boost.Context库简介及协程的构建》</a></li>
<li><a href="/201611/learn-note-of-tencent-libco-coroutine.html">《腾讯libco协程库学习笔记》</a></li>
<li><a href="/201611/libto-coroutine-library-base-on-boost-context2.html">《基于Boost.Context协程库的轮子libto设计与实现》</a></li>
</ul>
</li>
<li>数据库设计管理和优化<ul>
<li><a href="/201605/data-type-and-index-of-mysql-database.html">《MySQL数据库的数据类型和索引介绍》</a></li>
</ul>
</li>
<li>日志模块</li>
<li>互联网协议<ul>
<li><a href="/201605/fastcgi-support-for-http-server-libmicrohttpd.html">《对libmicrohttpd的HTTP服务器添加FastCGI支持》</a></li>
<li><a href="/201605/principle-of-oauth2.html">《互联网流行的OAuth 2.0 开放授权原理》</a></li>
<li><a href="/201612/http2-spec.html">《HTTP/2协议规范和特性》</a></li>
<li><a href="/201701/https-principle.html">《HTTPS原理简单介绍》</a></li>
</ul>
</li>
<li>后台开发可升缩性概论<ul>
<li><a href="/201702/study-note-of-scalable-backend-%281%29-front.html">《后台开发那些常用技术再次小结（一）：前端部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%282%29-web-service.html">《后台开发那些常用技术再次小结（二）：Web服务层》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%283%29-storage.html">《后台开发那些常用技术再次小结（三）：存储部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%284%29-cache.html">《后台开发那些常用技术再次小结（四）：缓存部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%285%29-message-queue.html">《后台开发那些常用技术再次小结（五）：消息队列》</a></li>
</ul>
</li>
</ul>
<p><strong>后台开发高级类</strong></p>
<ul>
<li>分布式系统<ul>
<li><a href="/201611/learn-note-of-distributed-system-%281%29-abstraction-and-2PC-3PC.html">《分布式系统入门笔记（一）：分布式系统基本概念和两三阶段提交》</a></li>
<li><a href="/201611/learn-note-of-distributed-system-%282%29-paxos-algorithm.html">《分布式系统入门笔记（二）：Paxos算法》</a></li>
<li><a href="/201611/learn-note-of-distributed-system-%283%29-see-paxos-from-phxpaxos.html">《分布式系统入门笔记（三）：从PhxPaxos中再看Paxos协议》</a></li>
<li><a href="/201612/learn-note-of-distributed-system-%284%29-raft-consensus.html">《分布式系统入门笔记（四）：Raft一致性算法》</a></li>
<li><a href="/201701/learn-note-of-distributed-system-%285%29-zab-consensus.html">《分布式系统入门笔记（五）：ZooKeeper之ZAB一致性协议》</a></li>
<li><a href="/201701/learn-note-of-distributed-system-%286%29-application.html">《分布式系统入门笔记（六）：基于ZooKeeper的分布式系统的应用场景》</a></li>
<li><a href="/201612/nginx-load-balancing.html">《Nginx的负载均衡原理》</a></li>
<li><a href="/201612/consistent-hashing.html">《一致性hash原理》</a></li>
<li><a href="/201612/read-note-of-amazon-dynamo.html">《Amazon Dynamo论文学习笔记》</a></li>
</ul>
</li>
<li>RPC<ul>
<li><a href="/201612/learn-note-of-google-grpc.html">《Google gRPC学习笔记》</a></li>
<li><a href="/201701/rpc-principle-and-tips.html">《RPC设计和使用中的一些杂谈》</a></li>
</ul>
</li>
<li>消息中间件</li>
<li>缓存<ul>
<li><a href="/201607/design-and-impl-of-minicached-base-on-memcached.html">《基于memcached的单机轻量级通用缓存库minicached的实现》</a></li>
</ul>
</li>
</ul>
<p><strong>技术和实战经验类</strong></p>
<ul>
<li>json、protobuf等序列化<ul>
<li><a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a></li>
</ul>
</li>
<li>系统测试、跟踪和性能调优<ul>
<li><a href="/201701/linux-performance-basic.html">《Linux服务器的那些性能参数指标》</a></li>
<li><a href="/201701/gnu-gdb-debug.html">《GNU GDB调试手册》</a></li>
<li><a href="/201702/cmake-cheatsheet.html">《CMake工具使用手册》</a></li>
</ul>
</li>
</ul>
<p>　　从上面的整理中可以看出，在不同的业务层次和业务需求下，后台开发涉及到的知识面相当之多。“吾生也有涯，而知也无涯。以有涯随无涯，殆已！”任何一个人都不可能把所有的这些知识做足、做透、做深入的，其中任何一个方面深入下去都有足够多的东西可以去挖掘和研究的。列举后会发现自己的博客都涉及到了，给人一种不务正业、蜻蜓点水的感觉，其实个人想法是：在对后台系统认识不够深入健全的情况下，最好把这些知识都涉及了解一些，后续再选择一两个方向做深入、纵向研究，就像临床医师学习的时候都是全科医生培养，然后在工作时候再在特定专科积累经验、做精做强，我想也是相同的道理。做任何事情，如果没有全局的观念和视野，那么往往能得到的也只是局部最优解。<br>　　另外就是像之前说的，学习的时候如果能够由项目带着，自然是最幸福不过的事情了；否则的话，就多看看开源项目的代码吧。作为后台服务端开发的话，在此十分推荐Nginx项目，是一个异步多进程的经典实践。虽然是一个Web服务器，但是支持相当多的特性，后台开发中的很多问题都有涉及，比如长连接keepalive、负载均衡等，C语言也容易看的懂，可以快速借鉴用到自己的项目中去。<br>　　“源码面前，了无秘密！”这是个好习惯。</p>
<p>　　后续要做的事情，就是要把之前的博客整理一下，主要是:<br>　　(1). 格式方面: 虽然自己不是做前端的，别人也提供了现成的框架和模板，做到像<a href="https://imququ.com/" target="_blank" rel="external">《JerryQu 的小站》</a>这样的博客，文章整洁的可以当手册来用。<br>　　(2). 文字方面：以前自己的博客写完一般就直接发布了，难免有用词不当、语句不通的情况。后面自己每篇文章都要好好读一下。<br>　　(3). 知识更新方面： 这也是最重要的，因为随着自己学习的深入、见识的增加、理解的深入，之前的某些观点可能不完整，甚至是错误的，本着对自己对网友的负责，不合理的东西必须立即的修正。这些部分争取用修订的模式展示出来，个人癖好——成长的足迹也是一种快乐。<br>　　PS：之前的博客URL使用默认的中文模式，导致经过urlencode的地址看上来丑爆了，长痛不如短痛，所以前两天将所有的URL都修成了英文模式的。这导致之前共享出来的链接都是死链了，默认让跳转到首页了，很是抱歉！</p>
<blockquote>
<p>路漫漫其修远兮，吾将上下而求索！</p>
</blockquote>
<p>本文完!</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　专注后台服务端开发也好久了，自我感觉经验增加了很多，接触到的东西确实不少，博文也批量更新了很多。表面看似很多很杂，但个人心中思路计划感觉还是比较明确的，此处做一阶段性整理和总结吧。<br>　　其实不仅仅是后台服务端开发，就整个软件开发的知识构成也是有所层次的。个人毕竟不是正规计算机科班出身，也就是大家所说的半路出道的野程序员，很多时候感觉自己的知识构成还是有所缺陷。长痛不如短痛，晚补不如早补，该学的终究跑不掉！<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="读书笔记" scheme="https://taozj.org/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="博客" scheme="https://taozj.org/tags/%E5%8D%9A%E5%AE%A2/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="造轮子" scheme="https://taozj.org/tags/%E9%80%A0%E8%BD%AE%E5%AD%90/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[设计模式整理总结（三）：行为型模式]]></title>
    <link href="https://taozj.org/201612/design-patterns-(3)-behavioral.html"/>
    <id>https://taozj.org/201612/design-patterns-(3)-behavioral.html</id>
    <published>2016-12-11T13:39:41.000Z</published>
    <updated>2017-02-28T08:33:29.000Z</updated>
    <content type="html"><![CDATA[<h1 id="三、行为型模式">三、行为型模式</h1><p>　　行为型模式主要包括：职责链(Chain of Responsibility)、命令(Command)、解释器(Interpreter)、迭代器(Iterator)、中介者(Mediator)、备忘录(Memento)、观察者(Observer)、状态(State)、策略(Strategy)、模板方法(Template Method)、访问者(Visitor)，行为型模式共有11种。</p>
<h2 id="3-1_职责链(Chain_of_Responsibility)模式">3.1 职责链(Chain of Responsibility)模式</h2><p>　　定义：是多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。<br><img src="/post_images/images/201612/45efdf59850422593bbcfc54db35f529.png" alt="coresponse"><br>　　Handler类，引用下一个Handler，同时提供接口设置下一个Handler以实现后继链，还包括具体处理方式的抽象接口HandleRequest；ConcreteHandler处理它所负责的请求，可以访问它的后继者，即可以调用HandleRequest处理该请求，或者将请求转发给后继者。<br>　　当有多个对象可以处理同一个请求的时候，哪个对象处理该请求由运行时候自动确定。这样使得接收者和发送者都没有对方明确的信息，且链中的对象自己也不知道链的结构，职责链可以简化对象的相互链接，他们仅需保持一个指向其后继者的引用就可以了，而不需要保持其所有候选接收者的引用。</p>
<h2 id="3-2_命令(Command)模式">3.2 命令(Command)模式</h2><p>　　定义：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。<br><img src="/post_images/images/201612/94e0c5a6540e5ec253d38c99ee1d71c1.png" alt="command"><br>　　源于行为请求者和行为实现者如果紧密耦合的话，虽然实现简单，但是极为的僵化。命令模式可以把请求一个操作的对象和知道怎么执行一个操作的对象分割开来。实践人家建议不要为代码急于实现命令模式，即使后面需要重构，也很容易实现它，只有真正需要记录、撤销、恢复等操作的功能时，才考虑实现命令模式。<br>　　Command类抽象出一个Execute()接口；ConcreteCommand将一个接收者对象绑定于一个动作，然后调用接收者响应的操作，以实现Execute()；Client创建一个具体命令对象并设定它的接收者；Invoker要求该命令执行这个请求；Receiver知道如何实现请求对应的具体操作，就是实现Action的内容。<br>　　实例：Command模式很容易实现一个菜单Menu的功能，菜单的每一个MenuItem都是一个ConcreteCommand，当用户点击一个菜单项的时候，MenuItem调用Command规定的Execute()方法执行相应的操作。MenuItem本身并不知道他用的是哪个ConcreteMenu类，但是在创建MenuItem的时候已经通过构造函数放着请求的接收者，而Execute则可以直接调用接收者的一个或者多个操作。<br><a id="more"></a></p>
<h2 id="3-3_解释器(Interpreter)模式">3.3 解释器(Interpreter)模式</h2><p>　　定义：给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。<br><img src="/post_images/images/201612/27dbb00eec448f9bc07ac58d885f7ffe.png" alt="interpreter"><br>　　如果一种特定类型的问题发生的频率足够的高，那么可能就值得将该问题的各个实例表达表述为一个简单语言中的句子，这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。解释器中的非终结符表达式定义相应子表达式的解释操作，而各终结符表达式的解释操作构成了递归的基础。<br>　　AbstractExpression抽象表达式声明一个抽象的解释操作Interpret()，这个接口为抽象语法树中所有的节点锁共享；TerminalExpression和NonterminalExpression为终结符表达式和非终结符表达式，都继承自AbstractExpression并实现Interpret接口；Context包含解释器之外的一些全局信息。</p>
<h2 id="3-4_迭代器(Iterator)模式">3.4 迭代器(Iterator)模式</h2><p>　　定义：提供一种方法顺序访问一个聚合对象中各个元素，而又不需要暴露该对象的内部表示。而且可以提供对聚集的多种方式遍历，为遍历不同的聚集结构提供如开始、下一个、是否结束、当前哪一项等统一接口。<br><img src="/post_images/images/201612/e649902f1fa7eb024f661e5b5ccb3266.png" alt="iterator"><br>　　Iterator声明访问和遍历元素的相关接口，如First()、Next()、IsDone()、CurrentItem()等接口；ConcreteIterator为具体迭代类，引用一个具体聚集对象，同时针对对象类型实现Iterator的操作接口，注意对该聚合遍历时候需要跟踪当前的位置信息；Aggregate提供Iterator对象的创建接口CreateIterator()；ConcreteAggregate具体聚合类，实现创建相应迭代器的抽象接口CreateIterator()。<br>　　总体来言，迭代器模式分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，有可以让外部代码透明的访问结合内部的数据。</p>
<h2 id="3-5_中介者(Mediator)模式">3.5 中介者(Mediator)模式</h2><p>　　定义：用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显式相互引用，从而使其耦合松散，而且可以独立地改变他们之间的交互。<br><img src="/post_images/images/201612/8defe9a79b6e6c30fd28563ede2b83ad.png" alt="mediator"><br>　　尽管将一个系统分割成许多对象通常可以增加其可复用性，不过对象间的相互关联的激增又反而会降低其可复用性。<br>　　Mediator类为抽象中介者类，需要知道所有的具体同事类，定义一个借口用于与各同时对象通信，从具体的同事接收消息，向具体同时发送命令；Colleague是抽象同事类，ConcreteColleague是具体同事类，每个同事只知道自己的行为，而不了解其他同事的情况，但他们都认识中介者对象并保持一个对中介者的引用，当需要与其他同事通信的生活，与它的中介者通信。当然如果中介者需要扩展，可以扩展到具体的ConcreteMediator。<br>　　当一组对下你个以定义良好但是复杂的方式进行通信，产生的相互依赖关系结构混乱难以理解，或者一个对象引用其他很多对象并且直接与这些对象通信，导致难以复用该对象的时候，可以考虑用中介者模式。由于把对象如何协作进行了抽象，将中介作为一个独立的概念并将其封装在一个对象中，这样关注的对象就从对象各自本身的行为转移到他们之间的交互上来了，就站在一个更宏观的角度上看待系统。但是由于ConcreteMediator控制了集中化，于是把交互的复杂性变为了中介者的复杂性，使得中介者变得比任何一个Colleague都复杂。<br>　　实例比如：房东和租房者都可以作为信息的发送者和接收者，他们同时需要有设置中介的接口SetMediator，而中介需要提供接口setPerson来把信息发送者和接收者相关联，同时负责转发消息。</p>
<h2 id="3-6_备忘录(Memento)模式">3.6 备忘录(Memento)模式</h2><p>　　定义：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。<br><img src="/post_images/images/201612/84574927a50d0731a3ef786022a1a25a.png" alt="memento"><br>　　比如为了允许用户取消不确定的操作，或者支持从错误中恢复过来，需要实现检查点和取消机制，因此需要事先将状态信息保存在某处，这样才能支持对象的恢复操作。如果简单的提供一个接口让其它对象直接得到这些状态，将会暴露对象的细节并且破坏对象的封装性。<br>　　Originator作为发起人内部包含状态信息，其负责创建一个Memento，用以记录保存当前时刻的状态，并支持用备忘录恢复其内部状态，发起人可以根据需要决定Memento可以存储Originator内部的哪些状态；Memento负责存储Originator内部的状态，并防止Originator以外其他对象访问备忘录，备忘录实际上有两个接口，其宽接口给Originator，可以访问恢复对象所需要的所有信息，窄接口给Caretaker（内部私有引用具体的memento），只能将备忘录传递给其他对象；Caretaker负责保存好备忘录，但不能对备忘录的内容进行操作或者检查。当需要保存部分的信息而不是全部信息Clone的时候，使用该模式。<br>　　Memento模式比较适用于功能比较复杂，但需要维护或记录属性历史的类，或者需要保存的属性是众多属性中的一小部分，Originator可以根据保存在Caretaker中的Memento信息还原到以前的某个状态。<br>　　实例比如：GameRole是一个发起者，其提供Save()和Load()接口可以创建Memento对象和加载Memento对象，CareTaker负责保存Memento对象，但是却不能访问其内容，可以发起保存memento或者在GameRole需要加载的时候取出memento。</p>
<h2 id="3-7_观察者(Observer)模式">3.7 观察者(Observer)模式</h2><p>　　定义：观察者模式通常也称为发布/订阅模式(Publish-Subsrcibe)，其定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象，当这个主题对象在状态发生变化时，所有依赖于它的对象都得到通知并被自动更新。<br><img src="/post_images/images/201612/07c6d34850c572ac653b1eeb152549cf.png" alt="observer"><br>　　Subject主题或者抽象通知者，知道其观察者，通常将所有观察者对象的引用或指针保存在一个聚集observers里，每个主题可以有任意数量(多个)的观察者，同时提供可以增删观察者的接口；Observer抽象观察者，为那些在目标发生改变时需获得通知的对象定义一个更新接口Update()；ConcreteSubject将有关状态存入subjectState，当它的状态发生改变的时候，给所有登记的观察者发出Notify通知；ConcreteObserver维护一个指向ConcreteSubject对象的引用，存储有关状态到observerState，这些状态应当同目标状态保持一致，实现Observer的更新接口，使自身状态与目标状态保持一致。<br>　　将一个系统分割成一系列相互协作的类，其最大副作用就是需要维护相关对象的一致性，如果希望维护一致性而使得各个类相互紧密耦合，会对维护、扩展和重用带来不便。而观察者模式之关键对象包括Subject和Observer，一个Subject可以有任意数目的依赖他的Observer，一旦Subject的状态发生变化，所有的Observer都可以得到通知，当Subject发出通知的时候，并不需要知道它的观察者。<br>　　当一个抽象模型有两个方面，其中一个方面依赖于另外一个方面，他们封装成独立的对象中可以增加使他们各自独立的改变和复用；同时当一个对象的改变需要通知其他对象的时候，而他不知道具体有多少对象有待改变的时候，这些情况都应该考虑使用观察者模式。<br>　　实例比如：Blog作为主题，Observer作为订阅者。Blog提供Attach()、Remove()接口来添加删除订阅者并保存在list<observer*>容器中，然后Notify()接口分别调用Blog中定义的Update()方法。前端中的数据和各个表格、饼状图等展示的关系，也可以使用观察者的模式来设计。</observer*></p>
<h2 id="3-8_状态(State)模式">3.8 状态(State)模式</h2><p>　　定义：当一个对象的内在状态改变时允许改变其行为，对象看起来像是修改了它的类。<br><img src="/post_images/images/201612/a456374ff7dc662232755ed2f0c2b307.png" alt="state"><br>　　Context类定义了用户感兴趣的Request()接口，不断处理请求、更改状态，同时引用维护一个ConcreteState子类的实例state，这个实例保存了当前状态，同时实现Request()接口，不断处理请求同时更改状态；State抽象状态类，定义一个接口Handle()以封装与Context的一个特定状态相关的行为；ConcreteState作为每一个子类实现一个与Context的一个状态相关的具体行为。<br>　　状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂的时候，把状态的判断逻辑转移到表示不同状态的一系列类当中，可以把复杂的判断逻辑简单化。<br>　　考虑使用状态模式的情况：<br>　　(1) 一个对象的行为取决于它的状态, 并且它必须在运行时刻根据状态改变它的行为。<br>　　(2) 一个操作中含有庞大的多分支的条件语句，且这些分支依赖于该对象的状态。<br>　　因此状态模式就是为了消除庞大的条件分支和转移语句，将所有与状态相关的代码都存在于某个具体的ConcreteState类中，通过定义新的ConcreteState类可以轻松的增加新的状态和转移。<br>　　实例比如：TCPConnection中的状态机，连接对象根据连接的状态(TCPState-TCPEstablished,TCPListen,TCPClosed)的不同表现出不同的行为操作。</p>
<h2 id="3-9_策略(Strategy)模式">3.9 策略(Strategy)模式</h2><p>　　定义：定义了一个算法家族，把他们一个个封装起来，让它们之间可以互相替换。此模式让算法的变化，不会影响到使用算法的客户，使得算法可独立于使用它的客户而变化。<br><img src="/post_images/images/201612/df3416af0920848768346469d24cbe2f.png" alt="strategy"><br>　　Strategy定义所有支持的算法的公共接口AlgorithmInterface()，Context使用这个接口来调用某个具体的ConcreteStrategy定义的算法；ConcreteStrategy具体算法类实现这个接口产生某具体算法；Context类用一个具体的ConcreteStrategy对象来配置，维持一个对Strategy对象的引用strategy，并定义一个接口来让Strategy类访问它的数据，接口ContextInterface()通过调用具体的strategy.AlgorithmInterface()实现功能而不影响客户的使用。<br>　　策略模式是一种定义一系列算法的方法，从概念上说这些算法完成的都是相同的工作，只是实现不同而已。他们可以以相同的方式调用所有的算法，减少各种算法与使用算法类之间的耦合。<br>　　策略模式的Strategy类层次为Context定义了一系列可供重用的算法或行为，其作为父类的继承关系有助于汲取出这些算法中的公共功能。当不同的行为堆砌到一个类里面，难免会使用条件语句选择合适的行为，而将这些行为封装在独立的Strategy类里面，可以用于消除这些条件语句，源于在策略模式中，选择所需具体实现的职责，由客户端对象承担，并转嫁给Context对象了。 策略模式在使用的时候，要么创建好具体的算法对象传递进去，要不使用名字、标签等形式来指定算法类型，而在C++中，也可以使用模板参数的方式直接实例化需要的类型。</p>
<h2 id="3-10_模板方法(Template_Method)模式">3.10 模板方法(Template Method)模式</h2><p>　　定义：定义一个操作中的算法的骨架，而将一些步骤延迟到子类当中，模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。<br><img src="/post_images/images/201612/21026edf67b004a3d9e0eb313c8ab16e.png" alt="template-method"><br>　　AbstractClass抽象模板负责定义抽象的原语操作，具体的子类将重新定义它们以实现一个算法的各步骤，同时实现一个一个模板方法，还需要定义一个算法的骨架，该模板方法不仅可以调用原语操作，也调用定义在AbstractClass或其他对象中的操作(反正都会被ConcreteClass所继承)；ConcreteClass实现原语操作以完成算法中与特定子类相关的步骤。每个AbstractClass可以有任意多个ConcreteClass与之对应，而每个ConcreteClass都可以给出这个抽象方法的不同实现。<br>　　当使用了继承体系，并且肯定这个继承有意义，就应该将所有重复的代码都应该上升到父类去，而不是让每个子类都去重复。当需要完成一系列的步骤或者过程，但个别步骤(上文的原语)在更详细的实现上可能不同的话，通常应该使用模板方法的模式来处理。也就是一次性实现一个算法的不可变部分，并将可变的行为留给子类来实现。<br>　　模板的方法通过把不变的行为移到超类，去除子类中的重复代码，从而实现一个好的代码复用平台。而当不可变和可变的行为在方法的子类中混合在一起的时候，不变的行为就会在子类中重复出现，需要通过模板方法把这些行为移动到单一的地方。<br>　　实例比如：填写简历，可以抽象出Resume类并定义FillResume()进行创建过程(比如SetPersonalInfo、SetEducation等)，然后在Resume的各个派生类中实现构造过程的具体细节。</p>
<h2 id="3-11_访问者(Visitor)模式">3.11 访问者(Visitor)模式</h2><p>　　定义：表示一个作用于某对象结构中的各元素的操作，它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。<br><img src="/post_images/images/201612/4942fdb4717846ef56dffcbf5f5ef903.png" alt="visitor"><br>　　Visitor为该对象结构中ConcreteElement的每一个类声明一个Visit操作，该操作的名字和特征标识了发送Visit请求给该访问者的哪个类；ConcreteVisitor1,2为具体访问者，实现每个由Visitor声明的操作，每个操作实现算法的一部分；Element定义了一个Accept()操作，它以一个Visitor访问者作为参数；ConcreteElementA,B实现具体的Accept()操作；ObjectStructure能枚举它的元素，可以提供一个高层的接口允许访问者访问他的元素，他可以是一个Composite或是一个集合，比如一个列表或者一个无序集合。<br>　　访问者模式的目的是要把处理从数据结构中分离出来，很多系统是数据结构和算法分开，如果系统有比较稳定的数据结构，又有易于变化的算法的话，使用访问者模式比较的合适，访问者模式让算法操作的增加变得容易，因为新增加的操作就等于新增加一个访问者类。但是访问者模式d的缺点是增加新的数据结构变的困难了。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="三、行为型模式">三、行为型模式</h1><p>　　行为型模式主要包括：职责链(Chain of Responsibility)、命令(Command)、解释器(Interpreter)、迭代器(Iterator)、中介者(Mediator)、备忘录(Memento)、观察者(Observer)、状态(State)、策略(Strategy)、模板方法(Template Method)、访问者(Visitor)，行为型模式共有11种。</p>
<h2 id="3-1_职责链(Chain_of_Responsibility)模式">3.1 职责链(Chain of Responsibility)模式</h2><p>　　定义：是多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。<br><img src="/post_images/images/201612/45efdf59850422593bbcfc54db35f529.png" alt="coresponse"><br>　　Handler类，引用下一个Handler，同时提供接口设置下一个Handler以实现后继链，还包括具体处理方式的抽象接口HandleRequest；ConcreteHandler处理它所负责的请求，可以访问它的后继者，即可以调用HandleRequest处理该请求，或者将请求转发给后继者。<br>　　当有多个对象可以处理同一个请求的时候，哪个对象处理该请求由运行时候自动确定。这样使得接收者和发送者都没有对方明确的信息，且链中的对象自己也不知道链的结构，职责链可以简化对象的相互链接，他们仅需保持一个指向其后继者的引用就可以了，而不需要保持其所有候选接收者的引用。</p>
<h2 id="3-2_命令(Command)模式">3.2 命令(Command)模式</h2><p>　　定义：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。<br><img src="/post_images/images/201612/94e0c5a6540e5ec253d38c99ee1d71c1.png" alt="command"><br>　　源于行为请求者和行为实现者如果紧密耦合的话，虽然实现简单，但是极为的僵化。命令模式可以把请求一个操作的对象和知道怎么执行一个操作的对象分割开来。实践人家建议不要为代码急于实现命令模式，即使后面需要重构，也很容易实现它，只有真正需要记录、撤销、恢复等操作的功能时，才考虑实现命令模式。<br>　　Command类抽象出一个Execute()接口；ConcreteCommand将一个接收者对象绑定于一个动作，然后调用接收者响应的操作，以实现Execute()；Client创建一个具体命令对象并设定它的接收者；Invoker要求该命令执行这个请求；Receiver知道如何实现请求对应的具体操作，就是实现Action的内容。<br>　　实例：Command模式很容易实现一个菜单Menu的功能，菜单的每一个MenuItem都是一个ConcreteCommand，当用户点击一个菜单项的时候，MenuItem调用Command规定的Execute()方法执行相应的操作。MenuItem本身并不知道他用的是哪个ConcreteMenu类，但是在创建MenuItem的时候已经通过构造函数放着请求的接收者，而Execute则可以直接调用接收者的一个或者多个操作。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[设计模式整理总结（二）：结构型模式]]></title>
    <link href="https://taozj.org/201612/design-patterns-(2)-structural.html"/>
    <id>https://taozj.org/201612/design-patterns-(2)-structural.html</id>
    <published>2016-12-11T13:39:28.000Z</published>
    <updated>2017-02-28T08:33:35.000Z</updated>
    <content type="html"><![CDATA[<h1 id="二、结构型模式">二、结构型模式</h1><p>　　结构型模式主要包括：适配器(Adapter)、桥接(Bridge)、组合(Composite)、装饰(Decorator)、外观(Facade)、享元(Flyweight)、代理(Proxy)，总共有七种类型。</p>
<h2 id="2-1_适配器(Adapter)模式">2.1 适配器(Adapter)模式</h2><p>　　定义：将一个类的接口转换成客户希望的另外一个接口，Adaptor模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。<br>　　类适配器模式<br><img src="/post_images/images/201612/c2c1c67522d126c478b563084b413203.png" alt="adaptor"><br>　　对象适配模式<br><img src="/post_images/images/201612/984f9b6f02bd155897b4e811c5e72645.png" alt="adaptor2"><br>　　当需要的东西就在眼前，系统的数据和行为都正确，但是接口不符合，可以使用适配器模式，目的使得原有控制范围之外的一个原有对象与某个接口匹配。适配器模式主要应用于希望使用一些现存的类/工具，但是接口又与复用环境要求不一致的情况。其实现包括类适配器模式、对象适配模式两种：类适配器使用多重继承对一个接口与另一个借口进行匹配；对象匹配器依赖于对象组合的方式。<br>　　Target抽象出客户特定领域所期望的接口；Adaptee定义一个已存在的接口，是需要适配的接口；Adapter对前面的Adaptee接口与Target接口进行适配，如果是类适配ß方式则Adaptor派生Adaptee并实现其中的特定接口，如果是对象适配方式，则通过在内部封装一个私有的Adaptee对象，然后把源接口的调用转换为目标接口。<br>　　举例：一个现成的例子就是STL容器中，有标准的deque双端队列，而要实现stack/queue的数据结构就是通过适配器模式来实现的。</p>
<h2 id="2-2_桥接(Bridge)模式">2.2 桥接(Bridge)模式</h2><p>　　定义：将抽象部分与它的实现部分分离，使他们都可以独立地变化。<br><img src="/post_images/images/201612/a1baf46977e24c1e313dd8166b774850.png" alt="bridge"><br>　　当一个抽象可能有多个实现时候，通常采用继承来协调他们，但是这种方法不够灵活，类的继承关系是在编译的时候就定义好了，子类的实现和它的父类有非常紧密的依赖关系，很难让抽象部分和实现部分独立地进行修改和重用。实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多分角度分离出来让他们独立变化。<br>　　Abstraction定义接口，并且维护着对Implementor对象的指针或者引用；RefinedAbstraction扩充由Abstraction定义的接口；在Implementor中规定实现类的接口，其接口不一定要与Abstration的接口完全一致，而且通常两者的接口完全不同，一般Implementor接口仅提供基本操作，而Abstration定义了基于这些基本操作较高层次的操作；ConcreteImplementorA,B…负责实现Implementor接口并定义它的具体实现。<br>　　具体的例子：电脑制造商和操作系统，前者设计接口installOS()，后者实现接口installOS_impl()，然后两者可以分别独立的演化，在Computer中包含对OS的一个引用就可以调用具体的installOS_impl()了。再比如抽象Window和实现WindowsImpl，前者包含后者对象的一个引用imp，那么Icon/TransientWindow的任何操作都可以调用imp-&gt;XXX()来实现了。<br><a id="more"></a></p>
<h2 id="2-3_组合(Composite)模式">2.3 组合(Composite)模式</h2><p>　　定义：将对象组合成树形结构以表示“部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。处理的是整体和部分可以被一致对待的问题。<br><img src="/post_images/images/201612/5ea6a10e047a95a672107c21676af19a.png" alt="bridge"><br>　　Component为组合中的对象声明接口，在适当情况下实现所有类公有接口的默认行为，同时也提供访问和管理(Add/Remove)Component的子部件；Leaf在组合中表示叶节点对象，叶节点没有子节点；Composite定义有子部件的那些部件的行为，存储子部件，同时在Component接口中实现与子部件有关的操作。<br>　　Composite模式的关键是一个抽象类，它既可以代表元素，又可以代表元素的容器，即支持元素类型的一些操作，又有一些额外的操作访问和管理他的子部件。当需求中是体现部分与整体层次结构的时候，以及希望用户可以忽略组合对象和单个对象的不同，统一地使用组合结构中的所有对象时，就应该考虑使用组合模式了。<br>　　举个例子就是总公司和分公司以及各个部门的关系，Company列出接口，而ConcreteCompany可以进行Add/Remove操作，同时XXXDepartment不支持Add/Remove操作。</p>
<h2 id="2-4_装饰(Decorator)模式">2.4 装饰(Decorator)模式</h2><p>　　定义：动态地给一个对象添加一些额外的职责，就增加的功能来说，装饰模式比生成子类更为灵活。<br><img src="/post_images/images/201612/9c851b3346872ad685e123e983f3dc5b.png" alt="decorator"><br>　　虽然通过继承机制是添加功能的一种有效途径，但是这种方式不够灵活，因为继承关系是静态的，用户就不能控制添加功能的方式和时机，解决的方式是将组件嵌入到另一个对象中，由这个对象实现额外功能，这个嵌入的对象就叫做装饰。对Component类本身来说，是无需知道Decorator的存在的(组件无需对他的装饰有任何的了解，而Strategy模式中component组件本身知道可能进行哪些扩充，必须引用和维护相应的策略，这是两者最大的区别)，但是通过Decorator却起到给Component增加职责的功能，而且其对于使用该组件的客户是透明的，客户的请求被转发到该组件，透明性还允许嵌套多个装饰，实现任意多的功能。<br>　　Component定义一个对象的接口，可以给这些对象动态地增加一些职责；ConcreteDecorator可以通过实现Component定义的接口，给对象添加一些具体的职责；Decorator维持一个指向Component对象的指针或者引用，并定义一个与Component接口一致的接口；ConcreteDecorator用于向组件添加职责。<br>　　装饰类通过接口SetComponent()来设置需要装饰的对象(实参可以是Component或者更加具体的ConcreteComponent，指针或者引用类型)，其参数必须是Component，这样就可以把装饰后的ConcreteDecorator再进装饰形成具有顺序的多次装饰了。这里提取两个抽象层，是为了扩展的方便，如果简单的话，是不需要提取Component和/或Decorator抽象类的。<br>　　实践中当需要新功能的时候，可以向旧类直接添加代码，但是这些代码应当是原有类的核心或者主要职责功能，但想主类增加字段、方法、逻辑会增加主类的复杂度。对于某些在特定情况下才会执行的特殊行为需要，可以将装饰的功能放在单独的类当中，并让这个类包装它需要装饰的对象，客户代码可以在运行的时候根据需要有选择、按顺序地使用装饰功能包装对象了。 这样的好处就是把类的核心职能和装饰功能分开，同时能去除相关类中重复的装饰逻辑。<br>　　实例比如Phone类，在产生具体的NokiaPhone、iPhone的核心功能子对象的同时，如果需要额外的装饰，可以依据Phone派生出DecPhone1、DecPhone2等装饰子类，然后通过调用DecPhone(nokiaPhone)就可以实现装饰了。</p>
<h2 id="2-5_外观(Facade)模式">2.5 外观(Facade)模式</h2><p>　　定义：为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，每个接口使得这一子系统更加容易使用。<br>　　Facade知道哪些子系统类负责处理请求，同时将客户的请求代理给适当的子系统对象。<br>　　比如在设计和开发阶段，应当在数据访问层、业务逻辑层、表示层之间建立外观Facade，这样可以为复杂的子系统提供一个简单的接口，降低层层之间的耦合；<br>　　在维护阶段，对于一个大型系统，可以为新系统开发一个外观类，来为设计粗糙或者高度复杂的系统提供一个简单清晰的接口；<br>　　外观模式的特点是：(1)它对客户屏蔽子系统组件，因而减少了客户处理的对象的数目并使得子系统使用起来更加方便；(2)它实现了子系统与客户之间的松耦合关系，而子系统内部的功能组件往往是紧耦合的；(3)如果应用需要，它并不限制它们使用子系统类，可以自由的在易用性和通用性之前权衡。</p>
<h2 id="2-6_享元(Flyweight)模式">2.6 享元(Flyweight)模式</h2><p>　　定义：运用共享技术有效的支持大量细粒度的对象。<br><img src="/post_images/images/201612/c1ce49f3388172fc8b9de9000664bb70.png" alt="flyweight"><br>　　享元模式可以避免大量非常相似类的开销，比如文档中的每个文字用对象来表示，大量的对象会产生很大的内存开销。在程序设计中，有时候需要生成大量细粒度的类实例来表示数据，如果能发现这些实例除了几个参数外基本上都是相同的，有时就能够大幅度的减少需要实例化的类的数量。把那些参数移到类实例的外面，在方法调用的时候再将它们传递进来，在满足相同效果的同时就可以通过共享大幅度地减少单个实例的数目。<br>　　对于享元类，那些不会随环境改变而改变的共享部分，称为享元对象的内部状态，而随着环境改变而改变的，不可以共享的状态称为外部状态。如果程序使用大量的共享对象，而大量对象造成了很大的存储开销就应该考虑使用享元，还有就是对象的大多数状态可以作为外部状态，如果删除外部状态，那么可以用相对较少的共享对象取代很多种情况的组合对象，也考虑使用享元。<br>　　Flyweight类是所有具体享元类的超类或者接口Operation(var)，通过这个接口，Flyweight可以接收并作用于外部状态；ConcreteFlyweight实现Flyweight所定义的接口，并为内部状态增加容器存储空间，ConcreteFlyweight对象必须是可共享的，它所存储的状态必须是内部的；UnsharedConcreteFlyweight是那些不需要共享的Flyweight的子类；FlyweightFactory是一个享元工厂，用来创建并管理Flyweight对象，他确保合理地共享Flyweight，当用户请求一个Flyweight的时候，负责返回一个已创建的实例或者创建一个新的对象。<br>　　实例比如棋盘的棋子Piece，颜色作为内在属性可以创建Black/WhitePiece，同时棋子的位置在棋盘上是外在属性，可以存储在std::vector中，此时std::vector存储的只是位置信息而非棋子对象，所以效率会提高不少。</p>
<h2 id="2-7_代理(Proxy)模式">2.7 代理(Proxy)模式</h2><p>　　定义：为其他对象提供一种代理以控制对这个对象的访问。<br><img src="/post_images/images/201612/c36aa451ce8d4782ccacbfb2aa251898.png" alt="proxy"><br>　　Subject定义指明了RealSubject和Proxy的公用接口(比如show()方法)，RealSubject和Proxy都需要继承Subject这个类，这样在任何使用RealSubject的地方都可以使用Proxy进行代理；Proxy类保存一个RealSubject的引用，从而使得代理可以访问代理实体，提供一个与Subject的接口相同的接口，这样代理就可以用来代替实体，在用户调用接口方法的时候，通过引用对象调用其具体的同名接口方法。<br>　　远程代理：远程代理，为一个对象在不同的地址空间提供局部代表，以隐藏一个对象在不同地址空间的事实。<br>　　虚拟代理：用于根据需要创建开销很大的对象，通过它来存放实例化需要很长世间的真实对象，这些对象在需要使用的时候才会被创建。<br>　　安全代理：用来控制真实对象访问时候的权限，一般用于对象应该有不同访问权限的时候。<br>　　智能指引：当调用真实对象的时候，代理额外处理一些事情，比如引用计数，锁定等。<br>　　实例的话，就想想SmartPointer就好啦！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="二、结构型模式">二、结构型模式</h1><p>　　结构型模式主要包括：适配器(Adapter)、桥接(Bridge)、组合(Composite)、装饰(Decorator)、外观(Facade)、享元(Flyweight)、代理(Proxy)，总共有七种类型。</p>
<h2 id="2-1_适配器(Adapter)模式">2.1 适配器(Adapter)模式</h2><p>　　定义：将一个类的接口转换成客户希望的另外一个接口，Adaptor模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。<br>　　类适配器模式<br><img src="/post_images/images/201612/c2c1c67522d126c478b563084b413203.png" alt="adaptor"><br>　　对象适配模式<br><img src="/post_images/images/201612/984f9b6f02bd155897b4e811c5e72645.png" alt="adaptor2"><br>　　当需要的东西就在眼前，系统的数据和行为都正确，但是接口不符合，可以使用适配器模式，目的使得原有控制范围之外的一个原有对象与某个接口匹配。适配器模式主要应用于希望使用一些现存的类/工具，但是接口又与复用环境要求不一致的情况。其实现包括类适配器模式、对象适配模式两种：类适配器使用多重继承对一个接口与另一个借口进行匹配；对象匹配器依赖于对象组合的方式。<br>　　Target抽象出客户特定领域所期望的接口；Adaptee定义一个已存在的接口，是需要适配的接口；Adapter对前面的Adaptee接口与Target接口进行适配，如果是类适配ß方式则Adaptor派生Adaptee并实现其中的特定接口，如果是对象适配方式，则通过在内部封装一个私有的Adaptee对象，然后把源接口的调用转换为目标接口。<br>　　举例：一个现成的例子就是STL容器中，有标准的deque双端队列，而要实现stack/queue的数据结构就是通过适配器模式来实现的。</p>
<h2 id="2-2_桥接(Bridge)模式">2.2 桥接(Bridge)模式</h2><p>　　定义：将抽象部分与它的实现部分分离，使他们都可以独立地变化。<br><img src="/post_images/images/201612/a1baf46977e24c1e313dd8166b774850.png" alt="bridge"><br>　　当一个抽象可能有多个实现时候，通常采用继承来协调他们，但是这种方法不够灵活，类的继承关系是在编译的时候就定义好了，子类的实现和它的父类有非常紧密的依赖关系，很难让抽象部分和实现部分独立地进行修改和重用。实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多分角度分离出来让他们独立变化。<br>　　Abstraction定义接口，并且维护着对Implementor对象的指针或者引用；RefinedAbstraction扩充由Abstraction定义的接口；在Implementor中规定实现类的接口，其接口不一定要与Abstration的接口完全一致，而且通常两者的接口完全不同，一般Implementor接口仅提供基本操作，而Abstration定义了基于这些基本操作较高层次的操作；ConcreteImplementorA,B…负责实现Implementor接口并定义它的具体实现。<br>　　具体的例子：电脑制造商和操作系统，前者设计接口installOS()，后者实现接口installOS_impl()，然后两者可以分别独立的演化，在Computer中包含对OS的一个引用就可以调用具体的installOS_impl()了。再比如抽象Window和实现WindowsImpl，前者包含后者对象的一个引用imp，那么Icon/TransientWindow的任何操作都可以调用imp-&gt;XXX()来实现了。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HTTP/2协议规范和特性解读]]></title>
    <link href="https://taozj.org/201612/http2-spec.html"/>
    <id>https://taozj.org/201612/http2-spec.html</id>
    <published>2016-12-08T23:39:09.000Z</published>
    <updated>2017-02-24T08:55:44.000Z</updated>
    <content type="html"><![CDATA[<p>　　HTTP/2也算是个比较新的东西吧，虽然很多特性是基于之前的Google SPDY，但毕竟自2015年5月正式发布到现在也就一年半的时间。虽说绝大多数的主流浏览器在2015年底就基本都支持了HTTP/2协议(估计之前的SPDY“预演”功不可没)，但是对于生产环境的服务端来说可不会这么迅速就得到普及的，Apache 2.4.12通过mod_h2模块支持HTTP/2，nginx 1.9.5支持HTTP/2，所以一般服务器除非自己编译安装，要等到发行版入稳定仓库估计估计还得要个两年吧，毕竟最新的RHEL 7上的Apache还是2.4.6呢。<br>　　Google的主页已经全部部署了HTTP/2了(但是那个sffe服务器是个什么鬼？)，通过后面查看RFC发现HTTP/2具有很多优秀的特性，并且完全可以退化至HTTP/1.1，想想也是十分诱人啊。如果想在自己服务器部署Nginx支持HTTP/2的话，推举Ubuntu 16.04 LTS或许是一个不错的选择，最主要是因为<a href="https://www.nginx.com/blog/supporting-http2-google-chrome-users/" target="_blank" rel="external">新版Google Chrome移除了NPN只支持ALPN</a>，而这依赖于openSSL 1.0.2，但是很多系统都没有更新到这个版本，而系统最重要的基础库又不能轻易升级，所以用Ubuntu 16.04 LTS是在稳定性和便捷性一个比较好的平衡点，不过如果你的服务器跑的其他非企业级发行版就另当别论了。<br>　　至于突然想到这个，是因为昨天看到gRPC/Protobuf，底层是用的HTTP/2的协议，而且一个朋友做OTT，也是使用的HTTP/2的协议传输的。虽说现实很凄惨，但是前途很光明，瞄一下RFC7540流水帐一把吧！错过了HTTP/1.x，不要再错过了HTTP/2了。<br><img src="/post_images/images/201612/1655d08c.png" alt="http2"><br>　　PS：网上流传的baidu/fex-team的中文版翻译，大家在参阅的时候需要特别注意，一方面那份文档是基于草案翻译的，和正式发布的版本还是有一些差异，二来一些翻译的质量还待商榷，只建议用来对照正式版协议辅助理解，而不可作为依赖。</p>
<h1 id="一、HTTP/1-x主要缺点和HTTP/2协议概述">一、HTTP/1.x主要缺点和HTTP/2协议概述</h1><h2 id="1-1_HTTP/1-x的主要缺陷">1.1 HTTP/1.x的主要缺陷</h2><p>　　HTTP/1.0的请求都是短连接，服务端应答之后会主动关闭掉该连接，HTTP/1.1为了减少这种频繁连接建拆支持KeepAlive长连接，但是请求和应答仍然是串行报头阻塞的，因此HTTP/1.x如果需要实现真正的并发则必须建立多个连接才可以。通常，增加HTTP/1.x的传输效率有：<br>　　(1) 通常浏览器和服务端允许建立6~8个长连接，但是这增加了服务器并发量的压力；<br>　　(2) 将资源分布到多个主机上面去，那么整体来说就可以建立更多的并发数，算是横向扩展的一种方式；<br>　　(3) 将多个图片组合成一个大的图片，然后通过CSS的方式将各个部分逻辑分割成小的图片，总体减少了请求的次数；<br>　　(4) HTTP/1.1 pipeline，允许多个请求在应答之前发送出去，不过服务端的返回必须是严格按照FIFO的顺序返回，也就是说只要其中一个请求响应时间长了也会导致后续的响应被阻塞。<br>　　HTTP/1.x是纯文本格式的协议，协议头附带很多冗余的信息，而且这种头部会被反复传输，最终会占用大量带宽，而且TCP的拥塞控制更加会恶化响应时间。</p>
<h2 id="1-2_HTTP/2概述">1.2 HTTP/2概述</h2><p>　　HTTP/2针对上面问题做出了改进，允许在单个TCP连接上面通过Stream的逻辑概念实现复用机制，在增加传输效率的同时减少了连接数(自然也降低了服务端和客户端压力)。HTTP/2通过流量控制和优先级机制，有助于只传播接受者需要使用的数据资源，并在有限的资源下建议某些资源优先被传输处理。<br>　　HTTP/2允许服务器主动推送响应给客户端，主要是基于服务端预测客户端将来会用到的资源。<br>　　传统HTTP/1.x的每个请求和应答都是Header+Body的形式传输的，HTTP/2对传输帧进行了重新设计，采用二进制进行封装和压缩，增加了传输效率和可扩展性。HTTP/2的报头(HEADERS)帧和数据(DATA)帧组成了基本的HTTP请求和响应，而设置(SETTINGS)帧、窗口更新(WINDOW_UPDATE)帧、推送承诺(PUSH_PROMISE)帧可以实现HTTP/2的其他功能。</p>
<h2 id="1-3_HTTP/2协议包的抓取">1.3 HTTP/2协议包的抓取</h2><p>　　因为HTTP/2所有流量都是加密的，虽然使用浏览器F12调试器可以查看上层的数据，尤其是一些协议相关的非数据帧是无法查看的，任何分析协议不抓包的行为都是耍流氓，但是如果直接用Wireshark得的抓包是无法查阅的。调试SSL/TLS加密数据的方法有两种：<br>　　(1). 如果针对是使用自己的网站，则可以使用你部署服务器的私钥来解密数据包；<br>　　(2). 如果是调试第三方的网站，则可以通过设置浏览器的SSLKEYLOGFILE环境变量以导出对称密钥，然后让Wireshark共享读取这个文件就可以解密浏览器回话过程中的包。<br>　　第三方的服务端和浏览器可能会有这样那样的问题，自己截取了一份Chrome访问Google的数据包，设置一下SSL中的(Pre)-Master-Secret就可以了，过滤条件使用http2，懒癌患者晚期可以直接<a href="/upload/http2_package.zip">下载</a>使用。<br><img src="/post_images/images/201612/42aa82451aaaf166f59f2fb57f1e9182.png" alt="http2-flow"></p>
<h1 id="二、HTTP/2连接的启动">二、HTTP/2连接的启动</h1><p>　　HTTP/2需要客户端感知服务端是否支持HTTP/2，而不能一开始就进行HTTP/2通信。因为HTTP通信包括http和https两种情况，虽然HTTP/2必定是加密的，但是源请求方式不同，探测HTTP/2的方式也不相同。<br>　　在http的模式下，客户端发起一个普通的HTTP/1.1请求，外加HTTP升级机制所需要的额外头部信息，即 Upgrade: h2c头。如果服务端不支持HTTP/2则忽略这个请求，按照HTTP/1.1的模式正常的返回通信，后续对话退化到HTTP/1.x协议上面；而支持HTTP/2的服务端可以返回一个101(转换协议)响应来接受升级请求，这是一个空相应，紧接着两者就可以发送HTTP/2的帧了(先前主要是SETTINGS设置帧)。<br>　　鉴于https在2017年将会大量代替http，且很多服务器都将http直接301重定向到https，所以https下的HTTP/2连接的建立比较普遍。在这种情况下需要先协商建立TLS连接，然后在TLS的应用层协议协商(ALPN)中得出支持h2协议。ALPN是TLS的一个扩展，允许客户端在TLS连接建立后协商接下来需要使用的协议类型，当客户端或者服务器端不支持ALPN时HTTP/1.1将会被使用，否则客户端会向服务器端发送自己支持的协议列表，服务器会决定接下来要选用的协议并发送响应，比如下图中选用h2代表使用HTTP/2协议。<br><img src="/post_images/images/201612/73cb3b0bac9aa53312ed78266c8bc82f.png" alt="http2-start"><br>　　当然还有比如客户端通过其他方式知道某些主机一定支持HTTP/2，或者叫做先验知识知道协议支持。<br>　　上面的任何情况下，每个端点(客户端和服务端)都需要发送一个固定的24个字节连接序言(Magic)作为HTTP/2协议的最终确认<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n</div></pre></td></tr></table></figure></p>
<p>　　紧接着序言后面是一个设置帧，详细内容可以看上面的h2截图。</p>
<h1 id="三、HTTP/2_Frame帧结构">三、HTTP/2 Frame帧结构</h1><p><img src="/post_images/images/201612/5efd484de1faf2aa803318f932000426.png" alt="http2-frame"><br>　　所有的帧都是由9个字节的固定前缀打头的。Length指定了Payload长度，默认不超过2^14 (16,384)，除非设置了SETTINGS_MAX_FRAME_SIZE为更大的参数；Type指定了是前面某种帧的一种，比如SETTINGS、DATA等；Flags是一些bit的标志位；Stream Identifier用作后面的stream标识，0被保留用于表示连接相关的整体而不是一个具体的流。<br>　　关于流的长度，前面说道默认是2^14+9，任何的协议实现都必须能至少处理这个长度，通过SETTINGS_MAX_FRAME_SIZE可以最大扩展长度为2^24-1。任何接受到的帧太小而无法处理，或者操果设置值，应当返回FRAME_SIZE_ERROR。<br>　　HTTP/2的Header包含一个或者多个键值对，然后使用报头压缩序列化到header block中，然后他们会被分割成1个或多个header block fragments，并在HEADERS/PUSH_PROMISE/CONTINUATION中作为Payload部分传输。Cookie部分会被额外单独处理。如果fragment只有一份，那么只会在一个HEADERS/PUSH_PROMISE帧中传输，而且Flag的END_HEADERS会被置位，否则后面连续的PUSH_PROMISE/CONTINUATION只会在最后一个fragment处置位END_HEADERS，而且这些fragment必须作为一个连续的帧序列传输，没有任何类型或任何其他流的交错帧在中间。<br><a id="more"></a></p>
<h1 id="四、stream(流)和多路复用">四、stream(流)和多路复用</h1><p>　　stream流应该算在一个TCP连接中分组交换的逻辑概念，在单个的TCP连接上面，客户端可以发送多个请求，服务端可以在资源就绪的时候响应任何一个请求。其特性主要包括：<br>　　(1). 一个单独的HTTP/2连接能够保持多个同时打开的流，各个端点间从多个流中交换帧；<br>　　(2). 流可以被内部建立和使用，也可以用于客户端和服务端建立和共享，而且任何一个端点都可以关闭流；<br>　　(3). 流中帧的传输顺序十分重要，接收方将按照接收到的顺序处理帧；<br>　　(4). 流通过一个整型来标识，由发起的端点分配这个标识号。</p>
<h2 id="4-1_stream的状态">4.1 stream的状态</h2><h3 id="4-1-1_stream的状态和状态切换">4.1.1 stream的状态和状态切换</h3><p><img src="/post_images/images/201612/706987b79550d63f3e197f1065ae9e11.png" alt="http2-stream"><br>　　(1) <strong>idle</strong><br>　　流都是从idle状态开始的，发送或者接受一个HEADERS会导致其变为open状态，也可能导致其变成半关闭half-closed的状态；发送一个PUSH_PROMISE将导致流变成reserved (local)；收到一个PUSH_PROMISE将导致流变成reserved (remote)。<br>　　(2) <strong>reserved (local)</strong><br>　　发送PUSH_PROMISE的流将会变成reserved (local)，此时端点可以发送HEADERS使流变成half-closed (remote)；或者任意端点都可以发送一个RST_STREAM导致流变成closed状态，导致释放stream reservation。<br>　　(3) <strong>reserved (remote)</strong><br>　　收到PUSH_PROMISE的流将会变成reserved (remote)，此时端点收到HEADERS会使流变成half-closed (local)；或者任意端点都可以发送一个RST_STREAM导致流变成closed状态，导致释放stream reservation。<br>　　(4) <strong>open</strong><br>　　处于open状态的流可以用来发送任意类型的帧。任何一个端点都可以发送带有END_STREAM标记的帧，将会导致流变成half-closed状态：发送方变成half-closed (local)，接收方变成half-closed (remote)。任何一端发送RST_STREAM将会导致流变成closed状态。<br>　　(5) <strong>half-closed (local)</strong><br>　　此状态下的流只能发送WINDOW_UPDATE/PRIORITY/RST_STREAM类型的帧，当接收到END_STREAM或者任何一端发送RST_STREAM将会使流转为close状态。该状态下的流可以接收任何的帧。<br>　　(6) <strong>half-closed (remote)</strong><br>　　该状态的流表明对端不会再用其发送帧了，所以除了受到WINDOW_UPDATE/PRIORITY/RST_STREAM之外任何类型的帧都是错误的。该状态的流可以接收任何帧，而同样的当发送END_STREAM或者任何一端发送RST_STREAM将会使流转为close状态<br>　　(7) <strong>closed</strong><br>　　流的终结状态。当流接收到RST_STREAM之后如果收到除PRIORITY类型的帧，或者收到END_STREAM后再次受到任何帧，都应当被认为是STREAM_CLOSED错误。</p>
<h3 id="4-1-2_stream的标识符">4.1.2 stream的标识符</h3><p>　　由31位的整形来标识，因为标识符是发起端分配的，所以规定client必须用奇数，server必须用偶数，0保留用于连接控制。一个新建立的流的标识符必须大于任何发起终端已经打开或者保留的流标识符，同时发起一个新的流也表示该端之前创建的所有比这个标识符小的处于idle的流转换成关闭状态。<br>　　因为标识符不能被重用，所以长时间存在的连接可能会产生标识符用尽的状况。这种情况下，客户端会重新打开一个TCP连接然后创建新的流；服务端可以发送GOAWAY强制客户端打开一个新的连接。</p>
<h3 id="4-1-3_stream的并发">4.1.3 stream的并发</h3><p>　　通过SETTINGS帧设置SETTINGS_MAX_CONCURRENT_STREAMS参数，而且这个参数连接的两端都可以设置，作用于对端可以创建流的并发数目。处于open和half-closed状态的流会被计数，而处于reserved状态的stream不会被计数。</p>
<h2 id="4-2_stream的流量控制">4.2 stream的流量控制</h2><p>　　引入stream的概念就是为了避免TCP连接中的阻塞，而HTTP/2通过WINDOW_UPDATE帧实现流量控制，主要确保同一个连接上的各个流不会造成破坏性的干扰。其流控制有以下特点：<br>　　(1) 流量控制只针对下一跳(hop)，而不是完整路径的端对端的控制；<br>　　(2) 流量控制是基于WINDOW_UPDATE帧的，接收者告知自己打算接收的数量，这是一种基于信任实现的机制；<br>　　(3) 流量控制是有方向性的，且由接收端全权控制。实现中客户端、服务端、中介者都可以设置流量控制；<br>　　(4) 初始窗口大小是65,535，针对新建的流以及整个连接；<br>　　(5) 只有DATA帧受流量控制，其它类型的帧都不会计入到流量控制中，确保控制帧不会因为流量控制而被阻塞；<br>　　(6) 流量控制不能被禁用；<br>　　(7) HTTP/2协议只规定了WINDOW_UPDATE帧的格式，而具体的算法和实现没有说明。<br>　　其实说白了，就是在内存、带宽等资源有限的条件下，通过流量控制保证资源的合理分配，不会被某些流不公平的独占。流和连接的窗口，表示了允许服务端发送的字节数，每次发送数据后这个窗口的值就会相应地减少，一旦被用完后就不允许再发送数据了，直到远端再次发送WINDOW_UPDATE帧来增加这个窗口的值。<br>　　在网络开发中，传输速率和处理速度不匹配的情况经常的发生，通常的做法就是：(1)不断的缓存数据，慢慢地下方到下游去处理，但是这显然是不安全的，因为不可能无限制的缓存下去；(2)缓存足够量的数据后，拒绝从底层socket再次接收数据，但这显然是不公平的，这会让其他的stream数据无法被接收，少数的stream占用了绝对的资源。所以流量控制机制是十分重要的。</p>
<h2 id="4-3_stream的优先级">4.3 stream的优先级</h2><p>　　stream的优先级是通过依赖关系和权重来实现的，优先级不是必须的，服务端可以选择完全忽略优先级。新建立的流，可以在HEADERS帧中指定流的优先级，而其他时刻对于已经存在的流，可以通过PRIORITY帧来改变优先级。<br>　　这也是一种在带宽、资源有限时候的一种分配机制。端点不能够保证按照特定顺序传输、处理这些并发流，这只能算是一种建议性的机制。优先级信息是可选的，没有指定将会使用默认优先级。</p>
<h2 id="4-4_错误处理">4.4 错误处理</h2><p>　　错误包括两种情况：连接错误和流错误。<br>　　(1) <strong>连接错误处理</strong><br>　　当阻止了frame layer的进一步处理，或者连接的状态被破坏了的情况。<br>　　当任何一个端点遇见这种错误的时候，应当首先发送一个包含如下信息的GOAWAY帧：自己最后一次从对端成功接收的stream标识符，解释连接错误原因的错误码。发送完GOAWAY帧后端点必须关闭连接。发送GOAWAY帧的机制只是尽量保证报告出错的原因信息，并不能保证对端一定可靠接收到该帧。<br>　　端点可以在任何时候结束连接。端点也可以选择将流错误当作连接错误来处理。端点在结束连接的时候在允许的条件下都应当发送GOAWAY帧。<br>　　(2) <strong>流错误处理</strong><br>　　特定流的错误，不会影响到其他流的处理。<br>　　端点检测到流错误的时候，应当发送一个带有错误标识码的RST_STREAM帧，端点一定不能发送RST_STREAM帧来响应一个接收到的RST_STREAM帧，避免出现死循环的情况。</p>
<h1 id="五、Frame帧定义">五、Frame帧定义</h1><p>　　帧的类型由前缀的8位Type所定义。<br>　　(1) <strong>DATA</strong> Type=0x0<br>　　用来传输任意可变长度的字节流。通常可以用一个或者多个DATA帧来传输HTTP响应或者请求。<br>　　DATA帧中如果PADDED标识被设置，则有一个8bit的Pad Length，数据后面的Padding是可选的，主要可以用来隐藏数据包的长度信息。DATA帧只允许在非0流标识流上传输。<br>　　(2) <strong>HEADERS</strong> Type=0x1<br>　　可以用来打开一个stream，携带header block fragment，当单个HEADERS帧不能传输时，使用后续的CONTINUATION帧继续传递。HEADERS帧只允许在非0流标识流上传输。<br>　　(3) <strong>PRIORITY</strong> Type=0x2<br>　　PRIORITY帧主要的参数是Stream Dependency，用于设置当前流所以来的stream的其流标识符。这个帧可以在idle或closed状态的流上设置，以间接影响具有依赖关系的其他流的优先级。这个帧的长度固定是5，PRIORITY帧只允许在非0流标识流上传输。<br>　　(4) <strong>RST_STREAM</strong> Type=0x3<br>　　RST_STREAM帧只包含一个32bit的Error Code，用于解释流被终止的原因。RST_STREAM帧会立即终止一个流使其进入closed状态，接收者收到RST_STREAM帧后则不能发送除了PRIORITY之外的任何帧。RST_STREAM帧的长度固定是4，且不能在idle状态流上发送。<br>　　(5) <strong>SETTINGS</strong> Type=0x4<br>　　设置不是一种协商，而是发送者描述了自身的特性以被对端所使用，所以即使同一个参数，在客户端和服务端其参数值很可能不一样。<br>　　设置帧必须在连接开始的时候就发送，而且在通信过程中任何时候也支持发送，接收到设置帧后端点直接用帧中的新值覆盖自己的旧值，而不用保持维护先前状态。接收端会发送特殊的带有ACK长度为0的SETTINGS帧以确认。<br>　　设置帧从来都是针对连接而非单个stream的，所以其流标识符必须是0，其长度必须是6的整数倍，因为除了ACK通常的SETTINGS帧都是Identifier(2)+Value(4)。具体的参数类型参见手册。<br>　　接收者收到SETTINGS帧必须尽快更新相关参数，然后参数按照他们出现的顺序依次处理，并且保证在处理这些参数的时候不再处理其他的帧，对于不能识别的参数作忽略处理。更新完成后进行ACK确认，发送者收到ACK信息后，就可以依赖自己之前请求的参数信息了。<br>　　(6) <strong>PUSH_PROMISE</strong> Type=0x5<br>　　PUSH_PROMISE帧是预先通知对端需要初始化的流，其包含了Promised Stream ID标识符和额外的header block fragment参数信息，主要用来预先初始化压缩状态，以及保留stream标识符成为reserved状态。<br>　　某些角度看来PUSH_PROMISE帧和HEADERS帧有些像，包含END_HEADERS标志以及CONTINUATION帧的支持，其必须在一个已经open或者half-closed (remote)的流上面传输，而且如果对端设置了SETTINGS_ENABLE_PUSH，那么如果收到这种帧的ACK就是PROTOCOL_ERROR。接收者也可以返回RST_STREAM来拒绝这个PUSH_PROMISE请求。<br>　　(7) <strong>PING</strong> Type=0x6<br>　　通过PING帧是一种从发送端测量最小RTT的机制，同样也是一种检测连接是否可用的方法，可以被任意端发送。<br>　　发送PING帧的流标识符必须是0，并且应当被给予高优先级。其负载必须是一个8字节的自定义数据，而接收端ACK的时候设置ACK标志并原样返回该负载。<br>　　(8) <strong>GOAWAY</strong> Type=0x7<br>　　GOAWAY帧主要是用于主动关闭连接或者当连接遇到严重错误的情况下。其是一种优雅的方式进行关闭：不再接受新的流，并且处理完之前已经建立的流。<br>　　当一端发送GOAWAY帧的时候，另外一端创建新的流就是一个竞争条件，于是GOAWAY帧带有一个Last-Stream-ID参数，表示承认发送GOAWAY帧的对端最大的流标识符，此后这个连接将不再接受新的更大标志符的流(对端可以尝试新建连接来继续建立新流)。当关闭一个连接的时候，总应当发送GOAWAY帧让对端知道那些流已经或者将要被处理，发送GOAWAY帧的流标识符必须是0。<br>　　发GOAWAY帧后发送端能丢弃流标识符大于Last-Stream-ID的帧，但是任何修改连接状态的帧不能被全部忽略。HEADERS帧、PUSH_PROMISE帧和CONTINUATION帧必须被处理来保证维持header compression状态的一致。<br>　　(9) <strong>WINDOW_UPDATE</strong> Type=0x8<br>　　主要用于实现流来控制的，包括两个级别的流量控制：流级别和整个连接级别，根据发送流的流标识符是否为0来区分。<br>　　流量控制只针对下一跳(hop-to-hop)，而不是客户端-服务端整条链路的设置(end-to-end)，因为WINDOW_UPDATE帧不会被转发，HTTP/2中只有DATA帧受流量控制限制，而且帧开头的固定9字节不会被计入。WINDOW_UPDATE的负载是一个保留位和31位的无符号整型，其值的范围为1~(2^31-1)，其值是用于累加(in addition)在端点当期剩余的窗口值上面的，端点的窗口值表明允许其发送的字节数目。<br>　　初始的流和连接窗口大小都默认是65,535，通过SETTINGS帧的SETTINGS_INITIAL_WINDOW_SIZE参数可以设置新流的初始窗口大小，而针对连接的窗口大小只能通过WINDOW_UPDATE来设置而不能通过SETTINGS帧来改变。<br>　　(10) <strong>CONTINUATION</strong> Type=0x9<br>　　可以是紧跟着前一个HEADERS帧/PUSH_PROMISE帧或者不带END_HEADERS标志的CONTINUATION帧，其负载必定是一个header block fragment。</p>
<h1 id="六、HTTP/2消息交换">六、HTTP/2消息交换</h1><h2 id="6-1_HTTP请求与应答交换">6.1 HTTP请求与应答交换</h2><p>　　客户端在一个新的流上发起请求，服务端在同一个流上做出应答。请求和应答的HTTP消息可以由HEADERS帧、CONTINUATION帧和DATA帧组合，原先chunked传输编码被废弃。HTTP的请求/应答交换完全占用了一个流：请求由客户端通过HEADERS帧发起并使流进入到open状态；当请求以END_STREAM标志帧结尾后请求结束，流进入到客户端half-closed (local)/服务端half-closed (remote)状态；响应通过服务端的HEADERS帧开始并通过END_STREAM标志帧结束，流进入到close状态。</p>
<h2 id="6-2_HTTP头部">6.2 HTTP头部</h2><p>　　HTTP的头部都是一些键值信息，在HTTP/1.x中都是ASCII编码且不区分大小写的，而在HTTP/2中需要全部转换成小写字母后再编码。这些头部组合后如果一个HEADERS帧不能传输，后面使用CONTINUATION帧继续传递，知道最后一个标志END_HEADERS意味着头部传输完毕。<br>　　(1) <strong>伪头字段</strong><br>　　HTTP/1.x有一个固定的请求头，比如“GET /resource HTTP/1.1”，来携带请求方法、URI、协议版本以及相应码，而HTTP/2用’:’开头表示的伪头部(而非真真HTTP协议头部)来携带这些信息，并且所有的伪头部必须在正规HTTP协议标准头部之前出现完。<br>　　(2) <strong>连接相关的字段</strong><br>　　在HTTP/2协议中，不应当包含连接相关(Connection-Specific)的头部，trailers是个例外。<br>　　(3) <strong>请求相关的伪字段</strong><br>　　:method GET、POST等标准方法<br>　　:scheme 通常是http或https<br>　　:authority 比如www.googleapis.com，类似于HTTP/1.x的Host头信息<br>　　:path 请求目的的URI，包括路径名和参数<br>　　对于一个请求，必须为:method、:scheme、:path包含一个准确合法的值，这些伪头部必须首先且在第一帧中出现。请求可以带DATA帧(比如POST请求)或者不带DATA帧，完整的请求最后一帧通过END_STREAM标示结束。<br>　　(4) <strong>响应相关的伪字段</strong><br>　　:status 所有的响应中都必须包含该字段。响应通过一个HEADERS帧和可选的CONTINUATION帧开始，然后通过DATA帧传输响应body。<br>　　(5) <strong>压缩和Cookie字段</strong><br>　　Cookie字段可能会有多个，他们既可以作为键值对多次出现，也可以单个cookie键接多个值，值与值之间用”; “连接。<br><img src="/post_images/images/201612/ffb18df8ced7cc0e5eeba0a962a8c801.png" alt="http2-example"><br>　　这里只是定义了头部字段和结构，而头部压缩是HTTP/2的另外一大特性，其使用的HPACK header compression技术的具体的细节，可以参看RFC7541。HPACK维护着一个static头表，是在HTTP协议中经常用到的头部结构，同时在通信的服务端和客户端维护着一个dynamic头部表，在通信过程中增加的头部信息都会记录到这个表中，此后如果需要再次传输这个头，就只需要传输在动态头表中的索引就可以了。头表的键和值采用了高效的Huffman编码，默认头表4k的大小，可以通过SETTINGS帧来修改。</p>
<h2 id="6-3_Server_push">6.3 Server push</h2><p>　　Server Push是HTTP/2中的一个新特性，不过在抓Google首页的包中没有该帧，所以也只能看着手册瞎说了。这个行为一定是服务端对客户端的行为，客户端可以通过SETTINGS_ENABLE_PUSH来控制是否开启这个功能。服务端可以预测接下来客户端需要请求的资源，然后发送这些可以被缓存的资源，最显式的好处就是提高了页面加载的速度。<br>　　Promised请求必须满足——cacheable、safe、no request body，cacheable可以让服务端校验后由客户端缓存，同时服务端必须支持:authority以支持认证。<br>　　(1) <strong>Push请求</strong><br>　　在语义上Server Push等同于一个响应，只不过这个相应的请求也是由服务端通过PUSH_PROMISE帧发起的。<br>　　比如，一个服务器接收到一个来自客户端的页面请求，页面中嵌入了其他图片连接，那么服务器会在发送这个DATA帧之前，先发送PUSH_PROMISE帧，这样可以确保客户端在接受到相应解析之前PUSH_PROMISE帧已经被接受生效了。请求帧中包含完整的头部信息，最重要的包含:path信息，所以客户端可以知道服务端推送的是哪个资源。<br>　　只可以在服务器观来open或者half-closed (remote)状态的流上发送PUSH_PROMISE帧，效果是创建一个新的流并将流切换到服务端看来reserved (local)的状态。<br>　　(2) <strong>Push响应</strong><br>　　发送完PUSH_PROMISE帧后，服务端就可以在这些预留的流上面发送响应了。如果客户端想要取消(比如客户端本地已经缓存了这个资源了)或者等待超时了这个响应，可以发送RST_STREAM帧附带CANCEL/REFUSED_STREAM进行取消这个响应。<br>　　响应以HEADERS帧开始，流会立即进入服务端视角half-closed (remote)状态，后面会带有DATA帧传输响应数据，并经过带有END_STREAM标记的帧结束，然后流进入closed状态。</p>
<p>　　洋洋洒洒这么多，就暂且这样吧！太长了自己看着也恶心。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/HTTP/2" target="_blank" rel="external">Wikipedia</a></li>
<li><a href="https://tools.ietf.org/rfc/rfc7540.txt" target="_blank" rel="external">Hypertext Transfer Protocol Version 2 | HTTP/2</a></li>
<li><a href="https://www.nginx.com/blog/7-tips-for-faster-http2-performance/" target="_blank" rel="external">7 Tips for Faster HTTP/2 Performance</a></li>
<li><a href="https://http2.github.io/faq/" target="_blank" rel="external">HTTP/2 Frequently Asked Questions</a></li>
<li><a href="https://blog.cloudflare.com/tools-for-debugging-testing-and-using-http-2/" target="_blank" rel="external">Tools for debugging, testing and using HTTP/2</a></li>
<li><a href="https://github.com/fex-team/http2-spec/blob/master/HTTP2%E4%B8%AD%E8%8B%B1%E5%AF%B9%E7%85%A7%E7%89%88%2806-29%29.md" target="_blank" rel="external">HTTP2中英对照版 06-29</a></li>
<li><a href="https://developers.google.com/web/fundamentals/performance/http2/" target="_blank" rel="external">Introduction to HTTP/2</a></li>
<li><a href="http://undertow.io/blog/2015/04/27/An-in-depth-overview-of-HTTP2.html" target="_blank" rel="external">An in depth overview of HTTP/2</a></li>
<li><a href="https://lwn.net/Articles/558302/" target="_blank" rel="external">What’s new in HTTP 2</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　HTTP/2也算是个比较新的东西吧，虽然很多特性是基于之前的Google SPDY，但毕竟自2015年5月正式发布到现在也就一年半的时间。虽说绝大多数的主流浏览器在2015年底就基本都支持了HTTP/2协议(估计之前的SPDY“预演”功不可没)，但是对于生产环境的服务端来说可不会这么迅速就得到普及的，Apache 2.4.12通过mod_h2模块支持HTTP/2，nginx 1.9.5支持HTTP/2，所以一般服务器除非自己编译安装，要等到发行版入稳定仓库估计估计还得要个两年吧，毕竟最新的RHEL 7上的Apache还是2.4.6呢。<br>　　Google的主页已经全部部署了HTTP/2了(但是那个sffe服务器是个什么鬼？)，通过后面查看RFC发现HTTP/2具有很多优秀的特性，并且完全可以退化至HTTP/1.1，想想也是十分诱人啊。如果想在自己服务器部署Nginx支持HTTP/2的话，推举Ubuntu 16.04 LTS或许是一个不错的选择，最主要是因为<a href="https://www.nginx.com/blog/supporting-http2-google-chrome-users/">新版Google Chrome移除了NPN只支持ALPN</a>，而这依赖于openSSL 1.0.2，但是很多系统都没有更新到这个版本，而系统最重要的基础库又不能轻易升级，所以用Ubuntu 16.04 LTS是在稳定性和便捷性一个比较好的平衡点，不过如果你的服务器跑的其他非企业级发行版就另当别论了。<br>　　至于突然想到这个，是因为昨天看到gRPC/Protobuf，底层是用的HTTP/2的协议，而且一个朋友做OTT，也是使用的HTTP/2的协议传输的。虽说现实很凄惨，但是前途很光明，瞄一下RFC7540流水帐一把吧！错过了HTTP/1.x，不要再错过了HTTP/2了。<br><img src="/post_images/images/201612/1655d08c.png" alt="http2"><br>　　PS：网上流传的baidu/fex-team的中文版翻译，大家在参阅的时候需要特别注意，一方面那份文档是基于草案翻译的，和正式发布的版本还是有一些差异，二来一些翻译的质量还待商榷，只建议用来对照正式版协议辅助理解，而不可作为依赖。</p>
<h1 id="一、HTTP/1-x主要缺点和HTTP/2协议概述">一、HTTP/1.x主要缺点和HTTP/2协议概述</h1><h2 id="1-1_HTTP/1-x的主要缺陷">1.1 HTTP/1.x的主要缺陷</h2><p>　　HTTP/1.0的请求都是短连接，服务端应答之后会主动关闭掉该连接，HTTP/1.1为了减少这种频繁连接建拆支持KeepAlive长连接，但是请求和应答仍然是串行报头阻塞的，因此HTTP/1.x如果需要实现真正的并发则必须建立多个连接才可以。通常，增加HTTP/1.x的传输效率有：<br>　　(1) 通常浏览器和服务端允许建立6~8个长连接，但是这增加了服务器并发量的压力；<br>　　(2) 将资源分布到多个主机上面去，那么整体来说就可以建立更多的并发数，算是横向扩展的一种方式；<br>　　(3) 将多个图片组合成一个大的图片，然后通过CSS的方式将各个部分逻辑分割成小的图片，总体减少了请求的次数；<br>　　(4) HTTP/1.1 pipeline，允许多个请求在应答之前发送出去，不过服务端的返回必须是严格按照FIFO的顺序返回，也就是说只要其中一个请求响应时间长了也会导致后续的响应被阻塞。<br>　　HTTP/1.x是纯文本格式的协议，协议头附带很多冗余的信息，而且这种头部会被反复传输，最终会占用大量带宽，而且TCP的拥塞控制更加会恶化响应时间。</p>
<h2 id="1-2_HTTP/2概述">1.2 HTTP/2概述</h2><p>　　HTTP/2针对上面问题做出了改进，允许在单个TCP连接上面通过Stream的逻辑概念实现复用机制，在增加传输效率的同时减少了连接数(自然也降低了服务端和客户端压力)。HTTP/2通过流量控制和优先级机制，有助于只传播接受者需要使用的数据资源，并在有限的资源下建议某些资源优先被传输处理。<br>　　HTTP/2允许服务器主动推送响应给客户端，主要是基于服务端预测客户端将来会用到的资源。<br>　　传统HTTP/1.x的每个请求和应答都是Header+Body的形式传输的，HTTP/2对传输帧进行了重新设计，采用二进制进行封装和压缩，增加了传输效率和可扩展性。HTTP/2的报头(HEADERS)帧和数据(DATA)帧组成了基本的HTTP请求和响应，而设置(SETTINGS)帧、窗口更新(WINDOW_UPDATE)帧、推送承诺(PUSH_PROMISE)帧可以实现HTTP/2的其他功能。</p>
<h2 id="1-3_HTTP/2协议包的抓取">1.3 HTTP/2协议包的抓取</h2><p>　　因为HTTP/2所有流量都是加密的，虽然使用浏览器F12调试器可以查看上层的数据，尤其是一些协议相关的非数据帧是无法查看的，任何分析协议不抓包的行为都是耍流氓，但是如果直接用Wireshark得的抓包是无法查阅的。调试SSL/TLS加密数据的方法有两种：<br>　　(1). 如果针对是使用自己的网站，则可以使用你部署服务器的私钥来解密数据包；<br>　　(2). 如果是调试第三方的网站，则可以通过设置浏览器的SSLKEYLOGFILE环境变量以导出对称密钥，然后让Wireshark共享读取这个文件就可以解密浏览器回话过程中的包。<br>　　第三方的服务端和浏览器可能会有这样那样的问题，自己截取了一份Chrome访问Google的数据包，设置一下SSL中的(Pre)-Master-Secret就可以了，过滤条件使用http2，懒癌患者晚期可以直接<a href="/upload/http2_package.zip">下载</a>使用。<br><img src="/post_images/images/201612/42aa82451aaaf166f59f2fb57f1e9182.png" alt="http2-flow"></p>
<h1 id="二、HTTP/2连接的启动">二、HTTP/2连接的启动</h1><p>　　HTTP/2需要客户端感知服务端是否支持HTTP/2，而不能一开始就进行HTTP/2通信。因为HTTP通信包括http和https两种情况，虽然HTTP/2必定是加密的，但是源请求方式不同，探测HTTP/2的方式也不相同。<br>　　在http的模式下，客户端发起一个普通的HTTP/1.1请求，外加HTTP升级机制所需要的额外头部信息，即 Upgrade: h2c头。如果服务端不支持HTTP/2则忽略这个请求，按照HTTP/1.1的模式正常的返回通信，后续对话退化到HTTP/1.x协议上面；而支持HTTP/2的服务端可以返回一个101(转换协议)响应来接受升级请求，这是一个空相应，紧接着两者就可以发送HTTP/2的帧了(先前主要是SETTINGS设置帧)。<br>　　鉴于https在2017年将会大量代替http，且很多服务器都将http直接301重定向到https，所以https下的HTTP/2连接的建立比较普遍。在这种情况下需要先协商建立TLS连接，然后在TLS的应用层协议协商(ALPN)中得出支持h2协议。ALPN是TLS的一个扩展，允许客户端在TLS连接建立后协商接下来需要使用的协议类型，当客户端或者服务器端不支持ALPN时HTTP/1.1将会被使用，否则客户端会向服务器端发送自己支持的协议列表，服务器会决定接下来要选用的协议并发送响应，比如下图中选用h2代表使用HTTP/2协议。<br><img src="/post_images/images/201612/73cb3b0bac9aa53312ed78266c8bc82f.png" alt="http2-start"><br>　　当然还有比如客户端通过其他方式知道某些主机一定支持HTTP/2，或者叫做先验知识知道协议支持。<br>　　上面的任何情况下，每个端点(客户端和服务端)都需要发送一个固定的24个字节连接序言(Magic)作为HTTP/2协议的最终确认<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n</div></pre></td></tr></table></figure></p>
<p>　　紧接着序言后面是一个设置帧，详细内容可以看上面的h2截图。</p>
<h1 id="三、HTTP/2_Frame帧结构">三、HTTP/2 Frame帧结构</h1><p><img src="/post_images/images/201612/5efd484de1faf2aa803318f932000426.png" alt="http2-frame"><br>　　所有的帧都是由9个字节的固定前缀打头的。Length指定了Payload长度，默认不超过2^14 (16,384)，除非设置了SETTINGS_MAX_FRAME_SIZE为更大的参数；Type指定了是前面某种帧的一种，比如SETTINGS、DATA等；Flags是一些bit的标志位；Stream Identifier用作后面的stream标识，0被保留用于表示连接相关的整体而不是一个具体的流。<br>　　关于流的长度，前面说道默认是2^14+9，任何的协议实现都必须能至少处理这个长度，通过SETTINGS_MAX_FRAME_SIZE可以最大扩展长度为2^24-1。任何接受到的帧太小而无法处理，或者操果设置值，应当返回FRAME_SIZE_ERROR。<br>　　HTTP/2的Header包含一个或者多个键值对，然后使用报头压缩序列化到header block中，然后他们会被分割成1个或多个header block fragments，并在HEADERS/PUSH_PROMISE/CONTINUATION中作为Payload部分传输。Cookie部分会被额外单独处理。如果fragment只有一份，那么只会在一个HEADERS/PUSH_PROMISE帧中传输，而且Flag的END_HEADERS会被置位，否则后面连续的PUSH_PROMISE/CONTINUATION只会在最后一个fragment处置位END_HEADERS，而且这些fragment必须作为一个连续的帧序列传输，没有任何类型或任何其他流的交错帧在中间。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="协议" scheme="https://taozj.org/tags/%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Google gRPC框架学习笔记]]></title>
    <link href="https://taozj.org/201612/learn-note-of-google-grpc.html"/>
    <id>https://taozj.org/201612/learn-note-of-google-grpc.html</id>
    <published>2016-12-06T11:46:00.000Z</published>
    <updated>2016-12-18T07:48:21.000Z</updated>
    <content type="html"><![CDATA[<p>　　其实gRPC算是比较年轻的项目，虽据说已在Google内部被大规模部署使用，但从GitHub上看是2016年8月19日打的v1.0.0的tag，而官方博客发布声明在2016年8月23日。正式发布也就意味着通信协议的确定、接口API已经稳定，而性能、压力、稳定性各项测试已经满足需求，可以部署到生产环境中，广大基佬们可以安心使用了。<br>　　与gRPC/Protobuf相对应的，莫过于当前最熟悉的传统经典HTTP/JSON模式了，传统开发的惯用手法就是：客户端发起请求、服务端接收请求、服务端解析请求、服务端进行业务逻辑处理、服务端打包响应、服务端发送响应、客户端解析响应。虽然现在的序列化库和网络开发框架漫山遍野多如牛毛，但是服务端和客户端开发还是需要不断地封装、解析数据，处理网络传输的各项细节。<br>　　RPC从本质上来说，就是通过客户端和服务器的协作，将客户端的本地调用转化成请求发送到服务端，服务端进行实际操作后，再将结果返回给客户端，所以从客户端的角度看来就和一个本地调用的效果一样，虽然实际上跨进程、跨主机的调用会遇见各种复杂的情况，但是RPC框架负责屏蔽这些细节信息，用户只需要专注于业务逻辑开发即可。从Wikipedia的资料看来，RPC的概念很早就已经被提出来，而最近风光无限的几个开源RPC框架基本都出自大厂之手，其源于在互联网环境下，大量的分布式应用或服务可以使用RPC的方式轻松解耦，增加了复用性，提高了开发效率。<br>　　此外还想罗嗦一句：gRPC/Protobuf不仅可以用于常规网络服务开发，甚至可以作为本地进程间通信方式使用，因为RPC本来就属于一种IPC手段。<br><img src="/post_images/images/201612/ba2490413b2c260f24d4a8f22e7c2cf0.jpg" alt="grpc"><br>　　gRPC和Protobuf天生有着紧密的联系，在gRPC中Protobuf不仅作为一种序列化的工具使用，而且用于定义服务端与客户端之间的RPC调用接口(IDL的效果)，然后通过protoc工具可以快速生成客户端和服务端的代码。gRPC允许通过Protobuf的插件，独立指定客户端和服务端生成的语言类型，这对于时下移动互联网时代的开发意义重大。Protobuf是一种重要的序列化工具，其编码效率和速率非常的高，而且在工程化的过程中Google考虑到前向兼容等各项事宜，简单的手册可以参见之前的<a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a>。无论以后用哪家的RPC，都建议好好学习熟练掌握它，因为当前一些新开源的框架库基本都默认用它作为数据交互格式。</p>
<p>　　下面借着gRPC官方的手册，流水帐般地过一下gRPC的相关东西。</p>
<h1 id="一、RPC生命周期">一、RPC生命周期</h1><p>　　gRPC支持四种服务类型：Unary RPCs、Server streaming RPCs、Client streaming RPCs和Bidirectional streaming RPCs，通过参数和返回类型是否有stream关键字来标识区分。最简单的是Unary RPC调用，客户端发送一个请求参数，服务端做出一个应答数据；Server stream RPC调用是服务端可以返回多个数据，客户端一般在while中一直读取结束；Client stream是客户端可以向服务端传输多个请求，告知服务端传输结束后等待服务端返回；而Bidirectional stream则是一个全双工的通信，两端可以在任意时刻发送和接收数据，互相独立互不干扰。<br>　　gRPC允许client提供额外的超时参数，在超时之后如果服务端还没有返回响应的话，则会返回DEADLINE_EXCEEDED错误。服务端可以查询请求的超时参数，以及该调用所剩余的完成时间值。<a id="more"></a><br>　　RPC调用结果，是由服务端和客户端本地独立决定的，比如服务端认为自己成功发送了response，但是客户端可能在超时后仍然没有收到服务端响应，而认为此次调用失败，毕竟跨进程、跨主机的调用涉及到的可能问题会很多。<br>　　客户端和服务端可以在任何时候取消(cancel)RPC调用，取消的请求会立即生效，之后的工作不会再执行，同时之前的工作也不会undo进行回滚。客户端如果使用同步模式调用，一般是无法取消调用的，因为其执行流已经被block阻塞住了。<br>　　当创建Client Stub的时候，会要求和服务端的指定端口创建一个Channel通道，这个通道可以控制各项参数，以细致化地影响和控制gRPC的行为。<br>　　从上面描述，可见gRPC不保证原子性、最终一致性等特性，这个锅看来是甩给了用户处理了！<br><!--more--></p>
<h1 id="二、Authentication认证">二、Authentication认证</h1><p>　　gRPC/Protobuf原生支持SSL/TLS加密方式传输(Token模式暂不讨论)，可以加密服务端和客户端的所有通信数据。<br>　　gRPC的认证都围绕着Credentials这个对象，分为ChannelCredentials和CallCredentials两种类型，也可以将两者关联成一个CompositeChannelCredentials，然后用其产生一个新的ChannelCredentials后，那么之后在这个Channel上所有的调用都会默认使用前面设置的CallCredentials。<br>　　(1). <strong>无加密通信模式</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> channel = grpc::CreateChannel(<span class="string">"localhost:50051"</span>, InsecureChannelCredentials());</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Greeter::Stub&gt; stub(Greeter::NewStub(channel));</div></pre></td></tr></table></figure></p>
<p>　　(2). <strong>SSL/TSL通信</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Create a default SSL ChannelCredentials object.</span></div><div class="line"><span class="keyword">auto</span> creds = grpc::SslCredentials(grpc::SslCredentialsOptions());</div><div class="line"><span class="comment">// Create a channel using the credentials created in the previous step.</span></div><div class="line"><span class="keyword">auto</span> channel = grpc::CreateChannel(server_name, creds);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Greeter::Stub&gt; stub(Greeter::NewStub(channel));</div><div class="line">grpc::Status s = stub-&gt;sayHello(&amp;context, *request, response);</div></pre></td></tr></table></figure></p>
<h1 id="三、gRPC/Protobuf_C++语言使用实例">三、gRPC/Protobuf C++语言使用实例</h1><p>　　(1). <strong>创建IDL描述文件route_guide.proto</strong><br>　　gRPC是需要先定义服务接口约定，才可以进行RPC调用，使用.proto可以同时定义客户端和服务端交换的数据格式以及RPC调用的接口，然后使用protoc工具加上特定语言的插件生成特定语言版本的辅助代码。其实相比之前的<a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a>，这里只是新增了service定义和rpc定义的语法。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">syntax = <span class="string">"proto3"</span>;</div><div class="line">package routeguide;</div><div class="line"></div><div class="line">service RouteGuide &#123;</div><div class="line">  <span class="function">rpc <span class="title">GetFeature</span><span class="params">(Point)</span> <span class="title">returns</span> <span class="params">(Feature)</span> </span>&#123;&#125; </div><div class="line">  <span class="comment">// server-to-client streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">ListFeatures</span><span class="params">(Rectangle)</span> <span class="title">returns</span> <span class="params">(stream Feature)</span> </span>&#123;&#125;</div><div class="line">  <span class="comment">// client-to-server streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">RecordRoute</span><span class="params">(stream Point)</span> <span class="title">returns</span> <span class="params">(RouteSummary)</span> </span>&#123;&#125;</div><div class="line">  <span class="comment">// Bidirectional streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">RouteChat</span><span class="params">(stream RouteNote)</span> <span class="title">returns</span> <span class="params">(stream RouteNote)</span> </span>&#123;&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Latitudes +/- 90 degrees and longitude +/- 180 degrees (inclusive).</span></div><div class="line">message Point &#123;</div><div class="line">  int32 latitude = <span class="number">1</span>;</div><div class="line">  int32 longitude = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A latitude-longitude rectangle</span></div><div class="line">message Rectangle &#123;</div><div class="line">  Point lo = <span class="number">1</span>;</div><div class="line">  Point hi = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A feature names something at a given point.</span></div><div class="line"><span class="comment">// If a feature could not be named, the name is empty.</span></div><div class="line">message Feature &#123;</div><div class="line">  <span class="built_in">string</span> name = <span class="number">1</span>; <span class="comment">// The name of the feature.</span></div><div class="line">  Point location = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A RouteNote is a message sent while at a given point.</span></div><div class="line">message RouteNote &#123;</div><div class="line">  Point location = <span class="number">1</span>;</div><div class="line">  <span class="built_in">string</span> message = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A RouteSummary is received in response to a RecordRoute rpc.</span></div><div class="line">message RouteSummary &#123;</div><div class="line">  int32 point_count = <span class="number">1</span>; <span class="comment">// number of points received.</span></div><div class="line">  int32 feature_count = <span class="number">2</span>; <span class="comment">// number of known features passed while traversing</span></div><div class="line">  int32 distance = <span class="number">3</span>; <span class="comment">// distance covered in metres.</span></div><div class="line">  int32 elapsed_time = <span class="number">4</span>; <span class="comment">// duration of the traversal</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(2). <strong>使用protoc产生服务端和客户端代码</strong><br>　　通过protoc和C++ plugin，可以产生C++的服务端和客户端代码<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ protoc --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` ../protos/route_guide.proto</div><div class="line">$ protoc --cpp_out=. ../protos/route_guide.proto</div></pre></td></tr></table></figure></p>
<p>　　上面的操作会分别产生数据交换和服务接口的源文件：route_guide.pb.[cc|h]和route_guide.grpc.pb.[cc|h]，前者覆盖所有数据类型序访问和操作的接口，后者主要生成定义的RPC服务RouteGuide的相关代码。<br>　　grpc_out参数编译之后的源代码，主要产生了class RouteGuide，包含了和客户端Stub相关的内部类class StubInterface和class Stub GRPC_FINAL : public StubInterface，以及和服务端相关的class Service : public ::grpc::Service类。<br>　　(3). <strong>实现服务端业务接口</strong><br>　　通过上面步骤，操作数据和服务接口相关代码都已经自动生成了，接下来服务端的重点就是接口业务逻辑的实现了。手册样例的服务端代码实现在route_guide_server.cc源文件中，通过实现RouteGuide::Service中定义的虚函数接口，可以实现以同步阻塞方式的服务端实现(class RouteGuideImpl final : public RouteGuide::Service)，而异步方式则跟RouteGuide::AsyncService这个类相关。<br>　　此处服务端首先需要实现proto service中定义的四个调用接口，通过观察这些虚函数接口，发现他们都是返回::grpc::Status类型(返回值的详细信息可以参看<a href="http://www.grpc.io/docs/guides/error.html" target="_blank" rel="external">Error model</a>)，并且第一个参数都是::grpc::ServerContext*，而剩余部分的参数就跟当初proto文件中声明的参数一致了。在函数的具体实现代码中，设置和获取proto的数据项，就是Protobuf的标准数据操作方式了。通常操作成功后，返回Status::OK。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">GetFeature</span><span class="params">(ServerContext* context, <span class="keyword">const</span> Point* point,</span></span></div><div class="line">        Feature* feature) override &#123;</div><div class="line">  feature-&gt;set_name(GetFeatureName(*point, feature_list_));</div><div class="line">  feature-&gt;mutable_location()-&gt;CopyFrom(*point);</div><div class="line">  <span class="keyword">return</span> Status::OK;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面代码是最简单的Unary调用方式，客户端发出一个请求参数，然后服务端返回一个数据响应。对于RPC的服务端，在使用stream模式的调用参数或者返回结果，需要使用到特殊的ServerWriter、ServerReader类型，服务端可以在循环中多次写入/读取以传递多个对象，最后返回Status状态以表示调用结束。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (<span class="keyword">const</span> Feature&amp; f : feature_list_) &#123;</div><div class="line">  ... writer-&gt;Write(f);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span> (reader-&gt;Read(&amp;point)) &#123; ... &#125;</div></pre></td></tr></table></figure></p>
<p>　　对于请求和响应都是stream的类型，那么参数将直接变成为ServerReaderWriter<routenote, routenote="">* stream类型，此时的stream是一个两方向完全独立的全双工信道。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (stream-&gt;Read(&amp;note)) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> RouteNote&amp; n : received_notes) &#123;</div><div class="line">      <span class="keyword">if</span> ( ... )</div><div class="line">        stream-&gt;Write(n);</div><div class="line">    &#125;</div><div class="line">    received_notes.push_back(note);</div><div class="line">&#125;</div></pre></td></tr></table></figure></routenote,></p>
<p>　　当把RouteGuide::Service中的虚函数接口全部实现后，服务端的业务开发也就完成了。下面是通用的服务端网络例程，绑定地址端口，接收客户端请求，十分的清晰明白：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">RunServer</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; db_path)</span> </span>&#123;</div><div class="line">  <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">server_address</span><span class="params">(<span class="string">"0.0.0.0:50051"</span>)</span></span>;</div><div class="line">  <span class="function">RouteGuideImpl <span class="title">service</span><span class="params">(db_path)</span></span>;</div><div class="line"></div><div class="line">  ServerBuilder builder;</div><div class="line">  builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());</div><div class="line">  builder.RegisterService(&amp;service);</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Server&gt; server(builder.BuildAndStart());</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Server listening on "</span> &lt;&lt; server_address &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">  server-&gt;Wait(); <span class="comment">// until killed or server-&gt;Shutdown()</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> db = routeguide::GetDbFileContent(argc, argv);</div><div class="line">  RunServer(db);</div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(4). <strong>创建客户端</strong><br>　　客户端的业务代码定义在route_guide_client.cc源文件中。在RPC的调用体系中，业务相关的代码都已经实现在服务端，所以通常来说客户端会定义同服务端接口相同的函数名(非必需)，然后在这些函数实现中，完成对服务端的RPC调用，并获取调用返回的结果。<br>　　客户端在初始化的时候，需要首先创建grpc::Channel和RouteGuide::Stub两个对象。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Channel&gt; channel = grpc::CreateChannel(<span class="string">"localhost:50051"</span>,</div><div class="line">                          grpc::InsecureChannelCredentials();</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;RouteGuide::Stub&gt; stub_ = RouteGuide::NewStub(channel);</div></pre></td></tr></table></figure></p>
<p>　　上面是用的简单非加密方式创建的Channel。然后，客户端通过stub_对象就可以直接进行RPC调用了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Point point = MakePoint(<span class="number">409146138</span>, <span class="number">-746188906</span>);</div><div class="line">Feature feature;</div><div class="line">GetOneFeature(point, &amp;feature);</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">GetOneFeature</span><span class="params">(<span class="keyword">const</span> Point&amp; point, Feature* feature)</span> </span>&#123;</div><div class="line">  ClientContext context;</div><div class="line">  Status status = stub_-&gt;GetFeature(&amp;context, point, feature);</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　可见，每次调用都需要传入一个context对象的地址，上面是进行的默认构造，可以通过对这个context对象设置RPC调用相关的细节参数(比如超时等)。因为在不同的RPC调用之间不能共享这个对象，所以其一般都是以局部自动对象的方式创建的。<br>　　上面的Unary调用是最简单的情况。对于stream类型的调用，客户端同样有与服务端相似的ClientReader、ClientWriter以及ClientReaderWriter对象来完成相关操作。这些对象可以调用Finish()来获取服务端返回来的RPC调用状态，而WritesDone()可以显式通知对端写入完成，特别适合client-to-server streaming RPC类型的调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (reader-&gt;Read(&amp;feature)) &#123; ... &#125;</div><div class="line">Status status = reader-&gt;Finish();</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;ClientWriter&lt;Point&gt; &gt; writer(</div><div class="line">    stub_-&gt;RecordRoute(&amp;context, &amp;stats));</div><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; kPoints; i++) &#123;</div><div class="line">  <span class="keyword">if</span> (!writer-&gt;Write(f.location())) &#123;</div><div class="line">    <span class="keyword">break</span>;     <span class="comment">// Broken stream.</span></div><div class="line">  &#125;</div><div class="line">  <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(</div><div class="line">      delay_distribution(generator)));</div><div class="line">&#125;</div><div class="line">writer-&gt;WritesDone();</div><div class="line">Status status = writer-&gt;Finish();</div><div class="line"><span class="keyword">if</span> (status.IsOk()) &#123; ... &#125;</div></pre></td></tr></table></figure></p>
<p>　　对于C++语言，gRPC/Protobuf还原生支持通过CompletionQueue实现异步模式(Asynchronous)工作。但因为手册不是很详细，此处先不讨论。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="external">wiki Remote_procedure_call</a></li>
<li><a href="http://www.grpc.io/blog/gablogpost" target="_blank" rel="external">gRPC Project is now 1.0 and ready for production deployments</a></li>
<li><a href="https://github.com/grpc/grpc" target="_blank" rel="external">GitHub gRPC</a></li>
<li><a href="http://www.grpc.io/docs/guides/" target="_blank" rel="external">What is gRPC?</a></li>
<li><a href="http://purecpp.org/?p=933" target="_blank" rel="external">真正好用的RPC框架REST_RPC正式发布第一个版本</a></li>
<li><a href="http://blog.csdn.net/qicosmos/article/details/52386920" target="_blank" rel="external">什么样的RPC才是好用的RPC</a></li>
<li><a href="https://cloud.google.com/blog/big-data/2016/03/announcing-grpc-alpha-for-google-cloud-pubsub" target="_blank" rel="external">Announcing gRPC Alpha for Google Cloud Pub/Sub</a></li>
<li><a href="https://github.com/grpc/grpc/tree/v1.0.0/examples/cpp/route_guide" target="_blank" rel="external">gRPC example route_guide</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　其实gRPC算是比较年轻的项目，虽据说已在Google内部被大规模部署使用，但从GitHub上看是2016年8月19日打的v1.0.0的tag，而官方博客发布声明在2016年8月23日。正式发布也就意味着通信协议的确定、接口API已经稳定，而性能、压力、稳定性各项测试已经满足需求，可以部署到生产环境中，广大基佬们可以安心使用了。<br>　　与gRPC/Protobuf相对应的，莫过于当前最熟悉的传统经典HTTP/JSON模式了，传统开发的惯用手法就是：客户端发起请求、服务端接收请求、服务端解析请求、服务端进行业务逻辑处理、服务端打包响应、服务端发送响应、客户端解析响应。虽然现在的序列化库和网络开发框架漫山遍野多如牛毛，但是服务端和客户端开发还是需要不断地封装、解析数据，处理网络传输的各项细节。<br>　　RPC从本质上来说，就是通过客户端和服务器的协作，将客户端的本地调用转化成请求发送到服务端，服务端进行实际操作后，再将结果返回给客户端，所以从客户端的角度看来就和一个本地调用的效果一样，虽然实际上跨进程、跨主机的调用会遇见各种复杂的情况，但是RPC框架负责屏蔽这些细节信息，用户只需要专注于业务逻辑开发即可。从Wikipedia的资料看来，RPC的概念很早就已经被提出来，而最近风光无限的几个开源RPC框架基本都出自大厂之手，其源于在互联网环境下，大量的分布式应用或服务可以使用RPC的方式轻松解耦，增加了复用性，提高了开发效率。<br>　　此外还想罗嗦一句：gRPC/Protobuf不仅可以用于常规网络服务开发，甚至可以作为本地进程间通信方式使用，因为RPC本来就属于一种IPC手段。<br><img src="/post_images/images/201612/ba2490413b2c260f24d4a8f22e7c2cf0.jpg" alt="grpc"><br>　　gRPC和Protobuf天生有着紧密的联系，在gRPC中Protobuf不仅作为一种序列化的工具使用，而且用于定义服务端与客户端之间的RPC调用接口(IDL的效果)，然后通过protoc工具可以快速生成客户端和服务端的代码。gRPC允许通过Protobuf的插件，独立指定客户端和服务端生成的语言类型，这对于时下移动互联网时代的开发意义重大。Protobuf是一种重要的序列化工具，其编码效率和速率非常的高，而且在工程化的过程中Google考虑到前向兼容等各项事宜，简单的手册可以参见之前的<a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a>。无论以后用哪家的RPC，都建议好好学习熟练掌握它，因为当前一些新开源的框架库基本都默认用它作为数据交互格式。</p>
<p>　　下面借着gRPC官方的手册，流水帐般地过一下gRPC的相关东西。</p>
<h1 id="一、RPC生命周期">一、RPC生命周期</h1><p>　　gRPC支持四种服务类型：Unary RPCs、Server streaming RPCs、Client streaming RPCs和Bidirectional streaming RPCs，通过参数和返回类型是否有stream关键字来标识区分。最简单的是Unary RPC调用，客户端发送一个请求参数，服务端做出一个应答数据；Server stream RPC调用是服务端可以返回多个数据，客户端一般在while中一直读取结束；Client stream是客户端可以向服务端传输多个请求，告知服务端传输结束后等待服务端返回；而Bidirectional stream则是一个全双工的通信，两端可以在任意时刻发送和接收数据，互相独立互不干扰。<br>　　gRPC允许client提供额外的超时参数，在超时之后如果服务端还没有返回响应的话，则会返回DEADLINE_EXCEEDED错误。服务端可以查询请求的超时参数，以及该调用所剩余的完成时间值。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[网络开发中客户端连接保鲜机制的实现方法]]></title>
    <link href="https://taozj.org/201612/tcp-connection-keep-alive.html"/>
    <id>https://taozj.org/201612/tcp-connection-keep-alive.html</id>
    <published>2016-12-05T14:41:19.000Z</published>
    <updated>2016-12-18T08:00:37.000Z</updated>
    <content type="html"><![CDATA[<p>　　网络开发中的TCP连接分为长连接模式和短连接的模式，短连接就是在服务端接收到客户端请求，完成处理和应答后会主动关闭这个连接，而长连接顾名思义就是这个连接会一直存在着。一般来说，短链接的程序更容易编写和维护，因为一旦收到断开消息表明当前请求结束了，新的请求也会重新发起新的连接，而长连接需要处理拆包，粘包，错误累计飘移等各种复杂的问题。不过有得必有失，短链接最主要的问题是性能问题，每个请求都需要做三次握手和四次拆链操作，那么相同客户端和服务端交互的效率会因此大大的降低，尤其在网络连接慢的链路上会严重影响页面的加载速度。在后台局域网之中的主机高效通信，通常采用长连接的方式进行。<br>　　现在的网页做的是越来越复杂了，基本一个页面的渲染需要做到几十甚至上百次的请求才完成。HTTP协议中定义了Keep-Alive字段就是为此而定义的，现代的浏览器通常都会开6-8个长连接请求，而Apache和Nginx也可以打开配置选项支持这个特性。</p>
<h1 id="一、连接保活的原理和影响">一、连接保活的原理和影响</h1><h2 id="1-1_HTTP和TCP的KeepAlive">1.1 HTTP和TCP的KeepAlive</h2><p>　　除了HTTP协议中的Keep-Alive选项外，TCP中也有SO_KEEPALIVE这个选项。虽然名字类似，但是毕竟属于不同的网络层，所以他们之间是没有什么直接关系的。<br>　　HTTP协议中的Keep-Alive主要是在应用层实现对一个长连接的管理方式，其不需要周期性的检测这个连接是否可用，而是在每次服务端发送响应后重启一个time span的定时器，当定时器到点就表明这个time span没有数据交互，那么服务端就会主动关闭掉这个连接。TCP中的SO_KEEPALIVE是TCP协议支持的，其会在规定的时间内发送0负载的探测包给对端，正常情况下对端会返回ACK进行确定，以此探测TCP连接是否正常，在实际中这个选项可以用以：探测对端主机/服务是否活着；探测两者之间的网络连接是否正常。<br><img src="/post_images/images/201612/b77a07126d2c75f42a3920afe7c13cef.png" alt="keepalive"></p>
<h2 id="1-2_HTTP_KeepAlive对服务器的性能影响">1.2 HTTP KeepAlive对服务器的性能影响</h2><p>　　这段的内容在Nginx的手册中描述的十分清楚。因为HTTP KeepAlive的本质是一定时间内的长连接，所以这会大大降低服务端的并发量，而相比于Nginx基于事件驱动的服务端可以胜任大量的并发连接之外，Apache这种Prefork以及线程/线程池等传统型服务端模型会因为进程、线程的昂贵开销，并发量一般也就限制在几百的范围之内，一旦并发连接被KeepAlive占用后，服务器将不能再接受处理新的请求了。更加要命的是，不怀好心的人可以慢慢探测出KeepAlive的超时时间，从而更加高效地实现服务端的DDoS攻击。<br>　　KeepAlive对服务器的影响很难在测试环境中复现出来，而在线上环境运行后上面的矛盾才会显得比较的尖锐。因为测试环境一般是局域网环境，客户端和服务端都是高速本地网络连接，这时候短连接的建立、拆除连接对整个吞吐量的连接有限；而即使使用了KeepAlive的长连接，一般来说客户端的并发数目都会在服务端之下，而且快速的网络也会导致KeepAlive被大量的重用而不会超时。而且大多数测试工具都只报告成功的transactions，有些深入的特性很难挖掘出来。<br><a id="more"></a></p>
<h2 id="1-3_解决方案">1.3 解决方案</h2><p>　　Nginx给出的方案，除了详细考量KeepAlive开关、KeepAliveTimeout等参数调优之外，推荐使用Nginx作为前端HTTP Proxy。<br>　　因为Nginx是基于事件驱动的框架设计的，所以可以处理大量非活跃连接的情况，并发性能相对传统服务端有质的改变，而Nginx的后端可以和传统的服务端建立数目极少的长连接甚至短连接进行高效的通信。</p>
<h1 id="二、Nginx中连接保活的实现">二、Nginx中连接保活的实现</h1><p>　　从上面的背景知识可以看出，即便是事件驱动的网络模型，也需要处理KeepAliveTimeout的问题。实现这个功能不难，比如轮训遍历连接、创建N个超时定时器等，但是真正的挑战是对于巨大并发量情况来说，怎么样高效地更新、处理数据结构才是重点。<br>　　当前我所接触到的解决方案有：</p>
<h2 id="2-1_libco中的方案">2.1 libco中的方案</h2><p>　　之前在分析<a href="/201611/learn-note-of-tencent-libco-coroutine.html">《腾讯libco协程库学习笔记》</a>的时候，已经描述了他们对于超时侦测的解决方法：<br>　　创建stTimeout_t数据结构，然后分配40*1000的stTimeoutItemLink_t数组，每个元素的偏移量代表1ms，任何新加入的超时侦听事件都是按照和数组头超时时间的差值ms数添加到指定便宜位置数组元素中的双向链表中。每次epoll_wait获取活动事件之后，会顺便检测超时链表，将所有的已超时事件提取出来就可以了，因为使用的是双向链表的数据结构，所以即使在超时之前时间发生而删除单个的元素，以及在本应用中由于发送数据而删除并重新插入操作，都是极为快速的。<br>　　这种方式算是比较高效和优化的，而且一般KeepAliveTimeout也是有限的时间值，而通过设置数组元素的个数也可以进行时间精度和时间最大长度之间的平衡。</p>
<h2 id="2-2_陈硕的《Linux_多线程服务端编程》的方案">2.2 陈硕的《Linux 多线程服务端编程》的方案</h2><p>　　陈硕老师在其大作中所给出的解决方式是simple time wheeling，采用的数据结构是circle_buffer + hash_set + 智能指针(引用计数)的方式来管理的。具体来说：<br>　　a. 建立一个circle_buffer的数据结构，长度为指定的Timeout的秒数；同时建立一个1s间隔的定时器Timer，定时器回调函数的操作就是在circle_buffer的尾端添加一个空容器，这时候circle_buffer顶端容器的所有元素会被弹出析构；<br>　　b. 当建立连接的时候，创建连接的shared_ptr并丢入当前指定的circle_buffer容器中，同时在外部保存其一个weak_ptr待用；<br>　　c. 当这个连接有新数据的时候，取外部保存的weak_ptr提升为强引用share_ptr，添加到当前指定的circle_buffer容器中；<br>　　d. 根据智能指针的原理，如果整个circle_buffer都没有该连接的强引用的时候，表明是个不活跃的连接，而且已经被正确析构了；否则活跃的连接一直被添加到circle_buffer中，保证其不会被析构掉。</p>
<h2 id="2-3_Nginx的方案">2.3 Nginx的方案</h2><p>　　Nginx的解决方案也是十分简单的，和libco不同的是其使用了rbtree的数据结构，而且不像libco具有最大超时值的限制。<br>　　Nginx的超时timer是一个放在rbtree结构中的一个node，其中记录了当前连接超时的绝对时间。每当Nginx处理完HTTP Request之后，会调用操作ngx_http_set_keepalive()更新该连接的timer，且更新过程中做了一个优化，就是如果(存在)之前超时值和现在需要新设置超时值差异不超过NGX_TIMER_LAZY_DELAY(300ms)的话就直接返回，降低热连接反复修改的频次，否则就删除之前的超时timer，更新超时时间后重新插入到rbtree结构中。<br>　　在Nginx主事件循环每次调用ngx_process_events_and_timers()的时候，会先从rbtree中快速提取最接近的超时间隔ts，并将ts作为epoll_wait()的最后一个参数传递进去以保证最坏的情况下也会在这个时间返回。之后通过ngx_event_expire_timers()处理整个rbtree中的超时链接，而其ngx_http_keepalive_handler默认就是关闭掉这个连接。<br>　　感觉这种情况下，如果使用堆的数据结构也比较的合适，可以立即返回最近的超时队列，而且当初看见好像Libevent就是这样来管理超时操作的。Nginx没有使用堆结构而是使用红黑二叉树，是不是因为堆作为完全二叉树类型，调整起来代价比较大还是？</p>
<p>　　小结：上面的几种连接超时机制，没有一种实现方式是直接基于定时器实现的。一方面这类功能不需要高精度的定时需求，二来在异步框架下可以方便的嵌入轮训定时器队列的状态；队列中的连接可以是绝对超时时间或者相对时间，只要保持一种有序的状态即可。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://varvy.com/pagespeed/keep-alive.html" target="_blank" rel="external">How to enable keep alive</a></li>
<li><a href="http://www.nowamagic.net/academy/detail/23350305" target="_blank" rel="external">HTTP Keep-Alive是什么？如何工作？</a></li>
<li><a href="https://www.nginx.com/blog/http-keepalives-and-web-performance/" target="_blank" rel="external">HTTP Keepalive Connections and Web Performance</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　网络开发中的TCP连接分为长连接模式和短连接的模式，短连接就是在服务端接收到客户端请求，完成处理和应答后会主动关闭这个连接，而长连接顾名思义就是这个连接会一直存在着。一般来说，短链接的程序更容易编写和维护，因为一旦收到断开消息表明当前请求结束了，新的请求也会重新发起新的连接，而长连接需要处理拆包，粘包，错误累计飘移等各种复杂的问题。不过有得必有失，短链接最主要的问题是性能问题，每个请求都需要做三次握手和四次拆链操作，那么相同客户端和服务端交互的效率会因此大大的降低，尤其在网络连接慢的链路上会严重影响页面的加载速度。在后台局域网之中的主机高效通信，通常采用长连接的方式进行。<br>　　现在的网页做的是越来越复杂了，基本一个页面的渲染需要做到几十甚至上百次的请求才完成。HTTP协议中定义了Keep-Alive字段就是为此而定义的，现代的浏览器通常都会开6-8个长连接请求，而Apache和Nginx也可以打开配置选项支持这个特性。</p>
<h1 id="一、连接保活的原理和影响">一、连接保活的原理和影响</h1><h2 id="1-1_HTTP和TCP的KeepAlive">1.1 HTTP和TCP的KeepAlive</h2><p>　　除了HTTP协议中的Keep-Alive选项外，TCP中也有SO_KEEPALIVE这个选项。虽然名字类似，但是毕竟属于不同的网络层，所以他们之间是没有什么直接关系的。<br>　　HTTP协议中的Keep-Alive主要是在应用层实现对一个长连接的管理方式，其不需要周期性的检测这个连接是否可用，而是在每次服务端发送响应后重启一个time span的定时器，当定时器到点就表明这个time span没有数据交互，那么服务端就会主动关闭掉这个连接。TCP中的SO_KEEPALIVE是TCP协议支持的，其会在规定的时间内发送0负载的探测包给对端，正常情况下对端会返回ACK进行确定，以此探测TCP连接是否正常，在实际中这个选项可以用以：探测对端主机/服务是否活着；探测两者之间的网络连接是否正常。<br><img src="/post_images/images/201612/b77a07126d2c75f42a3920afe7c13cef.png" alt="keepalive"></p>
<h2 id="1-2_HTTP_KeepAlive对服务器的性能影响">1.2 HTTP KeepAlive对服务器的性能影响</h2><p>　　这段的内容在Nginx的手册中描述的十分清楚。因为HTTP KeepAlive的本质是一定时间内的长连接，所以这会大大降低服务端的并发量，而相比于Nginx基于事件驱动的服务端可以胜任大量的并发连接之外，Apache这种Prefork以及线程/线程池等传统型服务端模型会因为进程、线程的昂贵开销，并发量一般也就限制在几百的范围之内，一旦并发连接被KeepAlive占用后，服务器将不能再接受处理新的请求了。更加要命的是，不怀好心的人可以慢慢探测出KeepAlive的超时时间，从而更加高效地实现服务端的DDoS攻击。<br>　　KeepAlive对服务器的影响很难在测试环境中复现出来，而在线上环境运行后上面的矛盾才会显得比较的尖锐。因为测试环境一般是局域网环境，客户端和服务端都是高速本地网络连接，这时候短连接的建立、拆除连接对整个吞吐量的连接有限；而即使使用了KeepAlive的长连接，一般来说客户端的并发数目都会在服务端之下，而且快速的网络也会导致KeepAlive被大量的重用而不会超时。而且大多数测试工具都只报告成功的transactions，有些深入的特性很难挖掘出来。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[设计模式整理总结（一）：创建型模式]]></title>
    <link href="https://taozj.org/201611/design-patterns-(1)-creational.html"/>
    <id>https://taozj.org/201611/design-patterns-(1)-creational.html</id>
    <published>2016-11-29T11:52:28.000Z</published>
    <updated>2017-02-28T08:33:11.000Z</updated>
    <content type="html"><![CDATA[<p>　　大多抽象于特定语言的东西都比较难，设计模式便是其中之一。大家都说设计模式是前人工程实践中的经验，所以多读历史多看看前辈走过的路可以少挖点、少踩点坑，而且对设计意图熟练掌握后，对于快速阅读代码融入项目也是很有帮助的。<br>　　据说设计模式最好使用范例ACE的源代码，不过对于这个“学之者生，用之者死”(了解到的华为、腾讯例外)的著名网络库，目前还没有接触的打算。其实之前自己也总结了一份wiki，但是感觉这东西用自然语言的方式来描述反而难以讲清楚，所以这里打算用starUML工具把这些设计模式重新画一下，配上GOF的经典定义和网络上的一些典型例子，便于大家快速查阅和回忆。<br>　　UML工具觉得starUML听轻巧好用的，其v1分支版本原来是开源的，但是后来作者抱怨缺少sponsor，所以新的v2已经闭源商业版了。其实starUML可以无限期的evaluate，而且网上所谓的破解就是简单粘贴几行代码，可见作者还是很良心大度的，目的也在于防君子不防小人了，经济自由的还是适当赞助这些慷慨的码农吧！<br>　　在使用starUML的过程中，甚至不需要了解UML语言本身，图形化的操作就可以快速设计出模型。在使用starUML的时候，建议安装C++插件，可以帮助reverse分析已有代码的设计，可以将当前的设计自动生成C++代码。<br><img src="/post_images/images/201611/8e70ac935449dec9a7ff12d8d2f26fce.jpg" alt="UML"><br>　　UML中的难点，是依赖(Dependency)、继承(Generalization)、关联(Assosiciation)、聚合(Aggregation)、组合(Composition)这几种关系Relationships的理解和区分，其实粗分类来也就前三种，聚合和组合是关联关系特化一些条件的结果。<br>　　(1) <strong>Dependency</strong><br>　　体现的是一种<strong><em>using</em></strong>的类与类之间的关系，而且这种关系是单向的。这种依赖关系体现在对一个被依赖类的结构或者行为改变，会影响到依赖于它的类。<br>　　(2) <strong>Generalization</strong><br>　　体现的是一种<strong><em>is-a-kind-of</em></strong>或者<strong><em>is-a</em></strong>的关系，即常见的派生/继承关系。<br>　　(3) <strong>Assosiciation</strong><br>　　表述的是除了上面两种方式之外类与类的联系，可以是一对多、多对一、一对一、多对多的关系，而且这种关系体现没有拥有的联系。如果在设计中不能确定区分出下面的Aggregation、Composition，可以模糊地使用Assosiciation表示。<br>　　(4) <strong>Aggregation</strong><br>　　特例化的Assosiciation关系，体现的<strong><em>has-a</em></strong>的ownership关系，部分可以离开整体而单独存在。<br>　　(5) <strong>Composition</strong><br>　　特例化的Aggregation关系，部分不能离开整体而单独存在，所以是一种Strong/Dead的依赖关系。</p>
<p>　　设计模式共分为三类：创建型、结构型、设计型。一篇文章整理起来比较冗长，所以分成了三篇。<br>　　创建型模式主要包括：抽象工厂(Abstract Factory)、生成器/建造者(Builder)、工厂方法(Factory Method)、原型(Prototype)、单件(Singleton)五种类型。<br><a id="more"></a></p>
<h1 id="一、抽象工厂(AbstractFactory)模式">一、抽象工厂(AbstractFactory)模式</h1><p>　　定义：提供一个创建一系列相关或者相互依赖对象的接口，而无序指定他们具体的类。<br><img src="/post_images/images/201611/c3766ca04cc03da98d6b36d49f67a629.png" alt="AF"><br>　　抽象工厂可以算是工厂方法的更高级一层次的抽象。AbstractFactory类可以包括多个生成某种类型的工厂方法的接口，然后再由ConcreteFactory负责具体产品的创造实现。AbstractProduct为某一类的产品声明接口，然后ConcreteProduct实现这些接口后，就可以创建该类型的实际对象了。<br>　　举例：AbstractFactory定义了用户界面工具包创建的接口，然后ConcreteFactory可以指明具体Motif、PM风格包的创建方法；而AbstractProduct指明了风格包需要操作窗口的Window、Scrollbar控件，那么经过组合之后就可以得到四种不同类型的ConcreteProduct产品了。</p>
<h1 id="二、生成器/建造者(Builder)模式">二、生成器/建造者(Builder)模式</h1><p>　　定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。<br><img src="/post_images/images/201611/d17bb6d38ba02b63d447d1448bcc743c.png" alt="Builder"><br>　　其通过将一个产品的内部表象和产品生成过程分割开来，从而一个建造过程可以生成具有不同内部表示的产品对象，用户只需要指定需要建造的类型就可以得到他们，而具体的建造过程和细节不需知道了。<br>　　Builder为创建一个Product对象的各个部件指定抽象接口，ConcreteBuilder实现Builder定义的创建接口以构造和装配产品的各个部分，同时ConcreteBuilder需要提供一个检索产品的接口，Director构造一个使用Builder接口的对象。<br>　　构造过程可以表示为：Client首先创建目的ConcreteBuilder对象，然后用其作为参数创建Director对象，通过调用Director的Construct()方法，在这个函数中实际调用ConcreteBuilder的具体构建方法创建Product的各个部分，其GetResult()查询接口可以将构造的对象返回给Client。<br>　　构造者模式通常用于创建一些复杂的对象，这些对象的内部构建间的顺序通常是稳定的，但不同的对象内部的构造面临着复杂的变化。而且这里没有给Product做出一层的抽象，因为这种模式默认生成出的Product差异巨大，产生抽象基类没有太大意义。<br>　　举例：比如文档交互器将文档转换成各种格式，那么Client先根据需要创建需要的ConcreteBuilder(比如ASCIICov,TeXCov,TextCov)，然后用这个对象作为参数创建Director对象，调用Director对象的Construct()方法就可以返回创建结果了。<br>　　注意：咋看一下和模板方法十分的相像，只是Builder多了一个Director的角色。从分类看来Builder属于创建型模式，主要目的是创建和实例化对象，而模板方法属于行为模式，主要是对多个相似行为进行上层抽象，如果把Director去掉，那么生成模式可以退化成模板方法。</p>
<h1 id="三、工厂方法(Factory_Method)模式">三、工厂方法(Factory Method)模式</h1><h2 id="3-1_简单工厂">3.1 简单工厂</h2><p>　　定义：通过专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。通常也叫做参数化工厂方法。<br>　　简单工厂的特点是需要在工厂类中判断需要创建的类型，从而创造相应的产品，而当需要增加新的类型时，就需要修改简单工厂类本身。该模式的最大优点是工厂类中包含了必要的逻辑判断，根据客户端的选择参数动态实例化相关的类，对Client来说使用简单，免除了与具体产品的依赖。但是增加、减少、修改产品的操作都需要对简单工厂类代码进行变动，违反了开放-封闭原则。 </p>
<h2 id="3-2_工厂方法">3.2 工厂方法</h2><p>　　定义：定义一个用于创建对象的接口，让子类决定实例化哪一个类，使得一个类的实例化延迟到其子类。<br><img src="/post_images/images/201611/60fa169d90cdab8adc2e5120705f0dad.png" alt="FM"><br>　　像往常一样，Product和ConcreteProduct定义了具体产品的接口和其实现，Creator声明了工厂方法的接口FactoryMethod()，该方法返回一个Product类型的对象，ConcreteCreator实现Creator定义的FactoryMethod()，并返回一个ConcreteProduct实例。实际中Creator也可以提供一个默认的对象构造。<br>　　工厂方法模式实现的时候，客户端决定实例化哪个具体的ConcreteCreator类型，把简单工厂的内部逻辑判断转移到了客户代码中了，所以工厂方法是简单工厂模式的进一步抽象和推广。工厂方法每增加一个类型，就需要增加一个对应的工厂类，所以工厂方法中类的数目会比较多。</p>
<h1 id="四、原型(Prototype)模式">四、原型(Prototype)模式</h1><p>　　定义：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象，拷贝是原型模式的关键所在。<br><img src="/post_images/images/201611/154422a06ae2053fbc268e9e87a7c613.png" alt="Proto"><br>　　Prototype声明一个克隆自身的Clone()接口，ConcretePrototype()负责实现克隆自身的操作。其主要限制是每一个Prototype的子类都必须实现Clone()操作，才能实现对象的完整克隆。此外在克隆的时候，需要注意浅复制和深复制的区别。<br>　　Prototype模式原理实现比较简单，但是重点在于其使用场景和价值：原型模式从一个对象创建另外一个可定制的对象，而不需要知道任何创建的细节；原型模式通常会产生一个原型管理器，然后允许客户在运行时候动态的增加、删除、修改原型实例，更加的灵活；通过修改参数、修改结构等方式，可以扩充原型实例的数目，而不需要原先为产生这些类型而修改创建细节。</p>
<h1 id="五、单件(Singleton)模式">五、单件(Singleton)模式</h1><p>　　定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。<br><img src="/post_images/images/201611/aed945f4a76f0b85258be07632c7f83e.png" alt="Single"><br>　　Instance()操作允许客户访问它的唯一实例，在C++中通常是一个静态类方法和static局部变量。<br>　　关于单例的讨论问题，已经在另外一篇文章<a href="/201610/talk-about-singleton.html">说说设计模式中的单例</a>中讨论过了，此处不再细究。</p>
<p>本文的starUML文件上传到了<a href="/post_images/images/201611/DesignPatterns.mdj">这里</a>，欢迎使用！同时随着我的认识，本文件和本系列文档也会持续更正滴。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://dotnetfreakblog.wordpress.com/2014/01/11/concept-of-dependency-generalization-association-aggregation-composition-in-object-oriented-programming/" target="_blank" rel="external">Dependency, Generalization, Association, Aggregation, Composition in Object Oriented Programming</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　大多抽象于特定语言的东西都比较难，设计模式便是其中之一。大家都说设计模式是前人工程实践中的经验，所以多读历史多看看前辈走过的路可以少挖点、少踩点坑，而且对设计意图熟练掌握后，对于快速阅读代码融入项目也是很有帮助的。<br>　　据说设计模式最好使用范例ACE的源代码，不过对于这个“学之者生，用之者死”(了解到的华为、腾讯例外)的著名网络库，目前还没有接触的打算。其实之前自己也总结了一份wiki，但是感觉这东西用自然语言的方式来描述反而难以讲清楚，所以这里打算用starUML工具把这些设计模式重新画一下，配上GOF的经典定义和网络上的一些典型例子，便于大家快速查阅和回忆。<br>　　UML工具觉得starUML听轻巧好用的，其v1分支版本原来是开源的，但是后来作者抱怨缺少sponsor，所以新的v2已经闭源商业版了。其实starUML可以无限期的evaluate，而且网上所谓的破解就是简单粘贴几行代码，可见作者还是很良心大度的，目的也在于防君子不防小人了，经济自由的还是适当赞助这些慷慨的码农吧！<br>　　在使用starUML的过程中，甚至不需要了解UML语言本身，图形化的操作就可以快速设计出模型。在使用starUML的时候，建议安装C++插件，可以帮助reverse分析已有代码的设计，可以将当前的设计自动生成C++代码。<br><img src="/post_images/images/201611/8e70ac935449dec9a7ff12d8d2f26fce.jpg" alt="UML"><br>　　UML中的难点，是依赖(Dependency)、继承(Generalization)、关联(Assosiciation)、聚合(Aggregation)、组合(Composition)这几种关系Relationships的理解和区分，其实粗分类来也就前三种，聚合和组合是关联关系特化一些条件的结果。<br>　　(1) <strong>Dependency</strong><br>　　体现的是一种<strong><em>using</em></strong>的类与类之间的关系，而且这种关系是单向的。这种依赖关系体现在对一个被依赖类的结构或者行为改变，会影响到依赖于它的类。<br>　　(2) <strong>Generalization</strong><br>　　体现的是一种<strong><em>is-a-kind-of</em></strong>或者<strong><em>is-a</em></strong>的关系，即常见的派生/继承关系。<br>　　(3) <strong>Assosiciation</strong><br>　　表述的是除了上面两种方式之外类与类的联系，可以是一对多、多对一、一对一、多对多的关系，而且这种关系体现没有拥有的联系。如果在设计中不能确定区分出下面的Aggregation、Composition，可以模糊地使用Assosiciation表示。<br>　　(4) <strong>Aggregation</strong><br>　　特例化的Assosiciation关系，体现的<strong><em>has-a</em></strong>的ownership关系，部分可以离开整体而单独存在。<br>　　(5) <strong>Composition</strong><br>　　特例化的Aggregation关系，部分不能离开整体而单独存在，所以是一种Strong/Dead的依赖关系。</p>
<p>　　设计模式共分为三类：创建型、结构型、设计型。一篇文章整理起来比较冗长，所以分成了三篇。<br>　　创建型模式主要包括：抽象工厂(Abstract Factory)、生成器/建造者(Builder)、工厂方法(Factory Method)、原型(Prototype)、单件(Singleton)五种类型。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[forkp多进程程序管理库的轮子]]></title>
    <link href="https://taozj.org/201611/forkp-mulit-process-manage-framework.html"/>
    <id>https://taozj.org/201611/forkp-mulit-process-manage-framework.html</id>
    <published>2016-11-27T08:37:31.000Z</published>
    <updated>2017-01-04T02:19:21.000Z</updated>
    <content type="html"><![CDATA[<p>　　是前两天写的一个小工具，主要目的是实现Linux平台下master进程对worker子进程的监控和管理，并且必要情况下自动重启worker进程以实现保活的功能，这应该算是运维人员最喜欢的东西了吧。<br>　　本人在之前的文章<a href="/201611/about-multi-process-thread-dev-manage.html">《浅谈多进程程序的控制和管理》</a>中介绍了Nginx中master process和worker process的工作原理，其实这基本也可以作为多进程程序的开发范例来使用，虽然通常情况下的业务需求不用像Nginx做的那么复杂和完整，比如支持二进制程序不停服务平滑升级等，但是master进程对子进程进行监测并异常情况下自动重启服务的功能还是比较有用的。这种情况下，本人就萌生了写一个多进程程序开发的框架的想法，以后写多进程程序就不用重头做起了。<br>　　在Linux中进程管理的基本方式基本都是通过信号来实现的，因为子进程正常或者异常退出后，会由操作系统保证向其父进程发送SIGCHLD信号，所以父进程可以通过监听SIGCHLD的方式，高效异步的获取子进程退出的通知并对应做出相应地处理。如果只想让子进程保活，那么父进程只需要自定义处理SIGCHLD信号，并进行waitpid调用释放子进程的资源，然后重启子进程就可以了。不过既然想做一个通用点的库或者框架，那么还有一些细节的地方需要注意和完善，同时增加一些便利的功能还是很实际的。<br>　　forkp的子进程以两种方式工作：Process库和Exec管理服务，在同一个forkp实例中，同时对这两种方式提供了支持。<br>　　<strong>(1) Process库</strong><br>　　这种模式实际就是将Nginx的子进程管理模块抽象出来的效果，在新开发的多进程项目中，子进程的服务以可调用对象的方式注册启动。Nginx的配置文件可以设置worker process的进程数量，但这也假设了产生的所有worker process都是同构的，但是实际上多进程的子进程有可能会是异构的，因此在设计的时候，forkp会严格完全按照启动时候调用spawnWorkers的种类和次数来监测子进程。<br>　　master进程除了接收和处理SIGCHLD信号之外，还借助看门狗的模式来监测子进程，虽然实际上我不确定这有实际的意义，比如出现worker进程还没挂掉但是已经不能正常工作了的情况，因为通常程序错误或者跑飞了都会挂掉的。master进程和worker进程之间建立了匿名管道，master进程以1sec间隔向worker进程发送SIGWINCH信号，worker进程接收到该信号后通过匿名管道发回一个字节，如果master连续错过3个回应，就会发送kill杀死该子进程。这个功能是通过子进程屏蔽SIGWINCH信号来测试的。<br>　　需要额外说明的是，这里不要期待master进程做过多业务相关的内容。通常，master进程创建了侦听套接字后，所有的worker进程也继承了这个侦听套接字，而内核可以直接将侦听套接字的连接请求自动分发到worker进程中去，如果使用forkp开发类似Nginx这类程序，就可以很容易采用这种模式来满足需求。如果要期待master进程做过多的事情，由于master进程已经集成了一个epoll异步事件框架，那么程序可能要大改，还需三思。另外一点，就是master进程如果出错，所有的子进程都会退出，让master处理过多的任务，无异于增加了单点风险。<br>　　<strong>(2) Exec管理服务</strong><br>　　这种工作模式是对于已经存在的二进制程序，此时master进程fork出worker进程后，worker进程通过execv系统调用执行新的二进制程序，这个时候我把子进程调用exec后的实体叫做 <strong>子程序</strong>。由于exec系统调用重新执行一个二进制程序，所以此时master进程和worker进程除了通常的父子进程之外没有什么其他联系了，唯一的便捷就是可以同现有的所有程序方便的集成。此时像上面看门狗的形式就不能工作了，而是通过kill不发送任何具体信号的方式，来侦测指定pid的子进程是否存在。<br>　　事先说明最好还是把程序和服务写稳定一些，这只是作为一个补救措施，不可过度依赖这种机制。还有就是，比如我的ss5服务器偶尔会挂掉，此时通过forkp调用，就会在退出后自动重启服务了。<br>　　当然，工业上有现成的zabbix等更加成熟、可靠的开源方案……<br><a id="more"></a><br>　　在实现中，还有一些需要注意的地方，在此标记下来：<br>　　<strong>(1) 信号处理上下文</strong><br>　　本来说，master是一个单进程，没用什么竞争条件，但是当引入了信号处理程序之后情况就比较复杂了。信号是异步的，master任何时候都可能收到子进程和用户控制台发送的信号，所以这种情况下进程上下文和信号处理上下文对数据的访问需要互斥保护，尤其对容器的迭代访问和修改会导致冲突概率非常大，而信号处理上下文默认只对正在处理的信号是BLOCK的，如果多个信号修改同一个数据，信号处理程序之间还需要同步。所以在进程中访问互斥数据的时候，除了需要使用volatile关键字防止编译器优化外，还需要对应地BLOCK住相应信号集才可以。<br>　　如果直接用这种方式进行保护的，会发现维护工作很繁杂。其实看看Nginx的处理方式，再想想Linux信号处理下半部分，解决方式就很明朗了：在信号处理上下文中做最少的关键性工作，然后将其他任务记录并推迟，后面在进程的上下文中进行处理。所以在Nginx的信号处理中，绝大多数都是根据信号的种类设置对应的状态标识，然后master进程轮训根据状态做对应的操作，这样就可以保证处理完全串行化了。<br>　　<strong>(2) 重定向子进程的输出</strong><br>　　这个是因为当时的某个程序没有规划好日志，很多信息都是打印到标准输出和标准错误输出上的，这样默认情况下所有子进程的标准输出和错误输出都出现在了master进程的终端上，这在多个进程的情况下必然导致消息的混杂。所以这里的处理方法是，在父子进程之间创建一条匿名管道，在fork子进程之后，通过dup2将子进程的STDOUT_FILENO和STDERR_FILENO和这个管道相关联，master异步方式读取管道传输的内容后，写入进程相关的log文件中去。</p>
<p>　　正如前面提到的，Process模式和Exec模式两种情况，实际上也是该项目两个发展维度：<br>　　（1）前者讲求父进程和子进程之间进行一定的耦合，可以封装增强父子进程间的通信，比如创建socketpair进行全双工通信、共享内存、进程间文件锁进行数据共享等，这样master进程可以不断收集子进程的数据，甚至担任中介者的模式进行信息转发。不过进程之间的耦合也不应该过强，缺点前面说过了，而且还很容易将原本多线程的程序写成复杂的多进程程序。<br>　　（2）后者讲求程序的控制，希望可以在不停服务的情况，动态增加、删除、控制子程序。这种情况下只用信号的方式肯定是不能满足需求的了，后续需要添加配置文件支持，以启动时候预加载某些子程序，可能还需要写一个客户端才能向forkp服务传递更加复杂的信息。<br><img src="/post_images/images/201611/137563f4.png" alt="forkp"><br>　　PS:管理类某些二进制程序，发现定时器不能工作量。看了一下exec手册，原来exec族系列函数不会完全重新来，会继承calling process的一些属性，其中就包括signal_mask和signal_pending，这些东西还真是不用不知道啊。</p>
<p>　　Show you the code, just do it!</p>
<div class="github-widget" data-repo="taozhijiang/forkp"></div>]]></content>
    <summary type="html">
    <![CDATA[<p>　　是前两天写的一个小工具，主要目的是实现Linux平台下master进程对worker子进程的监控和管理，并且必要情况下自动重启worker进程以实现保活的功能，这应该算是运维人员最喜欢的东西了吧。<br>　　本人在之前的文章<a href="/201611/about-multi-process-thread-dev-manage.html">《浅谈多进程程序的控制和管理》</a>中介绍了Nginx中master process和worker process的工作原理，其实这基本也可以作为多进程程序的开发范例来使用，虽然通常情况下的业务需求不用像Nginx做的那么复杂和完整，比如支持二进制程序不停服务平滑升级等，但是master进程对子进程进行监测并异常情况下自动重启服务的功能还是比较有用的。这种情况下，本人就萌生了写一个多进程程序开发的框架的想法，以后写多进程程序就不用重头做起了。<br>　　在Linux中进程管理的基本方式基本都是通过信号来实现的，因为子进程正常或者异常退出后，会由操作系统保证向其父进程发送SIGCHLD信号，所以父进程可以通过监听SIGCHLD的方式，高效异步的获取子进程退出的通知并对应做出相应地处理。如果只想让子进程保活，那么父进程只需要自定义处理SIGCHLD信号，并进行waitpid调用释放子进程的资源，然后重启子进程就可以了。不过既然想做一个通用点的库或者框架，那么还有一些细节的地方需要注意和完善，同时增加一些便利的功能还是很实际的。<br>　　forkp的子进程以两种方式工作：Process库和Exec管理服务，在同一个forkp实例中，同时对这两种方式提供了支持。<br>　　<strong>(1) Process库</strong><br>　　这种模式实际就是将Nginx的子进程管理模块抽象出来的效果，在新开发的多进程项目中，子进程的服务以可调用对象的方式注册启动。Nginx的配置文件可以设置worker process的进程数量，但这也假设了产生的所有worker process都是同构的，但是实际上多进程的子进程有可能会是异构的，因此在设计的时候，forkp会严格完全按照启动时候调用spawnWorkers的种类和次数来监测子进程。<br>　　master进程除了接收和处理SIGCHLD信号之外，还借助看门狗的模式来监测子进程，虽然实际上我不确定这有实际的意义，比如出现worker进程还没挂掉但是已经不能正常工作了的情况，因为通常程序错误或者跑飞了都会挂掉的。master进程和worker进程之间建立了匿名管道，master进程以1sec间隔向worker进程发送SIGWINCH信号，worker进程接收到该信号后通过匿名管道发回一个字节，如果master连续错过3个回应，就会发送kill杀死该子进程。这个功能是通过子进程屏蔽SIGWINCH信号来测试的。<br>　　需要额外说明的是，这里不要期待master进程做过多业务相关的内容。通常，master进程创建了侦听套接字后，所有的worker进程也继承了这个侦听套接字，而内核可以直接将侦听套接字的连接请求自动分发到worker进程中去，如果使用forkp开发类似Nginx这类程序，就可以很容易采用这种模式来满足需求。如果要期待master进程做过多的事情，由于master进程已经集成了一个epoll异步事件框架，那么程序可能要大改，还需三思。另外一点，就是master进程如果出错，所有的子进程都会退出，让master处理过多的任务，无异于增加了单点风险。<br>　　<strong>(2) Exec管理服务</strong><br>　　这种工作模式是对于已经存在的二进制程序，此时master进程fork出worker进程后，worker进程通过execv系统调用执行新的二进制程序，这个时候我把子进程调用exec后的实体叫做 <strong>子程序</strong>。由于exec系统调用重新执行一个二进制程序，所以此时master进程和worker进程除了通常的父子进程之外没有什么其他联系了，唯一的便捷就是可以同现有的所有程序方便的集成。此时像上面看门狗的形式就不能工作了，而是通过kill不发送任何具体信号的方式，来侦测指定pid的子进程是否存在。<br>　　事先说明最好还是把程序和服务写稳定一些，这只是作为一个补救措施，不可过度依赖这种机制。还有就是，比如我的ss5服务器偶尔会挂掉，此时通过forkp调用，就会在退出后自动重启服务了。<br>　　当然，工业上有现成的zabbix等更加成熟、可靠的开源方案……<br>]]>
    
    </summary>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="造轮子" scheme="https://taozj.org/tags/%E9%80%A0%E8%BD%AE%E5%AD%90/"/>
    
      <category term="运维" scheme="https://taozj.org/categories/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（三）：从PhxPaxos中再看Paxos协议工程实现]]></title>
    <link href="https://taozj.org/201611/learn-note-of-distributed-system-(3)-see-paxos-from-phxpaxos.html"/>
    <id>https://taozj.org/201611/learn-note-of-distributed-system-(3)-see-paxos-from-phxpaxos.html</id>
    <published>2016-11-18T14:57:24.000Z</published>
    <updated>2016-12-18T08:06:11.000Z</updated>
    <content type="html"><![CDATA[<p>　　Phxpaxos已经开源了，且他们号称开源和内部使用的是同一套代码，那么作为小厂的程序员可有福了，可以一睹研究一下生产环境下大规模分布式系统是怎样练成的。初看代码可能会比较犯晕，果真生产环境的实现跟<a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">《Paxos made code》</a>的复杂度不是一个数量级的，可是复杂归复杂，但毕竟代码中没有用到复杂的Moden C++特性、大量的模板元编程和晦涩难懂的编码技巧，所以只要功夫下到位相信还是肯定能搞明白其内部流程的。<br>　　本文就是通过Phxpaxos中所附带的简单例子，摸索了解Phxpaxos中对Paxos算法的实现，算是验证一下前面对Paxos算法的学习吧。当然之前也说过，Phxpaxos同Lamport老爷爷的原版Multi-Paxos相比已经修改了很多，毕竟老爷爷的文章比较的偏理论化，所以理论上不修改的Multi-Paxos是不可能满足线上分布式系统的可用性和可靠性需求的，具体对于遇到的修改再行另表吧。</p>
<h1 id="一、预备操作">一、预备操作</h1><p>　　默认情况下Phxpaxos的存储模块使用的是glog，但不知道怎么回事，在我MacOS下VMware Fusion虚拟机Ubuntu-1604的环境下，严格按照<a href="https://github.com/tencent-wechat/phxpaxos/wiki/%E4%B8%AD%E6%96%87%E8%AF%A6%E7%BB%86%E7%BC%96%E8%AF%91%E6%89%8B%E5%86%8C" target="_blank" rel="external">《编译安装手册》</a>还是会报无法创建log文件的错误，不知道是不是因为目录使用NFS挂载的原因，因为在实体机上面本地存储没有发现这个问题，此处也不详究了。其实Phxpaxos的实现中，很多地方都有详细的且分好等级的日志信息，查看代码发现只要设置了pLogFunc函数指针，就可以在所有log记录之前执行这个hook函数，于是乎可以在sample中设置这个option，那么整个系统的运行路径和运行状态也就一览无余了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdarg.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">custLog</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> iLogLevel, <span class="keyword">const</span> <span class="keyword">char</span> * pcFormat, va_list args)</span> </span>&#123;</div><div class="line">    <span class="keyword">char</span> sBuf[<span class="number">1024</span>] = &#123;<span class="number">0</span>&#125;;</div><div class="line">    vsnprintf(sBuf, <span class="keyword">sizeof</span>(sBuf), pcFormat, args);</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; sBuf &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line">oOptions.pLogFunc = custLog;</div></pre></td></tr></table></figure></p>
<p>　　Phxpaxos的代码虽然是多，但是当除掉存储模块、网络模块、CheckPoint模块、Benchmark和单元测试等部分代码后，核心代码其实也是十分有限的，而且和Paxos算法相关的部分都单独放在algorithm目录中了，查看这个文件夹中的文件名，赫然醒目的acceptor、proposer、learner、instance，就让我们估计道知道他们是什么角色履行的职责了。</p>
<h1 id="二、附带phxelection选主例程解析">二、附带phxelection选主例程解析</h1><p>　　Phxpaxos附带的两个sample详细构建过程都在<a href="https://github.com/tencent-wechat/phxpaxos/blob/master/README.zh_CN.md" target="_blank" rel="external">《README》</a>中描述清楚了，本来是想phxelection和phxecho两个例子都一起跟踪的，但是后面看着看着发现，phxelection流程走完基本就定型了，phxecho和前者的差异主要就是传递了自定义的StateMachine，所以在Paxos算法Chosen Value之后，会额外的执行客户提供的状态机转移函数Execute()，这其实和phxelection在原理上没有本质的差异，因为后者算是对于选主的特殊情况，预先定义了MasterStateMachine状态机而已。不过phxecho的日志量要小一些，可以两个例程结合起来看。<a id="more"></a></p>
<h3 id="2-1_Phxpaxos中的Master_Node">2.1 Phxpaxos中的Master Node</h3><p>　　在Phxpaxos的设计中弱化了Multi-Paxos中提到的Leader角色，而是使用了Master的概念，在后面PhxSQL项目的文档中也强调了：Master是唯一具有外部写权限的Node，所以可以保证这个Node的数据肯定是最新的副本，Client的所有写请求和强一致性的读请求都需要直接或者由其他Node代理转发到这个Master Node上面，而对数据一致性要求不高的普通读请求，其读请求才可以在非Master Node上面执行。<br>　　由此可见，在稳定的情况下Master Node起到了单点协调者的作用。但是当系统新启动，或者在Master Node挂掉的时候，就需要有一个选主的操作。<a href="https://zhuanlan.zhihu.com/p/21540239" target="_blank" rel="external">《Paxos理论介绍(3): Master选举》</a>已经将选主的原理详细说明了。概而言之，就是在没有Master的时候，大家都可以认为自己是Master并发出TryBeMaster请求，这就等于大家实现一个Basic-Paxos的流程，根据Paxos的算法原理可以保证，最后只有唯一一个节点的提案被Chosen，这时候被Chosen提案的Proposer就被选为Master Node。在系统运行的过程中，各个节点会事先约定一个租赁周期，在这个周期到达之前Master Node可以提起续约的请求，其他节点当发现约定的检查周期到达之后并且Master租赁有效期间之前还能够请求到Master Node，就表示Master Node续约成功，此时就不再发起TryBeMaster的请求。这样在稳定的情况下Master Node可以一直稳定的运行下去，而当Master Node异常或者普通Node和Master Node通信失常情况下的处理方式，会在后文中作进一步的解释。</p>
<h3 id="2-2_phxelection选主的实现流程">2.2 phxelection选主的实现流程</h3><p>　　Phxpaxos中的两个项目默认是使用的三个节点来实验的，根据Paxos中Majority的需求，其节点数至少是三个，而且尽可能的是奇数数目。每一个运行的进程对外被抽象成Node节点，在内部使用带序列号的Instance作为执行单元，且每个Instance内部都含有完整的Acceptor、Proposer、Leader的角色，而且同一个Instance中的三个角色是存在于同一个进程中的，相互之间的结果是立即可见的。</p>
<h3 id="2-2-1_Node初始化操作">2.2.1 Node初始化操作</h3><p>　　Phxelection历程启动很简单，当代码创建PhxElection对象oElection后，直接调用其成员函数PhxElection::RunPaxos()启动。在这个成员函数中，可以设置相关参数oOptions(注意这个选项很大，而且后续会深入透传到整个Phxpaxos内部)，这个sample中，最主要的是要打开选主开关bIsUseMaster，然后调用Node::RunNode()，也只在这个函数中才进行PNode实体的创建和初始化工作，并将得到对象的地址保存返回给poNode指针，这样用户程序也可以操作Node(而非PNode)规定的其他可用接口来访问或操作底层对象了。<br>　　PNode对象的创建采用典型的两段式构造，当然下面很多对象都是两段式构造，主要工作在PNode::Init()中实现，这个初始化涉及的内容比较的多，几乎贯穿了整个系统的启动过程：<br>　　(1). InitLogStorage: 好像底层是基于啥LevelDB搞的吧，先不管它了；<br>　　(2). InitNetWork: 默认的网络配置是根据命令行参数解析到的节点网络信息IP:Port，对于UDP协议创建接收套接字和一个发送套接字，对于TCP则是通常的bind-listen服务端初始化。TCP类型的初始化工作，还包括使用epoll_create创建异步事件侦听，同时创建封装了pipe匿名管道的Notify对象用于对接收到的消息进行传递，并设置管道NONBLOCK且将管道的读端添加EPOLLIN事件侦听；设置成员变量poNetWork；<br>　　(3). MasterList: 由于我们只用到一个Group，所以只创建一个MasterDamon对象，可见默认的Master Lease是10s，可以通过SetLeaseTime自由自定义设置这个租赁周期但是必须大于1s；同时还要创建一个MasterStateMachine对象，首先尝试从之前保存的数据加载历史信息，如果读取失败进行默认初始化，同时设置version的值为(uint64_t)-1；<br>　　(4). Group: 和上面一样也只有一个，主要把上面已经初始化的信息保存到这个容器里面；这个里面，让我们最感兴趣的是创建了一个Instance类型的m_oInstance对象，大概看了一下Instance类的声明就让人感到十分兴奋，因为大部分的消息回调OnRecieveXXX都在这个类的声明里面，同时还包含了Acceptor、Proposer、Learner成员，表明我们离Paxos已经是很接近了；<br>　　(5). ProposeBatch: 批量提交，算是Phxpaxos相比Multi-Paxos的一个新操作，待到我后面研究到这个深度的时候再深入；<br>　　(6). InitStateMachine: 参数只有一个——Options，一个超大巨形体参数，但是在这个sample中我们并没有创建StateMachine，所以这里的AddStateMachine啥也没做，当然对于另外一个Phxecho需要使用用户定义的StateMachine，此处就会进行添加；然后当我们开启了选主的功能后，各个Node都会启动运行RunMaster()，这个操作会创建一个线程运行MasterDamon::run()，这个线程就是Master Node选取和维护的主要实现部分，此处跳过，后面会单独展开详述；<br>　　(7).  Group Init: 将启动时候添加的所有Node列表信息添加到SystemVSM中，同时添加GetSystemVSM()、GetMasterSM()两个StateMachine。其实看到这里，让人感觉到StateMachine实际等价于某个带状态的函数，当所谓的StateMachine发生转移的时候，实际就是其对应的函数被执行。然后执行Instance::Init()，由于Instance的初始化有较多操作，且是跟Paxos密切相关的，下面单独展开介绍。</p>
<h3 id="2-2-2_Instance初始化操作">2.2.2 Instance初始化操作</h3><p>　　在Instance初始化的过程中，主要是对Paxos中的几个角色的初始化，其角色大多都是继承自Thread类，所以意味着各自以线程的方式独立运行。我们主要关心的角色有：<br>　　(1). Learner<br>　　最终映射成LearnerSender::run()线程，做的事情就是：等待条件变量m_bIsComfirmed被设置，然后调用SendLearnedValue(m_llBeginInstanceID, m_iSendToNodeID);从llBeginInstanceID开始一直发送到当前的m_llInstanceID。对在每一个instance发送的过程中，都需要从log中查取这个instance的相关信息(比如提案节点、提案号、Chosen Value等)后打包发送，具体的信息请参看Learner::SendLearnValue()中的打包过程，然后可以选择之前在Node初始化中网络部分的TCP还是UDP方式发送，具体任务交由网络模块负责了。<br>　　Learner会等待记录ACK信息，当前被确认的ID保存在m_llAckInstanceID变量中，确认超时后错误返回，错误时候记录当前已经发送的llSendInstanceID变量不被更新。<br>　　(2). Acceptor<br>　　初始化较为的简单，因为我们没有历史记录，所以加载数据发现为空，就将m_llInstanceID设置为0就可以了；<br>　　(3). CheckpointMgr<br>　　这个暂时也不展开说了。作为一个状态机如果要重新加载状态，最直观的就是从最开始零状态一直进行历史记录回放，但是这种方式效率低，而且随着状态机的运行记录所有的历史信息也是不现实的，所以为了增加效能实现的CheckPoint功能就是将历史记录某个时间点的状态做完整快照，加载状态可以从那个CheckPoint开始重放到当前日志记录的状态(这个过程叫做CatchUp)，具体的信息可以查看<a href="https://github.com/tencent-wechat/phxpaxos/wiki/%E7%8A%B6%E6%80%81%E6%9C%BACheckpoint%E8%AF%A6%E8%A7%A3" target="_blank" rel="external">《状态机Checkpoint详解》</a>。<br>　　本sample都是从头开始的，这些东西基本都是0状态的。<br>　　(4). IOLoop<br>　　这也是开辟一个线程，主要是在一个消息队列m_oMessageQueue中不断的完成取出消息和处理消息(主要就是通过一个带互斥锁、条件变量封装的std::deque<t>，腾讯说好的无锁队列呢？)的工作，正常情况下会取出消息，然后发配到OnReceive(*psMessage)处理，而OnReceive的处理流程会对数据包拆包检查，然后根据消息类型分别发配给Learner、Acceptor、Proposer对应角色去处理，消息的类型定义在了comm\commdef.h的enum PaxosMsgType中，看上去Proposer和Acceptor比较明确，而Learner处理的消息比较多啊。<br>　　通过把这个OnReceive的处理大概逛了一下，基本就是标准的Paxos协议的内容了，比如Proposer接收到Acceptor的表决信息后，会先调用m_oMsgCounter.AddReceive()，然后检查m_oMsgCounter.IsPassedOnThisRound()看看是不是已经满足超过半数决议了，如果是就进行接下来的例程Accept()或者向Learner广播消息ProposerSendSuccess()，而如果投票失败(否决票过多或者超时)则等待几十毫秒后重新发起Prepare请求。<br>　　上面提及的只是消费消息，消息的生产者在哪里呢？之前说道PNode在初始化网络层的时候有过TCP和UDP两种通信方式，TCP通过使用event异步事件，而UDP在一个线程中不断的接收消息，这些渠道接收到的信息，最后都会放到这个队列中去的。<br>　　此外Instance还保留了一个m_oRetryQueue重试队列，用于处理Paxos相关消息，具体什么原理暂时不详。<br>　　上面的这些线程的循环，都在m_bIsEnd=true的时候会退出来，在IOLoop::Stop()会设置这个变量，检索后在Instance对象被析构的时候会调用之。</t></p>
<h3 id="2-2-3_MasterDamon主线程工作">2.2.3 MasterDamon主线程工作</h3><p>　　唉，代码中有好多错误的单词，不知道可不可以作为一个槽点……<br>　　根据上面说到的选主原理，这个线程的工作内容也十分简单，实质的工作内容就是TryBeMaster()：首先在Master Node稳定正常的情况下自身会自动续约，那么在m_llAbsExpireTime之前就会返回m_iMasterNodeID和版本号，否则返回nullnode；当Node发现返回nullnode的时候，无论是Master Node的原因还是自己和其通信的原因，都会发起一个包含llMasterVersion信息的Proposer请求，那么：<br>　　(1). 系统刚开始的时候，所有的Node都认为自己是Master Node，然后发起Propose()请求，经过Basic-Paxos的正常流程，会最终有一个Node被Chosen，由于大家都在同一个Instance中，被Chosen Value所对应同一进程中的Learner已经知道Chosen Value了，然后就会立即发送ProposerSendSuccess()广播给所有的Learner(也可以配置该节点自身需不需要进行学习)，所有Learner接收到该消息后都通过OnProposerSendSuccess()进行学习，并设置m_bIsLearned=true状态；Learner的后续执行流程检查到这个状态后，就会执行状态机MasterStateMachine状态转移Execute()即LearnMaster()，设置所有节点的m_iMasterNodeID为被Chosen Value的节点。系统启动Master Node新选取成功时候，m_llAbsExpireTime的值为0，而后面续约的时候更新为提起Propose时刻+Master租赁时长-100ms长度，自此选主成功。<br>　　(2). 所有节点都会在Lease Timer之前发起(但不一定会实质执行)TryBeMaster()，为了减少异常情况下通过Basic-Paxos新选取Master时候可能的“活锁”冲突，大家发起Prepare的时间点会有个微小的elf差异，当发现Master Node在超时时间之前仍然有效的时候，非Master节点都直接返回而不执行BeMaster()，Master节点会发起一个续约的正常Propose请求，最终状态机转移的时候更新时间等信息，然后所有节点学习重新调整即可；<br>　　(3). 当Master Node本身挂掉的时候，大家都会发起Propose请求，那么此时就退化成初始状态多个Node采用Basic-Paxos的方法选主的情况了；<br>　　(4). 当某个非Master Node因为通信或者其他的原因，错误的发起了BeMaster()的时候，wiki也说了这里是个“乐观锁”的解决思路：这个节点将自己观测到的最大version打包到Propose参数里面去，后续通过正常的Paxos流程会被Chosen，待到最后执行状态转移LearnMaster()的时候，会解包对参数进行校验，发现请求的version版本和当前最新版本不符，那么放弃这次状态机的实质切换操作而直接返回了。我们乐观的预估，此时改节点和系统的通信正常了，在真正的MasterNode下次续约的时候，改节点将会正确学习到Master Node的信息并正常工作。</p>
<h1 id="三、小结">三、小结</h1><p>　　排除代码中很多写错的英文单词，虽然涉及到的模块、对象众多，但是整个项目的设计和实现还是挺清晰的，配合详细的wiki和文档以及详细的日志信息，初学者花时间跟踪项目流程还不是很困难，同时也算是了解到了腾讯内部C++的开发风格，而在代码的关键点添加BreakPoint()回调接口还是挺有新意的。<br>　　还有，项目作者号称需要C++11标准的支持，但是发现除了for表达式、nullptr关键字外，C++的新特性基本可以说都没用到，不过也好，这样的代码更容易跟踪理解。项目中使用了大量的定时器和延时操作，就像当初通信核心网代码一样，这也是复杂系统所不能避免的。此外成员变量十分的多，但是基本都没有提供注释，这点读起来比较的费力。<br>　　本篇文章算是走了个流水，但是核心重要的CheckPoint、成员动态变更和他们创造的BatchPropose都被略过了，有时间再研究吧。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">Paxos made code</a></li>
<li><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf" target="_blank" rel="external">Paxos Made Live - An Engineering Perspective</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos" target="_blank" rel="external">Phxpaxos</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/blob/master/README.zh_CN.md" target="_blank" rel="external">Phxpaxos README</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　Phxpaxos已经开源了，且他们号称开源和内部使用的是同一套代码，那么作为小厂的程序员可有福了，可以一睹研究一下生产环境下大规模分布式系统是怎样练成的。初看代码可能会比较犯晕，果真生产环境的实现跟<a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf">《Paxos made code》</a>的复杂度不是一个数量级的，可是复杂归复杂，但毕竟代码中没有用到复杂的Moden C++特性、大量的模板元编程和晦涩难懂的编码技巧，所以只要功夫下到位相信还是肯定能搞明白其内部流程的。<br>　　本文就是通过Phxpaxos中所附带的简单例子，摸索了解Phxpaxos中对Paxos算法的实现，算是验证一下前面对Paxos算法的学习吧。当然之前也说过，Phxpaxos同Lamport老爷爷的原版Multi-Paxos相比已经修改了很多，毕竟老爷爷的文章比较的偏理论化，所以理论上不修改的Multi-Paxos是不可能满足线上分布式系统的可用性和可靠性需求的，具体对于遇到的修改再行另表吧。</p>
<h1 id="一、预备操作">一、预备操作</h1><p>　　默认情况下Phxpaxos的存储模块使用的是glog，但不知道怎么回事，在我MacOS下VMware Fusion虚拟机Ubuntu-1604的环境下，严格按照<a href="https://github.com/tencent-wechat/phxpaxos/wiki/%E4%B8%AD%E6%96%87%E8%AF%A6%E7%BB%86%E7%BC%96%E8%AF%91%E6%89%8B%E5%86%8C">《编译安装手册》</a>还是会报无法创建log文件的错误，不知道是不是因为目录使用NFS挂载的原因，因为在实体机上面本地存储没有发现这个问题，此处也不详究了。其实Phxpaxos的实现中，很多地方都有详细的且分好等级的日志信息，查看代码发现只要设置了pLogFunc函数指针，就可以在所有log记录之前执行这个hook函数，于是乎可以在sample中设置这个option，那么整个系统的运行路径和运行状态也就一览无余了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdarg.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">custLog</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> iLogLevel, <span class="keyword">const</span> <span class="keyword">char</span> * pcFormat, va_list args)</span> </span>&#123;</div><div class="line">    <span class="keyword">char</span> sBuf[<span class="number">1024</span>] = &#123;<span class="number">0</span>&#125;;</div><div class="line">    vsnprintf(sBuf, <span class="keyword">sizeof</span>(sBuf), pcFormat, args);</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; sBuf &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line">oOptions.pLogFunc = custLog;</div></pre></td></tr></table></figure></p>
<p>　　Phxpaxos的代码虽然是多，但是当除掉存储模块、网络模块、CheckPoint模块、Benchmark和单元测试等部分代码后，核心代码其实也是十分有限的，而且和Paxos算法相关的部分都单独放在algorithm目录中了，查看这个文件夹中的文件名，赫然醒目的acceptor、proposer、learner、instance，就让我们估计道知道他们是什么角色履行的职责了。</p>
<h1 id="二、附带phxelection选主例程解析">二、附带phxelection选主例程解析</h1><p>　　Phxpaxos附带的两个sample详细构建过程都在<a href="https://github.com/tencent-wechat/phxpaxos/blob/master/README.zh_CN.md">《README》</a>中描述清楚了，本来是想phxelection和phxecho两个例子都一起跟踪的，但是后面看着看着发现，phxelection流程走完基本就定型了，phxecho和前者的差异主要就是传递了自定义的StateMachine，所以在Paxos算法Chosen Value之后，会额外的执行客户提供的状态机转移函数Execute()，这其实和phxelection在原理上没有本质的差异，因为后者算是对于选主的特殊情况，预先定义了MasterStateMachine状态机而已。不过phxecho的日志量要小一些，可以两个例程结合起来看。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[腾讯libco协程库学习使用笔记]]></title>
    <link href="https://taozj.org/201611/learn-note-of-tencent-libco-coroutine.html"/>
    <id>https://taozj.org/201611/learn-note-of-tencent-libco-coroutine.html</id>
    <published>2016-11-18T14:56:58.000Z</published>
    <updated>2016-12-18T08:06:55.000Z</updated>
    <content type="html"><![CDATA[<p>　　在跟踪libco库时候发现一位网友提的issue，实在是看不下去了，哔了狗了。人家说程序员最喜欢的事是别人的项目有详细的wiki或文档，最讨厌的事情就是自己写文档，看来果真如此啊。不过libco自带了好几个例子，算是把libco的功能都展示了出来，过一遍也就知道怎么使用了。<br><img src="/post_images/images/201611/8064b68a1b41936d255f92f5a91eb647.png" alt="libco"><br>　　libco算是一个比较轻巧的协程库吧，看着代码不多，都是用朴实的C语言写的，而且完全不依赖于外部的ucontext或Boost.Context库，就想着读下代码彻底了解一下这个腾讯内部大规模用的协程库是怎么炼成的。从背景资料看来，一般对于新立项开发的系统，很多公司可能选择异步的方式来搞定，但是对于历史遗留的大规模同步模型的业务，异步化改造将会极具挑战性的事情，因为异步的方式需要代码分割重布，算是大换血的手术了；而如果采用协程和hook阻塞调用的方式，可以对传统同步类型业务基本无侵入的情况下享受异步带来的好处，这种手段确实很诱人。<br>　　额外想说的是，人家说隔行如隔山，其实当前在分工这么明确的环境下，隔业也同隔山啊，据说协程在游戏引擎行业早就大规模的被应用了以至于游戏开发者都不屑于提及这些，反而在互联网的后台压力越来越大的情况下，传统搞后台的兴起这个概念出来了。还有一点好奇的是，代码里面居然用了<strong>APPLE</strong>关键字和对kqueue异步的支持，腾讯不是一直是SuSE的粉丝么，难道后台也用到了很多BSD的服务器？</p>
<h1 id="一、协程的创建和调度">一、协程的创建和调度</h1><p>　　libco支持的协程原语包括：co_create、co_resume、co_yield、co_yield_ct、co_release。</p>
<h1 id="1-1_协程的创建管理">1.1 协程的创建管理</h1><p>　　(1). co_create()：创建一个协程。因为协程寄生于线程中的，所以每个线程需要有自己线程级别的资源来维护管理自己的协程。这里程序没有使用到线程局部存储TLS的方式，而是采用全局的stCoRoutineEnv_t类型的指针数组，然后采用线程tid进行索引的方式获取线程独立的存储结构。虽然定义上pid_t一般是int类型，但是系统一般不会用到这么大的范围，如果没有额外配置系统，默认最大的线程ID值定义在/proc/sys/kernel/pid_max为32768，所以这里使用上没什么问题，且空间浪费也不是很大。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> stCoRoutineEnv_t &#123;</div><div class="line">	stCoRoutine_t *pCallStack[ <span class="number">128</span> ];</div><div class="line">	<span class="keyword">int</span> iCallStackSize;</div><div class="line">	stCoEpoll_t *pEpoll;</div><div class="line">	stCoRoutine_t* pending_co; stCoRoutine_t* ocupy_co;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　在创建上述线程相关资源的时候，还会自动创建一个没有执行体的主协程，同时线程中还会创建一个stCoEpoll_t结构用于异步事件相关的操作，默认侦听fd数目最多为1024x10，同时在pTimeout-&gt;pItem上还创建了60x1000个stTimeoutItemLink_t结构(但是事件最大支持20s的超时，注释说40s，这里实际是60s!!!)，且后续在事件循环中，根据fd的事件状态会挂载到pstActiveList和pstTimeoutList链表上面去。<a id="more"></a><br>　　真正创建协程的函数是co_create_env()，每个协程有自己密切相关的结构stCoRoutine_t。对于协程可以分配的栈空间是128k~8M的范围，并且以4k对齐，传统的stackfull协程基本都是采用独立栈的方式实现的。<br>　　libco除了协程独立栈支持外，最大的创新是支持共享栈。原理就是通常stackfull实现所使用的fixed_stack分配的内存都用不了多少，内存浪费巨大导致系统整体创建的协程数目有限；而segment_stack的效率性能低下；所以共享栈采用的方式就是每次发生协程切换的时候，把实际用到的栈内容stack_bp-stack_sp通过save_stack_buffer来保存到malloc的内存中去，然后调用coctx_swap进行寄存器信息的切换，再把切换进来的新协程之前以相同方式保存的栈数据再拷贝到上面的共享栈空间的对应的内存位置上去(栈指针在coctx_swap已经更新完了，这里只是填补数据的作用，而且每个协程切换前后一直使用相同的共享栈，即使有局部指针也没有问题)，从而大大增加了内存的利用效率。<br>　　(2). co_release、co_free<br>　　只是释放了stCoRoutine_t的资源，虽然对于共享栈没有问题，但是对于独立栈貌似连栈空间内存资源都没释放啊？<br>　　(3). co_resume、co_yield、co_yield_ct<br>　　这几个函数都是跟协程切换相关的，他们底层都会调用co_swap进行在独立栈/共享栈环境下的切换，只是在操作前会进行协程管理相关资源的更新。<br>　　co_resume可以恢复协程的执行，同时创建的协程第一次启动也是使用这个接口，并且在第一次启动的时候会初始化特殊的coctx_t结构(具体啥东西就不细究了)。在协程执行结束后，会自动设置cEnd=1，同时将自己yield出去，虽然是CPP的代码但是没有用到RAII，所以相关的资源需要调用者手动释放。</p>
<h2 id="1-2_协程的切换">1.2 协程的切换</h2><p>　　libco的协程调度比较的有意思，env-&gt;pCallStack[ env-&gt;iCallStackSize-1 ]永远指向了当前执行的协程，所以co_self()最终返回的就是相同的内容。<br>　　当co_resume调用时候实际是将新协程添加到这个pCallStack并iCallStackSize++，co_yield实际将当前协程和上一个协程pCallStack[ env-&gt;iCallStackSize-2 ]进行切换并iCallStackSize–。所以从这个原理上看来，pCallStack永远包含了可以被运行的协程，并通过co_resume、co_yield将协程从这个可运行Stack中进行添加和删除操作，当然大多处时候都是使用手动或者异步事件驱动来实现。在最开始环境初始化的时候创建了一个主协程，这个主协程coctx_t是默认初始化的且没有执行体(?)，驻守在了pCallStack结构的顶部。<br>　　当创建协程时候传入的函数执行完毕后，会在CoRoutineFunc可见其设置co-&gt;cEnd=1;并自动将自己yield出去。<br>　　基于异步事件的程序开发，通常是由主线程不断的调用epoll_wait收取就绪和超时事件，然后对这些Item依次执行OnPollProcessEvent()函数，这个函数通常就是co_resume()让那个等待的协程继续执行下去，所以协程的调度完全算是由事件驱动完成并串行执行的。</p>
<h1 id="二、协程应用开发接口">二、协程应用开发接口</h1><p>　　当上面创建协程、释放协程、切换协程的原语有了，就可以进行一些高级接口和特性的封装，方便协程库用户的使用，并尽可能对现有的业务代码做最小化侵入了。这些封装和接口其实也是其他协程库在设计中可以考虑实现的。</p>
<h2 id="2-1_阻塞调用Hook">2.1 阻塞调用Hook</h2><p>　　涉及到的接口有：co_enable_hook_sys、co_disable_hook_sys、co_is_enable_sys_hook。<br>　　在libco里面，大多数的默认阻塞例程基本都打开了sys_hook的支持了。这个Hook的原理，就是通过glibc中dlfcn.h的dlsym和RTLD_NEXT结合起来，从而给标准库函数添加钩子或者产生一个wrapper的效果。比如下面的这个常见的默认阻塞的read()函数，在没有打开sys_hook或套接字是阻塞类型的情况下，通过RTLD_NEXT将直接调用后面链接库的原始标准read()版本，否则会插入一个poll的操作，当然这个poll本身也是打了Hook的，详细的内容后面会有介绍。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">read_pfn_t</span> g_sys_read_func = (<span class="keyword">read_pfn_t</span>)dlsym(RTLD_NEXT,<span class="string">"read"</span>);</div><div class="line"></div><div class="line"><span class="keyword">ssize_t</span> read( <span class="keyword">int</span> fd, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte ) &#123;</div><div class="line">	HOOK_SYS_FUNC( read );</div><div class="line">	</div><div class="line">	<span class="keyword">if</span>( !co_is_enable_sys_hook() )</div><div class="line">		<span class="keyword">return</span> g_sys_read_func( fd,buf,nbyte );</div><div class="line">		</div><div class="line">	<span class="keyword">rpchook_t</span> *lp = get_by_fd( fd );</div><div class="line"></div><div class="line">	<span class="keyword">if</span>( !lp || ( O_NONBLOCK &amp; lp-&gt;user_flag ) ) &#123;</div><div class="line">		<span class="keyword">ssize_t</span> ret = g_sys_read_func( fd, buf, nbyte );</div><div class="line">		<span class="keyword">return</span> ret;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">int</span> timeout = ( lp-&gt;read_timeout.tv_sec * <span class="number">1000</span> ) </div><div class="line">				+ ( lp-&gt;read_timeout.tv_usec / <span class="number">1000</span> );</div><div class="line"></div><div class="line">	<span class="keyword">struct</span> pollfd pf = &#123; <span class="number">0</span> &#125;;</div><div class="line">	pf.fd = fd; </div><div class="line">	pf.events = ( POLLIN | POLLERR | POLLHUP );</div><div class="line">	<span class="keyword">int</span> pollret = poll(&amp;pf, <span class="number">1</span>, timeout );</div><div class="line"></div><div class="line">	<span class="keyword">ssize_t</span> readret = g_sys_read_func( fd, (<span class="keyword">char</span>*)buf, nbyte );</div><div class="line">	<span class="keyword">if</span>( readret &lt; <span class="number">0</span> )</div><div class="line">		co_log_err(<span class="string">"CO_ERR: read fd %d ret %ld errno %d poll ret %d timeout %d"</span>,</div><div class="line">					fd, readret, errno, pollret, timeout);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> readret;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　基本大多数的C库和系统调用函数都被打上了hook，当然原文档里面特别提到了gethostbyname()，有兴趣的可以单独深入了解一下。</p>
<h2 id="2-2_异步Event">2.2 异步Event</h2><p>　　涉及到的接口有：co_poll、co_eventloop、co_get_epoll_ct。<br>　　co_get_epoll_ct() 就是用于查找返回当初在线程级初始化中，创建stCoRoutineEnv_t的时候所创建的stCoEpoll_t类型pEpoll指针。<br>　　co_eventloop() 就是对epoll_wait调用处理的一个死循环，epoll_wait会进行一个1ms超时的短时间blocking调用，然后将可用的Item添加到pstActiveList中去，然后检查超时的事件并把超时的事件也添加到pstActiveList中去。当收集了这么多的active事件后，接下来依次调用各个Item的pfnProcess函数(这个函数通常是执行co_resume唤醒协程)。<br>　　co_poll() 该接口不仅可以在用户协程程序中直接使用，在hook_sys中也是被hook成poll()的形式而被大量使用。其操作较为复杂，分为以下几个步骤：<br>　　(1). 首先创建stPoll_t对象，设置完描述符相关的参数后，最重要的是设置pfnProcess=OnPollProcessEvent、pArg=co_self()；当事件就绪后就是通过这个函数和参数将自己切换回来；<br>　　(2). 将自己添加到ctx-&gt;pTimeout队列中去。关于这个ctx-&gt;pTimeout队列，其实是一个简单的链表数组结构，可以维持60x1000ms=60s的超时间隔，然后新的Item要插入进去的话，是就算其相对表头绝对超时时间的偏移长度来定位到指定的数组位置并进行插入的。当然这个接口设计的有点问题，就是poll的系统调用可以设置timeout=-1表示永不超时，但是这里的超时是必须设置且不能超过相对超时表头(理论是)60s，使用起来可能会有些误解。通过这样的数据结构，每次epoll_wait循环后取超时事件就十分方便快速了。<br>　　(3). epoll_ctl通过EPOLL_CTL_XXX将实际的事件侦听添加到操作系统中去。这里才发现poll和epoll的事件类型好像不兼容，所以两者常常会用函数转来转去的。<br>　　(4). co_yield_env()将自己切换出去；<br>　　(5). 后续执行表明因为事件就绪或者超时的因素又被切换回来了，此时调用epoll_ctl将事件从操作系统中删除掉(这也暗示了是ONE SHOT模式的哦)，保存返回得到的就绪事件。<br>　　(6). 释放资源，本次调用完成。</p>
<h2 id="2-3_协程局部存储">2.3 协程局部存储</h2><p>　　涉及到的接口有：co_setspecific、co_getspecific。<br>　　这个还是比较简单实现的，对于非协程执行环境或者主协程环境，直接调用pthread库的pthread_setspecific、pthread_getspecific的线程局部存储接口，而如果是在一般工作协程的环境，每个协程预留分配了1024个指针用于存储这些value的地址。</p>
<h2 id="2-4_协程同步">2.4 协程同步</h2><p>　　涉及到的接口有：co_cond_alloc、co_cond_signal、co_cond_broadcast、co_cond_timedwait。<br>　　大家都知道mutex和条件变量是多线程环境下的开发利器，由于协程是用户态主动切换的，所以感觉对mutex需求不是很大，但是条件变量很有作用，在生产者-消费者模型中可以快速唤醒等待资源的合作者，增加调度效率。<br>　　co_cond其实也是一个小Trick：<br>　　(1). 首先通过co_cond_alloc()创建一个stCoCond_t对象管理所有的条件事件，其实是一个stCoCondItem_t类型的链表头尾；<br>　　(2). 当co_cond_timedwait()等待的时候实际是创建一个stCoCondItem_t，设置pArg=co_self()、pfnProcess=OnSignalProcessEvent，然后将其添加到先前的stCoCond_t链表中去，当然如果设置了超时参数还需要添加到线程的pEpoll-&gt;pTimeout中去，然后通过co_yield_ct();把自己切换出去；<br>　　(3). 当生产者资源就绪的时候，通过co_cond_signal/co_cond_broadcast在stCoCond_t链表中取出后添加到pEpoll-&gt;pstActiveList中等待被调度，当然如果超时了还没有被生产者唤醒，如上所述线程epoll_wait循环中，会自动将其添加到就绪队列中执行回调的。<br>　　所以条件变量实际上就是除却使用poll的方式外，由协程自己控制将需要唤醒的协程添加到pEpoll-&gt;pstActiveList队列中去来实现的。</p>
<h2 id="2-5_闭包操作">2.5 闭包操作</h2><p>　　感觉怪怪的，那就先不看了，C++的std::bind、lambda用起来也是爽哒哒滴！</p>
<h1 id="三、小结">三、小结</h1><p>　　设计的亮点在于：可运行协程Stack管理结构，调度的效率更高；shared_stack共享栈设计，节约内存提高创建协程的数量；hook阻塞系统调用和标准库函数，对原有业务代码侵入性小；抽象出多种协程应用开发常用接口，使用简洁方便。<br>　　我的libto小轮子还有不少的东西可以完善哈，再次广告一下！</p>
<div class="github-widget" data-repo="taozhijiang/libto"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/tencent-wechat/libco" target="_blank" rel="external">libco</a></li>
<li><a href="http://dev.qq.com/topic/58203cfcd149ba305c5ccf85" target="_blank" rel="external">揭秘：微信是如何用libco支撑8亿用户的</a></li>
<li><a href="https://www.zhihu.com/question/52193579/answer/129597362" target="_blank" rel="external">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么?</a></li>
<li><a href="http://docs.oracle.com/cd/E19253-01/819-7050/chapter3-24/" target="_blank" rel="external">链接程序和库指南</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　在跟踪libco库时候发现一位网友提的issue，实在是看不下去了，哔了狗了。人家说程序员最喜欢的事是别人的项目有详细的wiki或文档，最讨厌的事情就是自己写文档，看来果真如此啊。不过libco自带了好几个例子，算是把libco的功能都展示了出来，过一遍也就知道怎么使用了。<br><img src="/post_images/images/201611/8064b68a1b41936d255f92f5a91eb647.png" alt="libco"><br>　　libco算是一个比较轻巧的协程库吧，看着代码不多，都是用朴实的C语言写的，而且完全不依赖于外部的ucontext或Boost.Context库，就想着读下代码彻底了解一下这个腾讯内部大规模用的协程库是怎么炼成的。从背景资料看来，一般对于新立项开发的系统，很多公司可能选择异步的方式来搞定，但是对于历史遗留的大规模同步模型的业务，异步化改造将会极具挑战性的事情，因为异步的方式需要代码分割重布，算是大换血的手术了；而如果采用协程和hook阻塞调用的方式，可以对传统同步类型业务基本无侵入的情况下享受异步带来的好处，这种手段确实很诱人。<br>　　额外想说的是，人家说隔行如隔山，其实当前在分工这么明确的环境下，隔业也同隔山啊，据说协程在游戏引擎行业早就大规模的被应用了以至于游戏开发者都不屑于提及这些，反而在互联网的后台压力越来越大的情况下，传统搞后台的兴起这个概念出来了。还有一点好奇的是，代码里面居然用了<strong>APPLE</strong>关键字和对kqueue异步的支持，腾讯不是一直是SuSE的粉丝么，难道后台也用到了很多BSD的服务器？</p>
<h1 id="一、协程的创建和调度">一、协程的创建和调度</h1><p>　　libco支持的协程原语包括：co_create、co_resume、co_yield、co_yield_ct、co_release。</p>
<h1 id="1-1_协程的创建管理">1.1 协程的创建管理</h1><p>　　(1). co_create()：创建一个协程。因为协程寄生于线程中的，所以每个线程需要有自己线程级别的资源来维护管理自己的协程。这里程序没有使用到线程局部存储TLS的方式，而是采用全局的stCoRoutineEnv_t类型的指针数组，然后采用线程tid进行索引的方式获取线程独立的存储结构。虽然定义上pid_t一般是int类型，但是系统一般不会用到这么大的范围，如果没有额外配置系统，默认最大的线程ID值定义在/proc/sys/kernel/pid_max为32768，所以这里使用上没什么问题，且空间浪费也不是很大。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> stCoRoutineEnv_t &#123;</div><div class="line">	stCoRoutine_t *pCallStack[ <span class="number">128</span> ];</div><div class="line">	<span class="keyword">int</span> iCallStackSize;</div><div class="line">	stCoEpoll_t *pEpoll;</div><div class="line">	stCoRoutine_t* pending_co; stCoRoutine_t* ocupy_co;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　在创建上述线程相关资源的时候，还会自动创建一个没有执行体的主协程，同时线程中还会创建一个stCoEpoll_t结构用于异步事件相关的操作，默认侦听fd数目最多为1024x10，同时在pTimeout-&gt;pItem上还创建了60x1000个stTimeoutItemLink_t结构(但是事件最大支持20s的超时，注释说40s，这里实际是60s!!!)，且后续在事件循环中，根据fd的事件状态会挂载到pstActiveList和pstTimeoutList链表上面去。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[基于Boost.Context2库的协程库轮子libto的设计与实现]]></title>
    <link href="https://taozj.org/201611/libto-coroutine-library-base-on-boost-context2.html"/>
    <id>https://taozj.org/201611/libto-coroutine-library-base-on-boost-context2.html</id>
    <published>2016-11-15T12:18:40.000Z</published>
    <updated>2016-12-29T01:47:50.000Z</updated>
    <content type="html"><![CDATA[<p>　　个人对协程开发还是比较感兴趣的，当然不仅仅是因为从最近的各大开源系统趋势中，发现基于协程的高性能服务端系统被各大厂所越来越重视，而是以前自己对操作系统有过一段时间的学习和专研，可是内核级的线程让我们能做的事情十分有限(不如说是水平太差了吧)，反而是现在协程作为用户级别的线程，用户态程序就可以对其做很多事情，比如调度、定时、io阻塞、睡眠等操作，所以说协程库的开发具有很强的可玩性啊，当然要写一个好的协程库也是十分有挑战的。同时，多个协程存在于同一个线程中，且同一时刻只有一个协程处于运行状态，所以很多的调用必须仔细小心，任何一个协程被阻塞就会导致整个线程被阻塞。<br>　　自己学习Boost.Context后，虽然对其基本原理略知一二，但是实际使用上却是无从下手，虽然也知道也有现成可用的Boost.Coroutine协程库，可惜和往常一样，Boost库的代码都想当的晦涩难懂。幸好Meizu的libgo开源来着，代码写的也是能给人看的，抛去Windows兼容和其他一些复杂的技法，模仿着写一个朴实易懂的协程库轮子看来也并非不无可能。当然在最终的实践中，也还是有一些同原库不一致的地方，虽然不一定会比原库的好，但是觉得更符合自己的思维习惯吧。此处还需要提到另外一个协程库libcopp，也据称是一个服务于生产环境的协程库了，虽然在github上面十分低调，但是从博客看来作者的C++和系统底层功力比较深厚。其实啊，有些人一直就很牛，而这位作者的博客历程看来其实前几年也很菜，但是近两年来成长迅速，真是让吾等可望不可及啊，虽然偶也在拼命奔跑着。</p>
<h1 id="一、基本结构">一、基本结构</h1><p>　　本着“开发库不应该默默地单独创建线程”的原则，libto可以以两种方式运行，如果创建Task、Timer的时候不添加额外的dispatch参数，那么协程的调度和执行、epoll事件的查询都只会在主线程中执行；如果创建Task、Timer的时候指定了dispatch参数，就会将这个协程创建在指定索引对应的线程中(如果线程不存在就创建对应的线程)，每个线程单独调度自己的协程，但是协程状态阻塞事件的检查和更新全部都在主线程中操作。<br>　　在多工作线程模式下把所有的事件轮训放到主线程中，主要的考虑的一方面是将异步的工作放在主线程中，当主线程中不添加其他复杂任务的时候可以及时的轮训各个线程的异步事件，异步信息不会受到各个工作线程的负载量而受影响；二来当工作线程没有活跃的事件时候可以将其阻塞睡眠，主线程在必要的时候可以异步唤醒对应的工作线程，借此降低活跃的线程数节约资源。由于主线程和工作线程都需要修改任务队列，这里就需要额外的同步操作以保护数据结构。<br><a id="more"></a></p>
<h1 id="二、协程开发原语">二、协程开发原语</h1><h2 id="2-1_sch_yield">2.1 sch_yield</h2><p>　　类似于yield的工作，当前工作的协程被无条件的被切换出去，然后每个线程的主协程负责调度选择下一个要执行的协程并将其切换至运行的状态。虽然不一定有主协程这个名词，我把线程运行时候默认的执行环境叫做主协程，而对应的其他使用Boost.Context创建出来的执行环境叫做工作协程，由于不像多线程中可以用内核态这个特权状态强制切换执行上下文，线程中的所有协程都是平等的，只能自己主动交出执行权。<br>　　在协程库中，每个工作协程都是从主协程切换进去的，当yield切换出来的时候也是返回到主协程中，主协程在这个时机可以选择下个要执行的协程以实现调度。</p>
<h2 id="2-2_sch_read/write/rdwr">2.2 sch_read/write/rdwr</h2><p>　　Linux中几乎所有的文件描述符的操作默认都是阻塞的，但是理论上在协程中的任何操作都不应当被阻塞，否则整个线程都被阻塞了，浪费的是“大家”(所有协程)的时间，所以正确的方法是对于所有可能阻塞的异步操作，都应该把当前协程切换出去，等到资源可用的时候再无障碍顺利执行，这也就是select/poll/epoll的本质思路。<br>　　libgo做了一个小trick(当然libco也是这么个做法，或者是谁借鉴谁，亦或者是整个协程库的通用做法)，把原先所有可能阻塞的C库和系统调用接口(accept、read、recv…)都同名重写打了一个hook，根据C++调用名字查找规则，编译器会优先调用相同命名空间中的函数，然后通过libgo_poll-&gt;add_into_reactor方式将文件描述符和事件添加到epoll中去，之后立即把自己切换出去，主协程的Run()会轮训检查调用epoll_wait检查底层的就绪事件，并调度的时候在适当时机唤醒这个等待的协程。<br>　　这样固然是好，用户甚至无需修改代码就可以充分利用协程和异步的优势，只是工作量要大一些。我就用了更直接的模式，我认为每个开发者应该有足够的素质知道哪写操作会阻塞，实现调用sch_xxxx进行异步检查，然后进行无阻塞的IO操作，当然缺陷就是要显式把所有的sch_xxxx显式侵入用户代码，好的协程库肯定不能这么干滴。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">libto::st_make_nonblock(sock);</div><div class="line"></div><div class="line">sch_read(sock);</div><div class="line"><span class="keyword">size_t</span> count = recv (sock, buf, <span class="number">512</span>, <span class="number">0</span>);</div><div class="line">sch_write(sock);</div><div class="line">write(sock, msg_200.c_str(), msg_200.size());</div></pre></td></tr></table></figure></p>
<p>　　当然非阻塞socket读取数据什么时候结束是考验网络开发基本素质了哦。</p>
<h2 id="2-3_sch_timer">2.3 sch_timer</h2><p>　　这个的实现主要得益于内核中的timerfd，把定时器也进行fd化了，这一方面是基于信号实现的定时器使用起来是极其不可靠的，同时提供fd接口就是方便统一到select/poll/epoll的框架下面。所以根据上面的思路，添加一个带回调的定时器操作，其实也就是创建一个任务，只是在回调函数前面增加一个timerfd的异步侦听操作。让人兴奋的是内核的很多东西都开始fd化了，比如eventfd、timerfd、signalfd……<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> ( (timerfd = <span class="number">_</span>timer_prep(msec, forever)) == <span class="number">-1</span>)</div><div class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line"><span class="keyword">if</span> (forever) &#123;</div><div class="line">    <span class="function">Task_Ptr <span class="title">p_task</span><span class="params">( <span class="keyword">new</span> Task([=] &#123;</span></span></div><div class="line">        <span class="keyword">for</span>(;;)&#123;</div><div class="line">            <span class="keyword">char</span> null_read[<span class="number">8</span>];</div><div class="line">            <span class="number">_</span>sch_read(timerfd);</div><div class="line">            read(timerfd, null_read, <span class="number">8</span>);</div><div class="line">            func();</div><div class="line">        &#125;</div><div class="line">    &#125;));</div><div class="line">    addTask(p_task);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面用for(;;)循环设置了一个连续间隔定时器，如果只需要one_shot类型的定时器就把循环拿掉，同时在回调结束的时候关闭事先创建的timerfd释放资源就可以了。</p>
<h2 id="2-4_sch_sleep_ms">2.4 sch_sleep_ms</h2><p>　　有了sch_timer那么sch_sleep_ms的协程睡眠实现更是不在话下了，使用相同的思路，创建一个timerfd并再次通过_sch_read等待事件就绪，然后关闭timerfd后执行流程得以继续进行，模拟了一个睡眠等待的效果，此处就不多表了。<br>　　这些fd的异步操作不能在主线程的主协程中被调用，主协程没有Task结构，所以也无法添加到阻塞队列中去。还有就是不要依靠这些定时、睡眠操作有多么高的准确度，因为它基于主线程主协程的事件检测和工作协程的工作负载情况，所以这里十分考量协程调度算法的效率。</p>
<h1 id="三、小结">三、小结</h1><p>　　项目的主页在：</p>
<p><div class="github-widget" data-repo="taozhijiang/libto"></div><br>　　当然，现在也仅仅是出了一个原型，后面还有很多工作需要做：资源的安全释放、协程的调度和空闲处理、任务和定时器的取消删除、各种异常情况的处理等等，离生产环境的要求还差的远。最近搜索发现一篇系统性的协程文章<a href="http://www.akira.ruc.dk/~keld/research/COROUTINE/COROUTINE-1.0/DOC/COROUTINE_REPORT.pdf" target="_blank" rel="external">A Portable C++ Library for Coroutine Sequencing</a>比较的好，后面仔细研究一下，希望能把这个小项目做地不断完善健壮起来。<br>　　协程的工作实际就是达到基于事件的异步开发效果，但是相比传统的异步开发，因为每个协程都要一个协程栈，所以对内存的要求会多一些；还有就是，用协程开发的程序，线下虽然可以通过不链接协程库采用阻塞的方式进行调试，但是线上遇到问题，协程库程序问题的跟踪调试估计会比较棘手。<br>　　通过main.c中的代码写了个简易的http response服务端，启动了11个线程，然后accept得到的客户端轮询分发的方式，使用-c 30的seige压了一下，发现并发量还不到20 trans/sec。发现自己写过的服务端用这种方式测试性能从来都没有过百的，而同样的方式测试Nginx也是只有几十的响应并发量，对网上那些库单机成千上万的请求量真是望洋兴叹了，是我哪里的姿势不对么？</p>
<p>更新 20161122：<br>　　根据libco的思路，添加了一些系统调用的hook，同时修复了调度BUG，再通过增加siege测试的并发请求数目，吞吐量涨了一些了哦，但是这个协程库的最大并发量还没有去探测。经过大致的测试，跟预想的一样，其性能跟异步模式下的多线程还是有一些差距的(也有可能我本身的调度和切换有问题)。<br><img src="/post_images/images/201611/504374a23605e708dc62eb5e915102bf.png" alt="libto"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/yyzybb537/libgo" target="_blank" rel="external">libgo</a></li>
<li><a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a></li>
<li><a href="https://www.owent.net/" target="_blank" rel="external">I’m OWenT</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　个人对协程开发还是比较感兴趣的，当然不仅仅是因为从最近的各大开源系统趋势中，发现基于协程的高性能服务端系统被各大厂所越来越重视，而是以前自己对操作系统有过一段时间的学习和专研，可是内核级的线程让我们能做的事情十分有限(不如说是水平太差了吧)，反而是现在协程作为用户级别的线程，用户态程序就可以对其做很多事情，比如调度、定时、io阻塞、睡眠等操作，所以说协程库的开发具有很强的可玩性啊，当然要写一个好的协程库也是十分有挑战的。同时，多个协程存在于同一个线程中，且同一时刻只有一个协程处于运行状态，所以很多的调用必须仔细小心，任何一个协程被阻塞就会导致整个线程被阻塞。<br>　　自己学习Boost.Context后，虽然对其基本原理略知一二，但是实际使用上却是无从下手，虽然也知道也有现成可用的Boost.Coroutine协程库，可惜和往常一样，Boost库的代码都想当的晦涩难懂。幸好Meizu的libgo开源来着，代码写的也是能给人看的，抛去Windows兼容和其他一些复杂的技法，模仿着写一个朴实易懂的协程库轮子看来也并非不无可能。当然在最终的实践中，也还是有一些同原库不一致的地方，虽然不一定会比原库的好，但是觉得更符合自己的思维习惯吧。此处还需要提到另外一个协程库libcopp，也据称是一个服务于生产环境的协程库了，虽然在github上面十分低调，但是从博客看来作者的C++和系统底层功力比较深厚。其实啊，有些人一直就很牛，而这位作者的博客历程看来其实前几年也很菜，但是近两年来成长迅速，真是让吾等可望不可及啊，虽然偶也在拼命奔跑着。</p>
<h1 id="一、基本结构">一、基本结构</h1><p>　　本着“开发库不应该默默地单独创建线程”的原则，libto可以以两种方式运行，如果创建Task、Timer的时候不添加额外的dispatch参数，那么协程的调度和执行、epoll事件的查询都只会在主线程中执行；如果创建Task、Timer的时候指定了dispatch参数，就会将这个协程创建在指定索引对应的线程中(如果线程不存在就创建对应的线程)，每个线程单独调度自己的协程，但是协程状态阻塞事件的检查和更新全部都在主线程中操作。<br>　　在多工作线程模式下把所有的事件轮训放到主线程中，主要的考虑的一方面是将异步的工作放在主线程中，当主线程中不添加其他复杂任务的时候可以及时的轮训各个线程的异步事件，异步信息不会受到各个工作线程的负载量而受影响；二来当工作线程没有活跃的事件时候可以将其阻塞睡眠，主线程在必要的时候可以异步唤醒对应的工作线程，借此降低活跃的线程数节约资源。由于主线程和工作线程都需要修改任务队列，这里就需要额外的同步操作以保护数据结构。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="造轮子" scheme="https://taozj.org/tags/%E9%80%A0%E8%BD%AE%E5%AD%90/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（二）：Paxos算法介绍]]></title>
    <link href="https://taozj.org/201611/learn-note-of-distributed-system-(2)-paxos-algorithm.html"/>
    <id>https://taozj.org/201611/learn-note-of-distributed-system-(2)-paxos-algorithm.html</id>
    <published>2016-11-09T16:00:16.000Z</published>
    <updated>2016-12-25T14:36:42.000Z</updated>
    <content type="html"><![CDATA[<p>　　Paxos算法是一种基于消息传递通信模型的分布式系统中，使得各节点就某个值达成一致的问题的算法，其既可以工作在单机的多个进程上面，也可以工作在网络上面的多个主机上面。Paxos协议假定各个节点之间的通信采用异步的方式，且基于非拜占庭模型，也就是允许消息的延迟、丢失或者重复，但是不会出现内容损坏、篡改的情况，在实践中通过添加额外的校验信息很容易保证收到的消息是完整的。<br>　　在Paxos算法中主要有以下几种角色：Client、Acceptor、Proposer、Learner。由于本文是直接从<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>开始学习研究的，其已经是一个被优化过的所谓Multi-Paxos算法，允许指令预取提交，算是针对原始Basic-Paxos的一种改进模型了，通常会借助选举算法在多个Proposer和Learnner中选取出Leader，后面涉及的时候再讨论。<br>　　a. <strong>Client</strong>：主要是向分布式系统发送请求，并等待分布式系统的响应，虽然实现的时候也有跟Proposer联系在一起的，但是通常不建议这么做；<br>　　b. <strong>Acceptor</strong>(Voters)：被组织成投标团体，对Proposer提出的决议Prepare/Accept进行表决；<br>　　c. <strong>Proposer</strong>：起到客户代理的作用，请求Acceptor批准客户的请求，同时当发生冲突的时候起着协调者的作用，增加提案号重新请求；<br>　　d. <strong>Learner</strong>：学习已经被Chosen通过的提案，大部分起到replication备份的作用，当客户的请求被批准后，采取相应的行为动作，如果其想要知道某提案是否被通过，比如遗漏了某个命令的决案消息，也可以主动(向Acceptor)发起查询；</p>
<h1 id="一、Paxos算法原理">一、Paxos算法原理</h1><p>　　Paxos算法中根据Client的请求，由Proposer发起提案，其中每个提案都有一个全局唯一的数字编号来进行标识，这个编号由外部组件负责生成并且不断地递增，所以在Paxos中每个提案应该是以[提案编号, Value]的组合形式来表示。在Multi-Paxos中每个instance之间是完全独立的，所以不要求这些instance提案编号是相互不同的，而且在一些实现中会同时发送[instance_id, 提案编号, value]的，下文仅考虑一个instance中的Basic-Paxos算法的过程。<br>　　下面的描述中，对于每个节点，假设[n_a, n_value]是已经被accept的提案编号及其值，n_h表示Acceptor已经遇到并处理过的最大提案编号，n_my表示Proposer当前使用的提案编号：<br>　　(1). <strong>阶段一：Prepare阶段</strong><br><img src="/post_images/images/201611/405ea0de21228fe51ad392742b75d23e.jpg" alt="Paxos-Prepare"><br>　　a. Proposer选择一个提案编号n_my&gt;n_h，然后向某个多数派Acceptor所组成的集合发送请求<prepare, n_my="">，要求该集合中的Acceptor作出回应；<br>　　b. 当Acceptor收到<prepare, n="">这个消息后，如果发现n_my<n_h小于已经看到响应过的提案编号，则直接拒绝返回<prepare-reject>，否则n_h=n，同时返回已经被accept的值<prep-ok, n_a,="" n_value="">，同时该Proposer不会再响应小于n_h(n)的提案了；<a id="more"></a><br>　　(2). <strong>阶段二：Accept阶段</strong><br><img src="/post_images/images/201611/51580dde724fea031c4627b36b71e779.jpg" alt="Paxos-Accept"><br>　　a. 如果Proposer没有接收到绝大多数的<prep-ok>回应，则延时后重试，采用更大的提案编号；否则<br>　　b. 如果Proposer接收到大部分Acceptor的<prep-ok>回应，那么查看前面<prep-ok>的返回消息，如果之前所有回复的Acceptor都还没有accept任何值(当V=null时)，Proposer可以自己选择任何的V值(当然不会乱选啦，就是原先提案值)，否则V设置为所有<prep-ok, n_a,="" n_value="">中最大n_a对应的n_value，然后返回<accept, n_my,="" v="">给所有的节点；<br>　　c. 当被发送的Acceptor节点接受到<accept, n,="" v="">的时候，如果n<n_h，则回复<accept-reject>，否则更新n_a=n, n_value=V, n_h=n，同时返回<accept-ok>；<br>　　(3). <strong>阶段三：Decide阶段</strong>(Learner获取提案)<br><img src="/post_images/images/201611/b80428b6fb42b4b06944a2f4217c97e0.jpg" alt="Paxos-Decide"><br>　　a. 如果Learner从绝大多数Acceptor节点获得<accept-ok>，则发送<decide, n_value="">给所有Learner学习；否则<br>　　b. 如果Learner没能获得绝大多数Acceptor的<accept-ok>，则放弃；<br>　　Learner获取一个已经被Chosen选定提案的前提，是这个提案被大多数的Acceptor通过发送<acceptor-ok>所批准。最简单的方式是所有的Acceptor将所有的<acceptor-ok>回复消息发送给所有的Learner，那么通信的数量将会是Acceptor和Leaner数量相乘；优化方法之一是选取一个主Learner，主Leaner得知提案被通过后，再将结果送达给其他Learner，但是这样会引入单点故障的问题；还可以选择一个小范围的Learner集合，这里面的Learner直接接收Acceptor的Chosen消息，然后将结果转达给其他的Learner。当然这里也是假定非拜占庭模型，Learner传播给其他Learner的Chosen Value是可信完整的。<br>　　实现上为了可能崩溃或者失效后处理，所有Acceptor在发送响应前必须持久化存储该响应，每一次Paxos结算至少要记录propose、promise、<br>accept、acknowledgment、commit五类消息，而且为了可靠性必须快速刷新到磁盘上面。</acceptor-ok></acceptor-ok></accept-ok></decide,></accept-ok></accept-ok></n_h，则回复<accept-reject></accept,></accept,></prep-ok,></prep-ok></prep-ok></prep-ok></prep-ok,></n_h小于已经看到响应过的提案编号，则直接拒绝返回<prepare-reject></prepare,></prepare,></p>
<h1 id="二、Multi-Paxos">二、Multi-Paxos</h1><p>　　虽然最初Lamport爷爷富具幽默感的Basic-Paxos没有拜读过，但是从网上资料以及<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>的Multi-Paxos也得知之前Basic-Paxos在工程化中会有一些固有的问题。其实<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>中的各种优化，算是已经为工程实现提供了较多的预备和考量了。<br>　　Basic-Paxos中所有的Proposer都可以发布提案，用后面的话来说就是所有的Proposer都认为自己是Leader，那么可能出现的问题就是产生活锁——当多个Proposer的提案被否决后，都增加自己的提案编号再次尝试，最终导致的结果就是循环僵持下去而没有任何的提案被Chosen。Multi-Paxos的解决方式是在稳定的状态下，只有唯一的Proposer Leader，因为只有这个Leader能够发起Prepare增加提案值，所以正常情况下他的提案总能够被接受和选择，那么Phase-I的Prepare阶段就可以被省略优化了(同时也省略了prepare、promise日志写盘操作)。而且，Paxos的算法保证可以在短时间(比如选举Leader)的情况下，允许有多少个Leader同时存在，此时退化到Basic-Paxos算法了，但是算法的正确性不会被破坏。<br>　　实现中可以把Proposer、Acceptor、Learner看成整体的Server端，而且文章中也是将他们和StateMachine融合在一个进程中去，Client向Server端发送请求以组成C/S模型架构。因为单Server端是不可靠的，所以通常会部署多个Server端，只要给这些Server端以相同的序列输入，那么根据决定状态机他们的输出肯定是相同的，所以Client可以使用任意一个Server的输出作为结果，而这里需要保证的，就是这多个Server执行输入状态机命令的顺序是相同的。<br>　　上面的说法还是比较的抽象，可以使用PhxPaxos的一张图来表明：<br><img src="/post_images/images/201611/8665a65ad07bb54f5380d53ed6bb3b62.jpg" alt="Paxos-Instance"><br>　　为了保证所有的机器(以Node来称呼)都以相同的顺序执行状态机命令，多个Node定义为网络进程，可以在一台物理主机上也可以分布在多台机器上，以IP:Port标识，我们定义顺序连续编号的Instance代表一个状态机命令(同时也就是对应一个Client请求)以用来确定一个Value，每个Instance都由单个Proposer、Accetpor、Learner和StateMachine组成，当我们假定Node的组成是固定的，那么所有Node上面相同编号的Instance的角色将组合成一个集合被Paxos算法所使用。每个编号的Instance负责确定相应编号的值，顺利的情况下可能一次提案就能通过，也有可能被否决后， Proposer增加提案号多次操作才被接收选定。上图的Paxos group是按照业务逻辑进行划分的，跟实现原理没有关系，当我们关注每一个单独的Paxos group，里面都是一个完整的Multi-Paxos的实例。对于Node A/B/C通常会产生一个Leader Proposer负责代理Client的请求提出议案，然后Node A/B/C的所有Acceptor组成Quorums负责投票表决，最后Learner整理表决的结果得到Chosen Value。<br>　　同时，每个单独编号的Instance之间是完全隔离的，他们单独执行互不干涉，也正是因为如此，Multi-Paxos使得多个Instance并行执行成为了可能。实际上在Lamport爷爷文章中也提到了，Leader可以预取r个命令——也就是说，在命令1到i被选择Chosen之后，它就可以同步提出命令i+1,…, i+r，这些命令有些可能会执行失败，正常情况下该instance的Proposer会重新提启动预案再次尝试，但是此时如果Leader挂掉之后，就在命令序列中留下一些间隔(gap)，新Leader会为这些gap重新执行Phase-I操作以便去获取其Chosen Value。但是后面说到节点使用不改变状态机状态的”no-op”命令占用这些间隔，然后继续执行，那么占用这些命令号原先的指令怎么办呢？丢弃？<br>　　PS：上面这个问题，刚才跟PhyPaxos的作者沟通过，至少在他们PhxPaxos里面，Chosen Value可以是并行的，但是状态机转移是完全序列化的，也就是当出现gap的时候状态机无法转移，所以才需要填充no-op指令让状态机跳过这些Instance Number然后执行下去。按照我的理解，Chosen Value可以在预取窗口中并行执行，而且Value以任意顺序被Chosen出来，但是commit使得状态机转移必须是严格串行化的，查看Paxos Made Live中，状态转移就是过各个Node执行callback函数，而这个过程是被严格序列化的，并且通常真正的业务变更和执行操作也是体现在callback中的。或许上面no-op占用命令就是通过某种机制告知客户端该命令执行失败了吧，猜的别打我！<br>　　前面说到开始打算从PhxPaxos入手了解Paxos机制的，但是后续发现Phxteam还是对Paxos做了一些的更改，因为纯粹的Paxos太过于理论，原版的协议是不可能直接拿来工程应用就达到可用性和可靠性的需求的，往往工程化的过程中会这里改改那里改改的，最终发现已经不是原版协议了，到头来改造成的协议其正确性也难以得到证明了。对于Paxos的实现，可以查阅Marco Primi的硕士论文《Paxos made code - Implementing a high throughput Atomic Broadcast》，这篇论文对Paxos算法进行了通俗的阐述，其合作者Daniele Sciascia将其中的LibPaxos库进行了开源，采用C语言实现并配备sample，虽然距离线上使用可能还有所欠缺，但是整个代码结构思路清晰、通俗易懂，本来想写篇文章说说它的，但是实现的真是太直白了，提笔后发现也没啥好写的了。<br>　　还有，学术级别的论文《Paxos Made Live》虽不够详细，但总结的也是工程实践中的精华，如果作者能开源其实现就棒极了！</p>
<h1 id="三、后言">三、后言</h1><p>　　在工程上得到验证的分布式协议并不多，2PC在数据库中使用较多，但是现在分布式系统肯定不是2PC、3PC协议所能解决的。Paxos算法的出现就是要异步、去中心化，通过陪审团民主选取的方式来确定一个值。无论是Multi-Paxos极其改进的ZAB、Raft现在是红的发紫(还有个Viewstamped Replication是什么鬼)，但归根结底其本质还是Paxos，只是在某些情况下增加了一些限制以便于工程化实现，因为Paxos本身过于的理论，实现起来确实是“reliable implementation proves to be nontrivial”！<br>　　关于ZAB和Raft，自己还了解的不太多。据说他们是限制命令提交是严格序列化的，当某一个命令没有被提交后后续的命令都全部阻塞在内存里面，所以性能和Multi-Paxos相比是他们被诟病的槽点，不过其设计思路后续还是可以了解借鉴的，尤其是Raft作者Diego Ongaro洋洋洒洒两百多页的PhD论文和算法伪代码的表述，大大增加了工程化的便捷性。<br>　　“Paxos只是个协议，用于在分布式环境下确定一个值”，现在念起来意味深长。Paxos的实现也只是在分布式系统中作为基础服务，然后构建上层的分布式存储、分布式数据库、分布式日志等服务还需要跟具体的业务相关联，分布式日志系统好理解，而将数据库的binlong作为分布式对象就可以得到分布式数据库了，当然分布式存储还不知道什么原理，因为目前的论文看来Paxos无法进行大尺寸文件的传输，期待PaxosStore早日开源吧！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">Paxos Made Simple</a></li>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/wiki" target="_blank" rel="external">phxpaxos wiki</a></li>
<li><a href="http://www.tudou.com/programs/view/e8zM8dAL6hM/" target="_blank" rel="external">paxos和分布式系统</a></li>
<li><a href="http://coolshell.cn/articles/10910.html" target="_blank" rel="external">分布式系统的事务处理</a></li>
<li><a href="https://en.wikipedia.org/wiki/Paxos_(computer_science" target="_blank" rel="external">wikipedia Paxos</a>)</li>
<li><a href="https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="external">Paxos算法</a></li>
<li><a href="https://www.ece.cmu.edu/~ece845/docs/paxos-govindan-2012.pdf" target="_blank" rel="external">Paxos, Agreement, Consensus</a></li>
<li><a href="http://blog.csdn.net/sparkliang/article/details/5740882" target="_blank" rel="external">Paxos Made Simple【翻译】</a></li>
<li><a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">Paxos made code</a></li>
<li><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf" target="_blank" rel="external">Paxos Made Live - An Engineering Perspective</a></li>
<li><a href="https://timyang.net/distributed/paxos-scenarios/" target="_blank" rel="external">Paxos在大型系统中常见的应用场景</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　Paxos算法是一种基于消息传递通信模型的分布式系统中，使得各节点就某个值达成一致的问题的算法，其既可以工作在单机的多个进程上面，也可以工作在网络上面的多个主机上面。Paxos协议假定各个节点之间的通信采用异步的方式，且基于非拜占庭模型，也就是允许消息的延迟、丢失或者重复，但是不会出现内容损坏、篡改的情况，在实践中通过添加额外的校验信息很容易保证收到的消息是完整的。<br>　　在Paxos算法中主要有以下几种角色：Client、Acceptor、Proposer、Learner。由于本文是直接从<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf">《Paxos Made Simple》</a>开始学习研究的，其已经是一个被优化过的所谓Multi-Paxos算法，允许指令预取提交，算是针对原始Basic-Paxos的一种改进模型了，通常会借助选举算法在多个Proposer和Learnner中选取出Leader，后面涉及的时候再讨论。<br>　　a. <strong>Client</strong>：主要是向分布式系统发送请求，并等待分布式系统的响应，虽然实现的时候也有跟Proposer联系在一起的，但是通常不建议这么做；<br>　　b. <strong>Acceptor</strong>(Voters)：被组织成投标团体，对Proposer提出的决议Prepare/Accept进行表决；<br>　　c. <strong>Proposer</strong>：起到客户代理的作用，请求Acceptor批准客户的请求，同时当发生冲突的时候起着协调者的作用，增加提案号重新请求；<br>　　d. <strong>Learner</strong>：学习已经被Chosen通过的提案，大部分起到replication备份的作用，当客户的请求被批准后，采取相应的行为动作，如果其想要知道某提案是否被通过，比如遗漏了某个命令的决案消息，也可以主动(向Acceptor)发起查询；</p>
<h1 id="一、Paxos算法原理">一、Paxos算法原理</h1><p>　　Paxos算法中根据Client的请求，由Proposer发起提案，其中每个提案都有一个全局唯一的数字编号来进行标识，这个编号由外部组件负责生成并且不断地递增，所以在Paxos中每个提案应该是以[提案编号, Value]的组合形式来表示。在Multi-Paxos中每个instance之间是完全独立的，所以不要求这些instance提案编号是相互不同的，而且在一些实现中会同时发送[instance_id, 提案编号, value]的，下文仅考虑一个instance中的Basic-Paxos算法的过程。<br>　　下面的描述中，对于每个节点，假设[n_a, n_value]是已经被accept的提案编号及其值，n_h表示Acceptor已经遇到并处理过的最大提案编号，n_my表示Proposer当前使用的提案编号：<br>　　(1). <strong>阶段一：Prepare阶段</strong><br><img src="/post_images/images/201611/405ea0de21228fe51ad392742b75d23e.jpg" alt="Paxos-Prepare"><br>　　a. Proposer选择一个提案编号n_my&gt;n_h，然后向某个多数派Acceptor所组成的集合发送请求<prepare, n_my>，要求该集合中的Acceptor作出回应；<br>　　b. 当Acceptor收到<prepare, n>这个消息后，如果发现n_my<n_h小于已经看到响应过的提案编号，则直接拒绝返回<prepare-reject>，否则n_h=n，同时返回已经被accept的值<prep-ok, n_a, n_value>，同时该Proposer不会再响应小于n_h(n)的提案了；]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[分布式系统入门笔记（一）：分布式系统基本概念和两三阶段提交]]></title>
    <link href="https://taozj.org/201611/learn-note-of-distributed-system-(1)-abstraction-and-2PC-3PC.html"/>
    <id>https://taozj.org/201611/learn-note-of-distributed-system-(1)-abstraction-and-2PC-3PC.html</id>
    <published>2016-11-09T14:30:48.000Z</published>
    <updated>2016-12-18T08:05:38.000Z</updated>
    <content type="html"><![CDATA[<p>　　现在觉得分布式系统比较的有意思，不是说这个概念流行时髦可以装逼，而是像Lamport爷爷在其论文中所描述的那样，分布式系统更像是一个场景，一个民主性团体协作的过程。在这个分布式的群体中，任何一个角色都有自己的行为，都可能出错，都可能无法跟别人通信，都有可能网络分区“脑裂”，也都有可能会死掉，分布式系统让我们的眼界从原先的单个人，扩展到一个社会团体了。<br>　　大名鼎鼎的分布式锁Google Chubby的作者Mike Burrows说过：“这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品！”Paxos在当前的生产环境中获的了巨大的成功，或许真的学了他就不用学别的分布式协议了，不过整个分布式系统中的概念、观念和涉及到的问题还是要了解一下的。<br>　　同时，后续Paxos的学习打算从微信团队的PhxPaxos入手，主要考虑到的是：他们声称基于Paxos Made Simple进行工程化，不进行任何算法变种，所以代码学习研究会比较的原汁原味；资料比较多比较详细，偶尔还会有相关更新资料放出；通过微信的生产环境进行验证，说明比较肯定稳定、可靠和高效；其实后面看了写些Google Chubby信息，感觉PhxPaxos工程实现中遇到的问题和解决的思路跟Chubby大部分比较相似，所以这些共性的东西跟谁学都没有太大的差异。</p>
<h1 id="一、基础预备知识">一、基础预备知识</h1><h2 id="1-1_事务极其ACID特性">1.1 事务极其ACID特性</h2><p>　　分布式系统中的事务(Transaction)是对系统中数据进行访问和更新操作所组成的程序执行逻辑单元，事务的应当具有四个特征ACID：原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability)。<br>　　原子性保证事务是一个不可分割的单位，事务中的操作要么全部成功执行，要么都不执行；一致性保证数据库中只能包含成功的事务提交的结果，从一个成功状态变更到另外一个成功状态；隔离性用于控制并发环境中事务之间的干扰关联程度；持久性一般是数据落盘，在提交后其修改应该是永久的，在宕机或者重启后数据能重新被恢复到成功结束的状态。<br>　　对于隔离性，标准SQL规范中定义了四种事务隔离级别：<br>　　(1). <strong>未授权读取</strong>：也称为读未提交(Read Uncommitted)，该隔离允许脏读，可以读到别的事务执行中任何可能的未提交中间状态，事务可以读取未提交的数据，这也被称为脏读。未提交读从性能上不会比其他级别好太多，但是缺乏其他级别的很多好处，在实际应用中一般很少使用；<br>　　(2). <strong>授权读取</strong>：也称为读已提交(Read Committed)，一个事务开始时只能“看见”已经提交的事务所做的修改，授权读取允许不可重复读取，因为两次执行同样的查询，可能会得到不一样的结果。这是除MySQL之外大多数数据库(SQL Server, Oracle)的默认隔离级别；<br>　　(3). <strong>可重复读取</strong>：(Repeatable Read)保证在一个事务处理的过程中如果多次读取同一个数据时，其值都跟事务开始时候是一致的，该事务级别禁止了不可重复读和脏读，但是可能会出现幻读(Phantom Read)。不可重复读和幻读还是有一定差异的，一般前者是update修改数据体现的差异，后者是在insert、delete时候体现出来的差异，比如范围查询的记录数在别的事务插入或者删除记录的时候会变得不一致；<br>　　(4). <strong>串行化</strong>：(Serializable)最高的隔离级别，其要求所有的事务都串行化执行，可以避免幻读问题。其会极大影响数据库的并发性能。</p>
<h2 id="1-2_CAP理论和BASE理论">1.2 CAP理论和BASE理论</h2><h3 id="1-2-1_CAP理论(布鲁尔定理)">1.2.1 CAP理论(布鲁尔定理)</h3><p>　　一个分布式系统不可能同时满足一致性(Consistency)、可用性(Availability)和分区容错性(Partition tolerance)这三个基本要求，最多只能同时满足其中的两项。<br>　　(1). <strong>一致性</strong>：指的在分布式环境下数据在多个副本之间是否能够保持一致性，如果针对数据项的更改操作执行成功后，所有的用户都可以读到其最新值，那么这个系统被认为是强一致性的。<br>　　(2). <strong>可用性</strong>：对于用户的每一个操作请求，都能够在有限的时间内返回结果。<br>　　(3). <strong>分区容错性</strong>(容忍网络分区)：分布式系统在遇到任何网络分区故    障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。<br>　　对于CAP理论的实践中，既然是分布式系统肯定要满足P，所以很多分布式系统的架构设计通常是根据业务类型是在A可用性和C一致性上面做出平衡的结果，这里的C一致性不是说放弃一致性，因为放弃一致性数据错误了整个系统就没有意义了，而是说放弃实时的强一致性，但是保证数据的最终一致性，需要到达最终一致性需要一个时间窗口，用于各个数据副本之间同步。<a id="more"></a></p>
<h3 id="1-2-2_BASE理论">1.2.2 BASE理论</h3><p>　　BASE理论是CAP中一致性和可用性互相权衡的结果，代表着：Basically Available(基本可用)、Soft State(软状态)、Eventually Consistent(最终一致性)，表明分布式系统即使无法做到强一致性，但是每个应用都可以根据业务的特点，采用适当的方式来使系统达到最终一致性。<br>　　(1). <strong>基本可用</strong>(Basically Availble)：当出现不可预知的故障的时候，允许在响应时间、或者功能上有所损失，核心功能仍然可用；<br>　　(2). <strong>弱状态</strong>(Weak State)：也称为软状态，指的允许系统中的数据存在中间状态，并认为该中间状态不会影响到系统整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时；<br>　　(3). <strong>最终一致性</strong>(Eventual Consistency)：强调系统中所有的数据副本，在经过一段时间的同步之后，最终总能够达到一个一致性的状态，其不需要实时保证系统数据的强一致性；在工程实践中最终一致性存在以下变种，他们可以按照需要自由组合搭配，以设计实现出最终一致性的分布式系统：<br>　　a. <strong>因果一致性</strong>(Causal Consistency)：如果进程A在更新完某个数据项之后通知了进程B，那么进程B之后对数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B对数据项进行更新的话，也是基于A更新后的最新值，不会发生丢失更新的状况。此外，与进程A无因果关系的进程C访问该数据没有任何限制；<br>　　b. <strong>读己之所写</strong>(Read Your Writes)：进程A更新一个数据项之后，它自己总能够访问到更新后的最新值；<br>　　c. <strong>会话一致性</strong>(Session Consistency)：会话一致性将对系统数据的访问框定在一个会话当中，系统能够保证在同一个有效的会话中实现“读己之所写”的一致性，执行更新操作之后客户端能够在同一个会话中始终读到该数据项的最新值；<br>　　d. <strong>单调读一致性</strong>(Monotonic Read Consistency)：如果进程从系统中读出一个数据项的某个值之后，那么系统对于该进程后续的任何数据操作都不应该返回更旧的值；<br>　　e. <strong>单调写一致性</strong>(Monotonic Write Consistency)：一个系统需要能够保证来自同一个进程的写操作都是被顺序执行的。</p>
<h1 id="二、两阶段提交">二、两阶段提交</h1><p>　　分布式系统中最经典的就是二阶段提交协议、三阶段提交协议和Paxos算法了。设计出这些协议的主要原因，就是在分布式系统中，每个节点可以知道自己在事务操作的过程中是成功还是失败，但是无法知道其他分布式节点的操作结果。传统上就是产生一个协调者Coordinator来统一调度各个分布式节点的执行逻辑，其负责调度参与者的行为，并决定这些参与者是否要把事务进行提交。<br>　　目前大部分的<a href="https://docs.oracle.com/cd/B28359_01/server.111/b28310/ds_txns003.htm#ADMIN12222" target="_blank" rel="external">数据库</a>都是采用二阶段提交协议来完成分布式事务处理的。</p>
<h2 id="2-1_事务执行过程">2.1 事务执行过程</h2><h3 id="2-1-1_阶段一：提交事务请求(Commit_request)">2.1.1 阶段一：提交事务请求(Commit request)</h3><p>　　(1). <strong>事务询问</strong>：协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待所有参与者的回应；<br>　　(2). <strong>执行事务</strong>：各参与者执行事务操作直到可以提交的点后暂停，并将Undo和Redo信息记入事务日志中；<br>　　(3). <strong>各参与者向协调者反馈事务询问的结果</strong>：如果参与者成功执行了事务操作，则反馈给协调者YES响应，表示事务可以执行，如果参与者没有成功执行事务，那么反馈给协调者NO响应，表示事务不可以执行；</p>
<h3 id="2-1-2_阶段二：执行事务提交(Commit_phase)">2.1.2 阶段二：执行事务提交(Commit phase)</h3><p>　　协调者会根据参与者反馈的情况来决定最终是否可以执行事务提交操作，正常情况包括如下两种情况：<br>　　(1). <strong>执行事务提交</strong>：假如协调者从所有的参与者获得的反馈都是YES响应<br>　　a. <strong>发送提交请求</strong>；协调者向所有参与者发出Commit信息；<br>　　b. <strong>事务提交</strong>：参与者收到Commit请求后，会正式执行事务提交操作，并在完成提交后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务提交结果</strong>：参与者在完成事务提交之后，向协调者发送Ack消息；<br>　　d. <strong>完成事务</strong>：协调者收到所有Ack消息后，完成事务。<br>　　(2). <strong>中断事务</strong>：任何一个参与者向协调者反馈了NO响应，或者在等待超时之后，协调者尚无接收到所有参与者的反馈响应，那么就会中断事务<br>　　a. <strong>发送回滚请求</strong>：协调者向所有参与者节点发送Rollback请求；<br>　　b. <strong>事务回滚</strong>：参与者收到Rollback请求后，会利用在阶段一种记录的Undo日志信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用锁和其他事务资源；<br>　　c. <strong>反馈事务回滚结果</strong>：参与者在完成事务回滚之后，向协调者发送Ack消息；<br>　　d. <strong>中断事务</strong>：协调者收到所有参与者反馈的Ack消息后，完成事务中断；</p>
<h2 id="2-2_2PC的优缺点">2.2 2PC的优缺点</h2><p>　　(1). <strong>优点</strong>：原理简单、实现方便，而且是强一致性算法。<br>　　(2). <strong>缺点</strong>：同步阻塞、单点问题、脑裂、太过保守。<br>　　a. <strong>同步阻塞</strong>：最严重的问题，会极大限制分布式系统的性能，当参与者向协调者发送投票信息后，必须阻塞等待直到收到commit/rollback命令；<br>　　b. <strong>单点问题</strong>：一旦协调者出现问题，整个2PC都无法运转，而且如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态当中；<br>　　c. <strong>数据不一致</strong>：当协调者向所有参与者发送Commit请求后如果部分协调者因为问题没有执行Commit，那么就会使得整个分布式系统出现数据不一致的情况；<br>　　d. <strong>太过保守</strong>：没有完善的容错机制，任意一个参与者节点的问题都会导致整个事务的失败；</p>
<h1 id="三、三阶段提交">三、三阶段提交</h1><p>　　将原先的事务拆分成canCommit、preCommit 和DoCommit三个阶段组成。</p>
<h2 id="3-1_事务执行过程">3.1 事务执行过程</h2><p><img src="/post_images/images/201611/f2f443bf6560482a3a4dd3eeb002bedb.png" alt="3PC"></p>
<h3 id="3-1-1_阶段一：CanCommit">3.1.1 阶段一：CanCommit</h3><p>　　(1). <strong>事务询问</strong>：协调者向所有的参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务的提交操作，并开始等待各参与者的响应；<br>　　(2). <strong>各参与者向协调者反馈事务询问的响应</strong>：参与者收到canCommit请求后，正常情况下如果其自身认为可以顺利执行事务，则反馈给协调者YES响应，并进入预备状态，否则反馈给协调者NO响应；</p>
<h3 id="3-1-2_阶段二：PreCommit">3.1.2 阶段二：PreCommit</h3><p>　　协调者会根据各参与者的反馈情况决定是否可以执行事务的preCommit操作，正常情况下，可能包含两种情况<br>　　(1). <strong>执行事务提交</strong>：协调者从所有的参与者获得的反馈都是YES响应<br>　　a. <strong>发送预提交请求</strong>：协调向所有参与者节点发出preCommit请求，并进入Prepared阶段；<br>　　b. <strong>事务预提交</strong>：参与者收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中；<br>　　c. <strong>各参与者向协调者反馈事务执行的响应</strong>：如果参与者成功执行了事务操纵，那么就反馈协调者ACK响应，同时等待最终指令：Commit或者Abort；<br>　　(2). <strong>中断事务</strong>：任何一个参与者反馈了NO响应，或者在等待超时之后，协调者尚不能收到所有参与者的反馈响应，就会中断事务<br>　　a. <strong>发送中断请求</strong>：协调者向所有参与者发出Abort请求；<br>　　b. <strong>中断事务</strong>：无论收到来自协调者的Abort请求，或者在等待协调者请求过程中出现超时，参与者都会中断事务；</p>
<h3 id="3-1-3_阶段三：doCommit">3.1.3 阶段三：doCommit</h3><p>　　该阶段是真正的事务提交，有两种情况<br>　　(1). <strong>执行提交</strong>：<br>　　a. <strong>发送提交请求</strong>：假设协调者处于正常状态，并且收到了来自所有参与者的ACK响应，那么它将从预提交状态切换到提交状态，并向所有的参与者发送doCommit请求；<br>　　b. <strong>事务提交</strong>：参与者收到doCommit请求之后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务提交结果</strong>：参与者完成事务提交之后，向协调者发送ACK消息；<br>　　d. <strong>完成事务</strong>：协调者收到所有参与者Ack消息后，事务结束。<br>　　(2). <strong>中断事务</strong>：假设协调者处于正常工作状态，并且有任意一个参与者向协调者发送了NO响应，或者在等待超时之后协调和尚无法收到所有参与者的反馈响应，那么就会中断事务<br>　　a. <strong>发送中断请求</strong>：协调者向所有参与者发送Abort请求；<br>　　b. <strong>事务回滚</strong>：参与者接收到Abort请求后，会利用其在阶段二中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务回滚结果</strong>：参与者在事务回滚之后，向协调者发送Ack信息；<br>　　d. <strong>中断事务</strong>：协调者收到所有参与者反馈的Ack消息后，中断事务。<br>　　需要注意的是，一旦进入阶段三，可能会出现两种故障：协调者故障或者协调者和参与者之间的网络通信出现故障，无论如何都会导致参与者无法及时收到来自协调者的doCommit或Abort请求，针对这种情况，只要参与者收到了preCommit命令，在参与者在等待超时之后如果还没有收到协调者的指令，会默认继续进行事务提交。</p>
<h2 id="3-2_3PC的优缺点">3.2 3PC的优缺点</h2><p>　　3PC的针对2PC的主要优化有：事先不申请资源的情况下进行preCommit演练，此处成功后续事务成功执行的可能性也会比较大；3PC是非阻塞的协议，在第三阶段如果参与者在时间窗口之内没有收到协调者的命令，会默认进行提交；<br>　　(1). <strong>优点</strong>：降低了参与者的阻塞范围，能够在出现单点故障后继续达成一致；<br>　　(2). <strong>缺点</strong>：在解决2PC的阻塞问题时候引入了新的问题，就是在参与者收到preCommit之后如果网络出现分化，此时协调者所在的节点和参与者无法进行正常的网络通信，此时参与者依然会进行事务的提交，很有可能会出现数据不一致的情况。同时3PC需要进行三次的消息传递，性能会有所影响。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/wiki" target="_blank" rel="external">phxpaxos wiki</a></li>
<li><a href="http://www.cnblogs.com/arccosxy/p/3986115.html" target="_blank" rel="external">数据库高分笔记02：隔离级别</a></li>
<li><a href="http://coolshell.cn/articles/10910.html" target="_blank" rel="external">分布式系统的事务处理</a></li>
<li><a href="https://docs.oracle.com/cd/B28359_01/server.111/b28310/ds_txns003.htm#ADMIN12222" target="_blank" rel="external">Two-Phase Commit Mechanism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol" target="_blank" rel="external">Two-phase_commit_protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol" target="_blank" rel="external">Three-phase_commit_protocol</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　现在觉得分布式系统比较的有意思，不是说这个概念流行时髦可以装逼，而是像Lamport爷爷在其论文中所描述的那样，分布式系统更像是一个场景，一个民主性团体协作的过程。在这个分布式的群体中，任何一个角色都有自己的行为，都可能出错，都可能无法跟别人通信，都有可能网络分区“脑裂”，也都有可能会死掉，分布式系统让我们的眼界从原先的单个人，扩展到一个社会团体了。<br>　　大名鼎鼎的分布式锁Google Chubby的作者Mike Burrows说过：“这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品！”Paxos在当前的生产环境中获的了巨大的成功，或许真的学了他就不用学别的分布式协议了，不过整个分布式系统中的概念、观念和涉及到的问题还是要了解一下的。<br>　　同时，后续Paxos的学习打算从微信团队的PhxPaxos入手，主要考虑到的是：他们声称基于Paxos Made Simple进行工程化，不进行任何算法变种，所以代码学习研究会比较的原汁原味；资料比较多比较详细，偶尔还会有相关更新资料放出；通过微信的生产环境进行验证，说明比较肯定稳定、可靠和高效；其实后面看了写些Google Chubby信息，感觉PhxPaxos工程实现中遇到的问题和解决的思路跟Chubby大部分比较相似，所以这些共性的东西跟谁学都没有太大的差异。</p>
<h1 id="一、基础预备知识">一、基础预备知识</h1><h2 id="1-1_事务极其ACID特性">1.1 事务极其ACID特性</h2><p>　　分布式系统中的事务(Transaction)是对系统中数据进行访问和更新操作所组成的程序执行逻辑单元，事务的应当具有四个特征ACID：原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability)。<br>　　原子性保证事务是一个不可分割的单位，事务中的操作要么全部成功执行，要么都不执行；一致性保证数据库中只能包含成功的事务提交的结果，从一个成功状态变更到另外一个成功状态；隔离性用于控制并发环境中事务之间的干扰关联程度；持久性一般是数据落盘，在提交后其修改应该是永久的，在宕机或者重启后数据能重新被恢复到成功结束的状态。<br>　　对于隔离性，标准SQL规范中定义了四种事务隔离级别：<br>　　(1). <strong>未授权读取</strong>：也称为读未提交(Read Uncommitted)，该隔离允许脏读，可以读到别的事务执行中任何可能的未提交中间状态，事务可以读取未提交的数据，这也被称为脏读。未提交读从性能上不会比其他级别好太多，但是缺乏其他级别的很多好处，在实际应用中一般很少使用；<br>　　(2). <strong>授权读取</strong>：也称为读已提交(Read Committed)，一个事务开始时只能“看见”已经提交的事务所做的修改，授权读取允许不可重复读取，因为两次执行同样的查询，可能会得到不一样的结果。这是除MySQL之外大多数数据库(SQL Server, Oracle)的默认隔离级别；<br>　　(3). <strong>可重复读取</strong>：(Repeatable Read)保证在一个事务处理的过程中如果多次读取同一个数据时，其值都跟事务开始时候是一致的，该事务级别禁止了不可重复读和脏读，但是可能会出现幻读(Phantom Read)。不可重复读和幻读还是有一定差异的，一般前者是update修改数据体现的差异，后者是在insert、delete时候体现出来的差异，比如范围查询的记录数在别的事务插入或者删除记录的时候会变得不一致；<br>　　(4). <strong>串行化</strong>：(Serializable)最高的隔离级别，其要求所有的事务都串行化执行，可以避免幻读问题。其会极大影响数据库的并发性能。</p>
<h2 id="1-2_CAP理论和BASE理论">1.2 CAP理论和BASE理论</h2><h3 id="1-2-1_CAP理论(布鲁尔定理)">1.2.1 CAP理论(布鲁尔定理)</h3><p>　　一个分布式系统不可能同时满足一致性(Consistency)、可用性(Availability)和分区容错性(Partition tolerance)这三个基本要求，最多只能同时满足其中的两项。<br>　　(1). <strong>一致性</strong>：指的在分布式环境下数据在多个副本之间是否能够保持一致性，如果针对数据项的更改操作执行成功后，所有的用户都可以读到其最新值，那么这个系统被认为是强一致性的。<br>　　(2). <strong>可用性</strong>：对于用户的每一个操作请求，都能够在有限的时间内返回结果。<br>　　(3). <strong>分区容错性</strong>(容忍网络分区)：分布式系统在遇到任何网络分区故    障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。<br>　　对于CAP理论的实践中，既然是分布式系统肯定要满足P，所以很多分布式系统的架构设计通常是根据业务类型是在A可用性和C一致性上面做出平衡的结果，这里的C一致性不是说放弃一致性，因为放弃一致性数据错误了整个系统就没有意义了，而是说放弃实时的强一致性，但是保证数据的最终一致性，需要到达最终一致性需要一个时间窗口，用于各个数据副本之间同步。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[浅谈多进程程序的进程控制和管理方式]]></title>
    <link href="https://taozj.org/201611/about-multi-process-thread-dev-manage.html"/>
    <id>https://taozj.org/201611/about-multi-process-thread-dev-manage.html</id>
    <published>2016-11-07T14:38:42.000Z</published>
    <updated>2017-02-05T07:45:39.000Z</updated>
    <content type="html"><![CDATA[<p>　　多线程程序、多进程程序是当前单机应用常用并行化的手段，线程是可以直接被CPU调度的执行单元，虽然多进程程序中每个进程也可以是多线程的，但是本文主要讨论的多进程程序默认是每个进程都有一个单独线程的情况。多线程程序和多进程程序，涉及到的线程间和进程间的通信、同步原语基本都是相同的，所以两者的开发在一定程度上有着高度的相似性，但同时差异化也十分的明显，所以高性能程序使用多线程还是多进程实现常常也是争论的焦点。<br>　　虽然自己之前开发的程序基本都是基于pthreads和C++ std::thread的多线程程序，但是多进程程序还是有它相应的用武之地的，比如大名鼎鼎的Nginx中master和worker机制就是采用多进程的方式实现的，所以这里也对多进程和多线程程序的区别联系整理一下，最后顺便看看Nginx中master和worker进程的管理和实现机制，在后续开发多进程程序的时候可以直接借鉴使用。</p>
<h1 id="一、多线程和多进程程序">一、多线程和多进程程序</h1><p>　　Linux中有一句耳熟能详的话——线程被认为是轻量级的进程，在现代操作系统的概念中，进程被认为是资源管理的最小单元，而线程被认为是程序执行的最小单元，所以多线程和多进程之间的差异基本体现在执行单元之间对资源耦合度的差异。虽然对于用户空间而言，最为广为使用的pthreads线程库提供了自己一套线程创建和管理、线程间同步接口，其实在Linux下面创线程和创建进程都是使用clone()系统调用实现的，只是在调用参数(flags)上不同，导致创建的执行单元具有不一样的资源共享情况，从而造就了线程和进程实质上的差异。<br><img src="/post_images/images/201611/22fcba011a0b363f047b1d5cc28e75f9.jpg" alt="线程和进程"></p>
<h2 id="1-1_多线程的特点_multi-threaded">1.1 多线程的特点 multi-threaded</h2><p>　　从上面的图中看出，同一个进程中的多个线程，跟执行状态相关的资源都是独立的，比如：运行栈、优先级、程序计数器、信号掩码等都是独立的，而打开的文件描述符(包含套接字)、地址空间(除了函数中的自动变量属于栈管理，还有新提出来的线程局部变量，其它基本都是共享的)都是共享的。这里还设计到信号处理句柄、信号掩码等，因为在多线程中信号的问题比较的复杂，后面单独列出来解释。<br>　　共享相同的地址空间、文件描述符给程序的开发带来了极大的便利，创建多线程的开销要小的多，而且在运行中任务切换损失也很小，很多的缓存都维持有效的，还有比如负责套接字listen的线程和工作线程之间可以方便的传递网络连接创建的套接字，生产线程和消费线程可以方便的用队列进行数据交换，程序设计也可以特化出日志记录、数据落盘等工作线程各司其职。但是天下没有免费的午餐，任何的便利都是需要付出代价的，多个执行单元可以访问资源意味着共享资源必须得到保护和同步，这是多线程程序设计不可回避的问题：<br>　　(1). 多个线程可以安全的访问只读的资源，但是哪怕只有一个修改者也是不安全的，额外说一句，我们说的保护是保护的资源，而不是行为；<br>　　(2). 传统很多库函数都不是线程安全的，这些函数当初设计的时候没有考虑到多线程的问题，所以使用了大量的全局变量和静态局部变量，这些函数是不可重入的。所以在你调用库函数、链接别人库的时候，一定要看看有没有”_r”后缀的版本；<br>　　(3). 还要就是之前不断被提到的内存模型，因为同个进程中的多个线程可能会并行的执行，这时候如果在线程之间有高速度的数据同步需求的时候，必须让资源的更新能够及时地被别的线程感知到；<br>　　(4). 多线程程序正因为线程之间共享的资源太多，所以如果一个线程出现严重的问题，其余的线程也会被杀死。遥想当年在TP-LINK的时候，所有的服务功能都以线程的形式被包裹在一个用户进程中，某个模块出现问题都可能导致上不了网需要重启，所以现在看来稳定运行的TP-LINK路由器不得不说是一个奇迹~ <a id="more"></a></p>
<h2 id="1-2_多进程的特点_multi-process">1.2 多进程的特点 multi-process</h2><p>　　多进程程序之间保证了资源的高度隔离，只在创建出来的父子进程之间有少量的联系，进程组、回话等就不在此讨论了。<br>　　这个时候需要共享的资源必须显式共享，虽然操作系统优化机制可以让他们的只读数据(比如执行代码)物理上共享，进程间的资源共享或者通过关联到文件系统的某个路径或者文件，或者通过全局字符串名字方式，通过以某个进程首先创建资源，其他进程打开资源的方式共享。由于历史原因，Linux进程间通信通常包含SYS V和Posix两套接口，其种类和功能大同小异，但是个人的实际感受Posix的操作接口要更加的好用一些。<br>　　Linux进程间通信通常用到的方法有：匿名管道、命名管道、信号、消息队列、共享内存、信号量和套接字，其中匿名管道只用于有亲属关系的父子进程之间的一种单功通信方式，在fork()创建进程之前创建匿名管道。其中个人用的最多的是命名管道、共享内存和信号量：命名管道由于返回的文件描述符，可以十分方便的融合到现有的select/poll/epoll框架下面去；信号量主要用于模拟进程间互斥的行为；共享内存用于进程间大规模的数据共享。陈硕的一句名言就是“在多进程之间共享内存无异于掩耳盗铃”，其实多进程间通过共享内存的方式共享数据弊端和限制确实很多：首先共享内存中不能共享指针，而指向共享内存段本身的指针也最好用便宜的方式退化指针；如果共享内存的数据经常会被修改，那更是个灾难。当然简单只读数据是可以的，比如Nginx的缓存也使用了共享内存。<br>　　多进程程序的好处，就是消除了进程之间的耦合度后，操作系统的保护机制可以让多个进程更加的独立可靠，而且分成多个进程之后管理进程比管理线程方便灵活的多；同时，多进程程序可以实现进程的特异化管理，比如在Nginx设计中master process是特权进程，可以读取配置文件、修改数重要数据等关键操作，而worker process是普通权限进程，只负责业务方面的处理，符合系统管理中的最小化权限原则；再有就是多进程程序可以进行业务的热更新平滑升级，下面的Nginx算是将这一功能使用的淋漓尽致啊。<br>　　但是多进程的程序也有个问题，就是很多共享的资源、同步的手段都是命名全局的，很有可能进程意外退出后这些资源都得不到回收，补救的办法只能是重启操作系统，汗~</p>
<h2 id="1-3_多线程程序和信号">1.3 多线程程序和信号</h2><p>　　感觉信号一直是Linux平台下开发比较头疼的问题，尤其对于多线程情况下的程序，信号的处理将更加的复杂。</p>
<h3 id="1-3-1_单线程程序中信号的处理方式">1.3.1 单线程程序中信号的处理方式</h3><p>　　Linux中的信号的处理方式可以是SIG_IGN、SIG_DFL以及自己通过sigaction设置自定义处理函数，进程创建的时候信号都有默认的处理方式，而用户可以后续选择忽略、默认处理方式、自定义处理这些信号(SIGKILL、SIGSTOP两个信号只能默认处理方式，不能被忽略或者重定义处理)，当进程接收到信号的时候就会转向信号处理历程去执行。<br>　　信号可以在某些情况下被系统发送(比如触发段错误)，或者被别的进程使用kill发送，或者进程自己调用kill、raise系统调用触发信号。进程可以通过signal mask去block某些信号，默认情况下是没有信号被block的，此时如果被block的信号发送过来了，将会被设置为pending的，然后一旦该进程unblock了该信号，pending的信号将会立即被传递。</p>
<h3 id="1-3-2_pthreads库多线程环境对信号处理的方式">1.3.2 pthreads库多线程环境对信号处理的方式</h3><p>　　pthreads库多线程中信号处理的方式，和信号的种类、各个线程对信号的mask状态共同决定的。<br>　　Linux中多线程环境下信号的种类可以分为同步(Synchronously)信号和异步(Asynchronously)信号：同步信号是针对某个线程的，比如某个线程执行过程中除以零(SIGFPE)、访问非法地址(SIGSEGV)、使用了broken的管道(SIGPIPE)，这些信号都根某个特定的线程特定的执行上下文有关，还有就是同个进程中线程之间通过pthread_kill显式发送信号的情况；异步信号主要是其他进程向该进程通过kill向这个进程(而非其中的线程)发送信号，并不跟某个特定的线程相关联的情况。<br>　　pthreads库中多线程之间共享sigaction结构但是不共享sig_mask结构，这意味所有的线程共享相同的信号处理方式，而不论信号处理方式是谁设置的。进程在最初fork()后创建的第一个线程继承了其signal mask，而通过pthread_create创建的其他线程也继承了这个信号mask，后续可以通过pthread_sigmask接口控制本线程对某些信号的block或者unblock。<br>　　有了上面的知识，信号在多线程下的行为就可以被确定了：<br>　　(1). 所有的线程共享相同的sigaction，所以所有进程对某个信号的处理方式是完全相同的；<br>　　(2). 同步信号是针对某个特定线程的，该线程是否接收处理这个信号看其signal mask设置情况；<br>　　(3). 异步信号是针对这个进程的，当这种信号到达的时候，进程会从没有block这个信号的线程集合中随机选出一个出来处理这个信号，如果所有的线程都block该信号，那么这个信号将被pending起来，直到有线程unblock这个信号，就将其发送给那个线程处理。</p>
<h2 id="1-4_其他">1.4 其他</h2><p>　　由于在Linux下面创线程和创建进程是通过不同的参数使用clone()系统调用来实现的，Linux的线程本质上就是采用进程的方式实现的。在task_struct结构中就涉及到以下域：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">1592</span>         <span class="keyword">pid_t</span> pid;</div><div class="line"><span class="number">1593</span>         <span class="keyword">pid_t</span> tgid;</div></pre></td></tr></table></figure></p>
<p>　　pid是内核自己维护的进程号，tgid是用户空间可见的进程号，通过gettid()调用可以返回pid，而getpid()调用返回的是tgid。在clone()系统调用中，通过传递CLONE_THREAD参数，新进程的tgid会被设置成父进程的tgid，否则新进程的tgid会设为其自身的pid。<br>　　这就说明内核自己通过pid的方式，把用户看来的线程当作进程来管理；而同个进程的各个线程通过相同的tgid被逻辑上形成一个整体——线程组。</p>
<h1 id="二、master管理多个worker进程">二、master管理多个worker进程</h1><p>　　在Nginx的配置文件中有个条目worker_processes，其用于指定master进程可以产生几个worker进程，默认情况下是CPU执行单元的数目。在Linux下实验发现，当kill掉worker进程的时候，master进程会自动再次启动worker进程，但是当kill掉master进程的时候，worker进程仍然活着并向外提供服务，这种方式或许是对于常驻服务最好的处理语义：master进程存在的时候会保证设定数目的工作进程存在，而master进程挂掉的时候worker进程仍然继续服务，不会存在单点故障导致服务立即停止的情况。<br>　　其基本原理也很简单，这源于在Linux平台下，当子进程退出的时候，内核会向父进程发送SIGCHLD信号，父进程可以捕获这个信号，并通过wait系统调用搜集子进程退出的相关信息，此后子进程的资源会被相应的释放掉。因此，父进程可以通过接收信号的方式异步得到子进程退出的消息，并且适当安排创建工作者进程。<br>　　当然，这仅仅是一个小trick，探究一下，发现Nginx的设计中，尤其是多进程服务端程序的开发维护中，大有学问可以借鉴！同时还有一个跟Nginx关系十分密切，估计也是使用相同master-worker方式构建的多进程的构架的，那就是php-fpm。之所以说关系密切，就是因为Apache本身支持php的解析，而Nginx只能通过外挂的方式，而挂件最常见的恰巧就是php-fpm了，通过ps查看，其也像是master-worker的结构，不过没看代码尚且不敢断定。<br><img src="/post_images/images/201611/e1d0cda50c4a1d7c54969d6895805fa6.gif" alt="NginxExt"></p>
<h2 id="2-1_跟踪环境的配置">2.1 跟踪环境的配置</h2><p>　　不知道啥时候，自己都快成了代码控了，GitHub上面一些感兴趣的项目代码都会clone下来并不断pull跟踪，nginx就是其中之一啊。调试环境设置很简单，只是有些点需要额外注意一下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">root@srv:~/nginx<span class="comment"># apt-get install libpcre3-dev zlib1g-dev</span></div><div class="line">root@srv:~/nginx<span class="comment"># auto/configure --with-debug</span></div><div class="line">root@srv:~/nginx<span class="comment"># make</span></div></pre></td></tr></table></figure></p>
<p>　　上面configure的时候一定要添加–with-debug参数，这个时候可以让可执行程序支持生成debug的log信息，同时如果是MacOS的系统的话，还需要事先用homebrew安装gcc，然后添加–with-cc=/usr/local/bin/gcc-5指定使用gcc编译器(后面有时间说是要折腾一下Clang的，而苹果xcode默认就是用的这货)，不过MacOS底层用的是kqueue而不是epoll，你应该知道我要说什么；make编译之后会在objs目录下面生成nginx可执行程序<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@srv:~/nginx<span class="comment"># mkdir logs</span></div><div class="line">root@srv:~/nginx<span class="comment"># objs/nginx -p .</span></div></pre></td></tr></table></figure></p>
<p>　　通过-p参数，可以避免使用默认系统路径的权限问题，以及对现有环境的干扰。此时进程全部转到后台执行了，更要命的是IDE的调试环境此处被断开失连了，所以需要在nginx.c中将系统初始化过程的ngx_daemon()注释起来，就可以正常断点跟踪了。<br>　　到此，Nginx的调试跟踪环境设置完成，设置conf/nginx.conf中log级别error_log  logs/error.log  debug;然后通过tail -f logs/error.log所有运行调试日志尽收眼底。</p>
<h2 id="2-2_多进程服务端程序设计">2.2 多进程服务端程序设计</h2><p>　　通过官网Nginx文档大致了解了一下他的构架，看的真是让人拍案叫绝大快人心，请待我慢慢道来。</p>
<h3 id="2-2-1_多进程下的套接字">2.2.1 多进程下的套接字</h3><p>　　传统上Nginx在启动开始的时候就bind一个地址进行listen，后续在fork()创建worker process的时候，这些进程是共享这个侦听套接字的，这个在linux fork()的手册中明确地被表示出了(PS:这里需要注意shutdown和close的区别，前者会主动进行拆链请求，后者会降低引用计数，shutdown在拆链后如果还有其他进程使用，那么读会返回EOF，写会引发SIGPIPE)</p>
<blockquote>
<p>The  child  inherits  copies  of the parent’s set of open file descriptors.  Each file descriptor in the child refers to the same open file description (see open(2)) as the corresponding file descriptor in the parent. The child inherits copies of the parent’s set of open message queue descriptors, open directory streams.</p>
</blockquote>
<p>　　所以master process创建出来的所有worker process都是可以accept()客户端请求的，当多个进程对同一个socket调用accept()接收连接的时候，他们都会把自己放到这个套接字的等待队列上面去，然后一旦有客户发起连接请求，这个队列上面等待的进程就会被唤醒，这个过程在之前分析epoll的时候就介绍过了，但是在较早的epoll版本中，上面的唤醒过程会产生惊群(Thundering Herd)的问题：即使只有一个连接请求到来，也会唤醒在这个共享侦听套接字上所有等待的进程，而所有进程争抢这个连接只有一个能获得连接，其他所有进程都无功而返，所以新版的epoll添加了EPOLLEXCLUSIVE这么一个新的flag，通过在EPOLL_CTL_ADD的时候使用，保证在事件就绪的时候不会产生惊群的问题。<br>　　Nginx对于共享accept套接字惊群问题的处理，有三个方法：<br>　　(1). accept_mutex = on<br>　　当这个选项打开的时候，worker process在其任务循环的时候，会首先通过ngx_trylock_accept_mutex去获得一个进程间的ngx_accept_mutex互斥锁，而该锁通常是使用文件锁来实现的。在持有这个锁的时候，首先收集底层就绪的事件，同时执行accept的所有回调，然后释放该锁，处理一般的非accept事件。<br>　　(2). accept_mutex = off<br>　　这个设置在较新版本的Nginx已经是默认关闭的，主要考虑到的是：一来通过EPOLLEXCLUSIVE、下面的SO_REUSEPORT等新技术可以避免accept的时候惊群的问题；另一方面Nginx采用基于事件的处理方式，worker process只有很少的几个，而不像Apache的技术Prefork很多的子进程，所以即使发生惊群对系统造成的影响也极为有限。<br>　　(3). reuseport<br>　　在Linux内核3.9的时候，内核Socket支持了SO_REUSEPORT选项，而Nginx在1.9版本中引入了这个选项，这样每个worker process都可以同时侦听同一个IP:Port地址，内核会发现哪些listener可用，从而自动将连接请求分配给给定的worker process，消除了Nginx传统上通过用户态采用accept_mutex互斥锁而带来的性能损耗问题。<br>　　上面三种方式的性能对比在官方也给出了<a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/" target="_blank" rel="external">测试结果</a>。</p>
<h3 id="2-2-2_基于事件的异步模型">2.2.2 基于事件的异步模型</h3><p>　　异步模型是新一代http服务器Nginx和老牌Apache最大的不同之处：<br>　　Apache采用的是Prefork技术，服务启动之后预先启动一定数目的子进程，当服务器压力增大的时候不断增加子进程的数目，而当服务器空闲后自动关闭一些子进程，虽然这种弹性常驻子进程比One Child per Client的模型要进步很多，但是经过这么久的多进程、协程开发技术的熏陶可知，子进程的增加只在一定范围内可以增加服务能力，同时子进程在进程切换、内存等方面会对服务器带来很大的压力，如果当连接客户达到C10K的时候其占用的资源是不可估量的。不过Apache 2.4版本具有线程、事件等特性，试图减少进程带来的巨额开销。<br>　　但是Apache毕竟是老牌的Web服务器，其扩展模块非常的多，可以直接解析执行各种脚本，而不需要CGI/FastCGI这类额外的支持，而且性机可能更好，所以常见的情况就是Apache做后端服务器，而Nginx做前端反向代理的设计模式。<br>　　Nginx采用的是基于事件驱动的模型来解决C10K问题，所以通常Nginx只需要启动很少(通常CPU执行单元个数)的worker process就可以同时服务大量连接，以至于越来越多的http服务器迁移到Nginx平台上面。其工作流程主要是：<br>　　当master process通过fork()创建出几个worker process的时候，worker process进程主执行函数为ngx_worker_process_cycle()，这里面除了检查各种状态标识(比如接受到父进程发送的信号后，设置ngx_terminate、ngx_quit、ngx_reopen等标识)作出特定行为外，其正事主要是通过ngx_process_events_and_timers处理事件：<br>　　此时如果accept_mutex==on，而当ngx_trylock_accept_mutex抢锁失败则直接返回，否则就会设置NGX_POST_EVENTS这个标识，表示事件的回调延后执行。因为我们要把持锁的临界区降低，所以在持锁的过程中，通过ngx_process_events(实质乃是ngx_epoll_module_ctx.actions)检查底层侦听套接字就绪的事件，根据epoll特性可以快速的收集就绪事件并添加到ngx_posted_accept_events和ngx_posted_events队列上去，执行ngx_posted_accept_events队列回调后释放锁，最后执行一般的事件回调操作。<br>　　如果accept_mutex==off，那么在ngx_process_events的过程中，事件的回调将会在搜集就绪事件的过程中同步执行。</p>
<h2 id="2-3_Nginx配置文件和二进制程序平滑升级">2.3 Nginx配置文件和二进制程序平滑升级</h2><p>　　Nginx中多进程之间将信号运用的活灵活现(Windows平台下没用借用信号的方式，而是用其特有的Event事件进行的通信)，使得Nginx可以在不间断服务的情况下进行配置文件，甚至是二进制文件的平滑升级操作，信号的含义可以参见ngx_config.h，信号处理参见ngx_process.c:ngx_signal_handler，在信号处理文件中其实也只是设置一些状态变量，然后在进程的时间循环中去执行相应的操作，比如向worker process发送特定信号、启动worker process等。</p>
<h3 id="2-3-1_Nginx配置文件平滑升级">2.3.1 Nginx配置文件平滑升级</h3><p>　　通过nginx –s reload或者直接kill -SIGHUP向Nginx master process发送信号，当master process接受到SIGHUP信号的时候：<br>　　a. 检查配置文件，然后打开新的listen socket和日志文件，如果失败则让old nginx继续执行，否则<br>　　b. 创建新的worker process，同时向old worker process发送信息，让他们graceful关闭，old worker process会关闭侦听套接字，服务已经连接的客户，当所有连接客户服务完了之后退出</p>
<h3 id="2-3-2_Nginx二进制程序平滑升级">2.3.2 Nginx二进制程序平滑升级</h3><p>　　将新的二进制文件拷贝覆盖原二进制执行文件，然后向master process发送SIGUSR2信号，当master process接收到该信号的时候：<br>　　a. 将pid文件重新命名为nginx.pid.oldbin<br>　　b. 执行新的可执行文件，按照常规的路径会产生new master process和new worker process，此时新老进程全部并存，并且全部正常工作——接受客户端连接请求和服务客户端<br>　　c. 向old master process发送SIGWINCH，其将会把自己所有的old master workers关闭，注意此时old master process的侦听套接字仍然工作的，必要时候还是会自动产生自己的worker process。调试新版本升级是否正常：如果正常就向old master process发送SIGQUIT，加上之前SIGWINCH工作所有的old process清理完毕；如果不正常，向old master process发送SIGHUP产生worker process，同时向new master process发送SIGTERM信号立即清理所有的new worker process，然后使用SIGKILL杀死new master process</p>
<h2 id="2-4_其它">2.4 其它</h2><p>　　Nginx这样的设计策略，在某些情况下也可能会出问题。<br>　　在Linux系统有一个重要参数/proc/sys/vm/overcommit_memory，当其值=0的时候表示采用启发式的内存管理，进程可以申请比当前空闲内存更多的内存需求，这主要是出于进程申请的内存很多情况下不会立即被使用，甚至在进程的整个生命周期也不会被用到，通过这种overcommit机制实际上是对内存资源最大化利用的一种优化，但是当进程的内存在需要使用的时候(兑现)可能会出现Out Of Memory的情况，此时操作系统就有这么一个机制：通过杀死一些普通进程来释放内存，以维持基本系统和大多数业务的正常运转，也是在极端情况下“弃车保帅、李代桃僵”的无奈之举，这种行为被称为OOM-killer。<br>　　此时需要牺牲哪个进程呢？内核有一套评分标准，进程的得分可以通过/proc/<pid>/oom_score来访问，针对这个分数的计算有两套标准：<br>　　<strong>早期内核</strong><br>　　早期内核会把进程内存空间大小(p-&gt;mm-&gt;total_vm)作为起始分数，然后通过进程的CPU使用时间(tms_utime+tms_stime)、进程的运行时间(jiffies - p-&gt;start_time)、进程的优先级调整值(nice)、进程的权限(root)、进程是否直接访问硬件(direct hardware access)来对这个points进行修正，以实现这样的一种选择模型：对已经完成的工作损失最小、可以获得大量的空闲内存、不会杀死虽然大量使用内存但是无辜的进程、尽量最小化牺牲进程的数目(最好是1个)。<br>　　内核采用/proc/<pid>/oom_adj接口来实现对最终badness的调整，实际是对badness()计算的结果采用bitshift移位的方式进行，其取值范围是-16~+15(-17表示将当前进程完全排除在kill候选之外)，当oom_adj&gt;0时，则badness&lt;&lt;=oom_adj，否则badness&gt;&gt;=-(oom_adj)。<br>　　<strong>当前内核</strong><br>　　当前内核对point的计算进行了简化重写，以实现更简单、更可预测性的启发式功能。其初始point值就是进程对应的RSS(Resident Set Size)+pagetable+swap space，然后通过进程的权限进行调整后就可以用了。这种方式得到的值采用原来oom_adj类似指数型的调整就不合适，所以内核提供了/proc/<pid>/oom_score_adj的接口进行线型调整，其取值范围为-1000~1000。<br>　　在父进程创建子进程的时候，前面的adj会被继承下去。</pid></pid></pid></p>
<p>　　在了解到上面的背景后，<a href="http://mogu.io/159-159" target="_blank" rel="external">文章</a>提到的现象也是可以理解的，Nginx创建的worker进程是非特权进程(运行时间短、内存消耗多)，很有可能在OOM情况下被牺牲，而master进程得知工作进程退出后，会尝试重建worker进程，于是上演了上面这么一出。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/nginx/nginx" target="_blank" rel="external">GitHub Nginx</a></li>
<li><a href="http://blogs.datalogics.com/2013/09/25/threads-vs-processes-for-program-parallelization/" target="_blank" rel="external">THREADS VS. PROCESSES FOR PROGRAM PARALLELIZATION</a></li>
<li><a href="http://elinux.org/images/1/1c/Ben-Yossef-GoodBadUgly.pdf" target="_blank" rel="external">On Threads, Processes and Co-Processes</a></li>
<li><a href="http://www.yolinux.com/TUTORIALS/LinuxTutorialPosixThreads.html" target="_blank" rel="external">POSIX thread (pthread) libraries</a></li>
<li><a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h033a/index.html" target="_blank" rel="external">Extending Traditional Signals</a></li>
<li><a href="http://maxim.int.ru/bookshelf/PthreadsProgram/htm/r_40.html" target="_blank" rel="external">Pthreads Programming Chapter 5 - Pthreads and UNIX Threads and Signals </a></li>
<li><a href="/201604/server-prog-port-from-windows-to-linux.html">Windows服务端程序向Linux平台移植事项</a></li>
<li><a href="http://blog.csdn.net/21aspnet/article/details/7420091" target="_blank" rel="external">深刻理解Linux进程间通信（IPC）</a></li>
<li><a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" target="_blank" rel="external">Inside NGINX: How We Designed for Performance &amp; Scale</a></li>
<li><a href="http://www.aosabook.org/en/nginx.html" target="_blank" rel="external">The Architecture of Open Source Applications – NGINX</a></li>
<li><a href="http://nginx.org/en/docs/control.html" target="_blank" rel="external">Controlling nginx</a></li>
<li><a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/" target="_blank" rel="external">Socket Sharding in NGINX Release 1.9.1</a></li>
<li><a href="http://linuxgazette.net/129/saha.html" target="_blank" rel="external">Issues In Concurrent Server Design on Linux Systems - Part I</a></li>
<li><a href="https://anturis.com/blog/nginx-vs-apache/" target="_blank" rel="external">Nginx vs Apache</a></li>
<li><a href="http://mogu.io/159-159" target="_blank" rel="external">Linux内核分析： OOM杀掉nginx后导致的系统hang问题</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　多线程程序、多进程程序是当前单机应用常用并行化的手段，线程是可以直接被CPU调度的执行单元，虽然多进程程序中每个进程也可以是多线程的，但是本文主要讨论的多进程程序默认是每个进程都有一个单独线程的情况。多线程程序和多进程程序，涉及到的线程间和进程间的通信、同步原语基本都是相同的，所以两者的开发在一定程度上有着高度的相似性，但同时差异化也十分的明显，所以高性能程序使用多线程还是多进程实现常常也是争论的焦点。<br>　　虽然自己之前开发的程序基本都是基于pthreads和C++ std::thread的多线程程序，但是多进程程序还是有它相应的用武之地的，比如大名鼎鼎的Nginx中master和worker机制就是采用多进程的方式实现的，所以这里也对多进程和多线程程序的区别联系整理一下，最后顺便看看Nginx中master和worker进程的管理和实现机制，在后续开发多进程程序的时候可以直接借鉴使用。</p>
<h1 id="一、多线程和多进程程序">一、多线程和多进程程序</h1><p>　　Linux中有一句耳熟能详的话——线程被认为是轻量级的进程，在现代操作系统的概念中，进程被认为是资源管理的最小单元，而线程被认为是程序执行的最小单元，所以多线程和多进程之间的差异基本体现在执行单元之间对资源耦合度的差异。虽然对于用户空间而言，最为广为使用的pthreads线程库提供了自己一套线程创建和管理、线程间同步接口，其实在Linux下面创线程和创建进程都是使用clone()系统调用实现的，只是在调用参数(flags)上不同，导致创建的执行单元具有不一样的资源共享情况，从而造就了线程和进程实质上的差异。<br><img src="/post_images/images/201611/22fcba011a0b363f047b1d5cc28e75f9.jpg" alt="线程和进程"></p>
<h2 id="1-1_多线程的特点_multi-threaded">1.1 多线程的特点 multi-threaded</h2><p>　　从上面的图中看出，同一个进程中的多个线程，跟执行状态相关的资源都是独立的，比如：运行栈、优先级、程序计数器、信号掩码等都是独立的，而打开的文件描述符(包含套接字)、地址空间(除了函数中的自动变量属于栈管理，还有新提出来的线程局部变量，其它基本都是共享的)都是共享的。这里还设计到信号处理句柄、信号掩码等，因为在多线程中信号的问题比较的复杂，后面单独列出来解释。<br>　　共享相同的地址空间、文件描述符给程序的开发带来了极大的便利，创建多线程的开销要小的多，而且在运行中任务切换损失也很小，很多的缓存都维持有效的，还有比如负责套接字listen的线程和工作线程之间可以方便的传递网络连接创建的套接字，生产线程和消费线程可以方便的用队列进行数据交换，程序设计也可以特化出日志记录、数据落盘等工作线程各司其职。但是天下没有免费的午餐，任何的便利都是需要付出代价的，多个执行单元可以访问资源意味着共享资源必须得到保护和同步，这是多线程程序设计不可回避的问题：<br>　　(1). 多个线程可以安全的访问只读的资源，但是哪怕只有一个修改者也是不安全的，额外说一句，我们说的保护是保护的资源，而不是行为；<br>　　(2). 传统很多库函数都不是线程安全的，这些函数当初设计的时候没有考虑到多线程的问题，所以使用了大量的全局变量和静态局部变量，这些函数是不可重入的。所以在你调用库函数、链接别人库的时候，一定要看看有没有”_r”后缀的版本；<br>　　(3). 还要就是之前不断被提到的内存模型，因为同个进程中的多个线程可能会并行的执行，这时候如果在线程之间有高速度的数据同步需求的时候，必须让资源的更新能够及时地被别的线程感知到；<br>　　(4). 多线程程序正因为线程之间共享的资源太多，所以如果一个线程出现严重的问题，其余的线程也会被杀死。遥想当年在TP-LINK的时候，所有的服务功能都以线程的形式被包裹在一个用户进程中，某个模块出现问题都可能导致上不了网需要重启，所以现在看来稳定运行的TP-LINK路由器不得不说是一个奇迹~]]>
    
    </summary>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="造轮子" scheme="https://taozj.org/tags/%E9%80%A0%E8%BD%AE%E5%AD%90/"/>
    
      <category term="运维" scheme="https://taozj.org/categories/%E8%BF%90%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[macOS新平台工作环境的设置和迁移]]></title>
    <link href="https://taozj.org/201611/transform-work-env-to-mac-os.html"/>
    <id>https://taozj.org/201611/transform-work-env-to-mac-os.html</id>
    <published>2016-11-07T14:29:23.000Z</published>
    <updated>2017-02-22T15:28:53.000Z</updated>
    <content type="html"><![CDATA[<p>　　感谢厨神Tim Cook在10月27日短暂而又精彩的MacBook Pro发布会，让我在期待了大半年之后，终于毫不犹豫地下单购买了2015年初期版本的老款Macbook Pro。新版Macbook Pro做的更加轻薄靓丽，无不彰显了Apple强大的工业设计能力，但是抛开缺了苹果标志的信仰灯不能装逼了暂且不说，Macbook Pro不仅仅是专供美工使用的，对于广大程序员同志而言缺失实体Esc和Fn键是不能容忍的，况且这次更新后处理器、内存方面并没有什么变更，对于实用主义者来说新款版本更新动力不大。<br>　　其实对于Linux平台的程序员而来，当经历过人生最能折腾的年代玩遍各大发行版之后，绝大多数人都投皈依到了MacOS的门下，而现在我就属于其中的一位，其中最主要的原因就是MacOS系统和Linux系统具有着极大的亲缘性，MacOS的很多组件都移植自开源的BSD系统，所以Linux程序员在MacOS下用Terminal会有十分亲切的感觉，同时对于原生没有打包进MacOS的软件和工具，外挂神器homebrew更是让其如虎添翼，基本Linux下的绝大多数软件包括gcc都可以一句命令安装，方便的不得了。除此之外就是MacOS系统良好的美学设计和极为完善的软件生态系统，大多Windows下的软件都有Mac的版本，更是可以让那些长久以往而来对Linux桌面怒其不争的人彻底摆脱双系统的困扰。<br>　　MacOS系统的软件，参见文章末尾的两个推荐链接就可以了。能力充裕财务自由的还是买正版吧，毕竟自己也是做软件的，破解软件虽然能省几个钱，有些需要打开系统安装未认证软件的权限，风险得失自己平衡。我把自己用到的软件罗列如下：</p>
<blockquote>
<p>　　Alfred3、iTerm、zsh、oh-my-zsh、搜狗输入法、WizNote、ShadowsocksX、WingIDE、Chrome、QQ、WeChat、SlickEdit、DropBox、Steam、KeePassX、VLC、ThunderBird、Sublime、Microsoft Office 2016、Photoshop CC、网易云音乐、Thunder、VMware Fusion、BetterZip、SecureCRT、Navicat Premium、iStat Menus、MacVim、Snip、MacDown、Moom、Adobe Acrobat Pro、CheetSheet、PopClip、CleanMyMac 3、Fantastical 2、Bartender 2、Dash、GnuPG2、Manico、Go2Shell</p>
</blockquote>
<p>　　当然上面的软件可能不是最优的，主要是以前一些常在Windows和Linux下面使用的软件保存了一些数据，如果换成别的软件数据的迁移会比较的麻烦，因此不是特别差的也将就着用了。<br>　　关于虚拟机，可能大家会疑惑，前面刚把万能的MacOS系统吹的天花乱坠兼容类Unix系统，有着类似Windows系统良好软件生态圈，为什么还是摆脱不了虚拟机的宿命呢？其实对于大多数不涉及系统级的开发，MacOS算是够用了，但是作为服务端开发的人，时常需要使用操作系统底层的异步特性，虽然select是Posix标准以至于连Windows都支持，但是对于高性能的异步构架却不然：Windows使用的I/O completion ports，BSD、MacOS使用的kqueue，Linux使用的epoll，基本是各自为政，所以要进行Linux的服务端软件开发调试，就不得不安装个虚拟机，然后再装一个原生的Linux操作系统才行。<a id="more"></a><br>　　MacOS下面的虚拟机算Parallels Desktop、Vmware Fusion、VirtualBox三分天下，VirtualBox据说其代码写的稀烂就PASS了，Parallels Desktop在苹果上使用的最为广泛，但是发现其对最新的Ubuntu 16.04 LTS支持的不好，最后就选择了Vmware Fusion了，其向来对Linux支持的最为完善，而且现在虚拟机的催化剂VMware Tools也已经交与社区维护了，所以现在各大主流的Linux发行版的官方仓库都集成了open-vm-tools-desktop软件包，可以一键虚拟机加速了，每个发行版都会对其进行测试验证，所以显然这样对Guest OS的支持是最优的了。<br>　　安装系统就不说了，需要注意的是：把虚拟机完全备份之后要排除在TimeMachine之外，否则很快你的备份硬盘就会被撑爆掉，其次Guest OS就不要开高分Retina分辨率了，虽说Ubuntu对高分屏支持的不错，但是你的显卡会爆掉的。这里主要讲究的是在MacOS和Linux之间通过NFS的方式共享文件，为啥选择NFS而不是CIFS或者vmhgfs，主要是因为NFS是类Unix下原生的东西，对Linux文件系统的特性和语义算是支持的最好的，操作如下：<br>　　(1). 在Host MacOS上面建立/etc/exports，并且导出自己想要共享出去的目录，后面-mapall是要共享出去的user和group。注意MacOS下面nfsd服务端文件共享的配置格式和Linux平台下是不一样的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  cat /etc/exports</div><div class="line">/Users/taozj/Dropbox/ReadTheCode/ -network 172.16.20.0 -mask 255.255.255.0 -mapall=taozj:staff:ubuntu</div><div class="line">/Users/taozj/Dropbox/GitHub/ -network 172.16.20.0 -mask 255.255.255.0 -mapall=taozj:ubuntu:staff</div><div class="line">➜</div></pre></td></tr></table></figure></p>
<p>　　(2). 让nfsd开启自动启动，然后每次修改了上面的/etc/exports，都可以用nfsd update进行刷新<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  sudo nfsd <span class="built_in">enable</span></div><div class="line">➜  sudo nfsd start</div><div class="line">➜  sudo nfsd update</div></pre></td></tr></table></figure></p>
<p>　　(3). 使用nfsd checkexports可以检查/etc/exports是否有配置错误，showmount -e列出本机成功共享出去的目录信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  nfsd checkexports</div><div class="line">➜  showmount <span class="_">-e</span></div><div class="line">Exports list on localhost:</div><div class="line">/Users/taozj/Dropbox/ReadTheCode    172.16.20.0</div><div class="line">/Users/taozj/Dropbox/GitHub         172.16.20.0</div></pre></td></tr></table></figure></p>
<p>　　(4). 这个时候可以在Linux平台命令行挂载是否成功，如果你是Ubuntu系统，你会看到共享过来的文件属主为(501,dialout)，那是因为在MacOS配置nfsd的时候使用的-mapall=taozj参数，我的用户taozj的uid和gid刚好是(501,20)，而Ubuntu上面默认第一个常规用户的uid是从1000开始的，而gid=20刚好代表dialout组，所以得到了这么个奇怪的用户所有者。解决的方法要么配置idmapd服务进行id映射，我就找了个简单的方法偷个懒，在Linux下面将当前用户的uid变成和MacOS一样的501<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># usermod -u 501 user</span></div><div class="line">root@ubuntu:~<span class="comment"># usermod -a user -G dialout</span></div></pre></td></tr></table></figure></p>
<p>　　通过这个操作，用户user的uid将会从1000变成现在的501，同时/home/user目录下的所有文件的属主也会自动被修改，其他位置的文件可能需要手动chown操作，挂载测试是否成功，读写是否正常，没有问题的话就可以写入/etc/fstab中开机自动挂载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">172.16.20.1:/Users/taozj/Dropbox/ReadTheCode/	/home/user/MacOS/ReadTheCode	nfs	auto,rw,noatime,nolock,intr,tcp,actimeo=1800	0	0</div><div class="line">172.16.20.1:/Users/taozj/Dropbox/GitHub/	/home/user/MacOS/GitHub		nfs	auto,rw,noatime,nolock,intr,tcp,actimeo=1800	0	0</div></pre></td></tr></table></figure></p>
<p>　　然后在网络上无意中浏览到了MacOS移植了BSD的xhyve容器库，不知道怎么样，玩容器的伙伴又可以摆弄了。<br>　　电脑买回来预装的EI Caption，用着这个版本也好，因为每次苹果系统的升级都会修复旧款设备运行过于流畅的Bug，况且据说新版的macOS Sierra软件兼容性和其他稀奇古怪的问题之多多，本人也就懒得升级了。工作环境的切换真心费神费力，希望这次入驻Mac平台后，Dropbox和TimeMachine能够保平安，让我把有限的精力投入到更加有意义的事情上去。</p>
<p>　　MacOS平台软件推荐帖<br>　　<a href="http://miao.hu/2012/02/26/osx-exp-share/" target="_blank" rel="external">http://miao.hu/2012/02/26/osx-exp-share/</a><br>　　<a href="https://github.com/hzlzh/Best-App" target="_blank" rel="external">https://github.com/hzlzh/Best-App</a><br>　　[系统设计推荐<br>　　<a href="http://www.codeceo.com/article/programmer-macbook-workplace.html" target="_blank" rel="external">http://www.codeceo.com/article/programmer-macbook-workplace.html</a><br>　　<a href="http://sourabhbajaj.com/mac-setup/" target="_blank" rel="external">Mac OS X Setup Guide</a></p>
<p>　　PS:用了一段时间，发现坑点还是蛮多的。虽然说Terminal支持很多Unix的工具，但是有的工具还是跟Linux有所差别，可能是因为苹果是BSD系的吧，当初耍FreeBSD的时候就遇到过类似的问题。默认的编译器是Clang，编译最新的Boost还是会出现这样那样的问题，想把默认编译器换成homebrew安装的gcc-5.4.0，但是貌似做不到，哭。。。<br>　　此外，大多数的软件对gcc支持好，但是Clang就不一定了，比如最新upstream在Linux用gcc编译重来没出现过问题，但是Apple Clang一直都有问题，最后切换到boost-1.62.0发布版本才可以。<br>　　虽然买的256G硬盘，另外扩充了一个Jet Drive 128G，空间是够用的，但是发现开启虚拟机还是内存压力很大的说。</p>
<p>　　PS：上班的时候，需要使用Windows电脑但是又想工作内容都在网盘中，这时候最简单的方法就是把Windows当作共享服务器，然后Linux挂载共享分区到自己的路径中。因为Windows对CIFS的支持算是最好的，Windows导出共享文件夹也是极为的简单，而且Linux作为客户端挂在也毫无压力：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ id taozj </div><div class="line">uid=1007(taozj) gid=1007(taozj) groups=1007(taozj)</div><div class="line">➜  ~ mkdir remote_build</div><div class="line">➜  ~ sudo mount -t cifs //192.168.1.194/Users/taozj/Dropbox/BitBucket/v5kf_dev /home/taozj/remote_build -o  username=<span class="string">"taozj"</span>,uid=<span class="string">"1007"</span>,gid=<span class="string">"1007"</span> -v</div><div class="line">Password <span class="keyword">for</span> taozj@//192.168.1.194/Users/taozj/Dropbox/BitBucket/v5kf_dev:  *************</div><div class="line">mount.cifs kernel mount options: ip=192.168.1.194,unc=\\192.168.1.194\Users,uid=1007,gid=1007,user=taozj,prefixpath=taozj/Dropbox/BitBucket/v5kf_dev,pass=********</div><div class="line">➜  ~ ls <span class="_">-l</span> remote_build </div><div class="line">total 0</div><div class="line">drwxr-xr-x 2 taozj taozj 0 Feb 10 09:43 aimlsrvd</div></pre></td></tr></table></figure></p>
<p>本文完！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　感谢厨神Tim Cook在10月27日短暂而又精彩的MacBook Pro发布会，让我在期待了大半年之后，终于毫不犹豫地下单购买了2015年初期版本的老款Macbook Pro。新版Macbook Pro做的更加轻薄靓丽，无不彰显了Apple强大的工业设计能力，但是抛开缺了苹果标志的信仰灯不能装逼了暂且不说，Macbook Pro不仅仅是专供美工使用的，对于广大程序员同志而言缺失实体Esc和Fn键是不能容忍的，况且这次更新后处理器、内存方面并没有什么变更，对于实用主义者来说新款版本更新动力不大。<br>　　其实对于Linux平台的程序员而来，当经历过人生最能折腾的年代玩遍各大发行版之后，绝大多数人都投皈依到了MacOS的门下，而现在我就属于其中的一位，其中最主要的原因就是MacOS系统和Linux系统具有着极大的亲缘性，MacOS的很多组件都移植自开源的BSD系统，所以Linux程序员在MacOS下用Terminal会有十分亲切的感觉，同时对于原生没有打包进MacOS的软件和工具，外挂神器homebrew更是让其如虎添翼，基本Linux下的绝大多数软件包括gcc都可以一句命令安装，方便的不得了。除此之外就是MacOS系统良好的美学设计和极为完善的软件生态系统，大多Windows下的软件都有Mac的版本，更是可以让那些长久以往而来对Linux桌面怒其不争的人彻底摆脱双系统的困扰。<br>　　MacOS系统的软件，参见文章末尾的两个推荐链接就可以了。能力充裕财务自由的还是买正版吧，毕竟自己也是做软件的，破解软件虽然能省几个钱，有些需要打开系统安装未认证软件的权限，风险得失自己平衡。我把自己用到的软件罗列如下：</p>
<blockquote>
<p>　　Alfred3、iTerm、zsh、oh-my-zsh、搜狗输入法、WizNote、ShadowsocksX、WingIDE、Chrome、QQ、WeChat、SlickEdit、DropBox、Steam、KeePassX、VLC、ThunderBird、Sublime、Microsoft Office 2016、Photoshop CC、网易云音乐、Thunder、VMware Fusion、BetterZip、SecureCRT、Navicat Premium、iStat Menus、MacVim、Snip、MacDown、Moom、Adobe Acrobat Pro、CheetSheet、PopClip、CleanMyMac 3、Fantastical 2、Bartender 2、Dash、GnuPG2、Manico、Go2Shell</p>
</blockquote>
<p>　　当然上面的软件可能不是最优的，主要是以前一些常在Windows和Linux下面使用的软件保存了一些数据，如果换成别的软件数据的迁移会比较的麻烦，因此不是特别差的也将就着用了。<br>　　关于虚拟机，可能大家会疑惑，前面刚把万能的MacOS系统吹的天花乱坠兼容类Unix系统，有着类似Windows系统良好软件生态圈，为什么还是摆脱不了虚拟机的宿命呢？其实对于大多数不涉及系统级的开发，MacOS算是够用了，但是作为服务端开发的人，时常需要使用操作系统底层的异步特性，虽然select是Posix标准以至于连Windows都支持，但是对于高性能的异步构架却不然：Windows使用的I/O completion ports，BSD、MacOS使用的kqueue，Linux使用的epoll，基本是各自为政，所以要进行Linux的服务端软件开发调试，就不得不安装个虚拟机，然后再装一个原生的Linux操作系统才行。]]>
    
    </summary>
    
      <category term="软件" scheme="https://taozj.org/tags/%E8%BD%AF%E4%BB%B6/"/>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="服务运维" scheme="https://taozj.org/tags/%E6%9C%8D%E5%8A%A1%E8%BF%90%E7%BB%B4/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="生活" scheme="https://taozj.org/categories/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Boost.Context库简介及Boost.Coroutine协程使用方式]]></title>
    <link href="https://taozj.org/201611/introduction-of-boost-context-and-new-coroutine-library.html"/>
    <id>https://taozj.org/201611/introduction-of-boost-context-and-new-coroutine-library.html</id>
    <published>2016-11-06T10:22:10.000Z</published>
    <updated>2016-12-18T08:03:50.000Z</updated>
    <content type="html"><![CDATA[<p>　　最近从各大公司的开源项目看来，基于协程的高性能服务端开发变得越来越流行了，比如我了解到的微信团队的<a href="https://github.com/tencent-wechat/libco" target="_blank" rel="external">libco</a>、魅族的<a href="https://github.com/yyzybb537/libgo" target="_blank" rel="external">libgo</a>、以及<a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a>。传统的高性能服务端的开发大多都是基于异步框架和多线程或者多进程的模型来设计的，这种架构虽然经历了长久的考验且经验丰富，但是却有着固有的缺点：<br>　　(1). 异步构架将代码逻辑强行分开，不利于人类常理的顺序思维习惯，自然也不是对开发者友好的；<br>　　(2). 线程虽然相对于进程共享了大量的数据，创建和切换效率较高，算是作为内核级别轻量级别的调度单元，在X86构架下线程的切换需要大量的CPU指令周期才能完成；同时，当业务增长的时候，如果通过增加工作线程的情况下增加处理能力，反而有可能让系统大部分的资源消耗在线程管理资源和线程调度的开销中去了，获得恰得其反的效果，所以在Nginx中工作进程的数目和CPU执行单元的数目是相同的，通过进程(线程)亲和CPU核的方式，可以最小化进程(线程)切换带来的损失(比如缓存失效等)；<br>　　(3). 虽然我们某些时候可以通过::sched_yield();主动放弃CPU请求调度，但是被切换进来的线程完全是调度算法决定的，相对于被切换进来的线程是被动的，作为常见的生产——消费者线程模型，两者只能被动苟合而很难做到高效“协作”；<br>　　(4). 也是因为上面的原因，线程之间的切换基本都属于用户程序不可控的被动状态，所以很多临界区必须通过加锁的方式进行显式保护才行。<br>　　在这种环境下，更加轻量级的协程开发便应运而生，且被各大厂家广为使用了。除了各个研发实力强的大厂开发出服务自己业务的高性能协程库之外，Boost库也发布了Boost.Coroutine2协程库，其中包含了stackless和stackful两种协程的封装，他们的简单使用方法，在我之前的《<a href="201609/usage-of-coroutine-in-boost-asio.html">Boost.Asio中Coroutine协程之使用</a>》已经做了相对比较详细的介绍说明了。这里主要了解介绍一下相对于协程高级接口之下，较为底层中涉及到协程切换过程中资源管理维护之类的基础性东西——Boost.Context库(适用于stackful协程)。<a id="more"></a><br>　　其实协程的实现方式有很多，有能力的大厂可以自己手动进行创建和维护栈空间、保存和切换CPU寄存器执行状态等信息，这些都是跟体系结构密切相关，也会涉及较多的汇编操作，而对于一般的开发者想要快速开发出协程原型，通常采用ucontext或者Boost.Context这现有工具来辅助栈空间和运行状态的管理，ucontext算是历史比较悠久的，通过ucontext_t结构体保存栈信息、CPU执行上下文、信号掩码以及resume所需要的下一个ucontext_t结构的地址，但是人家实测ucontext的性能要比Boost.Context慢的多，Boost.Context是今年来C++各大协程底层支撑库的主流，性能一直在被优化。<br>　　Boost.Context所做的工作，就是在传统的线程环境中可以保存当前执行的抽象状态信息(栈空间、栈指针、CPU寄存器和状态寄存器、IP指令指针)，然后暂停当前的执行状态，程序的执行流程跳转到其他位置继续执行，这个基础构建可以用于开辟用户态的线程，从而构建出更加高级的协程等操作接口。同时因为这个切换是在用户空间的，所以资源损耗很小，同时保存了栈空间和执行状态的所有信息，所以其中的函数可以自由被嵌套使用。<br>　　从我查阅的资料来看来，最近发布的Boost.Context新版本相对老版本更新了很多，抽象出了execution_context的类型，从其内部实现文件可以看出，其实内部的基础结构还是使用的fcontext_t来保存状态，使用make_fcontext、jump_fcontext以及新增的ontop_fcontext来操作之，对过往版本熟悉的<a href="https://www.owent.net/2016/06/boost-context-1-61%E7%89%88%E6%9C%AC%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%8F%98%E5%8C%96.html" target="_blank" rel="external">大佬们</a>当然可以直接调用这些接口。现在最新的Boost.Context依赖于C++11的一些新特性，而Boost的协程库也针对性的维护了两个版本Boost.Coroutine和Boost.Coroutine2，不知道是不是这个原因所致，毕竟他们的作者都是Oliver Kowalke。<br>　　创建execution_context会首先分配一个context stack空间，在其栈顶部保留了维持这个context信息的数据结构，设计中execution_context的环境中不能访问这个数据结构，只能在调用操作符operator()调用的时候其内部状态会自动的更新保存，用户无需关心。正如同boost::thread一样，operator()execution_context也是不支持拷贝的，只支持移动构造和移动赋值操作。<br>　　所有的execution_context都需要一个context-function，其函数签名如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">auto</span> <span class="title">execution_context</span><span class="params">(execution_context ctx, Args ... args)</span></span></div></pre></td></tr></table></figure></p>
<p>　　第一个参数ctx是固定的，表明是会在当前context被suspend的时候自动切换resume至的context，通常来说是当前context的创建和调用者，后面的可变参数会自动传递给execution_context::operator()函数作为参数。<br>　　Boost.Context的execution_context简单使用的例子<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> n = <span class="number">9</span>;</div><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>&gt; source(</div><div class="line">    [n](ctx::execution_context&lt;<span class="keyword">int</span>&gt; sink, <span class="keyword">int</span><span class="comment">/*not used*/</span> ) <span class="keyword">mutable</span> &#123;</div><div class="line">    <span class="keyword">int</span> a=<span class="number">0</span>, b=<span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span>(n-- &gt;<span class="number">0</span>)&#123;</div><div class="line">        <span class="keyword">auto</span> result = sink(a);</div><div class="line">        sink = <span class="built_in">std</span>::move(<span class="built_in">std</span>::get&lt;<span class="number">0</span>&gt;(result));</div><div class="line">        <span class="keyword">auto</span> next = a + b;</div><div class="line">        a = b; b = next;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> sink;</div><div class="line">&#125;);</div><div class="line"></div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">10</span>; ++i) &#123;</div><div class="line">    <span class="keyword">if</span>(source) &#123;</div><div class="line">        <span class="keyword">auto</span> result = source(<span class="number">0</span>);</div><div class="line">        source = <span class="built_in">std</span>::move( <span class="built_in">std</span>::get&lt;<span class="number">0</span>&gt;(result) );</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::get&lt;<span class="number">1</span>&gt;(result) &lt;&lt; <span class="string">" "</span>;   </div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// 输出结果为：0 1 1 2 3 5 8 13 21 0 %</span></div></pre></td></tr></table></figure></p>
<p>　　函数的返回类型跟实例化execution_context的模板参数类型有关：如果suspend和resume两个context之间不需要数据传递而仅仅是控制流的切换，可以使用void实例化execution_context类型创建对象，否则对于resume者来说其接收到的返回值是std::tuple类型，第一个值是suspend的context对象，其余部分是打包好的返回值，如果仅仅返回单个值但是是不同的数据类型，可以考虑使用boost::variant，多个返回值依次封装就可以了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">string</span>&gt; ctx1(</div><div class="line">    [](ctx::execution_context&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">string</span>&gt; ctx2, <span class="keyword">int</span> num, <span class="built_in">std</span>::<span class="built_in">string</span>) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> str;</div><div class="line">    <span class="built_in">std</span>::tie(ctx2, num, str) = ctx2(num+<span class="number">9</span>, <span class="string">"桃子是大神"</span>);</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::move(ctx2);</div><div class="line">&#125;);</div><div class="line"></div><div class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</div><div class="line"><span class="keyword">int</span> ret_j; <span class="built_in">std</span>::<span class="built_in">string</span> ret_str;</div><div class="line"><span class="built_in">std</span>::tie(ctx1, ret_j, ret_str) = ctx1(i, <span class="string">""</span>);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; ret_j &lt;&lt; <span class="string">"~"</span> &lt;&lt; ret_str &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div></pre></td></tr></table></figure></p>
<p>　　如果想要在某个被resumed的context上面额外执行自己指定的其他某个函数，可以将调用的第一个参数设置为exec_ontop_arg，然后紧接需要调用的函数，再正常传递context所需要传递的函数，在调用的时候，参数传递给这个指定的函数去执行，同时要求这个函数的返回类型必须是std::tuple封装的可以传递给resume context的参数，然后发生context切换resume使用其参数继续执行。这在新版Boost.Context中引入不久，效果相当于在原来执行context上面添加了一个hook调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>&gt; func1(ctx::execution_context&lt;<span class="keyword">int</span>&gt; ctx, <span class="keyword">int</span> data) &#123;</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered first time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered second time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered third time(atten): "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="keyword">return</span> ctx;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">std</span>::tuple&lt;boost::context::execution_context&lt;<span class="keyword">int</span>&gt;,<span class="keyword">int</span>&gt; func2(boost::context::execution_context&lt;<span class="keyword">int</span>&gt; ctx, <span class="keyword">int</span> data) </div><div class="line">&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func2: entered: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::make_tuple(<span class="built_in">std</span>::move(ctx), <span class="number">-3</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span>&#123;</div><div class="line">	<span class="keyword">int</span> data = <span class="number">0</span>;</div><div class="line">	ctx::execution_context&lt; <span class="keyword">int</span> &gt; ctx(func1);</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: returned first time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: returned second time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(ctx::exec_ontop_arg, func2, data+<span class="number">1</span>);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面代码输出的结果显示在下方，data+1==5被传递给func2，然后func2包装了ctx和自己的参数，ctx得到继续执行，使用了func2传递给的参数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">func1: entered first time: 1</div><div class="line">func1: returned first time: 2</div><div class="line">func1: entered second time: 3</div><div class="line">func1: returned second time: 4</div><div class="line">func2: entered: 5</div><div class="line">func1: entered third time(atten): -3</div></pre></td></tr></table></figure></p>
<p>　　对象execution_context在创建的时候会分配一个context stack，在context-function返回的时候会被自动析构。<br>　　经过追查，发现execute_context是在Boost-1.59中引入的，在其之前的版本还是直接通过联合调用jump_fcontext()、make_fcontext()来操作fcontext_t结构来保存和切换stack和执行状态信息的，虽然现在execution_context封装的更加易用，但是老式的fcontext_t操作结构更加的容易容易理解，感兴趣的想了解更加深入的内容可以查阅老版本的文档。</p>
<p>　　之前看Boost.Coroutine的时候，什么call_type、push_type……概念看的眼花缭乱，这里看看协程底层支持的基础框架Boost.Context，有一种豁然开朗的感觉，其实当有人帮你把这些复杂的、依赖于底层架构的东西做完封装好之后，或许期待我有时间的那一天，也能做一个属于自己的协程库，等后面了解一下libgo、libcopp等协程库的原理和思路之后，要不也来造个轮子！</p>
<p>PS：其实协程把用户的思路变成同步的了，那么开发协程库的人就要把执行流的跳转任务给担当下来。上面的例子应该还不是特别难理解，Boost::Context规定说execution_context::operator()被调用的时候，程序的运行发生切换，所以上面的切换点也就明白了。就是感觉最近发布的几个版本变化实在太大了，虽然名字一样，有时候是指针有时候不是指针，还是指定一个版本——1.62.0深入好了。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://msdn.microsoft.com/en-us/magazine/jj553509.aspx" target="_blank" rel="external">Windows with C++ - Lightweight Cooperative Multitasking with C++</a></li>
<li><a href="http://www.tolon.co.uk/2012/08/boost-context/" target="_blank" rel="external">LIGHTWEIGHT COOPERATIVE MULTITASKING WITH BOOST.CONTEXT</a></li>
<li><a href="http://www.boost.org/doc/libs/1_62_0/libs/context/doc/html/index.html" target="_blank" rel="external">Boost Context</a></li>
<li><a href="https://www.owent.net/2016/06/boost-context-1-61%E7%89%88%E6%9C%AC%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%8F%98%E5%8C%96.html" target="_blank" rel="external">boost.context-1.61版本的设计模型变化</a></li>
<li><a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a></li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0099r0.pdf" target="_blank" rel="external">A low-level API for stackful context switching</a></li>
<li><a href="http://www.boost.org/doc/libs/1_58_0/libs/context/doc/html/context/context.html" target="_blank" rel="external">Boost.Context fcontext_t</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　最近从各大公司的开源项目看来，基于协程的高性能服务端开发变得越来越流行了，比如我了解到的微信团队的<a href="https://github.com/tencent-wechat/libco">libco</a>、魅族的<a href="https://github.com/yyzybb537/libgo">libgo</a>、以及<a href="https://github.com/owt5008137/libcopp">libcopp</a>。传统的高性能服务端的开发大多都是基于异步框架和多线程或者多进程的模型来设计的，这种架构虽然经历了长久的考验且经验丰富，但是却有着固有的缺点：<br>　　(1). 异步构架将代码逻辑强行分开，不利于人类常理的顺序思维习惯，自然也不是对开发者友好的；<br>　　(2). 线程虽然相对于进程共享了大量的数据，创建和切换效率较高，算是作为内核级别轻量级别的调度单元，在X86构架下线程的切换需要大量的CPU指令周期才能完成；同时，当业务增长的时候，如果通过增加工作线程的情况下增加处理能力，反而有可能让系统大部分的资源消耗在线程管理资源和线程调度的开销中去了，获得恰得其反的效果，所以在Nginx中工作进程的数目和CPU执行单元的数目是相同的，通过进程(线程)亲和CPU核的方式，可以最小化进程(线程)切换带来的损失(比如缓存失效等)；<br>　　(3). 虽然我们某些时候可以通过::sched_yield();主动放弃CPU请求调度，但是被切换进来的线程完全是调度算法决定的，相对于被切换进来的线程是被动的，作为常见的生产——消费者线程模型，两者只能被动苟合而很难做到高效“协作”；<br>　　(4). 也是因为上面的原因，线程之间的切换基本都属于用户程序不可控的被动状态，所以很多临界区必须通过加锁的方式进行显式保护才行。<br>　　在这种环境下，更加轻量级的协程开发便应运而生，且被各大厂家广为使用了。除了各个研发实力强的大厂开发出服务自己业务的高性能协程库之外，Boost库也发布了Boost.Coroutine2协程库，其中包含了stackless和stackful两种协程的封装，他们的简单使用方法，在我之前的《<a href="201609/usage-of-coroutine-in-boost-asio.html">Boost.Asio中Coroutine协程之使用</a>》已经做了相对比较详细的介绍说明了。这里主要了解介绍一下相对于协程高级接口之下，较为底层中涉及到协程切换过程中资源管理维护之类的基础性东西——Boost.Context库(适用于stackful协程)。]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据结构和算法（四）：主流内排序算法]]></title>
    <link href="https://taozj.org/201611/data-structure-and-algorithm-(4)-sort.html"/>
    <id>https://taozj.org/201611/data-structure-and-algorithm-(4)-sort.html</id>
    <published>2016-11-05T07:00:58.000Z</published>
    <updated>2016-12-18T07:59:07.000Z</updated>
    <content type="html"><![CDATA[<p>　　数据结构中通用的算法主要涉及查找和排序。查找操作基本依赖于数据组织的方式(顺序存储、链表存储、树存储等)，主流的有顺序查找、折半查找、插值查找、散列查找等，其操作比较的简单明了；而排序算法算是算法中最热门的讨论话题，算法的考察要点包括对时间、空间的需求及排序的稳定性等。当然，C++标准库中已经封装了大量的容器类以及find、sort、stable_sort等通用算法，工程开发中直接传入迭代器参数就可以使用了。</p>
<h1 id="一、基础知识">一、基础知识</h1><h2 id="1-1_排序的分类">1.1 排序的分类</h2><p>　　(1). 排序的稳定性：<br>　　在排序中如果主关键字一致，对于假设ki=kj(i≠j)，在排序前序列中ri领先于rj(即i&lt;j)，如果排序后ri仍领先于rj，则称排序方法是稳定的；反之，若可能(但不一定)排序后的序列中rj领先ri，也就是关键码相同的记录，经过排序后这些记录的相对次序仍然保持不变，则称排序方法是不稳定的。<br>　　(2). 内排序(Internal Sort)和外排序(External Sort)：<br>　　内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中；外排序是由于排序个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。后面可知，归并排序可以处理外排序问题。<br>　　(3). 按照算法的原理分类<br>　　a. 插入排序：直接插入排序、二分插入排序、希尔排序<br>　　b. 交换排序：冒泡排序、鸡尾酒排序、快速排序<br>　　c. 选择排序：直接选择排序、堆排序、<br>　　d. 归并排序：归并排序<br>　　e. 分配排序：计数排序、桶排序、基数排序</p>
<h2 id="1-2_排序算法的复杂度">1.2 排序算法的复杂度</h2><h3 id="1-2-1_算法时间复杂度">1.2.1 算法时间复杂度</h3><p>　　在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。<br>　　算法的时间复杂度，也就是算法的时间度量，记作：T(n)=O(f(n))，它表示随着问题规模的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称为时间复杂度，其中f(n)是问题规模n的某个函数。这种记法称作大O记法。</p>
<h3 id="1-2-2_推导大O阶方法">1.2.2 推导大O阶方法</h3><p>　　(1). 用常数1取代运行时间中的所有加法常数；<br>　　(2). 在修改后的运行次数函数中，只保留最高阶项；<br>　　(3). 如果最高阶存在且不是1，则去除与这个项相乘的常数，从而最终得到结果。</p>
<h3 id="1-2-3_常见的复杂度">1.2.3 常见的复杂度</h3><p>　　要分析算法的复杂度，关键是要分析循环结构的运行情况，常见的时间复杂度有：</p>
<ul>
<li>O(1)常数阶；</li>
<li>O(logn)对数阶；</li>
<li>O(n)线性阶；</li>
<li>n(logn)表示nlogn阶；</li>
<li>O(n^2)平方阶；</li>
<li>O(n^3)立方阶；</li>
<li>O(2^n)指数阶。<br>　　上面的顺序也是复杂度从小到大的排列顺序。</li>
</ul>
<h1 id="二、经典排序方法总结">二、经典排序方法总结</h1><h2 id="2-1_冒泡排序">2.1 冒泡排序</h2><p>　　冒泡排序是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。<br>　　(1). 最常见的版本：经过两轮循环，用当前的i和后面的每个元素比较，如果不是最小就交换到i的位置，这样可以保证每轮外部循环都能将i位置的元素确定，但对其余的记录排序没有什么帮助，效率低。(内层循环从i开始)<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i+<span class="number">1</span>; j&lt;sz; ++j)</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[j])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[j]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(2). 正宗的冒泡排序：每次内循环的时候，进行紧密相邻两个元素的比较，将较小的数向前交换，就像是冒泡一样，确保每次最小的值能到达正确的位置，同时其余元素也能够相应地向对应的方向移动。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=<span class="number">0</span>; j&lt;sz<span class="number">-1</span>; ++j)</div><div class="line">            <span class="keyword">if</span> (store[j] &gt; store[j+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[j], store[j+<span class="number">1</span>]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(3). 优化：在上面正宗的冒泡排序中，如果经过一轮的检查，没有发生任何的swap交换活动，则表明已经有序了，此时就可以直接跳出循环表明排序完成了。<br>　　冒泡排序其总的时间复杂度为O(n^2)。<br>　　冒泡排序是一种稳定的排序方法。</p>
<h2 id="2-2_鸡尾酒排序(Shaker排序)">2.2 鸡尾酒排序(Shaker排序)</h2><p>　　该排序又叫作双向冒泡排序，算是冒泡排序的一种轻微改进版本。普通的冒泡排序只能每次从前往后进行一个次序遍历，而Shaker排序每次遍历包括两个方向，先从前往后遍历记录最后发生交换的两个元素位置，然后从这个位置开始从后往前遍历，这种双向交替比较不仅会使小的浮上水面，也会使大的沉到水底，因而效率会比较高。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> left=<span class="number">0</span>, right=sz<span class="number">-1</span>;</div><div class="line">    <span class="keyword">size_t</span> i=<span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (left&lt;right) &#123;</div><div class="line">        <span class="comment">//第一遍，从左到右</span></div><div class="line">        <span class="keyword">for</span> (i=left; i&lt;right; ++i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[i+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i+<span class="number">1</span>]);</div><div class="line">        &#125;</div><div class="line">        -- right;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (i=right; i&gt;left; --i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &lt; store[i<span class="number">-1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i<span class="number">-1</span>]);</div><div class="line">        &#125;</div><div class="line">        ++ left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　该排序也是稳定排序算法。<br><a id="more"></a></p>
<h2 id="2-3_简单选择排序">2.3 简单选择排序</h2><p>　　简单选择排序的过程就是通过n-i次关键字间的比较，从n-i+1个记录中选出关键字最小的记录，然后直接和第i(1≤i≤n)个记录交换之，按照这种方法依次对剩余排序位进行填充。<br>　　从简单选择排序的过程看来，其比较的次数并没有减少，但最大的特点就是交换移动数据次数相当少，所以效率会高一些。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> index = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i) &#123;</div><div class="line">        index = i;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i+<span class="number">1</span>; j&lt;sz; ++j)</div><div class="line">            <span class="keyword">if</span> (store[j] &lt; store[index])</div><div class="line">                index = j;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (i != index)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[index]);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　因为会有元素交换，所以简单选择排序不是稳定排序算法。<br>　　简单选择排序总的时间复杂度为O(n^2)。</p>
<h2 id="2-4_插入排序">2.4 插入排序</h2><h3 id="2-4-1_直接插入排序">2.4.1 直接插入排序</h3><p>　　直接插入排序的基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的、记录数增加1的有序表。<br>　　直接插入排序是一种插入排序的方法，实际使用的时候可以在序列的头部添加一个哨兵，将i的数据放到哨兵后就空出一个位置，便于后面数据的挪动，找到空位后将哨兵位置的原数据插入进去就可以了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; tmp;</div><div class="line">    <span class="keyword">auto</span> it = tmp.begin();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; i: store)</div><div class="line">    &#123;</div><div class="line">        <span class="keyword">for</span> (it = tmp.begin(); it!=tmp.end() &amp;&amp; *it&lt;i; ++it)</div><div class="line">            <span class="keyword">continue</span>;</div><div class="line">        tmp.insert(it, i);</div><div class="line">    &#125;</div><div class="line">    store.assign(tmp.cbegin(), tmp.cend());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　直接插入排序法的时间复杂度为O(n^2)。<br>　　直接插入排序是一种稳定的排序算法。</p>
<h3 id="2-4-2_二分插入排序">2.4.2 二分插入排序</h3><p>　　二分插入排序又叫折半插入排序，算是前面直接插入排序的变种改进，主要是用了折半查找的思路进行了优化。上面用了容器的方式直接插入排序，下面用传统的数组方式进行插入排序的模拟。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">1</span>; i&lt;sz; ++i) &#123;</div><div class="line">        <span class="keyword">int</span> elem = store[i];</div><div class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> right = i<span class="number">-1</span>;</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (left &lt;= right) <span class="comment">//当left==right，也需要判断mid前还是后</span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">ssize_t</span> mid = (left + right) / <span class="number">2</span>; <span class="comment">//向0取整</span></div><div class="line">            <span class="keyword">if</span> (elem &gt; store[mid])</div><div class="line">                left = mid + <span class="number">1</span>; <span class="comment">//必须+1 -1，否则相邻序死循环</span></div><div class="line">            <span class="keyword">else</span></div><div class="line">                right = mid - <span class="number">1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i; j&gt;left; --j)</div><div class="line">            store[j] = store[j<span class="number">-1</span>];</div><div class="line">        store[left] = elem;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-5_希尔排序">2.5 希尔排序</h2><p>　　希尔排序的思路是：将待排序列分割成若干个子序列，此时每个子序列待排序的记录个数比较少，可以在这些子序列内分别进行直接插入排序，当整个序列都基本有序时，注意只是基本有序时，再对全体记录进行一次直接插入排序。<br>　　但是这里的分组不是简单相邻的分组，而是将相隔某个“增量/increment”的记录组成一个子序列，实现跳跃式的交换移动，所以使得排序的效率提高。随着增量的不断减少，跳跃移动的步伐慢慢变小，而整个系列也变的更为的“基本有序”。还需要注意要确保最终的increment=1来实现最后一次精细的排序，然后整个序列就变的有序了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> gap = sz &gt;&gt; <span class="number">1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (gap)  &#123;</div><div class="line">        <span class="comment">//所有间隔gap的元素为一组，第一个元素不排序，所以跳过gap</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> i=gap; i&lt;sz; ++i)  &#123;</div><div class="line">            <span class="keyword">int</span> elem = store[i];</div><div class="line">            <span class="keyword">int</span> j = i;</div><div class="line"></div><div class="line">            <span class="keyword">while</span> ( j&gt;=gap &amp;&amp; elem &lt; store[j-gap] ) &#123;</div><div class="line">                store[j] = store[j-gap]; <span class="comment">//移动gap</span></div><div class="line">                j -= gap;</div><div class="line">            &#125;</div><div class="line">            store[j] = elem;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        gap &gt;&gt;= <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　目前关于增量/increment的选择还没有统一的方法。希尔排序的时间复杂度是O(n^(3/2))。<br>　　由于记录是跳跃式的移动，所以希尔排序并不是一种稳定的排序算法。</p>
<h2 id="2-6_堆排序">2.6 堆排序</h2><p>　　堆排序就是利用堆这种数据结构，实现的对简单选择排序进行的一种改进。<br>　　堆结构是具有下列性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。根结点一定是堆中所有结点最大（小）者，而同时较大（小）的结点也较靠近根结点。<br>　　对于一个满二叉树，根据其性质有：对于结点n，其双亲是结点[n/2]；对于节点i，其左右子树是2i和2i+i。<br>　　下面以大顶堆方法排序为例，其基本思路就是：将待排序列构造成一个大顶堆，此时整个序列的最大值就是堆顶的根结点。将它移走（其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的n-1个序列重新构造成一个大顶堆(调整使其成为大顶堆)，这样就会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">buildHeap</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, <span class="keyword">size_t</span> curr<span class="comment">/*父*/</span>, <span class="keyword">size_t</span> last<span class="comment">/*尾，包含*/</span>)</span> </span>&#123;</div><div class="line">    <span class="keyword">size_t</span> child = <span class="number">2</span>*curr + <span class="number">1</span>; <span class="comment">//左孩</span></div><div class="line">    <span class="keyword">int</span> elem = store[curr];</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (child &lt;= last) &#123;</div><div class="line">        <span class="comment">//两个儿子中较大的</span></div><div class="line">        <span class="keyword">if</span> (child&lt;last &amp;&amp; store[child]&lt;store[child+<span class="number">1</span>]) </div><div class="line">            ++child;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (elem &gt;= store[child]) </div><div class="line">            <span class="keyword">break</span>;</div><div class="line"></div><div class="line">        <span class="comment">// 元素交换，同时递归到子节点，另外一个儿子不用管了</span></div><div class="line">        store[curr] = store[child];</div><div class="line">        curr = child;</div><div class="line">        child = <span class="number">2</span>*curr + <span class="number">1</span>;    </div><div class="line">    &#125;</div><div class="line"></div><div class="line">    store[curr] = elem;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line"> </div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=((sz<span class="number">-1</span>)<span class="number">-1</span>)/<span class="number">2</span>; i&gt;=<span class="number">0</span>; --i) <span class="comment">// 首先建立堆</span></div><div class="line">        buildHeap(store, i, sz<span class="number">-1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=sz<span class="number">-1</span>; i&gt;<span class="number">0</span>; --i) &#123;</div><div class="line">        <span class="built_in">std</span>::swap(store[<span class="number">0</span>], store[i]);</div><div class="line">        buildHeap(store, <span class="number">0</span>, i<span class="number">-1</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面从L-&gt;length/2开始就是因为这里需要处理的是有孩子的节点。在HeapAdjust中的关键操作，就是从底向顶，递归的将两个孩子和父节点中最大值放到父节点上面，最终堆顶就是最大值了，然后交换到数组的尾部。<br>　　构建和调整堆的时间复杂度为O(logn)，所以总体来说堆排序的时间复杂度为O(nlogn)。由于记录的比较与交换是跳跃式进行，因此堆排序也是一种不稳定的排序方法。</p>
<h2 id="2-7_归并排序">2.7 归并排序</h2><p>　　归并在数据结构中的定义是将两个或两个以上的有序表组合成一个新的有序表的过程。<br>　　归并排序的原理是假设初始序列n个记录可以看成是n个有序子序列，每个子序列长度为1，然后两两归并，得到不小于n/2的整数个长度为2或1的有序子序列；再两两归并递归下去，……，如此重复直到得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。<br>　　具体操作是先分开进行do_merge_sort，然后再进行do_merge_merge进行合并，是一个很典型的递归调用形式。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_merge_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store,</span></span></div><div class="line">                    <span class="keyword">size_t</span> beg, <span class="keyword">size_t</span> last) &#123;</div><div class="line">    <span class="keyword">if</span> (beg &lt; last) &#123;</div><div class="line">        <span class="keyword">size_t</span> mid = (beg + last) / <span class="number">2</span>;</div><div class="line">        do_merge_sort(store, beg, mid);</div><div class="line">        do_merge_sort(store, mid+<span class="number">1</span>, last);</div><div class="line">        do_merge_merge(store, beg, last, mid);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_merge_merge</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, </span></span></div><div class="line">                    <span class="keyword">size_t</span> beg, <span class="keyword">size_t</span> last, <span class="keyword">size_t</span> mid<span class="comment">/*included in first*/</span>)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">size_t</span> index_1 = beg, index_2 = mid+<span class="number">1</span>;</div><div class="line">    <span class="keyword">size_t</span> index_s = <span class="number">0</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; tmp_vec(last - beg + <span class="number">1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (index_1 &lt;= mid || index_2 &lt;= last ) &#123;</div><div class="line">        <span class="keyword">if</span> (index_1 &gt; mid) &#123;</div><div class="line">            <span class="keyword">while</span> (index_2 &lt;= last)</div><div class="line">                tmp_vec[index_s ++] = store[index_2++];</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (index_2 &gt; last) &#123;</div><div class="line">            <span class="keyword">while</span> (index_1 &lt;= mid)</div><div class="line">                tmp_vec[index_s ++] = store[index_1++];</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span>&#123;</div><div class="line">            <span class="keyword">if</span> (store[index_1] &lt; store[index_2])</div><div class="line">                tmp_vec[index_s ++] = store[index_1++];</div><div class="line">            <span class="keyword">else</span></div><div class="line">                tmp_vec[index_s ++] = store[index_2++];</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//将最终的结果拷贝到对应的区段</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;tmp_vec.size(); ++i)</div><div class="line">        store[beg+i] = tmp_vec[i];</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　归并中需要对所有元素进行扫描合并，所以复杂度是O(n)，同时由于是二叉树类似的层次结构，所以递归遍历需要O(logn)，整体的时间复杂度是O(nlogn)。<br>　　在归并排序中只有两两比较，不存在跳跃操作，因此归并排序是一种稳定的排序算法。</p>
<h2 id="2-8_快速排序">2.8 快速排序</h2><p>　　快速排序又名分区排序，其实是冒泡排序的升级，同属于交换排序类。快速排序增大了比较和移动的距离，将较大的记录从前面直接移动到后面，较小的记录从后面直接移动到前面，从而减少了总的比较次数和移动交换次数。<br>　　快速排序基本思想：每次选择一个基准数据，通过一趟排序将待排记录分割成独立两部分，其中一部分记录均比另一部分记录小，然后分别对这两部分记录继续进行排序，最终以达到整个序列有序。<br>　　快速排序的核心思想就是数据分区、递归调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_quick_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, <span class="keyword">size_t</span> left, <span class="keyword">size_t</span> right)</span> </span>&#123;</div><div class="line">    <span class="keyword">size_t</span> i=left, j=right;</div><div class="line">    <span class="keyword">int</span> pivot = store[i];</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (i&lt;j) &#123;</div><div class="line">        <span class="keyword">while</span> (i&lt;j &amp;&amp; store[j] &gt; pivot)</div><div class="line">            --j;</div><div class="line">        <span class="keyword">if</span> (i&lt;j)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[j]); <span class="comment">//pivot == store[j]</span></div><div class="line"></div><div class="line">        <span class="keyword">while</span> (i&lt;j &amp;&amp; store[i] &lt; pivot)</div><div class="line">            ++i;</div><div class="line">        <span class="keyword">if</span> (i&lt;j)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[j]); <span class="comment">//pivot == store[i]</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (left != i)</div><div class="line">        do_quick_sort(store, left, i - <span class="number">1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (right != j)</div><div class="line">        do_quick_sort(store, j + <span class="number">1</span>, right);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面的while循环是整个快速排序的核心部分，设计的比较的巧妙，在右边查找比pivot小的元素，然后将其交换到前半部[i]的位置，再在前面查找比pivot大的值，将其交换到后半部[j]的位置，整个过程中所有的数据移动都是高效有作用的。当检查的目标i、j中间交汇的时候，本轮排序结束。<br>　　在最优的情况下(pivot的值选择刚好在整个排序范围的中间)，快速排序算法的时间复杂度为O(nlogn)；在最坏的情况下，其时间复杂度为O(n^2)；平均情况下快速排序的时间复杂度是O(nlogn)。<br>　　由于关键字的比较和交换是跳跃进行的，快速排序是一种不稳定的排序方法。<br>　　pivot枢轴的选取对于整个排序算法的性能至关重要，基本算法都是选择左边第一个值来作为pivot的，其他衍生算法可以对pivot值得选取做个考究。</p>
<h2 id="2-9_线性时间排序">2.9 线性时间排序</h2><h3 id="2-9-1_计数排序">2.9.1 计数排序</h3><p>其基本算法如下：<br>　　(1). 取出待排序列中的最小值n1和最大值n2，建立一个n2-n1+1长度的数组；<br>　　(2). 依次遍历待排元素，根据待排元素的值将对应数组项计数自增；<br>　　(3). 这步比较关键，统计数组计数，每项保存前N项和count_arr[k] += count_arr[k-1];这其实是进行了值到最终排列位置的映射关系；<br>　　(4). 再依次遍历待排元素，根据元素值查找count_arr中对应的最终排序位置，计入到排序结果中。<br>缺点是空间要求比较大。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">auto</span> it = <span class="built_in">std</span>::max_element(store.cbegin(), store.cend());</div><div class="line">    <span class="keyword">int</span> max_item = *it;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result(store.size());</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; bucket(max_item + <span class="number">1</span>);</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; elem: store)</div><div class="line">        bucket[elem] ++;</div><div class="line"></div><div class="line">    <span class="comment">// 关键，调整计数针对索引</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">1</span>; i&lt;bucket.size(); ++i)</div><div class="line">        bucket[i] += bucket[i<span class="number">-1</span>];</div><div class="line"></div><div class="line">    <span class="comment">//得到元素位置，保留结果</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; elem: store)</div><div class="line">        result[bucket[elem] - <span class="number">1</span>] = elem;</div><div class="line"></div><div class="line">    store = result;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-9-2_桶排序">2.9.2 桶排序</h3><p>　　桶排序是计数排序的升级版，通过一个映射函数将待排数据分配到各个桶里面，然后桶内部如果大于一个元素可以采用快速排序等操作方式；最后实现桶数据的合并；<br>　　(1). 设置桶的数目：bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1;<br>　　(2). 待排元素和桶的映射关系：buckets[Math.floor((arr[i] - minValue) / bucketSize)].push(arr[i]);<br>　　(3). 对桶进行从小到大的合并操作：arr.push(buckets[i][j]);<br>　　桶排序的f(k)值的计算，其作用就相当于快排中划分，已经把大量数据分割成了基本有序的数据块(桶)，然后只需要对桶中的少量数据做先进的比较排序即可。在内存足够的情况下桶的数目越多越好，确保每个桶中元素尽可能少甚至一个元素。</p>
<h3 id="2-9-3_基数排序">2.9.3 基数排序</h3><p>　　基数排序包括：从高位开始进行排序(MSD)和从低位开始进行排序(LSD)，大部分的例子都是LSD来排序的。其主要思路是从按照低位到高位，依次进行多次的桶排序，当最高位桶排序结束后，整个数据就是有序的了。</p>
<h1 id="三、排序算法小结">三、排序算法小结</h1><p>　　别人总结出来的排序算法选择的依据是：首先当数据量不大的时候选择插入或者选择排序，不要用冒泡排序；其次，当数据量大而又注重空间复杂性的生活，选择快速排序或者堆排序；再次，当数据量大有允许使用较多附加空间的时候，可以选择桶排序；最后，当在已经排序的记录上添加新的数据的时候，选择插入排序。<br>　　稳定性来看，对于非常在乎排序稳定性的应用中，归并排序是个好算法。</p>
<p>　　整理后的代码已经上传了，同样欢迎Review。</p>
<p><div class="github-widget" data-repo="taozhijiang/learncpp"></div><br>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　数据结构中通用的算法主要涉及查找和排序。查找操作基本依赖于数据组织的方式(顺序存储、链表存储、树存储等)，主流的有顺序查找、折半查找、插值查找、散列查找等，其操作比较的简单明了；而排序算法算是算法中最热门的讨论话题，算法的考察要点包括对时间、空间的需求及排序的稳定性等。当然，C++标准库中已经封装了大量的容器类以及find、sort、stable_sort等通用算法，工程开发中直接传入迭代器参数就可以使用了。</p>
<h1 id="一、基础知识">一、基础知识</h1><h2 id="1-1_排序的分类">1.1 排序的分类</h2><p>　　(1). 排序的稳定性：<br>　　在排序中如果主关键字一致，对于假设ki=kj(i≠j)，在排序前序列中ri领先于rj(即i&lt;j)，如果排序后ri仍领先于rj，则称排序方法是稳定的；反之，若可能(但不一定)排序后的序列中rj领先ri，也就是关键码相同的记录，经过排序后这些记录的相对次序仍然保持不变，则称排序方法是不稳定的。<br>　　(2). 内排序(Internal Sort)和外排序(External Sort)：<br>　　内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中；外排序是由于排序个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。后面可知，归并排序可以处理外排序问题。<br>　　(3). 按照算法的原理分类<br>　　a. 插入排序：直接插入排序、二分插入排序、希尔排序<br>　　b. 交换排序：冒泡排序、鸡尾酒排序、快速排序<br>　　c. 选择排序：直接选择排序、堆排序、<br>　　d. 归并排序：归并排序<br>　　e. 分配排序：计数排序、桶排序、基数排序</p>
<h2 id="1-2_排序算法的复杂度">1.2 排序算法的复杂度</h2><h3 id="1-2-1_算法时间复杂度">1.2.1 算法时间复杂度</h3><p>　　在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。<br>　　算法的时间复杂度，也就是算法的时间度量，记作：T(n)=O(f(n))，它表示随着问题规模的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称为时间复杂度，其中f(n)是问题规模n的某个函数。这种记法称作大O记法。</p>
<h3 id="1-2-2_推导大O阶方法">1.2.2 推导大O阶方法</h3><p>　　(1). 用常数1取代运行时间中的所有加法常数；<br>　　(2). 在修改后的运行次数函数中，只保留最高阶项；<br>　　(3). 如果最高阶存在且不是1，则去除与这个项相乘的常数，从而最终得到结果。</p>
<h3 id="1-2-3_常见的复杂度">1.2.3 常见的复杂度</h3><p>　　要分析算法的复杂度，关键是要分析循环结构的运行情况，常见的时间复杂度有：</p>
<ul>
<li>O(1)常数阶；</li>
<li>O(logn)对数阶；</li>
<li>O(n)线性阶；</li>
<li>n(logn)表示nlogn阶；</li>
<li>O(n^2)平方阶；</li>
<li>O(n^3)立方阶；</li>
<li>O(2^n)指数阶。<br>　　上面的顺序也是复杂度从小到大的排列顺序。</li>
</ul>
<h1 id="二、经典排序方法总结">二、经典排序方法总结</h1><h2 id="2-1_冒泡排序">2.1 冒泡排序</h2><p>　　冒泡排序是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。<br>　　(1). 最常见的版本：经过两轮循环，用当前的i和后面的每个元素比较，如果不是最小就交换到i的位置，这样可以保证每轮外部循环都能将i位置的元素确定，但对其余的记录排序没有什么帮助，效率低。(内层循环从i开始)<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i+<span class="number">1</span>; j&lt;sz; ++j)</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[j])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[j]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(2). 正宗的冒泡排序：每次内循环的时候，进行紧密相邻两个元素的比较，将较小的数向前交换，就像是冒泡一样，确保每次最小的值能到达正确的位置，同时其余元素也能够相应地向对应的方向移动。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=<span class="number">0</span>; j&lt;sz<span class="number">-1</span>; ++j)</div><div class="line">            <span class="keyword">if</span> (store[j] &gt; store[j+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[j], store[j+<span class="number">1</span>]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(3). 优化：在上面正宗的冒泡排序中，如果经过一轮的检查，没有发生任何的swap交换活动，则表明已经有序了，此时就可以直接跳出循环表明排序完成了。<br>　　冒泡排序其总的时间复杂度为O(n^2)。<br>　　冒泡排序是一种稳定的排序方法。</p>
<h2 id="2-2_鸡尾酒排序(Shaker排序)">2.2 鸡尾酒排序(Shaker排序)</h2><p>　　该排序又叫作双向冒泡排序，算是冒泡排序的一种轻微改进版本。普通的冒泡排序只能每次从前往后进行一个次序遍历，而Shaker排序每次遍历包括两个方向，先从前往后遍历记录最后发生交换的两个元素位置，然后从这个位置开始从后往前遍历，这种双向交替比较不仅会使小的浮上水面，也会使大的沉到水底，因而效率会比较高。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> left=<span class="number">0</span>, right=sz<span class="number">-1</span>;</div><div class="line">    <span class="keyword">size_t</span> i=<span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (left&lt;right) &#123;</div><div class="line">        <span class="comment">//第一遍，从左到右</span></div><div class="line">        <span class="keyword">for</span> (i=left; i&lt;right; ++i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[i+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i+<span class="number">1</span>]);</div><div class="line">        &#125;</div><div class="line">        -- right;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (i=right; i&gt;left; --i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &lt; store[i<span class="number">-1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i<span class="number">-1</span>]);</div><div class="line">        &#125;</div><div class="line">        ++ left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　该排序也是稳定排序算法。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据结构和算法（三）：红黑二叉树]]></title>
    <link href="https://taozj.org/201611/data-structure-and-algorithm-(3)-rbtree.html"/>
    <id>https://taozj.org/201611/data-structure-and-algorithm-(3)-rbtree.html</id>
    <published>2016-11-05T06:58:17.000Z</published>
    <updated>2016-12-18T07:59:01.000Z</updated>
    <content type="html"><![CDATA[<p>　　AVL自平衡二叉树在教科书上比较常见，因为是最先提出的自平衡二叉树，自然是学术价值比较的高，但是目前工业环境觉得名为红黑二叉树(Red-Black Tree)的自平衡二叉树使用的更为的广泛，比如C++标准库中的有序容器(std::set、std::map)，Linux内核中的很多数据结构等，都是用的RBTree来维护管理的。<br>　　当看完RBTree后发现，其实相对来说AVL自平衡树比RBTree更加的平衡，理论上访问效果也会更好，但是为此AVL自平衡树在插入、删除修改树结构的时候，会引入更多的旋转操作来保持平衡，所以对于经常需要添加、删除的高动态数据来说，维护这种数据结构的代价显得十分高昂，而RBTree对于树的高度限制相对要宽松的多，等于是在牺牲了部分完全性(平衡性)的条件下，以换取插入、删除操作时少量的旋转操作(但是一调整起来复杂的情况麻烦的要死~~~)。</p>
<h1 id="一、红黑二叉树简介">一、红黑二叉树简介</h1><p>　　说到红黑二叉树，不得不先请出红黑树的基本法则，虽然简单，但是维护起来还是挺复杂的：<br>　　(1). 节点都有颜色标记，且只能是红色或黑色。<br>　　(2). 根是黑色。<br>　　(3). 所有叶子都是黑色（叶子是NIL/nill_节点，不保存实际的数据）。<br>　　(4). 每个红色节点必须有两个黑色的子节点，也可以表述为从每个叶子到根的所有路径上不能有两个连续的红色节点。<br>　　(5). 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。<br>　　上述这些条件中，(1)(3)是很容易遵守的，(2)只有确实在操作到根节点的时候需要注意调整一下就行了，而(4)(5)是维持红黑树结构中常常会用到的准则。<br>　　之所以要有上面的条件和规则，就是为了这么一个保证：从根到任何一个叶子，最好的情况是整条路径全部都是黑色，假设为N，最坏的情况是黑色和红色交替的情况，那也不会超过2N，因此红黑二叉树对操作的复杂度作出了最差的保证。而维护这种数据结构，需要少量的颜色变更和不超过三次树旋转（对于插入操作最多是两次），虽然插入和删除很复杂，但操作时间复杂度仍可以保持为O(log n)而不会因为元素的数目增加而性能恶化。<br>　　之一个典型的红黑二叉树的样子。<br><img src="/post_images/images/201611/744553b4a5777c5a5e3c28140ce5ec01.jpg" alt="一个典型的红黑二叉树"><br><a id="more"></a></p>
<h1 id="二、红黑二叉树实现">二、红黑二叉树实现</h1><p>　　此处还需要事先强调一下，红黑树再复杂也是一个基本的BST，所以和AVL自平衡二叉树一样，所有的插入和删除操作，也是先按照操作BST的基本方式进行插入、删除，然后再检查是否平衡而做出相应调整，RBTree的调整操作包括着色重绘和旋转操作。</p>
<h2 id="2-1_节点数目">2.1 节点数目</h2><p>　　红黑二叉树的通用节点数据结构为<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> RBNode &#123;</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">int</span> data_;</div><div class="line">    SmartNodePtr left_;</div><div class="line">    SmartNodePtr right_;</div><div class="line">    SmartNodePtr parent_;</div><div class="line">    <span class="keyword">enum</span> Color color_;</div><div class="line">    ...</div><div class="line">    &#125;;</div></pre></td></tr></table></figure></p>
<p>　　和之前的AVL平衡二叉树一样，节点所有指针域都使用了智能指针，这样在删除的时候只需要更改指针域，智能指针维护引用计数，并在必要的时候自动析构节点并释放内存。但和AVL Tree节点不同的是，这里多了一个parent_节点，因为在后面对RBTree做维护的时候，会有大量涉及到父亲、兄弟节点的操作，而这些亲戚节点的访问，以及当前处于左还是右子树的判断，都需要parent_域辅助完成。</p>
<h2 id="2-2_插入操作">2.2 插入操作</h2><p>　　规定，新增加的节点着色必须是红色。插入操作分以下情况：<br>　　(1). 如果此时还是空的红黑树，则该节点为根节点，将其重绘为黑色，然后返回；否则进行步骤(2)<br>　　(2). 根据BST递归查找，找到可以插入的位置时候，创建新节点后进行BST插入(更新parent_、left_、right_指针域)，然后进行步骤(3)<br>　　(3). 如果父亲节点P是黑色，此时红色节点作为孩子是允许的，红色节点的加入不会影响黑色路径的计数，原先父亲的叶子节点黑色由新插入节点的叶子节点继承，对于(4)(5)规则没有任何影响，操作完成直接返回；否则进行步骤(4)<br>　　(4). 父亲节P点是红色的，如果此时叔父节点U也是红色的，而且此刻确定祖父节点G是黑色的，进行如下操作：将祖父节点G重绘为红色，将父亲P和叔父节U点重绘为黑色，此处操作虽然子树平衡了，但是修改了祖父节点G可能导致祖父节点G和其他节点不平衡，以祖父节点G为参数重新进入步骤(3)检查递归；否则进行(5)<br><img src="/post_images/images/201611/7eed920d3313cc32b5adce8f3ae5ae9d.png" alt="插入1">  <!--more--><br>　　(5). 此时父节点P是红色、叔父节点U是黑色、祖父节点G是黑色、新增节点N是红色，根据插入节点N是父亲节点G的左孩子还是右孩子，以及父亲节点P是祖父节点G的左孩子还是右孩子分别组合，一共形成四种情况，依次处理<br>　　　　a. 如果祖父节点G、父亲节点P、插入节点N在一条直线上，即插入节点N是父亲节点P的左孩子且父节点P是祖父节点G的左孩子，或者镜像情况下插入节点N是父亲节点P的右孩子且父亲节点P是祖父节点G的右孩子，此时只需将祖父节点G改为红色，父亲节点P改为黑色，然后以祖父亲节点G为中心做一个相反方向的旋转就可以了；<br><img src="/post_images/images/201611/33b286dcf5c8b483bd3c503bd9b90d8f.png" alt="插入2"><br>　　　　b. 如果祖父节点G、父亲节点P、插入节点N不在一条直线上，此时需要以父亲节点P为中心，事先进行一次旋转使得祖父节点、父亲节点、插入节点三者在一条直线上，然后就可以按照a的情况所对应的步骤进行处理了；<br>至此，红黑树的插入操作完成。<br><img src="/post_images/images/201611/046bcb436a2b8e3b595823444f319ccc.png" alt="插入3"></p>
<h2 id="2-3_删除操作">2.3 删除操作</h2><p>　　红黑树的删除操作算是比较复杂的数据结构操作了，分出的情况比较的多，而且操作过程中涉及到的亲戚节点也比较多。<br>　　此处需要说明的是，所有BST的删除操作，都可以转换看作是单个子树的删除操作，因为删除的节点只可能有三种情况：叶子节点，这时候可以将任意一个NIL节点看做单个子树；含有一个子树的节点；含有两个子树的节点，此时按照BST的删除操作，还是会寻找一个左子树最大值或者右子树最小值替换他，并将替换节点重绘成删除节点的颜色，然后问题实质上就转化成替换节点的删除了，而替换节点不可能有两个子树的情况。<br>　　(1). 如果整个RBTree为空，直接返回；否则进入(2)<br>　　(2). 查找当前节点是否待删除节点，如果不是递归进行左树或者右树删除，如果遍历完了还未找到直接返回，否则当前就是待删除节点，进入步骤(3)<br>　　(3). 如果当前待删除节点的右子树为空，表明无法找到一个用于替换的右子树最小值节点，直接进入步骤(4)，否则查找右子数最小节点，和当前节点进行数据部分的交换(而位置关系、着色得以保留)，然后将待删除节点设置为替换节点，进入步骤(4)，至此我们找到了需要真正进行删除操作的节点N<br>　　(4). 寻找当前删除节点node的非NIL子树(如果当前节点两个孩子都是NIL那就选随便选一个假设为非NIL)作为child，然后判断当前节点是否是根节点而需要做特殊处理(此处不展开这种情况，只考虑一般的删除节点)，对于一般的删除情况，通过将node父节点指针引用到child而使用child顶替当前删除节点node，node的引用计数减少(后续会被自动析构释放)，而且此时如果删除掉的节点node是红色的，那么表明被删除节点的父亲和孩子child都是黑色的，最主要的是删除一个红色节点不影响RBTree的规则，此处就可以直接返回了；否则进入步骤(5)<br>　　(5). 此处删除掉的节点node是黑色的，而如果替换的child是红色的，那么将孩子重绘为黑色，这样原来通过黑色删除节点的路线现在都由孩子去作为黑色节点顶替了，红黑树的特性没有被破坏，直接返回；否则进入步骤(6)<br>　　(6). 进入步骤(6)就是传说中最复杂的double black情况了，在所有讨论之前这里先声明，到达这里节点的删除工作已经完成，接下来的都是调整工作了。我们将主角命名为N，其本质就是(4)操作中顶替的child节点，原先的祖父节点现在是父亲节点，原先的叔父节点现在是兄弟节点，且此时节点N是黑色的。检测兄弟节点S如果是红色，那么父亲节点P肯定是黑色，此时重绘父亲节点P成红色，重绘兄弟节点S为黑，并且如果N是父亲节点P的左儿子，则以父亲节点P为中心进行左旋操作，否则进行右旋操作，经过这一步调整，N有了一个黑色的兄弟节点和一个红色的父亲节点，但是N和现在兄弟节点S原来的儿子(现在的兄弟)挂着子树上黑色节点的数目肯定不一样，子树是不平衡的，所以还需要继续进行下面的处理，进入步骤(7)<br><img src="/post_images/images/201611/bbd92ab3423061707a0c83470fbe6aa6.png" alt="删除1"><br>　　(7). 无论是原生的还是经过步骤(6)修改得到的，此处兄弟节点S是黑色、N是黑色，然后检查兄弟节点S的两个孩子的颜色，如果兄弟节点S的两个孩子都是黑色，那么就根据父亲节点P的颜色进行讨论<br>　　　　a.如果此时父亲节点P的颜色是红色，则重绘兄弟节点S成红色、重绘父亲节点P成黑色，通过这样后原先删除掉的黑色节点就由父亲节点P补偿回来了，而兄弟节点S的整个分支没有改变，满足红黑树条件，就直接返回；<br><img src="/post_images/images/201611/c08a95731367c6d1a394aced9c7e4f23.png" alt="删除2"><br>　　　　b.如果父亲节点P的颜色是黑色，则重绘兄弟节点S成红色，此时虽然得到的整个子树是平衡的，但是原先经过兄弟节点S的子树都减少了一个黑色，此处需要以父亲节点P为参数步入步骤(4)重新调整；<br><img src="/post_images/images/201611/d608f57fc2ca75812d83e83835cd1ad1.png" alt="删除3"><br>　　如果兄弟节点S的两个孩子不都是黑色，此时步入步骤(8)<br>　　(8). 此时兄弟节点S是黑色、N是黑色，而且兄弟节点S的两个孩子至少有一个是红色的，但是父亲节点P多次递归已经不确定颜色了，然后当Parnet-Sibling-r_child不在一条线上面时(此时兄弟节点S的孩子由一个红色和一个黑色构成的时候，假设红色孩子记为r_child)，需要先旋转成一条线，同时进行颜色的修正，把兄弟节点S改成红色且r_child改成黑色，经过这个旋转后的子树是满足二叉树性质的，但是N和新的兄弟节点S不平衡(本身这个操作不会涉及到N和父亲节点P)，而且这个不平衡的情况刚好会fall through到下面步骤(9)的情况处理；而如果Parnet-Sibling-r_child在一条线上面(这其实就是前面旋转着色后的结果)，直接进入步骤(9)处理<br><img src="/post_images/images/201611/0fb332761a9fc0383ab7db9dafe01ebf.png" alt="删除4"><br>　　(9). 此时兄弟节点S是黑色，且依次挂了红色孩子、黑色孙子一条线的子树，操作是通过以父亲节点P为中心进行旋转，让原来的兄弟节点S代替父亲节点P的颜色，同时重绘原来父亲节点P成黑色，重绘原来兄弟节点S的孩子成黑色。<br>　　由于原先的父亲节点P和现在兄弟节点S的颜色是不确定的，无非做两种情况进行讨论：a. 父亲节点P原先是黑色的；b. 父亲节点P原先是红色的，看图可以直接分析出来，修改之后这条子树到其所有子叶的黑色节点数目和原先都是一样的，满足红黑树条件，删除结束。<br><img src="/post_images/images/201611/537c20030520400b68eba43c293af5ca.png" alt="删除5"></p>
<p>　　按照维基百科的<a href="https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91" target="_blank" rel="external">红黑树</a>解释的代码，自己修改整理了一下并附上注释，代码已经上传了，欢迎各位Review。</p>
<div class="github-widget" data-repo="taozhijiang/learncpp"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91" target="_blank" rel="external">红黑树</a></li>
<li><a href="http://blog.csdn.net/kartorz/article/details/8865997" target="_blank" rel="external">红黑二叉树详解及理论分析</a></li>
<li><a href="http://www.geeksforgeeks.org/red-black-tree-set-2-insert/" target="_blank" rel="external">Red-Black Tree | Set</a></li>
<li><a href="https://www.cs.usfca.edu/~galles/visualization/RedBlack.html" target="_blank" rel="external">visualization/RedBlack</a></li>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　AVL自平衡二叉树在教科书上比较常见，因为是最先提出的自平衡二叉树，自然是学术价值比较的高，但是目前工业环境觉得名为红黑二叉树(Red-Black Tree)的自平衡二叉树使用的更为的广泛，比如C++标准库中的有序容器(std::set、std::map)，Linux内核中的很多数据结构等，都是用的RBTree来维护管理的。<br>　　当看完RBTree后发现，其实相对来说AVL自平衡树比RBTree更加的平衡，理论上访问效果也会更好，但是为此AVL自平衡树在插入、删除修改树结构的时候，会引入更多的旋转操作来保持平衡，所以对于经常需要添加、删除的高动态数据来说，维护这种数据结构的代价显得十分高昂，而RBTree对于树的高度限制相对要宽松的多，等于是在牺牲了部分完全性(平衡性)的条件下，以换取插入、删除操作时少量的旋转操作(但是一调整起来复杂的情况麻烦的要死~~~)。</p>
<h1 id="一、红黑二叉树简介">一、红黑二叉树简介</h1><p>　　说到红黑二叉树，不得不先请出红黑树的基本法则，虽然简单，但是维护起来还是挺复杂的：<br>　　(1). 节点都有颜色标记，且只能是红色或黑色。<br>　　(2). 根是黑色。<br>　　(3). 所有叶子都是黑色（叶子是NIL/nill_节点，不保存实际的数据）。<br>　　(4). 每个红色节点必须有两个黑色的子节点，也可以表述为从每个叶子到根的所有路径上不能有两个连续的红色节点。<br>　　(5). 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。<br>　　上述这些条件中，(1)(3)是很容易遵守的，(2)只有确实在操作到根节点的时候需要注意调整一下就行了，而(4)(5)是维持红黑树结构中常常会用到的准则。<br>　　之所以要有上面的条件和规则，就是为了这么一个保证：从根到任何一个叶子，最好的情况是整条路径全部都是黑色，假设为N，最坏的情况是黑色和红色交替的情况，那也不会超过2N，因此红黑二叉树对操作的复杂度作出了最差的保证。而维护这种数据结构，需要少量的颜色变更和不超过三次树旋转（对于插入操作最多是两次），虽然插入和删除很复杂，但操作时间复杂度仍可以保持为O(log n)而不会因为元素的数目增加而性能恶化。<br>　　之一个典型的红黑二叉树的样子。<br><img src="/post_images/images/201611/744553b4a5777c5a5e3c28140ce5ec01.jpg" alt="一个典型的红黑二叉树"><br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据结构和算法（二）：AVL自平衡二叉树]]></title>
    <link href="https://taozj.org/201611/data-structure-and-algorithm-(2)-avl.html"/>
    <id>https://taozj.org/201611/data-structure-and-algorithm-(2)-avl.html</id>
    <published>2016-11-05T06:44:35.000Z</published>
    <updated>2016-12-18T07:58:56.000Z</updated>
    <content type="html"><![CDATA[<h1 id="一、二叉树的基础知识">一、二叉树的基础知识</h1><h2 id="1-1_二叉树">1.1 二叉树</h2><p>　　二叉树(Binary Tree)是n个结点的有限集合，该集合或者为空集，或者由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成，且二叉树的左右要求是有顺序的。</p>
<h3 id="1-1-1_特殊种类的二叉树">1.1.1 特殊种类的二叉树</h3><p>　　(1). 斜树：所有的结点都只有左子树的二叉树称为左斜树，所有结点都只有右子树的二叉树称为右斜树。<br>　　(2). 满二叉树：在一棵二叉树中，如果所有分支节点都存在左子树和右子树，而且所有叶子都在同一层上，称为满二叉树。<br>　　(3). 完全二叉树：对一棵具有n个节点的二叉树按层序编号，如果编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，称为完全二叉树。在实际操作上，就是按照从上到下、从左到右这种层次顺序遍历各个元素，如果该出现元素的位置出现了空档，则不是完全二叉树。<br>　　根据定义我们可知，满二叉树是完全二叉树的一种特殊情况。</p>
<h3 id="1-1-2_二叉树的性质">1.1.2 二叉树的性质</h3><p>　　这里主要总结了二叉树结构中，数据元素、高度、父子节点位置的信息：<br>　　(1). 在二叉树的第i层上至多有2^(i-1)个结点。<br>　　(2). 深度为k的二叉树最多有2^k-1个结点。<br>　　(3). 对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。<br>　　(4). 具有n个结点的完全二叉树的深度为[log2(n)]+1，其中[x]表示不大于x的最大整数。满二叉树的度数k=log2(n+1)。<br>　　(5). 对一棵有n个结点的完全二叉树按照层序编号(从1层到[log2(n)]+1层，每层从左到右)，对任意一节点i，则有：<br>　　　　a. 如果i=1，则i是二叉树的根，无双亲；<br>　　　　b. 如果i&gt;1，则其双亲是结点[i/2]；<br>　　　　c. 如果2i&gt;n，则结点i无左孩子(结点i为叶子节点)，否则其左孩子是节点2i；<br>　　　　d. 如果2i+1&gt;n，则节点i无右孩子，否则其右孩子为结点2i+1。<br>　　通常顺序方式(数组)存储二叉树结构也是十分的常见的，如果按照完全二叉树从顶部分层遍历的，所以上面列出的二叉树的孩子和父亲之间的位置关系，也就对应了在数组中元素的索引值，这在堆排序中会被应用的最为典型。</p>
<h3 id="1-1-3_遍历二叉树">1.1.3 遍历二叉树</h3><p>　　二叉树的遍历是指从根结点出发，按照某种次序依次访问二叉树中的所有结点，使得每个结点都被访问到一次且仅被访问一次。<br>　　(1). 前序遍历：先访问根节点，然后前序遍历左子树，再前序遍历右子树；<br>　　(2). 中序遍历：从根节点开始，中序遍历根节点的左子树，然后访问根节点，最后中序遍历右子树；<br>　　(3). 后序遍历：从左到右先叶子后结点的方式遍历访问左右子树，最后访问根节点；<br>　　(4). 层序遍历：从树的第一层开始，从上而下逐层遍历，在同一层次中，按照从左到右的顺序对结点逐个访问。<br>　　二叉树的遍历虽然在语言上描述起来较为的复杂，其实代码实现上极为的简单，就是左树递归、右树递归、根元素访问三种操作顺序的排列组合的结果而已；而且，对于前序递归，其输出则是得到的元素从小到大排列的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">pre_order</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node) <span class="keyword">return</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt;node-&gt;data_&lt;&lt;<span class="string">", "</span>;</div><div class="line">    pre_order(node-&gt;left_);</div><div class="line">    pre_order(node-&gt;right_);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　当给定条件需要重建二叉树的时候，已知前序遍历序列和中序遍历序列，就可以唯一确定一棵二叉树；已知后序遍历序列和中序遍历序列，业可以唯一确定一棵二叉树；但是已知前序遍历序列和后序遍历序列，不能确定一棵二叉树。<br><a id="more"></a></p>
<h2 id="1-2_二叉排序树(Binary_Sort_Tree,_BST)">1.2 二叉排序树(Binary Sort Tree, BST)</h2><h3 id="1-2-1_二叉排序树的性质">1.2.1 二叉排序树的性质</h3><p>　　二叉排序树又称为二叉查找树，其如果不是空树，BST其具有以下性质(很显然，这是一个二叉树组织的递归定义)：<br>　　(1). 如果左子树不为空，则左子树上所有的节点都小于它的根结构的值；<br>　　(2). 若右子树不为空，则右子树上所有的节点都大于它的根结构的值；<br>　　(3). 其左右子树也分别是二叉排序树。</p>
<h3 id="1-2-2_二叉排序树的操作">1.2.2 二叉排序树的操作</h3><p>　　二叉排序树的操作包括查找、插入和删除，其中查找就是根据当前给定的键值和每个节点比较是否相等，如果不相等根据大小关系递归在左右子树上面去查找，这里我想到C++的很多标准库中表明，当查找某个值如果没有找到的话，其返回就是该值可以被插入的位置，此时想来不无道理。<br>　　插入操作和查找比较类似，也比较的简单，而删除的时候需要根据删除节点的情况分类来对待：<br>　　(1). 如果要删除的节点是叶子节点，其没有任何子树，那么就直接删除之；<br>　　(2). 如果要删除的节点仅有左子树或者仅有右子树，那么就将其对应的左子树或者右子树这个非空子树整个移动到删除节点的位置，以完成独子承父业；<br>　　(3). 如果要删除的节点其左右子树都有节点，具体的做法可以选择：<br>　　　　a. 要么沿着要删除节点的左子树，一直向右走，找出最右的节点，取出来替换该删除节点；<br>　　　　b. 或者沿着删除节点的右子树，一直向左走，找出最左的节点，然后替换之。<br>　　上面最后一种情况的删除原理，其实就是寻找待删除节点大小最相临的前驱或后驱来直接替代它，替代后整个二叉树还是保持有序的状态，同时替换的节点由于是选择的最左或者最右节点，其最多也就只有一个子数，所以替换节点的删除本身也是十分方便的，采用上面(2)的情况处理就可以了。<br>　　二叉树的性能取决于二叉树的层数，最好的情况是O(logn)，存在于完全二叉树情况下，其访问性能近似于折半查找；最差时候会是O(n)，比如在斜树的情况下，需要逐个遍历二叉树的元素才行。</p>
<h2 id="1-3_自平衡二叉树(AVL)">1.3 自平衡二叉树(AVL)</h2><p>　　前面说到，二叉树的查找、插入、删除操作的性能十分依赖于树的高度，所以如果能把树维持在一个完全二叉树的情况下，当然是最理想最高效的情况，所以在增加和删除这种会修改二叉树结构的操作中，能检测修改后的二叉树状态并修正之，限制二叉树的高度，即为平衡二叉树。<br>　　现实中绝对完全二叉树结构是很难维持的，而AVL作为最先发明的自平衡二叉树，通过对每个节点的左、右子树之间的高度差作出限定，同时在插入、删除的时候对不满足限定的子树进行一定的操作，以达到限制树的高度，从而保证其最优的查找性能。<br>　　AVL自平衡二规定每一个节点的左子树和右子树的高度差至多等于1，同时将二叉树上节点左子树高度减去右子树高度的值称为平衡因子BF，所以平衡的二叉树所有节点的平衡因子取值只可能是-1、0、1。<br>　　其它关于AVL自平衡二叉树的相关详细信息，将在下面实现部分再予以描述。</p>
<h1 id="二、实现平衡二叉树">二、实现平衡二叉树</h1><p>　　首先说道，AVL自平衡二叉树其本质上还是一个BST，所以AVL树的查找、添加和删除的基础操作都是上面描述到的BST的操作，只是在这些操作之后，需要修正节点的高度信息，在必要的情况下进行适当的操作来保证AVL树的约束。<br>　　本文借助于<a href="http://kukuruku.co/hub/cpp/avl-trees" target="_blank" rel="external">AVL Trees</a>的实现，探究AVL树的插入、删除的维护过程。</p>
<h2 id="2-1_旋转操作">2.1 旋转操作</h2><h3 id="2-1-1_基本旋转">2.1.1 基本旋转</h3><p>　　不仅仅是AVL，几乎所有的平衡二叉树都是通过旋转调整来实现的。在树的旋转中有左旋和右旋两个最基本的操作，而实际中针对左右左、右左右等结构采用的双旋转，其实也是这种原子操作的组合而已。<br><img src="/post_images/images/201611/71ad5dc7e6cd6c10b5fc683333257b73.jpg" alt="avl旋转"><br>　　看上面的图可知，左旋和右旋虽然结构表示不一，但是都保持了A&lt;x&lt;B&lt;y&lt;C的大小结构，两者可以互相旋转得到。比如在右图到左图的左旋操作中，则得到：y将成为新的根节点、原先的根节点x将成为y的左子树、y的右子树C不变，同时根据大小关系可知A&lt;q&lt;B，所以A和B分别成为q的左右子树；右旋情况也是类似的。<br>　　此时，A、B、C的子树都没有修改，而p、q的子树发生了变化，所以需要基于他们的子树修正p、q的高度。在传统学术上，AVL节点用一个字段保留记录平衡因子，但是这篇参考文章的作者建议保留树的高度信息height，因为一方面通过两个子树的height可以在需要的时候方便的计算出平衡因子，二来树的高度信息更新起来比较的方便明了，看看<a href="http://oopweb.com/Algorithms/Documents/AvlTrees/Volume/AvlTrees.htm" target="_blank" rel="external">AvlTrees</a>中维护平衡因子的分析就知道直接更新平衡因子是有多么麻烦了。不过这里的高度是一个绝对值，每次有修改的时候都必须让直接或者间接涉及到的节点全部更新调整，不过Nikolai Ershov的操作主要都是用递归方式来实现的，代码中绝大多数的操作都是返回修改或者平衡后的子树根节点，在递归函数中调用fix-height/rebalance会从最底层的修改节点一直检查处理到根节点去。</p>
<h3 id="2-1-2_双旋转">2.1.2 双旋转</h3><p>　　双旋转通常在我们所称为的“左右左”或者“右左右”的情形下会发生，而这里也有专业的结论表示出来：当高度h(s)&lt;=h(D)的时候，只需要一次旋转就可以了，否则就需要两次旋转才能达到平衡(原文章作者的配图容易被误导，一定要仔细思考+想象！！！！)<br>　　(1). h(s)&lt;=h(D)，单次旋转<br><img src="/post_images/images/201611/baac94cdf73a6b6b2530c267f3ff3653.jpg" alt="一次旋转"><br>　　(2). h(s)&gt;h(D)，两次旋转<br><img src="/post_images/images/201611/71ad5dc7e6cd6c10b5fc683333257b73.jpg" alt="两次旋转"></p>
<p>　　比如下面左旋操作的代码，这里一定要注意操作的顺序，同时在修复高度的时候父节点的高度是根据子节点直接计算出来的，所以修复的时候一定要先修复子节点，再修复当前节点。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">rotate_left</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    SmartAvlNodePtr tmp_root = node-&gt;right_;</div><div class="line">    node-&gt;right_ = tmp_root-&gt;left_;</div><div class="line">    tmp_root-&gt;left_ = node;</div><div class="line">    </div><div class="line">    fix_height(node);</div><div class="line">    fix_height(tmp_root);</div><div class="line">    <span class="keyword">return</span> tmp_root; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-2_插入操作">2.2 插入操作</h2><p>　　插入操作先是进行常规的BST插入，通过递归的方式查找插入点，然后创建新的节点，修改指针完成插入。<br>　　插入完成后，要沿着插入链沿着修改节点向树根的方向，递归调用rebalance调整树高度、计算平衡因子，并在必要的时候进行旋转修复操作。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">insert</span><span class="params">(SmartAvlNodePtr node, <span class="keyword">int</span> data)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node) &#123;</div><div class="line">        node = <span class="built_in">std</span>::make_shared&lt;AvlNode&gt;(data);</div><div class="line">        <span class="keyword">return</span> node;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    assert(data != node-&gt;data_);</div><div class="line">    <span class="keyword">if</span> (data &lt; node-&gt;data_) &#123;</div><div class="line">        node-&gt;left_ = insert(node-&gt;left_, data);</div><div class="line">        node = rebalance(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &gt; node-&gt;data_)&#123;</div><div class="line">        node-&gt;right_ = insert(node-&gt;right_, data);</div><div class="line">        node = rebalance(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> node;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function">SmartAvlNodePtr <span class="title">rebalance</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    </div><div class="line">    fix_height(node);</div><div class="line">    <span class="keyword">int</span> bal_factor = get_bal_factor(node);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (bal_factor &gt; <span class="number">1</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (get_bal_factor(node-&gt;right_) &lt; <span class="number">0</span>) <span class="comment">//rotate right first</span></div><div class="line">            node-&gt;right_ = rotate_right(node-&gt;right_);</div><div class="line">        <span class="keyword">return</span> rotate_left(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (bal_factor &lt; <span class="number">-1</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (get_bal_factor(node-&gt;left_) &gt; <span class="number">0</span>) <span class="comment">//rotate right first</span></div><div class="line">            node-&gt;left_ = rotate_left(node-&gt;left_);</div><div class="line">        <span class="keyword">return</span> rotate_right(node);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> node;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-3_删除操作">2.3 删除操作</h2><p>　　平衡二叉树最复杂的就是删除操作了(包括后面的红黑树，其删除更加的复杂)，首先根据BST的基本删除方法，进行左右子树递归查找要删除的节点，当找到待删除的节点的时候：<br>　　(1). 如果要删除的当前节点没有右子树，那么用其左孩子代替它的方式来直接删除之；否则<br>　　(2). 查找右子树中最小节点，用这个最小节点替代当前节点的方式来删除该节点，同时从替代节点原位置开始，递归修复树的高度和平衡关系。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">remove_right_min</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node-&gt;left_)</div><div class="line">        <span class="keyword">return</span> node-&gt;right_;</div><div class="line">    node-&gt;left_ = remove_right_min(node-&gt;left_);</div><div class="line">    <span class="keyword">return</span> rebalance(node);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function">SmartAvlNodePtr <span class="title">remove</span><span class="params">(SmartAvlNodePtr node, <span class="keyword">int</span> data)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (data &lt; node-&gt;data_)</div><div class="line">        node-&gt;left_ = remove(node-&gt;left_, data); </div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &gt; node-&gt;data_)</div><div class="line">        node-&gt;right_ = remove(node-&gt;right_, data);</div><div class="line">    <span class="keyword">else</span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">if</span> (!node-&gt;right_)</div><div class="line">            <span class="keyword">return</span> node-&gt;left_;</div><div class="line"></div><div class="line">        SmartAvlNodePtr repl = find_right_min(node-&gt;right_);</div><div class="line">        repl-&gt;right_ = remove_right_min(node-&gt;right_);</div><div class="line">        repl-&gt;left_  = node-&gt;left_;</div><div class="line">        <span class="keyword">return</span> rebalance(repl);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> rebalance(node);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面remove操作实际进行的步骤为:<br>　　a. find_right_min采用遍历的方式，实现在待删除节点的右子树种寻求最小的节点，作为选定的替换种子节点；<br>　　b. 调用一个remove_right_min的函数，注意这个函数也是一个递归函数，递归找到最小节点后用其右子树(无论是否为空)来替换这个节点以删除之，同时调用rebalance不断平衡直到待删除节点的右子树根部位置；<br>　　c. 修改repl的指针，接管待删除节点的左右子树资源；<br>　　d. 这个函数一旦返回(repl)，就用于顶替待删除节点在其父节点对齐引用，此时待删除节点智能指针引用递减(并被析构释放)；<br>　　e. 从删除节点的父节点开始，递归调用rebalance()到整个树的根，完成删除操作。</p>
<h2 id="2-4_小结">2.4 小结</h2><p>　　自认为讲清楚了，其实AVL还算是比较简单的自平衡二叉树了。<br>　　这里所有的节点都是使用智能指针管理的，所以看不到传统实现中那么多的new delete了，通过析构函数打印调试信息，发现删除的时候对象是被析构了，智能指针大法好！</p>
<p>整理后的代码已经上传了，欢迎各位大佬Review和拍砖!</p>
<div class="github-widget" data-repo="taozhijiang/learncpp"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://kukuruku.co/hub/cpp/avl-trees" target="_blank" rel="external">AVL Trees</a></li>
<li><a href="https://zh.wikipedia.org/wiki/AVL%E6%A0%91" target="_blank" rel="external">AVL树</a></li>
<li><a href="http://www.sanfoundry.com/cpp-program-implement-avl-trees/" target="_blank" rel="external">C++ Program to Implement AVL Trees</a></li>
<li><a href="http://oopweb.com/Algorithms/Documents/AvlTrees/Volume/AvlTrees.htm" target="_blank" rel="external">AVL Trees: Tutorial and C++ Implementation</a></li>
<li><a href="http://www.geeksforgeeks.org/avl-tree-set-1-insertion/" target="_blank" rel="external">AVL Tree | Set 1</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9" target="_blank" rel="external">二叉搜索树</a></li>
<li><a href="https://www.cs.usfca.edu/~galles/visualization/AVLtree.html" target="_blank" rel="external">visualization/AVLtree</a></li>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="一、二叉树的基础知识">一、二叉树的基础知识</h1><h2 id="1-1_二叉树">1.1 二叉树</h2><p>　　二叉树(Binary Tree)是n个结点的有限集合，该集合或者为空集，或者由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成，且二叉树的左右要求是有顺序的。</p>
<h3 id="1-1-1_特殊种类的二叉树">1.1.1 特殊种类的二叉树</h3><p>　　(1). 斜树：所有的结点都只有左子树的二叉树称为左斜树，所有结点都只有右子树的二叉树称为右斜树。<br>　　(2). 满二叉树：在一棵二叉树中，如果所有分支节点都存在左子树和右子树，而且所有叶子都在同一层上，称为满二叉树。<br>　　(3). 完全二叉树：对一棵具有n个节点的二叉树按层序编号，如果编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，称为完全二叉树。在实际操作上，就是按照从上到下、从左到右这种层次顺序遍历各个元素，如果该出现元素的位置出现了空档，则不是完全二叉树。<br>　　根据定义我们可知，满二叉树是完全二叉树的一种特殊情况。</p>
<h3 id="1-1-2_二叉树的性质">1.1.2 二叉树的性质</h3><p>　　这里主要总结了二叉树结构中，数据元素、高度、父子节点位置的信息：<br>　　(1). 在二叉树的第i层上至多有2^(i-1)个结点。<br>　　(2). 深度为k的二叉树最多有2^k-1个结点。<br>　　(3). 对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。<br>　　(4). 具有n个结点的完全二叉树的深度为[log2(n)]+1，其中[x]表示不大于x的最大整数。满二叉树的度数k=log2(n+1)。<br>　　(5). 对一棵有n个结点的完全二叉树按照层序编号(从1层到[log2(n)]+1层，每层从左到右)，对任意一节点i，则有：<br>　　　　a. 如果i=1，则i是二叉树的根，无双亲；<br>　　　　b. 如果i&gt;1，则其双亲是结点[i/2]；<br>　　　　c. 如果2i&gt;n，则结点i无左孩子(结点i为叶子节点)，否则其左孩子是节点2i；<br>　　　　d. 如果2i+1&gt;n，则节点i无右孩子，否则其右孩子为结点2i+1。<br>　　通常顺序方式(数组)存储二叉树结构也是十分的常见的，如果按照完全二叉树从顶部分层遍历的，所以上面列出的二叉树的孩子和父亲之间的位置关系，也就对应了在数组中元素的索引值，这在堆排序中会被应用的最为典型。</p>
<h3 id="1-1-3_遍历二叉树">1.1.3 遍历二叉树</h3><p>　　二叉树的遍历是指从根结点出发，按照某种次序依次访问二叉树中的所有结点，使得每个结点都被访问到一次且仅被访问一次。<br>　　(1). 前序遍历：先访问根节点，然后前序遍历左子树，再前序遍历右子树；<br>　　(2). 中序遍历：从根节点开始，中序遍历根节点的左子树，然后访问根节点，最后中序遍历右子树；<br>　　(3). 后序遍历：从左到右先叶子后结点的方式遍历访问左右子树，最后访问根节点；<br>　　(4). 层序遍历：从树的第一层开始，从上而下逐层遍历，在同一层次中，按照从左到右的顺序对结点逐个访问。<br>　　二叉树的遍历虽然在语言上描述起来较为的复杂，其实代码实现上极为的简单，就是左树递归、右树递归、根元素访问三种操作顺序的排列组合的结果而已；而且，对于前序递归，其输出则是得到的元素从小到大排列的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">pre_order</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node) <span class="keyword">return</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt;node-&gt;data_&lt;&lt;<span class="string">", "</span>;</div><div class="line">    pre_order(node-&gt;left_);</div><div class="line">    pre_order(node-&gt;right_);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　当给定条件需要重建二叉树的时候，已知前序遍历序列和中序遍历序列，就可以唯一确定一棵二叉树；已知后序遍历序列和中序遍历序列，业可以唯一确定一棵二叉树；但是已知前序遍历序列和后序遍历序列，不能确定一棵二叉树。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据结构和算法（一）：hash散列容器]]></title>
    <link href="https://taozj.org/201611/data-structure-and-algorithm-(1)-hash.html"/>
    <id>https://taozj.org/201611/data-structure-and-algorithm-(1)-hash.html</id>
    <published>2016-11-05T06:11:12.000Z</published>
    <updated>2016-12-18T07:58:45.000Z</updated>
    <content type="html"><![CDATA[<h1 id="一、散列表基础知识">一、散列表基础知识</h1><p>　　散列技术常常用于键－值关系的数据结构中，比如数据库索引、map、缓存等地方，其是通过在记录(值)的存储位置和其关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key)。散列技术的实现方式决定了其最适合的求解问题是查找与给值相等的记录(是否存在及其位置)，而对于其他查找不适合：比如某个关键字对应很多记录的情况、范围查找、查找最值等。<br><img src="/post_images/images/201611/ae697cc26bdbc100874e3ed41611619e.jpg" alt="hash散列表"></p>
<h2 id="1-1_散列函数">1.1 散列函数</h2><p>　　散列函数可以说是散列数据结构的核心，最直接的感受就是好的散列函数能够让记录能够在hash表中分布均匀(uniform distribution)，当然用于相似性查找的特殊hash类别不考虑在内。此外，在我们平常习惯性的思维中，认为只要满足X != Y，则f(X)!=f(Y)就是好的满足条件的hash函数，比如常用的CRC函数，其实如果将这类函数用在hash中，大多数情况下要比精心设计的hash函数冲突的可能性更大，会影响到hash的效率和性能。</p>
<h3 id="1-1-1_散列函数通常具备条件">1.1.1 散列函数通常具备条件</h3><p>(1). 散列均匀分布：<br>　　由于空间的限制散列表不可能无限的大，而散列冲突的几率会因为空间的限制而增大，这个时候就需要一个perfect的散列函数来作为弥补，通常设计一个好的均匀分布的散列函数是比较困难的，这也是很多散列函数专家努力的方向。<br>　　在绝大多数场合下，散列表的容量都设计成2的指数长度大小，而算出来的散列值通常采用掩码的方式快速得到散列表的索引值，所以此时的散列函数可以设计优化成在二进制的各个bit位为随机分布就可以了。不过murmur的作者也说了，好的hash函数不应当假定其用户采用’hash % tablesize’的方式来hash-to-table-index，只是作为一种常用的习惯性方法而已。<br>(2). 计算简单高效：<br>　　hash值不应当过于的复杂，hash计算的吞吐量也是hash函数的一个重要衡量标准，除了在设计中不要用过于复杂的计算操作外，实用新式CPU的高效运算指令也是提升性能的一个方面。</p>
<h3 id="1-1-2_简单常用构造散列函数的方法">1.1.2 简单常用构造散列函数的方法</h3><p>　　(1). 直接定值法：就是利用元素的关键码设计成某个线性函数的形式，比如<br>　　　　f = a × key + b;<br>　　其计算简单而且不会冲突，但是需要事先知道关键码的在小范围连续分布比较适用；<br>　　(2). 数字分析法：抽取部分数字进行诸如：反转、左环位移、右环位移、前两数与后两数相加等各种操作，其也主要用于事先知道关键字分布且关键字位数较多且若干位分布比较均匀的情况；<br>　　(3). 平方取中法：关键字位数不多的情况，先对关键字平方计算，然后取其中的某些固定位组合；这其实在实际中常用的方法，采用先放大再抽取的方式，是一种伪随机数的生成方法；<br>　　(4). 折叠法：将数字串平均分几个部分后重叠(移位法)对齐或者折叠(分界法)对齐后求和，通常用在关键字位数较多的情况下；<br>　　(5). 除留余数法：也是最常用的，mod取模缩减散列空间，这个操作可以直接针对关键字，或者是其他操作后的中间结果；若散列表表长为m，通常p为小于或等于表长的最小质数或包含不小于20的质因子的合数，因为这样产生hash冲突的可能性要少的多；<br>　　(6). 乘余取整法：<br>    f(key) = { Z × (a × key % 1) }<br>a通常取黄金分割数0.6180339，%1表示取结果的小数部分，Z为散列表的容量；<br>　　(7). 随机数法：f(key) = random(key)，适合于关键字长度不等的情况。<br><a id="more"></a>  </p>
<h2 id="1-2_散列表的冲突处理">1.2 散列表的冲突处理</h2><p>　　散列表的冲突处理主要分为闭散列法和开散列法，闭散列法也称为开放定址法。</p>
<h3 id="1-2-1_闭散列法（开放定址法）">1.2.1 闭散列法（开放定址法）</h3><p>　　当插入元素的时候，一旦发生了散列冲突，就去寻找下一个空的散列地址供插入，而查找的时候逐个查找，直到碰到开放的地址查找失败。闭散列法是通过将冲突的元素以一定的模式存储在原散列的空间中。<br>　　之所以叫做闭散列法，就是因为冲突的元素没有开辟额外的存储空间，还是在原先hash表的空间范围之内。<br>　　(1). 线性探测法：将散列表看作是一个循环向量，若初始地址是f(key)=d，则依照顺序d、d+1、d+2…的顺序取查找，即f(key)=(f(key)+1)mod N;<br>　　(2). 二次探测法：基本思路和线性探测法一致，只是搜索的步长和方向更加的多样，会交替以两个方向，步长为搜索次数的平方来查找；<br>　　(3). 双重散列法：通常双重散列法是开放地址中最好的方法，其通过提供hash()和rehash()两个函数，前者产生冲突的时候，定制化后者rehash()重新寻址，其机制比前面两种固定格式的要灵活的多；<br>　　开放定址法一般用于冲突极少的情况，同时因为没有用到指针，所以对于数据的传输是友好的。</p>
<h3 id="1-2-1_开散列法">1.2.1 开散列法</h3><p>　　与前面闭散列法对应的开散列法，一般也叫作拉链法或者链地址法，通过将冲突的元素组织在链表中，采用链表遍历的方式查找。链地址法和上面的开放定址法最大的优势是解决方法直观，实现起来简单，尤其在删除元素的时候此处只是简单的链表操作，但是前面需要考虑后面可能有元素，处理会比较复杂。同事开散列法可以存储超过散列表容量个数的元素。<br>　　(1). 链地址法：相同散列值的记录放到同一个链表中，他们在同一个Bucket中；<br>　　(2). 公共溢出法：将所有的冲突都放到一个公共的溢出表中去，适用于冲突情况很小的时候。<br>　　除了使用传统的链表，还可以使用dynamic array的方式存储，分配的时候也可以预分配多个，以保证对CPU的缓存优化友好。</p>
<h2 id="1-3_散列表的装填因子">1.3 散列表的装填因子</h2><p>　　装填因子=填入表中的记录个数/散列表的长度，实践中无论设计多好的散列函数，当装填因子超过0.7后散列表的性能就会因为散列冲突开始下降，当填入表的记录越多，装填因子就越大，产生冲突的可能性也就越大。此时可以考虑增加hash表的容量，以维持查找的性能，而且更重要的是常常在实践中，是事先不知道需要管理元素的个数的，所以动态增加散列表的容量是必须的。<br>　　修改散列表容量会导致之前元素寻址失效，这个过程也成为resize(rehash)的过程，Java的HashMap在loadfactor&gt;3/4，以及Python的dict在loadfactor&gt;2/3的时候就会自动触发resize。实践中常常使用的方法有：</p>
<h2 id="1-3-1_整体拷贝所有元素">1.3.1 整体拷贝所有元素</h2><p>　　最直观明了简单粗暴的方式，通常会double散列表的容量，然后将所有元素全部散列拷贝到新的表中，然后释放旧的表，没有什么特别的技术含量。<br>还有，有的散列库提供shrink的功能，这样就可以当loadfactor小到某个程度的时候缩减散列表的容量，释放节约内存。不过如果散列表元素动态变化较大的情况，这种反复的申请和释放对性能、缓存等有极大的破坏作用，所以很多时候shrink只是个请求，并不保证会真正实施。</p>
<h2 id="1-3-2_增量修改">1.3.2 增量修改</h2><p>　　对于元素数量多，实时性要求高的应用，通常是增量递进式的resize的，这种方式resize的步骤一般是：<br>　　(1). resize的时候分配新的hash表，同时保留旧的hash表；<br>　　(2). 当每次查找和删除的时候，同时对这两张表做操作；每次插入的时候，只对新hash表操作；<br>　　(3). 每次插入的时候，同时移动 r 个元素从旧hash表到新hash表；<br>　　(4). 当所有元素从旧hash表被移走后，resize结束，释放旧的hash表；<br>　　如果想看具体的实现，建议去读读memcached的代码，里面有这种增量resize的操作。</p>
<h2 id="1-3-3_其他方法">1.3.3 其他方法</h2><p>　　还有就是设计的hash-to-table-index的操作和是和散列表的容量是无关的等情况，在分布式缓存中一致性hash等会涉及到，有时间再展开吧。</p>
<h2 id="1-4_散列表和二叉树的对比">1.4 散列表和二叉树的对比</h2><p>　　散列表和二叉树两者原理完全不同，使用情况也各有千秋，为此C++标准对于基本的数据类型(multi_)set、(multi_)map也建立了有序和无序两个版本。还有就是在比如MySQL/Mariadb数据库建立索引的时候，就有BTree索引和Hash索引的类型：前者算是有序索引，索引记录都是按照顺序排列(数据库由于通常记录会比较多，BTree是为这种类型优化的数据结构，减少对磁盘IO的访问次数，其不是通过二叉树实现的)。<br>　　两者的选型和区别主要考虑到以下情况：<br>　　(1). 二叉树是有序容器类，散列表是无须容器类，前者可以用于比较、范围查找类的检索，后者属于只能用于检索是否存在的情况；<br>　　(2). 虽然自平衡二叉树访问效率平均为O(logn)，但是随着元素数目n的增加性能也会下降，所以对于数据量大的情况还是倾向于效率更高的O(1)代表的散列表；<br>　　(3). 在多线程的环境下，二叉树的操作往往要锁住整个数据结构，而散列表可以对每个bucket建立一个互斥锁，所以在并发率高的情况下，散列表的性能更加；<br>　　(4). 超大数据集下，分布式缓存hash有成熟的案例，二叉树？嘿嘿，从来没听过。</p>
<h1 id="二、工业上常用的散列函数">二、工业上常用的散列函数</h1><p>　　C++和Boost有unordered的散列库，而针对C就需要自己寻找散列实现。在memcached中有Jenkins和Murmur两种散列函数可选，Nginx使用的是Murmur散列函数，而最近几年原Jenkins的作者推出了SpookyHash，而Google也发布了Murmur的改进型CityHash。如果有空余时间的人可以把这些新型的hash func封装好给memcached和Nginx提PR，哈哈。</p>
<h2 id="2-1_Jenkins">2.1 Jenkins</h2><p>在整个Hash中占据重要的地位，其作者Bob Jenkins几十年钻研Hash，发表了无数相关论文，不容小觑吧。</p>
<h2 id="2-2_Murmur">2.2 Murmur</h2><p>当前使用的比较广泛，而且速度也比较快，尤其它提供32bit和64bit的输出版本，能够提供原生的高性能。</p>
<h2 id="2-3_CityHash和SpookyHash">2.3 CityHash和SpookyHash</h2><p>SpookyHash是Jenkins的作者Bob Jenkins发布的最新散列函数，而CityHash乃是大厂Google所出，且由Murmur作者Austin Appleby进行Review的。SpookyHash只提供128bit的结果，而CityHash提供64bit、128bit、256bit的输出。<br>所以新版的Hash输出的位数增多了，如果你需要32bit的散列值，那么Murmur由于是原生支持，性能会是最好的；而据Austin Appleby透露(其就职于Google)现在Google的所有产品都是基于64bit架构的，其将来也必定是大势所趋啊。</p>
<h1 id="三、C++标准库中散列的使用">三、C++标准库中散列的使用</h1><p>再次重申，如果想了解Hash的实现、使用和维护，就去读memcached的源码。我暂且还不知道C是否有现成的hash库可供使用，不过C++的用户就幸福许多了，标准库的unordered_模板容器开箱既用，而且对resize、loadfactor也提供了访问和调整的接口，十分方便。<br>不过，标准库下面C++只提供了对内置数据类型、std::string、智能指针类型定义了hash操作，而如果自己使用的key_type不是这些类型，就需要手动定义这些操作。</p>
<h2 id="3-1_在容器中指明容器模板的Hash和KeyEqual模板参数">3.1 在容器中指明容器模板的Hash和KeyEqual模板参数</h2><p>如果自定义类型需要放在unordered_(multi)set/map容器中时候，这些无须容器都是用hash的方法存放的，可以在定义声明容器对象的时候指定模板参数中的Hash和KeyEqual参数模板就可以了，前者用以从将要保存到容器Key的类型中提取计算出一个size_t的散列值，当然通常的方法是用自定义类型中某些标准std::hash支持的成员类型求得一个散列值，也可以尝试前面介绍得到的那么多散列函数计算出自己规则的size_t尺寸的散列值；而对于KeyEqual操作，如果该类型支持operator==运算符就可以不提供这个参数，我想可能是在hash冲突的时候被调用到。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">size_t</span> hasher(<span class="keyword">const</span> Sales_data&amp; sd) &#123;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::hash&lt;<span class="built_in">string</span>&gt;()(sd.isbn()); </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">eqOp</span><span class="params">(<span class="keyword">const</span> Sales_data &amp;lhs, <span class="keyword">const</span> Sales_data &amp;rhs)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> lhs.isbn() == rhs.isbn(); </div><div class="line">&#125;</div><div class="line"> </div><div class="line"><span class="keyword">using</span> SD_multiset = <span class="built_in">unordered_multiset</span>&lt;Sales_data, <span class="keyword">decltype</span>(hasher)*, <span class="keyword">decltype</span>(eqOp)*&gt;;</div><div class="line"><span class="function">SD_multiset <span class="title">bookstore</span><span class="params">(<span class="number">42</span>, hasher, eqOp)</span></span>;</div></pre></td></tr></table></figure></p>
<h2 id="3-2_模板特例化得方法">3.2 模板特例化得方法</h2><p>这个是治本的方法，让后面的std::hash真正认得我们的自定义类型。根据C++的规则，模板特例化必须在模板的原名字空间中，所以这里需要打开std名字空间，进行类型的模板特例化声明，然后进行定义实现操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">namespace std &#123;</div><div class="line">template &lt;&gt;</div><div class="line">struct hash&lt;Sales_data&gt; &#123; </div><div class="line">  typedef size_t result_type;</div><div class="line">  typedef Sales_data argument_type;</div><div class="line">  size_t operator()(const Sales_data&amp; s) const;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">size_t hash&lt;Sales_data&gt;::operator() (const Sales_data&amp; s) const&#123;</div><div class="line">  return hash&lt;string&gt;()(s.book) ^ hash&lt;double&gt;()(s.revenue); </div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125; //关闭std名字空间</div></pre></td></tr></table></figure></p>
<p>在C++类实现中，成员变量通常都是private的，所以上面的特例化成员通常要声明为类型的友元friend才能正常工作</p>
<pre><code class="cpp">emplate &lt;<span class="keyword">typename</span> T&gt; <span class="keyword">class</span> <span class="built_in">std</span>::hash; <span class="comment">//前置声明</span>
<span class="keyword">class</span> Sales_data {
<span class="keyword">friend</span> <span class="keyword">class</span> <span class="built_in">std</span>::hash&lt;Sales_data&gt;;
 ... };
</code></pre>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.reddit.com/r/programming/comments/ozodk/cityhash_new_hash_function_by_google_faster_than/" target="_blank" rel="external">CityHash: new hash function by Google (faster than Murmur)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="external">Hash table</a></li>
<li><a href="http://blog.reverberate.org/2012/01/state-of-hash-functions-2012.html" target="_blank" rel="external">State of the hash functions, 2012</a></li>
<li><a href="http://en.cppreference.com/w/cpp/utility/hash" target="_blank" rel="external">CPP reference</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="一、散列表基础知识">一、散列表基础知识</h1><p>　　散列技术常常用于键－值关系的数据结构中，比如数据库索引、map、缓存等地方，其是通过在记录(值)的存储位置和其关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key)。散列技术的实现方式决定了其最适合的求解问题是查找与给值相等的记录(是否存在及其位置)，而对于其他查找不适合：比如某个关键字对应很多记录的情况、范围查找、查找最值等。<br><img src="/post_images/images/201611/ae697cc26bdbc100874e3ed41611619e.jpg" alt="hash散列表"></p>
<h2 id="1-1_散列函数">1.1 散列函数</h2><p>　　散列函数可以说是散列数据结构的核心，最直接的感受就是好的散列函数能够让记录能够在hash表中分布均匀(uniform distribution)，当然用于相似性查找的特殊hash类别不考虑在内。此外，在我们平常习惯性的思维中，认为只要满足X != Y，则f(X)!=f(Y)就是好的满足条件的hash函数，比如常用的CRC函数，其实如果将这类函数用在hash中，大多数情况下要比精心设计的hash函数冲突的可能性更大，会影响到hash的效率和性能。</p>
<h3 id="1-1-1_散列函数通常具备条件">1.1.1 散列函数通常具备条件</h3><p>(1). 散列均匀分布：<br>　　由于空间的限制散列表不可能无限的大，而散列冲突的几率会因为空间的限制而增大，这个时候就需要一个perfect的散列函数来作为弥补，通常设计一个好的均匀分布的散列函数是比较困难的，这也是很多散列函数专家努力的方向。<br>　　在绝大多数场合下，散列表的容量都设计成2的指数长度大小，而算出来的散列值通常采用掩码的方式快速得到散列表的索引值，所以此时的散列函数可以设计优化成在二进制的各个bit位为随机分布就可以了。不过murmur的作者也说了，好的hash函数不应当假定其用户采用’hash % tablesize’的方式来hash-to-table-index，只是作为一种常用的习惯性方法而已。<br>(2). 计算简单高效：<br>　　hash值不应当过于的复杂，hash计算的吞吐量也是hash函数的一个重要衡量标准，除了在设计中不要用过于复杂的计算操作外，实用新式CPU的高效运算指令也是提升性能的一个方面。</p>
<h3 id="1-1-2_简单常用构造散列函数的方法">1.1.2 简单常用构造散列函数的方法</h3><p>　　(1). 直接定值法：就是利用元素的关键码设计成某个线性函数的形式，比如<br>　　　　f = a × key + b;<br>　　其计算简单而且不会冲突，但是需要事先知道关键码的在小范围连续分布比较适用；<br>　　(2). 数字分析法：抽取部分数字进行诸如：反转、左环位移、右环位移、前两数与后两数相加等各种操作，其也主要用于事先知道关键字分布且关键字位数较多且若干位分布比较均匀的情况；<br>　　(3). 平方取中法：关键字位数不多的情况，先对关键字平方计算，然后取其中的某些固定位组合；这其实在实际中常用的方法，采用先放大再抽取的方式，是一种伪随机数的生成方法；<br>　　(4). 折叠法：将数字串平均分几个部分后重叠(移位法)对齐或者折叠(分界法)对齐后求和，通常用在关键字位数较多的情况下；<br>　　(5). 除留余数法：也是最常用的，mod取模缩减散列空间，这个操作可以直接针对关键字，或者是其他操作后的中间结果；若散列表表长为m，通常p为小于或等于表长的最小质数或包含不小于20的质因子的合数，因为这样产生hash冲突的可能性要少的多；<br>　　(6). 乘余取整法：<br>    f(key) = { Z × (a × key % 1) }<br>a通常取黄金分割数0.6180339，%1表示取结果的小数部分，Z为散列表的容量；<br>　　(7). 随机数法：f(key) = random(key)，适合于关键字长度不等的情况。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="数据结构和算法" scheme="https://taozj.org/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[说说设计模式中的单例模式]]></title>
    <link href="https://taozj.org/201610/talk-about-singleton.html"/>
    <id>https://taozj.org/201610/talk-about-singleton.html</id>
    <published>2016-10-21T17:26:48.000Z</published>
    <updated>2016-12-18T08:09:31.000Z</updated>
    <content type="html"><![CDATA[<p>　　单例(Singleton)差不多算是设计模式种最简单的一种了，属于创建型模式，但是突然码起来感觉还有些不知所措。当然网上关于设计模式的范例比比皆是，但大多是限于简单说明设计模式本身，但是考究在生产环境中使用的话还是有不少其他讲究的。刚好网上搜到《Modern C++ Design: Generic Programming and Design Patterns Applied》这本书中，有一节是详细讲单例的，看了觉得不错。<br>　　单例模式的定义是指：单例模式，是保证一个类仅有一个实例，并提供一个访问它的全局访问点。通过把构造函数设置成private的，防止外部创建对象，同时提供一个公共的GetInstance方法，决定是否已经实例化过，如果没有就调用私有的构造方法创建一个实例。</p>
<p>　　文章主要是按照单例模式下三个最重要的方面：创建生成、寿命、多线程模型来考量的。当然C++讲求的是面向对象和代码重用，单例模式不能简单的通过继承来实现重用，因为构造函数是private的，所以通常单例模式可以写成模板的方式来重用，泛化比较简单，这里就不阐述了。</p>
<h1 id="一、创建生成">一、创建生成</h1><p>　　最容易迷惑初学者(包括我自己)的是单例模式很容易和“静态类(成员函数和成员变量都是静态的类)”相混淆，乍一看确实极为相似。其实他们最大的区别是单例模式是一个实实在在正常的类，所以有对象(只有一个)，也就有this指针和虚函数；而在“静态类”中没有对象，就没有引用、this指针，也没有虚函数，所以如果在你的类中有继承的话，首先遇到的就是析构函数就没法是虚函数，那么你用基类的指针或者引用析构的话，派生类的对象都没法被释放！其他成员函数的多态也就更无从谈起了。还有一点就是，“静态类”的成员初始化顺序是不确定的，这在静态成员具有复杂依赖关系的情况下更为的致命，而单例具有正常的构造函数，根据C++标准，成员初始化的顺序就是在类中声明的顺序，是可以得到保证的。<br>　　要实现单例模式的对象唯一性，那么这些成员必须是private的：构造函数、拷贝构造函数、赋值运算符，同时给予封装的需要，析构函数最好也是private的，防止用户意外删除对象。而且，GetInstance()公共方法最好返回引用的方式，原因跟上面一样的。<a id="more"></a><br>　　创建对象的方式，主流的有两种：Gamma和Meyers：<br>a. Gamma方式：是最常见的通过new T的方式在堆空间动态创建对象，但是这种方式创建的对象需要使用delete显式销毁，程序结束时虽然操作系统会回收所有的内存资源，但是析构函数并不会被自动调用，意味着所有的资源回收都依赖于操作系统默认行为。<br>b. Meyers方式：通过在函数中创建静态对象的方式在静态内存区创建对象，这里C++规定如果函数中的局部静态变量是内置类型且用常量初始化的，那么这个初始化发生在程序开始运行加载期间，而如果初始化值是非常量类型或者变量类型是具有构造函数的类型，那么初始化发生在运行期间第一次调用该函数的时候，所以：(1)new出来的对象不能自动析构，但是程序中的静态对象，在程序退出的时候可以自动析构，所以可以在析构函数中做额外的事情；(2)这个对象不是程序启动的时候创建，而是只在调用函数需要对象的时候进行创建，这在多个编译单元有依赖关系的时候更为的有效，因为编译器没法保证编译单元的处理顺序，而这种方法总是能保证在需要对象的时候能够被创建，同时懒汉创建也节省资源。</p>
<h1 id="二、寿命">二、寿命</h1><p>　　设计模式中对单例对象的生命周期没有过多的阐述，所以也容易被忽略，通常单例对象的生命周期是很明确的：产生的时候是需要访问这个对象的时候，结束的时候通常是程序(正常或者异常)退出的时候。<br>　　在程序退出的时候，C++规定，对象的析构以LIFO后创建者先析构的顺序进行(new/delete管理的对象不受此规则)，但是根据上面的方式，单例是在首次访问的时候创建对象的，所以我们无法预估和安排程序退出的时候各个单例对象的析构顺序，而尤其当这些析构对象互相调用的时候，情况将变得更加复杂。<br>　　比如我们希望一个日志单例能够在最后一刻被析构，但是某种顺序可能先就被析构了，这时候别的对象通过Instance访问的对象就是析构后无效的对象，这就是”dead-reference”问题。解决这个问题的方法，就是通过增加一个静态的成员变量destroyed_，默认为false，而在对象的析构函数中将其设置为true。这样在请求这个单例对象的时候，如果destroyed_为true，就表示对象已经被析构掉了，这个时候就需要使用placement new操作在原地再次重建这个对象，从而实现只要有用户，即使死掉也能复生的单例。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> Singleton::OnDeadReference() &#123;</div><div class="line">	Create();</div><div class="line">	<span class="keyword">new</span>(pInstance_) Singleton;</div><div class="line">	atexit(KillPhoenixSingleton);</div><div class="line">	destoryed_ = <span class="literal">false</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> Singleton::KillPhoenixSingleton() &#123;</div><div class="line">	pInstance_-&gt;~Singleton();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　作者后面还提到可以建立一种设置和追踪对象生命周期长度的机制，让某些对象“活的更长一些”，问题搞的更加复杂了，此处就不深究了。</p>
<h1 id="三、多线程模型">三、多线程模型</h1><p>　　多线程环境下，单例的创建涉及到一个竞争问题。如果直接把判断和创建的代码用一个互斥单元保护，那么每次调用对象的时候都要请求互斥量，造成了不必要的性能浪费。最经典的方式是”Double-Checked Locking”(DCL)。<br>　　但是就像在<a href="/201609/cpp11-atomic-and-memory-model.html">C++11新标准中的Atomic原子操作和内存模型</a>中所描述的，在C++11发布确定内存模型之前，对这个静态变量访问和修改在各个线程之间的可见是没有保证的，只能显式使用内存屏障保证。同时，作者还给出的方法是把这个变量设置为volatile的，查阅发现：某些编译器会保证volatile变量是一种内存屏障，阻止编译器和CPU重新安排读入和写出语义，比如Visual C++ 2005之后就做出了此类保证。<br>　　我是简单在变量的读写加了acquire和release的thread_fench，如果你想深入了解这个机制，或者想写出你认为的最高效的代码，可以参照附录中的文献。不过我觉得这里过于的纠结没什么意义，因为这个竞争条件只在创建的过程中会发生，创建之后都不会存在竞争条件了，这里过于的纠结优化这个问题真是钻牛角尖了。</p>
<p>考虑到简单实用，然后自用的一个Singleton像<a href="https://github.com/taozhijiang/ailawd/blob/c%2B%2B0x/include/redis.hpp" target="_blank" rel="external">这个样子</a>。<br>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/1755195/" target="_blank" rel="external">Modern C++ Design: Generic Programming and Design Patterns Applied</a></li>
<li><a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="external">Double-Checked Locking is Fixed In C++11</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/C-plus-plus-In-Theory-The-Singleton-Pattern-Part-I/" target="_blank" rel="external">C++ In Theory: The Singleton Pattern, Part I</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/C-plus-plus-In-Theory-The-Singleton-Pattern-Part-2/" target="_blank" rel="external">C++ In Theory: The Singleton Pattern, Part 2</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/The-Singleton-Pattern-Revisited/" target="_blank" rel="external">The Singleton Pattern Revisited</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　单例(Singleton)差不多算是设计模式种最简单的一种了，属于创建型模式，但是突然码起来感觉还有些不知所措。当然网上关于设计模式的范例比比皆是，但大多是限于简单说明设计模式本身，但是考究在生产环境中使用的话还是有不少其他讲究的。刚好网上搜到《Modern C++ Design: Generic Programming and Design Patterns Applied》这本书中，有一节是详细讲单例的，看了觉得不错。<br>　　单例模式的定义是指：单例模式，是保证一个类仅有一个实例，并提供一个访问它的全局访问点。通过把构造函数设置成private的，防止外部创建对象，同时提供一个公共的GetInstance方法，决定是否已经实例化过，如果没有就调用私有的构造方法创建一个实例。</p>
<p>　　文章主要是按照单例模式下三个最重要的方面：创建生成、寿命、多线程模型来考量的。当然C++讲求的是面向对象和代码重用，单例模式不能简单的通过继承来实现重用，因为构造函数是private的，所以通常单例模式可以写成模板的方式来重用，泛化比较简单，这里就不阐述了。</p>
<h1 id="一、创建生成">一、创建生成</h1><p>　　最容易迷惑初学者(包括我自己)的是单例模式很容易和“静态类(成员函数和成员变量都是静态的类)”相混淆，乍一看确实极为相似。其实他们最大的区别是单例模式是一个实实在在正常的类，所以有对象(只有一个)，也就有this指针和虚函数；而在“静态类”中没有对象，就没有引用、this指针，也没有虚函数，所以如果在你的类中有继承的话，首先遇到的就是析构函数就没法是虚函数，那么你用基类的指针或者引用析构的话，派生类的对象都没法被释放！其他成员函数的多态也就更无从谈起了。还有一点就是，“静态类”的成员初始化顺序是不确定的，这在静态成员具有复杂依赖关系的情况下更为的致命，而单例具有正常的构造函数，根据C++标准，成员初始化的顺序就是在类中声明的顺序，是可以得到保证的。<br>　　要实现单例模式的对象唯一性，那么这些成员必须是private的：构造函数、拷贝构造函数、赋值运算符，同时给予封装的需要，析构函数最好也是private的，防止用户意外删除对象。而且，GetInstance()公共方法最好返回引用的方式，原因跟上面一样的。]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Boost-Asio网络开发基础知识（三）：Strand序列化执行用户回调]]></title>
    <link href="https://taozj.org/201609/basics-of-boost-asio-(3)-strand.html"/>
    <id>https://taozj.org/201609/basics-of-boost-asio-(3)-strand.html</id>
    <published>2016-09-27T15:50:37.000Z</published>
    <updated>2016-12-18T08:41:53.000Z</updated>
    <content type="html"><![CDATA[<p>请参看Boost.Asio的官方文档，上面清楚的描述道：<br>　　strand可以保证严格序列化地(而不会并行地)执行event handlers，通过使用strand可以保证安全的在多线程环境下执行程序，而不需要使用者显式的使用类似mutex等方式来进行保护和同步操作。strand的可以以隐式(implicit)或者显式(explicit)的方式存在：<br>(1). 如果只在一个线程中调用io_service::run()，那么所有的event handlers都是在一个隐式strand中序列化执行的；<br>(2). 对于一个连接如果只有一个单链异步操作的时候，其不可能并发的执行event handlers，这也是隐式strand的。(文中提到了比如HTTP的单双工协议，我的理解是HTTP只会进行客户端请求、服务端返回数据这种形式，没有并行执行event handler的可能性)；<br>(3). 可以显式实例化一个strand对象，然后所有的event handlers必须使用io_service::strand::wrap()进行包裹，或者使用该strand对象显式调用post()/dispatch()发布异步操作请求；<br>(4). 对于composed asynchronous operations的操作，比如async_read()或者async_read_until()，其中间会多次调用async_read_some()，为了保证对象的安全，所有的intermediate handlers都必须在同一个strand中被串行化执行。</p>
<p>基本上strand对象创建之后，就从另外一个层次替换了io_service的行为，因为strand提供了和io_service_极其类似的成员函数：<br>(1). dispatch(CompletionHandler handler); 请求strand去执行handler，strand对象保证通过该strand添加的handlers不会被并行的执行，如果这个函数是在相同strand对象对应的handler中被调用的，那么该handler将会在函数中被立即执行(s.running_in_this_thread() == true)；<br>(2). post(CompletionHandler handler); 请求strand去执行handler并立即返回；<br>(3). get_io_service()<br>(4). running_in_this_thread(); 如果当前线程正在执行由该strand提交的handler，则返回true；<br>(5). wrap(Handler handler); 创建一个函数对象，当被invoke的时候会自动传递到strand的dispatch函数；<br><a id="more"></a><br>strand串行化执行的顺序问题：<br>在strand的文档中，对提交进取的多个handler需要串行化执行，执行的顺序有部分的保证。在以下情况下会保证asio_handler_invoke(a1, &amp;a1)会先于执行asio_handler_invoke(b1, &amp;b1)：<br>(1). s.post(a)先于执行s.post(b)；<br>(2). s.post(a)先于执行s.dispatch(b)，同时后者在strand外执行的；<br>(3). s.dispatch(a)先于执行s.post(b)，并且前者是在strand外执行的；<br>(4). s.dispatch(a)先于执行s.dispatch(b)，同时他们都是在strand外执行的；<br>(5). async_op_1(…, s.wrap(a)); async_op_2(…, s.wrap(b));这两者的执行顺序没有任何的保证，而strand所能给予的保证是a1和b1不会并行执行，如果s.wrap(x1)先被执行，那么x1也会先被执行；<br>其实，其要诀就是：如果在strand中，那么dispatch会直接在调用函数中执行，否则按照添加到队列中的顺序来排队执行。举个例子，比如假设<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> wrapped_handler1 = strand.wrap(handler1);</div><div class="line"><span class="keyword">auto</span> wrapped_handler2 = strand.wrap(handler2);</div><div class="line">socket.async_read_some(buffer1, wrapped_handler1); <span class="comment">// op1</span></div><div class="line">socket.async_read_some(buffer2, wrapped_handler2); <span class="comment">// op2</span></div></pre></td></tr></table></figure></p>
<p>由于op1先于op2启动，所以保证buffer1在stream中接收到的数据是先于buffer2的，但是wrapped_handler1和wrapped_handler2的调用顺序是没有保证的，strand做出的保证是：<br>(1). handler1和handler2不会并发的执行；<br>(2). 如果wrapped_handler1先于wrapped_handler2被执行，那么handler1先于handler2被执行，反之亦然。</p>
<p>strand类定义在[strand.hpp]boost::asio::io_service::strand，这个类只是个空壳，主要包括两个数据成员detail::strand_service&amp; service_和detail::strand_service::implementation_type impl_两个成员，具体实现需要查看strand_service类的实现细节，该类有几个重要的成员变量：<br>(1). io_service_impl&amp; io_service_; 构造strand的时候传递进来的io_service对象；<br>(2). detail::mutex mutex_; 主要用来保护下面的locked_等内部变量；<br>(3). bool locked_; 如果当前有其他的handler正在被执行或正在被调度执行，那么这个变量是true，如果此时有新的handler需要被加入就需要等待；<br>(4). op_queue<operation> waiting_queue_; 正在等待strand但是除非等到下次strand调度，否则不应当被运行，修改时候需要mutex_保护；<br>(5). op_queue<operation> ready_queue_; 已经拥有了lock_，即将被运行的队列；</operation></operation></p>
<p>想必看到上面的成员之后，对strand的串行化原理会猜个八九分了，但是如我们之前所跟的，一个async_read_some()调用的话，descriptor_state和reactor_op会多次加入到io_service上面，对于这个二段式的操作，其序列化需求还是跟之前的io_service直接调度有些区别的吧。strand其提供最常用的接口包括dispatch、post、wrap，我们可以从这些函数中了解strand串行化的机制：<br>(1). dispatch<br>如果当前的线程正在执行strand，那么就直接调用这个handler:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (call_stack&lt;strand_impl&gt;::contains(impl)) &#123;</div><div class="line">	<span class="function">fenced_block <span class="title">b</span><span class="params">(fenced_block::full)</span></span>;</div><div class="line">	boost_asio_handler_invoke_helpers::invoke(handler, handler);</div><div class="line">	<span class="keyword">return</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其中的invoke调用代码为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">using</span> boost::asio::asio_handler_invoke;</div><div class="line">asio_handler_invoke(function, boost::asio::detail::addressof(context));</div></pre></td></tr></table></figure></p>
<p>可见这个asio_handler_invoke就是在<a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/reference/io_service__strand.html" target="_blank" rel="external">strand介绍文档</a>中看到的，其默认操作就是直接调用用户提供的handler。关于这个asio_handler_invoke，如果要深究下去东西也很多，可以参见参考中的<a href="https://stackoverflow.com/questions/32857101/when-to-use-asio-handler-invoke" target="_blank" rel="external">When to use asio_handler_invoke?</a>，其主要思想是提供了一个可供记录的上下文环境context，因为比如composed operation中， intermediate handler可能会被创建零或者多次，这个状态必须在外层的wrap中保留下来才可以。不过在上面的例子中，貌似没有做什么额外的事情。</p>
<p>否则上面的dispatch()会调用strand_service::do_dispatch()，这里的判断就更明显了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (can_dispatch &amp;&amp; !impl-&gt;locked_)&#123;</div><div class="line">  impl-&gt;locked_ = <span class="literal">true</span>;</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">if</span> (impl-&gt;locked_)&#123;</div><div class="line">  impl-&gt;waiting_queue_.push(op);</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">&#125;</div><div class="line"><span class="keyword">else</span> &#123;</div><div class="line">  impl-&gt;locked_ = <span class="literal">true</span>;</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">  impl-&gt;ready_queue_.push(op);</div><div class="line">  io_service_.post_immediate_completion(impl, <span class="literal">false</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果当前是执行strand的线程并且没有lock_，那么就返回true，效果是直接执行handler；否则如果lock_了就添加到waiting_queue_上面；再则没有lock_就添加到ready_queue_队列上面，此时通过post_immediate_completion添加到io_service_.op_queue_上面被调度执行；<br>如果上面返回是true，此处就是在do_dispatch()函数内部执行了，通过设置on_dispatch_exit的RAII，在此次调用完后会把waiting_queue_的handler全部移动到ready_queue_，如果ready_queue_中真的有元素，就设置lock_为ture，并将队列中的handler添加到io_service_.op_queue_上面去。<br>上面介绍了都是善后工作，真正的函数内调用代码为：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">completion_handler&lt;Handler&gt;::do_complete(</div><div class="line">        &amp;io_service_, o, boost::system::error_code(), 0);</div><div class="line">        </div><div class="line">static void do_complete(io_service_impl* owner, operation* base,</div><div class="line">      const boost::system::error_code&amp; /*ec*/, std::size_t /*bytes_transferred*/)</div><div class="line">  &#123;</div><div class="line">    // Take ownership of the handler object.</div><div class="line">    completion_handler* h(static_cast&lt;completion_handler*&gt;(base));</div><div class="line">    ptr p = &#123; boost::asio::detail::addressof(h-&gt;handler_), h, h &#125;;</div><div class="line">...</div><div class="line">    Handler handler(BOOST_ASIO_MOVE_CAST(Handler)(h-&gt;handler_));</div><div class="line">    p.h = boost::asio::detail::addressof(handler);</div><div class="line">    p.reset();</div><div class="line"></div><div class="line">    // Make the upcall if required.</div><div class="line">    if (owner) &#123;</div><div class="line">      fenced_block b(fenced_block::half);</div><div class="line">      BOOST_ASIO_HANDLER_INVOCATION_BEGIN(());</div><div class="line">      boost_asio_handler_invoke_helpers::invoke(handler, handler);</div><div class="line">      BOOST_ASIO_HANDLER_INVOCATION_END;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>这里调用的时候owner不是空的，所以会调用用户提供的handler。</p>
<p>(2). post<br>post的逻辑就比上面要简单很多了，如果locked_==true，那么就直接添加到waiting_queue_，否则的话说明当前strand没有运行，就设置lock_=true并添加到ready_queue_队列上，同时添加到io_service_.op_queue_上面等待调度执行；</p>
<p>(3). wrap<br>wrap函数算是最常用的函数了，当原来所有的async_xxxx所传入的handler，都可以直接使用strand_.wrap进行包装，就可以保证在多线程环境下序列化调用安全了。其wrap成员函数使用了detail::wrapped_handler进行包装，类成员也就dispatcher_和handler_两个成员变量。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">wrap(Handler handler) &#123;</div><div class="line">	<span class="keyword">return</span> detail::wrapped_handler&lt;io_service::strand, Handler,</div><div class="line">      detail::is_continuation_if_running&gt;(*<span class="keyword">this</span>, handler);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由于strand在我们操作接口中的角色就是添加了一个wrap，基本的业务流程还是在io_service中进行的，所以这里预测，有无strand.wrap的差异也就是在需要调用的handler的期间：<br>当socket的IO操作完成之后，会继续调用o-&gt;complete(*this, ec, task_result);，此时会按照如下的调用链：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">task_io_service_operation::complete() -&gt; boost_asio_handler_invoke_helpers::invoke(handler, handler.handler_);</div><div class="line">-&gt; asio_handler_invoke(function, boost::asio::detail::addressof(context));</div><div class="line"></div><div class="line">asio_handler_invoke(Function&amp; function,</div><div class="line">    wrapped_handler&lt;Dispatcher, Handler, IsContinuation&gt;* this_handler)</div><div class="line">&#123;</div><div class="line">  this_handler-&gt;dispatcher_.dispatch(</div><div class="line">      rewrapped_handler&lt;Function, Handler&gt;(</div><div class="line">        function, this_handler-&gt;handler_));</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里看出了dispatcher_.dispatch()，就跟上面分析的dispatch联系起来了，也就是上面的成员函数添加真正的handler。由之前的分析知道，用户提供的handler是在实际的IO执行完成之后才会回掉的，所以可以看出这里的strand不会保护底层的IO操作，只会保护用户提供的回调handler的串行化执行。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_asio/overview/core/strands.html" target="_blank" rel="external">Strands: Use Threads Without Explicit Locking</a></li>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_asio/reference/io_service__strand.html" target="_blank" rel="external">io_service::strand</a></li>
<li><a href="http://stackoverflow.com/questions/39097644/how-strands-guarantee-correct-execution-of-pending-events-in-boost-asio" target="_blank" rel="external">How strands guarantee correct execution of pending events in boost.asio</a></li>
<li><a href="https://stackoverflow.com/questions/32857101/when-to-use-asio-handler-invoke" target="_blank" rel="external">hen to use asio_handler_invoke ?</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>请参看Boost.Asio的官方文档，上面清楚的描述道：<br>　　strand可以保证严格序列化地(而不会并行地)执行event handlers，通过使用strand可以保证安全的在多线程环境下执行程序，而不需要使用者显式的使用类似mutex等方式来进行保护和同步操作。strand的可以以隐式(implicit)或者显式(explicit)的方式存在：<br>(1). 如果只在一个线程中调用io_service::run()，那么所有的event handlers都是在一个隐式strand中序列化执行的；<br>(2). 对于一个连接如果只有一个单链异步操作的时候，其不可能并发的执行event handlers，这也是隐式strand的。(文中提到了比如HTTP的单双工协议，我的理解是HTTP只会进行客户端请求、服务端返回数据这种形式，没有并行执行event handler的可能性)；<br>(3). 可以显式实例化一个strand对象，然后所有的event handlers必须使用io_service::strand::wrap()进行包裹，或者使用该strand对象显式调用post()/dispatch()发布异步操作请求；<br>(4). 对于composed asynchronous operations的操作，比如async_read()或者async_read_until()，其中间会多次调用async_read_some()，为了保证对象的安全，所有的intermediate handlers都必须在同一个strand中被串行化执行。</p>
<p>基本上strand对象创建之后，就从另外一个层次替换了io_service的行为，因为strand提供了和io_service_极其类似的成员函数：<br>(1). dispatch(CompletionHandler handler); 请求strand去执行handler，strand对象保证通过该strand添加的handlers不会被并行的执行，如果这个函数是在相同strand对象对应的handler中被调用的，那么该handler将会在函数中被立即执行(s.running_in_this_thread() == true)；<br>(2). post(CompletionHandler handler); 请求strand去执行handler并立即返回；<br>(3). get_io_service()<br>(4). running_in_this_thread(); 如果当前线程正在执行由该strand提交的handler，则返回true；<br>(5). wrap(Handler handler); 创建一个函数对象，当被invoke的时候会自动传递到strand的dispatch函数；<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Boost.Asio网络开发基础知识（二）：异步框架总览]]></title>
    <link href="https://taozj.org/201609/basics-of-boost-asio-(2)-overview-of-the%20async-framework.html"/>
    <id>https://taozj.org/201609/basics-of-boost-asio-(2)-overview-of-the async-framework.html</id>
    <published>2016-09-26T15:19:13.000Z</published>
    <updated>2016-12-18T08:41:55.000Z</updated>
    <content type="html"><![CDATA[<p>　　虽然知道异步库实现基本都是对操作系统底层支持的select/poll/epoll/kqueue机制的封装，可是热爱学习的偶，还是想像之前对Libevent一样，如果能了解Boost.Asio的内部异步机制会让人感觉是一件很爽的事情，于是就厚着脸皮把Boost.Asio的核心——io_service代码跟踪读了一下。话说阅读C++的代码确实比C麻烦不少，尤其当其中夹杂着复杂的继承关系、大量泛型参数的时候，同时Boost库的一大风格是为了代码的整洁和编译速度的优化，进行了类声明和实现的分离，形成了大量重复文件名的代码以及一般编辑器不支持的ipp后缀，阅读跳转起来十分不便，想想也真是累啊。但是还是希望自己能早日适应下来！既然选择了这条路，就迟早得迈得过这条坎才行。<br>　　之前也分析过，Windows系统得益于其重叠IO(Overlapped I/O)和完成端口(I/O completion port)机制，算是在操作系统级别支持异步IO操作的，而Linux类系统虽然也有aio_xxx的异步接口，但是用之者寥寥，现在高性能服务端基本都是清一色的select/epoll+普通IO操作实现的。以前看文章据说Linux的aio_xxx不太给力，不知道是用户的选择导致了Linux内核对aio_xxx的发展缺乏动力，还是aio_xxx不完美导致开发者不愿意使用呢？<br>　　要实现跨平台的异步库，由Reactor来实现Proactor容易，因为只要额外添加一步IO操作就可以了，但是反过来要Proactor剥离出Reactor几乎是不可能的，所以当时研究Libevent在Windows平台下好像就只支持select机制，所以预估Libevent在Windows平台下的并发量性能有限。Boost.Asio则是选择了Proactor模式，完全利用了Windows的异步特性，同时在Linux平台下通过增强Reactor来实现Proactor模式，我想这也是Boost.Asio作为一个跨平台的网络库所了不起的地方，同时也是其立志进入C++标准最有力的一票。</p>
<h1 id="一、前期准备">一、前期准备</h1><p>对于了解一个项目，最佳实践当然是Read The Fuck Code!<br>可是在阅读项目代码的时候，虽然也可以像读文章一样人工判断出执行流程，但是如果能够以边调试边运行的方式来跟踪，那么结果将会更加的确信可靠。在Linux下面，虽然编辑神器Vim/Emacs可以各种外挂配置形成超级IDE神器，但是自己这个年纪还是怕折腾了——直接用的SlickEdit，这家伙号称是最贵的IDE，但是确实挺好用的，而且是跨平台的(但是真正Windows下大多人还是会用微软自家的Visual Studio吧，真幸福)，等在下能够经济自由的那一天，定要好支持一下。SlickEdit对于一般的代码是做的很好的，但是对于大量模板情况下的跟踪，还是有所缺陷，比如没法显示实例化的模板参数类型，希望能不断更新改进。<br>我在学习调试的时候，是直接使用upstream的boost版本，但是很多发行版会打包甚至安装一些旧的发布版本，为了使用自己控制的upstream版本，需要额外的配置一下环境：<br>(a). 在GitHub上面clone最新的boost源代码，然后编译安装到本地的目录，参考的编译命令可以是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  boost git:(master) ✗ ./bootstrap.sh</div><div class="line">➜  boost git:(master) ✗ ./b2 headers</div><div class="line">➜  boost git:(master) ✗ mkdir builddir installdir</div><div class="line">➜  boost git:(master) ✗ ./b2 --build-dir=builddir --prefix=installdir <span class="_">-a</span> -q toolset=gcc variant=debug </div><div class="line">➜  boost git:(master) ✗ <span class="comment">#./b2 -j4 --build-dir=builddir --prefix=/home/taozj/root/ --without-python -a -q toolset=gcc cxxflags="-std=c++0x" variant=debug threading=multi install</span></div></pre></td></tr></table></figure></p>
<p>(b). 随便新建一个项目，Boost.Asio的example中有一大把，比如找一个包含包含async_read/write_some调用的简单例程的(比如async_udp_echo_server.cpp)，然后修改项目的Makefile，将自己指定的boost安装目录中的include和lib添加到编译环境中去。Makefile的例子可以参考我<a href="https://github.com/taozhijiang/airobot_msgd/blob/master/Makefile" target="_blank" rel="external">项目</a>中使用的<br>此外，还要修改系统的LD_LIBRARY_PATH，可以通过在/etc/ld.conf.d目录中添加一个上面的安装目录，然后运行ldconfig刷新一下系统即可，否则最终链接的时候还是会报错找不到符号的。<br>(c). 这个时候，就可以使用ldd命令查看编译出来的可执行文件依赖哪些链接库，看看是不是最终依赖到了指定的本地版本boost，同时也可以运行一下可执行程序看是否正常。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  asio_learn ldd Debug/asio_learn </div><div class="line">	linux-vdso.so.1 =&gt;  (0x00007ffd33dc9000)</div><div class="line">	libboost_system.so.1.62.0 =&gt; /home/user/Dropbox/ReadTheCode/boost/installdir/lib/libboost_system.so.1.62.0 (0x00007f277ad55000)</div><div class="line">	libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f277ab38000)</div><div class="line">	libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f277a7b5000)</div><div class="line">	libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f277a59f000)</div><div class="line">	libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f277a1d6000)</div><div class="line">	/lib64/ld-linux-x86-64.so.2 (0x0000556214f39000)</div><div class="line">	libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2779ecc000)</div></pre></td></tr></table></figure></p>
<p>(d). 修改SlickEdit编辑器，在Project Properties-&gt;Directories-&gt;Include中，把本地的installdir/include加到最前面去，刷新Retag一下Slickedit，查看里面的变量定义跳转文件是不是正确。<br>至此，这个学习跟踪环境就完成了。</p>
<h1 id="二、io_service中三个成员变量">二、io_service中三个成员变量</h1><p>io_service核心类主要成员变量只有三个：init_、service_registry_和impl_。<br>(a). [detail/signal_init.hpp] detail::signal_init&lt;&gt; init_：在默认构造signal_init的时候，会将SIGPIPE的信号给忽略掉，这算基本是所有网络开发程序的默认行为；<br>(b). [io_service.hpp] impl_type&amp; impl_：通过宏的控制，impl_type在Linux平台等价于task_io_service类型，Linux和Windows两种平台的操作在这里会进行分流；<br>(c). [detail/service_registry.hpp] detail::service_registry* service_registry_：其实现类型是一个单例对象的侵入链表，其中每一个服务都有对应的ID号，Linux平台在后面经常遇到的服务有detail::task_io_service、detail::reactive_socket_service、detail::epoll_reactor，这些个类一方面是跟平台相关密切，同时他们之间的联系也是错综复杂，暂且不表吧！</p>
<p>[detail/impl/epoll_reactor.ipp]task_io_service中有几个重要的成员变量：<br>(a). atomic_count outstanding_work_; 表示未完成的work数目，在work_start()的时候会增加，在work_finished()的时候会递减；<br>(b). [detail/reactor_fwd.hpp] reactor* task_; 这个reactor在reactor_fwd.hpp中通过宏BOOST_ASIO_HAS_XXX来进行控制的，这也就是说没有Libevent那种可以通过调用代码的方式灵活的选择选择select/poll/epoll各种模型了，通常在Linux中会被定义成epoll_reactor；<br>(c). [detail/op_queue.hpp] op_queue<operation> op_queue_; 这里实现了一个operation_queue的队列容器，同时定义了op_queue_access这个访问者类对这个op队列进行操作管理。这个队列是多个线程共享的，存储的元素可以是descriptor_state、reactor_op类型，后面会经常涉及到这两种类型。<br><a id="more"></a></operation></p>
<h1 id="三、Initiator发起异步请求">三、Initiator发起异步请求</h1><p>从最常见的async_read_some这个socket读取请求，看看Initiator发起的这条路径是怎么处理的。<br>当开始创建和连接一个套接字的时候，其名字作用空间是[ip/tcp.hpp]ip::tcp::socket，从代码中可以看到所谓的socket(basic_stream_socket<tcp>)、accept(basic_socket_acceptor<tcp>)、resolver(basic_resolver<tcp>)都是一个个typedef的别名而已，而[basic_stream_socket.hpp]basic_stream_socket经过模板实例化，其类声明就变成了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> basic_stream_socket</div><div class="line">  : <span class="keyword">public</span> basic_socket&lt;tcp, stream_socket_service&lt;tcp&gt;&gt;</div></pre></td></tr></table></figure></tcp></tcp></tcp></p>
<p>看到这个basic_stream_socket中的成员函数，让人宽心了一点点，因为我们开发时候常见的IO操作接口(async_)send、(async_)receive、(async_)write_some、(async_)read_some都显露出来了，因为这些函数本来就是socket调用的嘛，定睛一看其基本都是调用this-&gt;get_service()中的同名成员函数，而既然basic_stream_socket中没有get_service()的定义，那么这个函数一定是在其基类中被继承而来的(原谅我后面的这些模板参数我直接替换掉了)：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">explicit basic_socket(boost::asio::io_service&amp; io_service)</div><div class="line">  : basic_io_object&lt;stream_socket_service&gt;(io_service);</div></pre></td></tr></table></figure></p>
<p>basic_socket的构造函数需要传递一个io_service的参数，这个参数后面喂给了basic_io_object，就是这个类消化了这个参数：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">explicit basic_io_object(boost::asio::io_service&amp; io_service)</div><div class="line">  : service(boost::asio::use_service&lt;stream_socket_service&gt;(io_service))&#123;</div><div class="line">  service.construct(implementation);</div><div class="line">&#125;</div><div class="line"></div><div class="line">service_type&amp; get_service()</div><div class="line">&#123;  return service;  &#125;</div></pre></td></tr></table></figure></p>
<p>下面就需要看看这个[stream_socket_service.hpp]stream_socket_service东西是个什么鬼了，原来在Linux平台下，它的实现就是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The platform-specific implementation.</span></div><div class="line">service_impl_type service_impl_;</div><div class="line"></div><div class="line"><span class="keyword">typedef</span> detail::reactive_socket_service&lt;tcp&gt; service_impl_type;</div></pre></td></tr></table></figure></p>
<p>[detail/reactive_socket_service.hpp]reactive_socket_service可是个好类啊，其继承自reactive_socket_service_base，两个类中几乎囊括了所有对于socket的设置、IO等操作，当然为了整洁起见，所有对于socket的控制操作和底层收发操作都被实现成了自由函数，并封装在[detail/impl/socket_ops.ipp]socket_ops名字空间中。<br>例如上面，对于socket.async_read_some()这个调用，那么它的调用链就是(其中的&lt;-&gt;表示继承关系)：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">basic_stream_socket::get_service().async_receive(<span class="keyword">this</span>-&gt;get_implementation(),</div><div class="line">        buffers, <span class="number">0</span>, BOOST_ASIO_MOVE_CAST(ReadHandler)(handler));</div><div class="line"> </div><div class="line">basic_stream_socket &lt;-&gt; basic_socket &lt;-&gt; basic_io_object::service</div><div class="line">reactive_socket_service &lt;-&gt; reactive_socket_service_base::async_receive</div></pre></td></tr></table></figure></p>
<p>然后整个async_receive的实现代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// buffer must be valid for the lifetime of the asynchronous operation.</span></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> MutableBufferSequence, <span class="keyword">typename</span> Handler&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">async_receive</span><span class="params">(base_implementation_type&amp; impl,</span></span></div><div class="line">  <span class="keyword">const</span> MutableBufferSequence&amp; buffers,</div><div class="line">  socket_base::message_flags flags, Handler&amp; handler)</div><div class="line">&#123;</div><div class="line"><span class="keyword">bool</span> is_continuation =</div><div class="line">  boost_asio_handler_cont_helpers::is_continuation(handler);</div><div class="line"> </div><div class="line"><span class="comment">// Allocate and construct an operation to wrap the handler.</span></div><div class="line"><span class="keyword">typedef</span> reactive_socket_recv_op&lt;MutableBufferSequence, Handler&gt; op;</div><div class="line"><span class="keyword">typename</span> op::ptr p = &#123; boost::asio::detail::addressof(handler),</div><div class="line">  boost_asio_handler_alloc_helpers::allocate(</div><div class="line">    <span class="keyword">sizeof</span>(op), handler), <span class="number">0</span> &#125;; <span class="comment">// h v p</span></div><div class="line">p.p = <span class="keyword">new</span> (p.v) op(impl.socket_, impl.state_, buffers, flags, handler);</div><div class="line"> </div><div class="line">BOOST_ASIO_HANDLER_CREATION((p.p, <span class="string">"socket"</span>, &amp;impl, <span class="string">"async_receive"</span>));</div><div class="line"> </div><div class="line">start_op(impl,</div><div class="line">  (flags &amp; socket_base::message_out_of_band)</div><div class="line">    ? reactor::except_op : reactor::read_op,</div><div class="line">  p.p, is_continuation,</div><div class="line">  (flags &amp; socket_base::message_out_of_band) == <span class="number">0</span>,</div><div class="line">  ((impl.state_ &amp; socket_ops::stream_oriented)</div><div class="line">    &amp;&amp; buffer_sequence_adapter&lt;boost::asio::mutable_buffer,</div><div class="line">      MutableBufferSequence&gt;::all_empty(buffers)));</div><div class="line">  p.v = p.p = <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这么一大段我先拷贝在这里，说句实话写的现在我确实看不懂，只知道有buffers和handler，后面发信给原作者问是什么回事，这才有些明白。对于reactive_socket_recv_op<mutablebuffersequence, handler="">::ptr的类型来源，可以发现在reactive_socket_recv_op类定义中有BOOST_ASIO_DEFINE_HANDLER_PTR这么一个宏，而这个宏定义在头文件[detail/handler_alloc_helpers.hpp]当中，在其中辅助生成了一个ptr类型的内部类，其实也是做了一个RAII的作用，并且可以可选择性的释放成员p.p、p.v的内容，p.h一般用来存储handler。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">BOOST_ASIO_DEFINE_HANDLER_PTR(reactive_socket_recv_op);</div><div class="line"></div><div class="line">p.p = <span class="keyword">new</span> (p.v) op(impl.socket_, impl.state_, buffers, flags, handler);</div></pre></td></tr></table></figure></mutablebuffersequence,></p>
<p>那么构造出来的p.p就是reactive_socket_recv_op类型了，其中包含了我们传递进去的buffers和handler，同时在调用start_op的时候，这个p.p也就是大名鼎鼎的descriptor_data。<br>然后就要关注通过调用start_op函数，这个函数映射到reactor_(epoll_reactor)的start_op操作，其这里完成的的工作主要有：<br>(a). 通过epoll_ctl的方式将套接字的EPOLLOUT事件侦听添加进去，同时把descriptor_data作为event的私有数据存储在ev.data.ptr；<br>(b). 将当前的操作的reactor_op添加到descriptor_data-&gt;op_queue_[op_type].push(op);这个依据操作类型相关(read_op = 0, write_op = 1, connect_op = 1, except_op = 2)的队列里面去；<br>(c). 调用work_start()来增加outstanding_work_的计数。<br>自此客户端发送的async_read_some已经被分派到操作系统epoll中去侦听相应注册的事件了，同时其buffers、handler等重要数据也被添加到了op队列中——完事具备，只欠东风了！</p>
<h1 id="四、io_service中收集就绪事件">四、io_service中收集就绪事件</h1><p>在开发中，我们都是先期做一系列的准备工作(比如增加accept的连接handler、信号处理回调等)，最后调用io_service.run()方法，从此主线程在此阻塞起来进行事件循环。当然，在io_service中与run同类的函数还要包括好几种，只是没有run()这么常用而已。这些函数都是映射到实现部分impl_(task_io_service)来调用的：<br>(a). std::size_t run();  一直阻塞直到所有的任务都完成，或者没有其他handler可以被dispatch、io_service被stop掉；多个线程可以调用同一个io_service的run()，他们共同组成没有差异的线程池模式；本函数的正常退出是调用stop或者run out of work。<br>(b). std::size_t run_one(); 最多执行一个handler，它会阻塞等待直到一个handler被dispatched、或者io_service被stop。<br>(c). std::size_t poll(); 该函数不会阻塞，它会立即运行可以运行的handlers，直到没有剩余的ready handler、或者io_service被stop。<br>(d). std::size_t poll_one(); 非阻塞的运行至多一个handler。<br>另外还有两个常用到的成员函数dispatch()和post()，只是我们在调用async_xxxx的时候隐含的实现了他们相同的功能：<br>(e). dispatch(CompletionHandler handler) 将会请求io_service立即执行给定的handler，如果当前线程是调用run(), run_one(), poll(), poll_one()的线程，那么这个handler将会被立即执行，否则会插入到task_io_service::op_queue_队列中；出现这种判断也不奇怪，因为任何的线程如果拿到io_service对象都可以用它发起异步操作请求，或者直接dispatch()/post()添加异步请求；<br>(f). post(CompletionHandler handler) 请求io_service立即执行给定的handler然后立即返回，实际就是插入到task_io_service::op_queue_当中然后就返回了。</p>
<p>就捡最常见的run来说事吧，其调用链为<br>io_service::run() -&gt; task_io_service::run()，核心代码如下<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="keyword">size_t</span> n = <span class="number">0</span>;</div><div class="line">  <span class="keyword">for</span> (; do_run_one(lock, this_thread, ec); lock.lock())</div><div class="line">    <span class="keyword">if</span> (n != (<span class="built_in">std</span>::numeric_limits&lt;<span class="built_in">std</span>::<span class="keyword">size_t</span>&gt;::max)()) <span class="comment">//计数操作</span></div><div class="line">      ++n;</div></pre></td></tr></table></figure></p>
<p>这个n就是run()返回的数目，代表了已经执行handler的计数，最大值不会超过size_t的类型最大值，关键点就落在了这个do_run_one上面了(暂时把多线程方面的东西拿掉了)：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="keyword">while</span> (!stopped_) &#123;</div><div class="line">    <span class="keyword">if</span> (!op_queue_.empty()) &#123;</div><div class="line">      operation* o = op_queue_.front();</div><div class="line">      op_queue_.pop();</div><div class="line">      <span class="keyword">bool</span> more_handlers = (!op_queue_.empty());</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (o == &amp;task_operation_) &#123;</div><div class="line">        task_interrupted_ = more_handlers;</div><div class="line">        task_cleanup on_exit = &#123; <span class="keyword">this</span>, &amp;lock, &amp;this_thread &#125;;</div><div class="line">        (<span class="keyword">void</span>)on_exit;</div><div class="line">        task_-&gt;run(!more_handlers, this_thread.private_op_queue);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">else</span> &#123;</div><div class="line">        <span class="built_in">std</span>::<span class="keyword">size_t</span> task_result = o-&gt;task_result_; <span class="comment">//events</span></div><div class="line">        work_cleanup on_exit = &#123; <span class="keyword">this</span>, &amp;lock, &amp;this_thread &#125;;</div><div class="line">        (<span class="keyword">void</span>)on_exit;</div><div class="line">        o-&gt;complete(*<span class="keyword">this</span>, ec, task_result);</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      wakeup_event_.clear(lock);</div><div class="line">      wakeup_event_.wait(lock);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"><span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>成员变量task_operation_是一个task_io_service_operation类型，这里涉及到一个分流操作。跟踪代码发现在task_init以及这里RAII的task_io_service::task_cleanup的行为看来，task_operation_的效果都像是扮演者一个队列的尾端标记的作用，当队列中取出这个op就意味表示就绪的事件处理完了，需要重新收集就绪事件了，所以<br>(a). 当弹出的队列元素是task_operation_表示没有任务可以处理了，此时会调用task_-&gt;run(!more_handlers, this_thread.private_op_queue);，这个操作会通过epoll_reactor::run调用底层的epoll_wait收集更多的就绪事件，其本质就对应着下面的调用：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[detail/impl/epoll_reactor.ipp] <span class="keyword">void</span> epoll_reactor::run(<span class="keyword">bool</span> block, op_queue&lt;operation&gt;&amp; private_op_queue);</div><div class="line"><span class="comment">// Block on the epoll descriptor.</span></div><div class="line">epoll_event events[<span class="number">128</span>];</div><div class="line"><span class="keyword">int</span> num_events = epoll_wait(epoll_fd_, events, <span class="number">128</span>, timeout);</div><div class="line"></div><div class="line"><span class="comment">// Dispatch the waiting events.</span></div><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_events; ++i)&#123;</div><div class="line">  <span class="keyword">void</span>* ptr = events[i].data.ptr; <span class="comment">//私有数据descriptor_state</span></div><div class="line">  &#123;</div><div class="line">    descriptor_state* descriptor_data = <span class="keyword">static_cast</span>&lt;descriptor_state*&gt;(ptr);</div><div class="line">    descriptor_data-&gt;set_ready_events(events[i].events);</div><div class="line">    private_op_queue.push(descriptor_data);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上面的代码会根据epoll_wait的结果，将就绪事件所关联的descriptor_state数据添加到调用线程的this_thread.private_op_queue这个私有队列上面去。<br>(b). 添加到this_thread.private_op_queue就不管了么？当然不是，这里添加了一个RAII类型的task_io_service::task_cleanup，会自动把this_thread_-&gt;private_op_queue的任务添加到task_io_service_-&gt;op_queue_这个全局队列当中去，同时添加一个垫底的task_operation_，再次等待io_service调度这个任务。下个循环时候，队列弹出来的元素就不是task_operation_，而是descriptor_state类型，此后就有文章可做了，task_result_表示就绪的事件集合。这里需要注意descriptor_state是在派生了operation(task_io_service_operation)的同时，也添加了一些自己的操作，当调用descriptor_state::complete()函数的时候，其调用了自身的func_函数，要想知道这个func_究竟是哪个函数实体，还得看它在构造的时候怎么初始化的，构造函数表明：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[detail/impl/epoll_reactor.ipp]</div><div class="line">epoll_reactor::descriptor_state::descriptor_state()</div><div class="line">  : operation(&amp;epoll_reactor::descriptor_state::do_complete)</div></pre></td></tr></table></figure></p>
<p>这个func_是被初始化成了descriptor_state::do_complete成员函数，所以这里等价调用了descriptor_state::do_complete，其所做的操作为根据events调用descriptor_data-&gt;perform_io(events)函数，而perform_io函数再根据传递进来的就绪事件类型，依次调用对应具体事件的perform()函数，至于这里为啥complete会绕圈而不直接调用perform_io()，其实是因为这个complete()-&gt;func_会被复用，类似于设计模式下的状态模式，等你看到下面就自然明白了。因此其调用链为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">descriptor_state::complete() -&gt; func_ -&gt; do_complete() -&gt; perform_io() -&gt; reactor_op::perform()</div><div class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">bool</span> <span class="params">(*perform_func_type)</span><span class="params">(reactor_op*)</span></span>;</div></pre></td></tr></table></figure></p>
<p>perform调用的是perform_func_函数。在之添加异步操作请求调用start_op的时候，创建了reactive_socket_recv_op对象，在其构造函数中可以清晰地看到：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reactor_op(&amp;reactive_socket_recv_op_base::do_perform, complete_func)</div></pre></td></tr></table></figure></p>
<p>所以这个perform_func_就是reactive_socket_recv_op_base::do_perform成员函数，打开这个函数的定义，实际的IO操作就自然显现出来了，这里的接收函数，以及很多同类的IO操纵函数，都是被定义在socket_ops名字空间中的自由函数，上面已经说到了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> socket_ops::non_blocking_recv(o-&gt;socket_, bufs.buffers(), bufs.count(), </div><div class="line">  o-&gt;flags_, (o-&gt;state_ &amp; socket_ops::stream_oriented) != <span class="number">0</span>,</div><div class="line">  o-&gt;ec_, o-&gt;bytes_transferred_);</div></pre></td></tr></table></figure></p>
<p>在perform_io的函数中，还定义了一个十分重要的RAII对象io_cleanup，原理和上面的task_cleanup一样都是RAII的典型用例，可以学习过来。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">operation* epoll_reactor::descriptor_state::perform_io(<span class="keyword">uint32_t</span> events)</div><div class="line">&#123;</div><div class="line">  <span class="function">perform_io_cleanup_on_block_exit <span class="title">io_cleanup</span><span class="params">(reactor_)</span></span>;</div><div class="line">  ...</div><div class="line">  io_cleanup.first_op_ = io_cleanup.ops_.front();</div><div class="line">  io_cleanup.ops_.pop();</div><div class="line">  <span class="keyword">return</span> io_cleanup.first_op_;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在io_cleanup的析构函数中，首先会返回第一个reactor_op对象io_cleanup.first_op_，然后后面如果还有处理过的op(比如event中堆积了多个就绪的事件)，就会调用reactor_-&gt;io_service_.post_deferred_completions(ops_)把剩余的处理完的opn依次添加到task_io_service::op_queue_上面去。<br>所以，第一个完成的op会被直接调用，其余的op会被添加全局的task_io_service::op_queue_队列上面去。至此，该descriptor_state的底层的IO已经全部完成了。</p>
<p>在上面的perform_io返回了io_cleanup.first_op_之后，会调用它的complete函数：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> epoll_reactor::descriptor_state::do_complete(</div><div class="line">    io_service_impl* owner, operation* base,</div><div class="line">    <span class="keyword">const</span> boost::system::error_code&amp; ec, <span class="built_in">std</span>::<span class="keyword">size_t</span> bytes_transferred)</div><div class="line">&#123;</div><div class="line">  ...</div><div class="line">    <span class="keyword">if</span> (operation* op = descriptor_data-&gt;perform_io(events)) &#123;</div><div class="line">      op-&gt;complete(*owner, ec, <span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可能会觉得，这些对象被反复添加到task_io_service::op_queue_中，而且都是调用complete，那么IO之前的complete和IO之后的complete是怎么区分的呢？其技巧在于：<br>(a). 第一次IO之前传递进去的是descriptor_state对象，在构造的时候将基类的operation::complete()的调用函数通过func_媒介，指向了自己的成员函数do_complete()，在这个函数中定义执行了perform_io()操作；<br>(b). 在IO结束之后，其返回的类型是reactor_op，该对象的complete()，实际是调用最初我们启动async_read()提供的回调函数。<br>因为这两个类都是继承自operation的，所以都可以放到全局op_queue_当中，公用同一套处理流程，而实际的操作会根据对象的不同而不同，算不算是一个状态模式呢。同时，这里也需要弄清楚：descriptor_state是以描述符为对象的，而reactor_op是以事件为对象的，一个描述符可以侦听多个事件，多个事件的op信息使用op_queue<reactor_op> op_queue_[max_ops];数组来保存。<br>通过最终调用reactive_socket_recv_op::do_complete，函数会将调用结果的ec和bytes_transferred传递进去，然后用户提供的回调函数被正式调用，整个异步操作流程到此结束。</reactor_op></p>
<p>自此，Initiator发起异步请求操作和Proactor发起套接字socket的事件侦听和处理就连接起来了，整个工作流程表述为：<br>(a). Intiator通过async_read_some发起请求，同时提供buffer和callback信息；<br>(b). 然后reactive_socket_service一方面将socket关注的事件添加到epoll侦听中去，同时将reactor_op相关的信息添加到与事件对应的op_queue_的队列中；<br>(c). 另外通过io_service::run()，线程会通过do_run_one()-&gt;task_-&gt;run()-&gt;epoll_wait()的方式等待socket就绪的事件，一旦发现就会取出来并将descriptor_state添加到io_service队列上，io_service调度到这个descriptor_state后会调用perform_io进行底层的IO操作；<br>(d). IO完成后，会随即调用第一个reactor_op的complete；此时如果还有其它的reactor_op，会将剩余的添加到io_service::op_queue_队列，让io_service稍后调度执行对应的complete。这些complete会最终会调用用户异步操作时候提供的回调函数，同时更新传递进来的引用参数做为调用结果。</p>
<h1 id="五、composed_operation">五、composed operation</h1><p>之前提到，async_read/write，async_read_until函数是composed operatio，比如一次调用async_read可能会调用零到多次的async_read_some直到某些条件被满足。这里的composed operation是自由函数，在[read.hpp,write.hpp]中声明和定义的，同时根据提供的buffer类型具有MutableBufferSequence和basic_streambuf两大类的重载版本。这里我们先只考虑MutableBufferSequence这种类型。<br>如果只考虑一种buffer类型(比如MutableBufferSequence)，那么其async_read其实还有两种重载类型：一个是用户指定完成条件的，一个是没有指定的。从底层实现看来，两者的实现是极为相似的，只是后者提供了默认的结束条件，差异就在于当用户没有提供CompletionCondition的时候，默认是填满buffer的容量、或者发送错误的情况下async_read结束。为了使用方面，其实对于CompletionCondition条件谓语，Boost.Asio也为我们提供了很多预先定义好的类型，比如boost::asio::transfer_all()等。<br>贴出async_read的函数体：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">template &lt;typename AsyncReadStream, typename MutableBufferSequence,</div><div class="line">    typename ReadHandler&gt;</div><div class="line">inline BOOST_ASIO_INITFN_RESULT_TYPE(ReadHandler,</div><div class="line">    void (boost::system::error_code, std::size_t))</div><div class="line">async_read(AsyncReadStream&amp; s, const MutableBufferSequence&amp; buffers,</div><div class="line">    BOOST_ASIO_MOVE_ARG(ReadHandler) handler)</div><div class="line">&#123;</div><div class="line">  detail::async_result_init&lt;</div><div class="line">    ReadHandler, void (boost::system::error_code, std::size_t)&gt; init(</div><div class="line">      BOOST_ASIO_MOVE_CAST(ReadHandler)(handler));</div><div class="line"></div><div class="line">  detail::read_op&lt;AsyncReadStream, MutableBufferSequence,</div><div class="line">    detail::transfer_all_t, BOOST_ASIO_HANDLER_TYPE(</div><div class="line">      ReadHandler, void (boost::system::error_code, std::size_t))&gt;(</div><div class="line">        s, buffers, transfer_all(), init.handler)(</div><div class="line">          boost::system::error_code(), 0, 1);</div><div class="line"></div><div class="line">  return init.result.get();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我靠，又是一个极其复杂的函数头，函数体主要执行了两个模板函数detail::async_result_init和detail::read_op，<br>在detail::read_op的operator()调用中，可以看到在一个for(;;)有关于async_read_some()的调用，不过这个for(;;)写的也非常诡异，只有在break的时候才表示执行结束的条件满足了，接下来调用handler_，否则会return掉，表示接下来还会再次跳入for(;;)循环中。</p>
<p>花了两天的功夫，总算看完了，也只能算是了解了个大概，很多的东西还是没懂。这个Boost.Asio中充斥着大量的闭包、模板元等特性，需要及其严密的逻辑和对整体的把控才能开发出来并稳定运行，由此真心膜拜一下大神<a href="https://github.com/chriskohlhoff" target="_blank" rel="external">Christopher M. Kohlhoff</a>，感谢你对C++ Network的工作，希望你的代码能让我看懂！</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="http://blog.csdn.net/luansxx/article/details/7854316" target="_blank" rel="external">boost asio 应用方法学（一）——序言</a></li>
<li><a href="http://blog.csdn.net/ithiker/article/details/24348047" target="_blank" rel="external">Linux下Boost.Asio Proactor模式实现分析</a></li>
<li><a href="http://stackoverflow.com/questions/14089412/whats-the-name-of-this-property-of-asynchronous-actions-boost-asio-related" target="_blank" rel="external">What’s the name of this property of asynchronous actions. (boost asio related)</a></li>
<li><a href="http://spiritsaway.info/cpp/asio-implementation.html" target="_blank" rel="external">Asio Implementation</a></li>
<li><a href="http://think-async.com/Asio" target="_blank" rel="external">Asio C++ Library</a></li>
<li><a href="http://vicendominguez.blogspot.com/2014/04/boost-c-library-rpm-packages-for-centos.html" target="_blank" rel="external">Boost C++ library RPM packages for CentOS 6</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　虽然知道异步库实现基本都是对操作系统底层支持的select/poll/epoll/kqueue机制的封装，可是热爱学习的偶，还是想像之前对Libevent一样，如果能了解Boost.Asio的内部异步机制会让人感觉是一件很爽的事情，于是就厚着脸皮把Boost.Asio的核心——io_service代码跟踪读了一下。话说阅读C++的代码确实比C麻烦不少，尤其当其中夹杂着复杂的继承关系、大量泛型参数的时候，同时Boost库的一大风格是为了代码的整洁和编译速度的优化，进行了类声明和实现的分离，形成了大量重复文件名的代码以及一般编辑器不支持的ipp后缀，阅读跳转起来十分不便，想想也真是累啊。但是还是希望自己能早日适应下来！既然选择了这条路，就迟早得迈得过这条坎才行。<br>　　之前也分析过，Windows系统得益于其重叠IO(Overlapped I/O)和完成端口(I/O completion port)机制，算是在操作系统级别支持异步IO操作的，而Linux类系统虽然也有aio_xxx的异步接口，但是用之者寥寥，现在高性能服务端基本都是清一色的select/epoll+普通IO操作实现的。以前看文章据说Linux的aio_xxx不太给力，不知道是用户的选择导致了Linux内核对aio_xxx的发展缺乏动力，还是aio_xxx不完美导致开发者不愿意使用呢？<br>　　要实现跨平台的异步库，由Reactor来实现Proactor容易，因为只要额外添加一步IO操作就可以了，但是反过来要Proactor剥离出Reactor几乎是不可能的，所以当时研究Libevent在Windows平台下好像就只支持select机制，所以预估Libevent在Windows平台下的并发量性能有限。Boost.Asio则是选择了Proactor模式，完全利用了Windows的异步特性，同时在Linux平台下通过增强Reactor来实现Proactor模式，我想这也是Boost.Asio作为一个跨平台的网络库所了不起的地方，同时也是其立志进入C++标准最有力的一票。</p>
<h1 id="一、前期准备">一、前期准备</h1><p>对于了解一个项目，最佳实践当然是Read The Fuck Code!<br>可是在阅读项目代码的时候，虽然也可以像读文章一样人工判断出执行流程，但是如果能够以边调试边运行的方式来跟踪，那么结果将会更加的确信可靠。在Linux下面，虽然编辑神器Vim/Emacs可以各种外挂配置形成超级IDE神器，但是自己这个年纪还是怕折腾了——直接用的SlickEdit，这家伙号称是最贵的IDE，但是确实挺好用的，而且是跨平台的(但是真正Windows下大多人还是会用微软自家的Visual Studio吧，真幸福)，等在下能够经济自由的那一天，定要好支持一下。SlickEdit对于一般的代码是做的很好的，但是对于大量模板情况下的跟踪，还是有所缺陷，比如没法显示实例化的模板参数类型，希望能不断更新改进。<br>我在学习调试的时候，是直接使用upstream的boost版本，但是很多发行版会打包甚至安装一些旧的发布版本，为了使用自己控制的upstream版本，需要额外的配置一下环境：<br>(a). 在GitHub上面clone最新的boost源代码，然后编译安装到本地的目录，参考的编译命令可以是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  boost git:(master) ✗ ./bootstrap.sh</div><div class="line">➜  boost git:(master) ✗ ./b2 headers</div><div class="line">➜  boost git:(master) ✗ mkdir builddir installdir</div><div class="line">➜  boost git:(master) ✗ ./b2 --build-dir=builddir --prefix=installdir <span class="_">-a</span> -q toolset=gcc variant=debug </div><div class="line">➜  boost git:(master) ✗ <span class="comment">#./b2 -j4 --build-dir=builddir --prefix=/home/taozj/root/ --without-python -a -q toolset=gcc cxxflags="-std=c++0x" variant=debug threading=multi install</span></div></pre></td></tr></table></figure></p>
<p>(b). 随便新建一个项目，Boost.Asio的example中有一大把，比如找一个包含包含async_read/write_some调用的简单例程的(比如async_udp_echo_server.cpp)，然后修改项目的Makefile，将自己指定的boost安装目录中的include和lib添加到编译环境中去。Makefile的例子可以参考我<a href="https://github.com/taozhijiang/airobot_msgd/blob/master/Makefile">项目</a>中使用的<br>此外，还要修改系统的LD_LIBRARY_PATH，可以通过在/etc/ld.conf.d目录中添加一个上面的安装目录，然后运行ldconfig刷新一下系统即可，否则最终链接的时候还是会报错找不到符号的。<br>(c). 这个时候，就可以使用ldd命令查看编译出来的可执行文件依赖哪些链接库，看看是不是最终依赖到了指定的本地版本boost，同时也可以运行一下可执行程序看是否正常。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  asio_learn ldd Debug/asio_learn </div><div class="line">	linux-vdso.so.1 =&gt;  (0x00007ffd33dc9000)</div><div class="line">	libboost_system.so.1.62.0 =&gt; /home/user/Dropbox/ReadTheCode/boost/installdir/lib/libboost_system.so.1.62.0 (0x00007f277ad55000)</div><div class="line">	libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f277ab38000)</div><div class="line">	libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f277a7b5000)</div><div class="line">	libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f277a59f000)</div><div class="line">	libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f277a1d6000)</div><div class="line">	/lib64/ld-linux-x86-64.so.2 (0x0000556214f39000)</div><div class="line">	libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2779ecc000)</div></pre></td></tr></table></figure></p>
<p>(d). 修改SlickEdit编辑器，在Project Properties-&gt;Directories-&gt;Include中，把本地的installdir/include加到最前面去，刷新Retag一下Slickedit，查看里面的变量定义跳转文件是不是正确。<br>至此，这个学习跟踪环境就完成了。</p>
<h1 id="二、io_service中三个成员变量">二、io_service中三个成员变量</h1><p>io_service核心类主要成员变量只有三个：init_、service_registry_和impl_。<br>(a). [detail/signal_init.hpp] detail::signal_init&lt;&gt; init_：在默认构造signal_init的时候，会将SIGPIPE的信号给忽略掉，这算基本是所有网络开发程序的默认行为；<br>(b). [io_service.hpp] impl_type&amp; impl_：通过宏的控制，impl_type在Linux平台等价于task_io_service类型，Linux和Windows两种平台的操作在这里会进行分流；<br>(c). [detail/service_registry.hpp] detail::service_registry* service_registry_：其实现类型是一个单例对象的侵入链表，其中每一个服务都有对应的ID号，Linux平台在后面经常遇到的服务有detail::task_io_service、detail::reactive_socket_service、detail::epoll_reactor，这些个类一方面是跟平台相关密切，同时他们之间的联系也是错综复杂，暂且不表吧！</p>
<p>[detail/impl/epoll_reactor.ipp]task_io_service中有几个重要的成员变量：<br>(a). atomic_count outstanding_work_; 表示未完成的work数目，在work_start()的时候会增加，在work_finished()的时候会递减；<br>(b). [detail/reactor_fwd.hpp] reactor* task_; 这个reactor在reactor_fwd.hpp中通过宏BOOST_ASIO_HAS_XXX来进行控制的，这也就是说没有Libevent那种可以通过调用代码的方式灵活的选择选择select/poll/epoll各种模型了，通常在Linux中会被定义成epoll_reactor；<br>(c). [detail/op_queue.hpp] op_queue<operation> op_queue_; 这里实现了一个operation_queue的队列容器，同时定义了op_queue_access这个访问者类对这个op队列进行操作管理。这个队列是多个线程共享的，存储的元素可以是descriptor_state、reactor_op类型，后面会经常涉及到这两种类型。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Boost.Asio网络开发基础知识（一）：读读文档]]></title>
    <link href="https://taozj.org/201609/basics-of-boost-asio-(1)-read-the-docs.html"/>
    <id>https://taozj.org/201609/basics-of-boost-asio-(1)-read-the-docs.html</id>
    <published>2016-09-25T04:52:32.000Z</published>
    <updated>2016-12-18T08:41:56.000Z</updated>
    <content type="html"><![CDATA[<p>　　虽然C++可以用Libevent等纯C实现框架进行异步操作，但是总感觉Boost.Asio才算是相对正统纯正的C++网络开发，而且据说已经起草的C++ Network Library就是基于Boost.Asio的，这不禁让我这个初入Boost的菜鸟暗中激动了一把。<br>　　在我所了解的Libevent和Boost.Asio当中，最大的差别是前者是Reactor模式，后者是Proactor模式了，不过Linux平台底层操作系统级别的select/poll/epoll只能适合Reactor模式的开发，所以Linux类平台下的Boost.Asio也是通过synchronous event demultiplexors的方式模拟实现的Proactor模式。除此之外，Libevent提供了一个Evbuffer的IO缓冲数据结构，而Boost.Asio同样也提供了boost::asio::buffer和boost::asio::streambuf两种缓冲类型，不过这也算是个壳吧，至少boost::asio:buffer构造的时候还是需要传输底层数组或者容器类实例作为实际数据的载体的。再则，Boost.Asio提供了自带线程池的功能，包括单个io_service运行在多个线程上和每个线程自己单独的io_service两种模式，这在网络库中并不多见吧。这个机制确实提高了多线程开发的效率，同时也免去了很多初学者自己制造垃圾线程池的烦恼。<br>　　可惜的是，据我Google关于Boost.Asio网上的资料确实好少，其中找到的大多都是那种教你怎么使用的简单例子，很少有深入剖析的资料，作为实际工业实现标准级别C++网络库Boost.Asio不觉得免有些奇怪，希望C++网络库标准敲定之后，这类部分能得到更多的关注吧。不过Boost.Asio确实还蛮好用的，看看附加的例子基本就能模仿出个不错的服务端了，今天把Boost.Asio的文档过了一遍，在此做个记录。</p>
<p><strong>1. 概述</strong><br>　　说到Boost.Asio，就不得不祭出这张Proactor设计模式的大图：<br><img src="/post_images/images/201609/7a27c440c2d2ebfee1afc8c1c860e7c6.png" alt="Boost.Asio Proactor"><br>　　关于图中的术语描述如下(其中当末尾明确指出了Reactor的，是在Windows和Linux类实现有所不同的地方，Linux类使用基于Reactor来模拟Proactor的模式)：<br>　　a. Initiator：应用程序相关的代码，主要是发起异步操作的请求，在启动异步操作的时候负责创建一个异步回调对象；<br>　　b. Asynchronous Operation Processor：执行异步操纵，并且将执行结束后，将时间排列到时间完成队列上去。在Reactor模式下的实现是，当select/epoll等指示出等待的资源就绪可以进行操作的时候，processor会执行实际的异步操作，完成之后会将与其关联的completion handler添加完成事件队列上去；<br>　　c. Asynchronous Operation：定义了异步执行的操作；<br>　　d. Completion Event Queue：缓存了已经完成事件直到被asynchronous event demultiplexer取出队列。在Reactor模式下通常是链接的函数对象；<br>　　e. Asynchronous Event Demultiplexer：阻塞形式地等待在完成事件队列上，直到有事件发生，然后返回一个完成事件给调用者。在Reactor模式下，是通过等待在某个事件或者某个条件变量上面，直到完成时间队列上completion handler就绪；<br>　　f. Completion Handler：用以处理异步操作完成的结果，其是个函数对象(function objects)，通常使用boost:bind()创建的；<br>　　g. Proactor：调用asynchronous event demultiplexer去从完成队列中取出完成的事件，并且调用处理(dispatch)事件对应的completion handler。<br><a id="more"></a><br><strong>2. Strand</strong><br>　　strand可以保证严格序列化地执行event handlers，使用strand可以安全的在多线程环境下执行程序，而不需要使用者显式的使用mutex等方式来同步。strand的可以以隐式或者显式的方式存在：<br>　　a. 如果只在一个线程中调用io_service::run()，那么所有的event handlers都是在一个隐式strand中序列化执行的；<br>　　b. 对于一个链接只有一个单链异步操作的时候，其不可能并发的执行event handlers，这也是隐式strand的。(文中提到了比如HTTP的单双工协议，我的理解是HTTP只会客户端请求、服务端返回数据这种形式，而不会服务端主动请求，没有并行的可能性，所以所有的请求应当必然是串行化的)；<br>　　c. 可以显式实例化一个strand对象，然后所有的event handlers必须使用io_service::strand::wrap()进行包裹，或者使用该strand对象显式post/dispatch；<br>　　关于Strand，Boost.Asio的手册说的不是很清楚，在此明确一下表示：<br>　　Boost.Asio对线程安全的保证描述是，concurrent使用不同的object是安全的，但是concurrent使用相同的object是不安全的，这就比如一个socket可以在一个线程中随便使用，或者在两个线程中不同时使用，但是绝对不允许在两个线程中重叠使用(即使通常意义上的socket也不要同时在多线程中使用)。Boost.Asio这里复杂了是因为async_write、async_read包括async_read_until这类函数被称为composed operation，他会在底层零次或者多次调用async_write_some这类函数来实现的，所以对这一类函数的调用，必须显式使用strand进行串行化其内部的操作，同时用户端程序还必须保证在执行这个操作的过程中不会有其他的async_write、async_write_some等函数的调用。这样HTTP Example3的strand也就不难解释了。</p>
<p><strong>3. 缓冲类型</strong><br>　　Boost.Asio是支持聚合读写(scatter-gather operations)的，当需要的时候将各个buffer装入容器中传递给聚合操作。对于单独的buffer，<br>　　a. boost::asio::buffer<br>　　主要有mutable_buffer、const_buffer两种类型，从一般的概念上讲是如下的含义<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">void</span>*, <span class="built_in">std</span>::<span class="keyword">size_t</span>&gt; mutable_buffer;</div><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">const</span> <span class="keyword">void</span>*, <span class="built_in">std</span>::<span class="keyword">size_t</span>&gt; const_buffer;</div></pre></td></tr></table></figure></p>
<p>　　但是实际Boost.Asio是定义了这两个类，主要基于以下考虑：(1)如果是上面类型，那么mutable可以转换成const的，但是反向的转换是不允许的；(2)可以保护防止缓冲区溢出，类可以通过传递的array、std::vector、std::string、std::arry、POD等各种类型自动推断出buffer的长度；(3)可以定义buffer_cast等成员函数做更丰富的操作需求，而不是底层数据的野蛮转换。<br>　　b. boost::asio::streambuf<br>　　派生自std::basic_streambuf类而关联了input和output两个序列，序列底层用一个或者多个字符数组存储数据的，当然这些数据是streambuf内部使用的，而streambuf提供一系列的接口来操作这些数据：<br>　　(1) data()成员函数访问input，返回的类型满足ConstBufferSequence类型；<br>　　(2) prepare()成员函数用于访问output，返回的类型满足MutableBufferSequence类型；<br>　　(3) commit()成员函数用于将output头部的数据移动到input的尾部；<br>　　(4) consume()成员函数用于移除input头部的数据；<br>　　streambuf的构造函数可以传递一个size_t的参数来指明input和output总共的最大尺寸，当使用的总空间超过这个限制的时候，会抛出std::length_error的异常。<br>　　此外，streambuf提供了迭代器的接口，可以连续访问内部存储的字节序列，其操作的模板是：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">std::size_t n = boost::asio::read_until(sock, sb, '\n');</div><div class="line">boost::asio::streambuf::const_buffers_type bufs = sb.data();</div><div class="line">std::string line(</div><div class="line">    boost::asio::buffers_begin(bufs),</div><div class="line">    boost::asio::buffers_begin(bufs) + n);</div></pre></td></tr></table></figure></p>
<p><strong>4. 流数据操作</strong><br>　　Boost.Asio中的大多数操作都是基于流(stream)的，所以：对消息没有边界的概念，真正传输的数据都是一些列连续的字节序列；读和写操作实际传输的字节数目可能会比请求的数目要少。常用的同步和异步操作有：read_some()、async_read_some()、write_some()、async_write_some()。<br>　　当开发过程中有需要传输指定长度的消息的时候，可以使用Boost.Asio的read()、async_read()、write()、async_write()来实现，他们会自动重复执行传输操作，直到请求的操作数完成。不嫌麻烦的话用户程序不断尝试直到完成也是可以的。<br>　　当流请求操作结束后会涉及到EOF，成功读返回读取长度为0表示该流已经结束了。</p>
<p><strong>5. Reactor模式风格的操作</strong><br>　　有时候有的程序可能自己进行I/O操作，Boost.Asio也支持这种机制。当在IO读写函数需要传递buffer对象的地方传递null_buffers对象既可，这时候null_buffers的操作会在底层的数据准备好(可以成功读写)之后返回。<br>　　然后，客户程序就可以使用同步读写函数来进行IO操作了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">socket.async_read_some(null_buffers(), read_handler);</div><div class="line">...</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_handler</span><span class="params">(boost::system::error_code ec)</span> </span>&#123;</div><div class="line">  <span class="keyword">if</span> (!ec) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; buf(socket.available());</div><div class="line">    socket.read_some(buffer(buf));</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>6. 基于行模式的操作</strong><br>　　很多网络引用层的协议(HTTP、SMTP、FTP)都是基于行(line-based)的，所以这些协议的元素都是用”\r\n”来分隔的，此时Boost.Asio的read_until和async_read_until就可以方便的来处理基于行或者基于特定分隔符的应用层协议了，简单用法其支持的分隔符包括char、std::string、boost::regex类型的表达式。<br>　　更高端的用法是(async_)read_until支持接收一个用户定义的函数或者函数对象，其函数或者函数对象具有以下的形式：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> boost::asio::buffers_iterator&lt;</div><div class="line">    boost::asio::streambuf::const_buffers_type&gt; iterator;</div><div class="line"> </div><div class="line"><span class="built_in">std</span>::pair&lt;iterator, <span class="keyword">bool</span>&gt;</div><div class="line">match_whitespace(iterator begin, iterator end)&#123;</div><div class="line">...</div><div class="line"><span class="keyword">return</span> <span class="built_in">std</span>::make_pair(i, <span class="literal">true</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　所以我在开发HTTP简单应用的时候，都是先用streambuf的async_read_until读取”\r\n\r\n”表示HTTP头部结束的位置，分析头部的Length字段得到数据体的具体大小，然后调用async_read添加transfer_exactly参数来进行精确传输的。这里使用需要格外注意的是，HTTP的头和体不是分开传输的，绝大多数async_read_until会读一部分的BODY，这时候需要手动将这部分的数据转移到async_read的缓冲区里面去。</p>
<p><strong>7. 其它</strong><br>　　C++11提供了右值引用和移动语义，所以在Boost.Asio中可以使用这些语义来移动IO object和Handler。在移动IO Object的时候需要特别的注意，当其上面还有pending的异步操作时候，移动它是很危险的，常常诸如async_read()会保存这些对象的引用，意味着很可能后面会用到move-from的对象。一般在开始构造connection的时候可以利用移动语句，后面使用还需谨慎。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tcp::socket socket_;</div><div class="line">connection(tcp::socket&amp;&amp; s) : socket_(<span class="built_in">std</span>::move(s)) &#123;&#125;</div><div class="line">...</div><div class="line"><span class="built_in">std</span>::make_shared&lt;connection&gt;(<span class="built_in">std</span>::move(socket_))-&gt;go();</div><div class="line">acceptor_.async_accept(socket_, ...);</div></pre></td></tr></table></figure></p>
<p><strong>8. 小结</strong><br>　　哈哈，基本没什么干货或者新东西，Boost.Asio的开发还是建议多看看官方提供的那些<a href="http://www.boost.org/doc/libs/1_51_0/doc/html/boost_asio/examples.html" target="_blank" rel="external">例子</a>，另外我的<a href="https://github.com/taozhijiang/airobot_msgd" target="_blank" rel="external">airobot_msgd</a>也囊括了大多数的操作，尽请指正。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4478.html" target="_blank" rel="external">Networking Library Proposal (Revision 5)</a></li>
<li><a href="http://blog.csdn.net/luansxx/article/details/7854316" target="_blank" rel="external">boost asio 应用方法学（一）——序言</a></li>
<li><a href="http://blog.csdn.net/ithiker/article/details/24348047" target="_blank" rel="external">Linux下Boost.Asio Proactor模式实现分析</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/overview.html" target="_blank" rel="external">Boost.Asio Overview</a></li>
<li><a href="http://www.crazygaze.com/blog/2016/03/17/how-strands-work-and-why-you-should-use-them/" target="_blank" rel="external">How strands work and why you should use them</a></li>
<li><a href="https://stackoverflow.com/questions/12794107/why-do-i-need-strand-per-connection-when-using-boostasio" target="_blank" rel="external">Why do I need strand per connection when using boost::asio?</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　虽然C++可以用Libevent等纯C实现框架进行异步操作，但是总感觉Boost.Asio才算是相对正统纯正的C++网络开发，而且据说已经起草的C++ Network Library就是基于Boost.Asio的，这不禁让我这个初入Boost的菜鸟暗中激动了一把。<br>　　在我所了解的Libevent和Boost.Asio当中，最大的差别是前者是Reactor模式，后者是Proactor模式了，不过Linux平台底层操作系统级别的select/poll/epoll只能适合Reactor模式的开发，所以Linux类平台下的Boost.Asio也是通过synchronous event demultiplexors的方式模拟实现的Proactor模式。除此之外，Libevent提供了一个Evbuffer的IO缓冲数据结构，而Boost.Asio同样也提供了boost::asio::buffer和boost::asio::streambuf两种缓冲类型，不过这也算是个壳吧，至少boost::asio:buffer构造的时候还是需要传输底层数组或者容器类实例作为实际数据的载体的。再则，Boost.Asio提供了自带线程池的功能，包括单个io_service运行在多个线程上和每个线程自己单独的io_service两种模式，这在网络库中并不多见吧。这个机制确实提高了多线程开发的效率，同时也免去了很多初学者自己制造垃圾线程池的烦恼。<br>　　可惜的是，据我Google关于Boost.Asio网上的资料确实好少，其中找到的大多都是那种教你怎么使用的简单例子，很少有深入剖析的资料，作为实际工业实现标准级别C++网络库Boost.Asio不觉得免有些奇怪，希望C++网络库标准敲定之后，这类部分能得到更多的关注吧。不过Boost.Asio确实还蛮好用的，看看附加的例子基本就能模仿出个不错的服务端了，今天把Boost.Asio的文档过了一遍，在此做个记录。</p>
<p><strong>1. 概述</strong><br>　　说到Boost.Asio，就不得不祭出这张Proactor设计模式的大图：<br><img src="/post_images/images/201609/7a27c440c2d2ebfee1afc8c1c860e7c6.png" alt="Boost.Asio Proactor"><br>　　关于图中的术语描述如下(其中当末尾明确指出了Reactor的，是在Windows和Linux类实现有所不同的地方，Linux类使用基于Reactor来模拟Proactor的模式)：<br>　　a. Initiator：应用程序相关的代码，主要是发起异步操作的请求，在启动异步操作的时候负责创建一个异步回调对象；<br>　　b. Asynchronous Operation Processor：执行异步操纵，并且将执行结束后，将时间排列到时间完成队列上去。在Reactor模式下的实现是，当select/epoll等指示出等待的资源就绪可以进行操作的时候，processor会执行实际的异步操作，完成之后会将与其关联的completion handler添加完成事件队列上去；<br>　　c. Asynchronous Operation：定义了异步执行的操作；<br>　　d. Completion Event Queue：缓存了已经完成事件直到被asynchronous event demultiplexer取出队列。在Reactor模式下通常是链接的函数对象；<br>　　e. Asynchronous Event Demultiplexer：阻塞形式地等待在完成事件队列上，直到有事件发生，然后返回一个完成事件给调用者。在Reactor模式下，是通过等待在某个事件或者某个条件变量上面，直到完成时间队列上completion handler就绪；<br>　　f. Completion Handler：用以处理异步操作完成的结果，其是个函数对象(function objects)，通常使用boost:bind()创建的；<br>　　g. Proactor：调用asynchronous event demultiplexer去从完成队列中取出完成的事件，并且调用处理(dispatch)事件对应的completion handler。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[C++11标准中的Atomic原子操作和内存模型]]></title>
    <link href="https://taozj.org/201609/cpp11-atomic-and-memory-model.html"/>
    <id>https://taozj.org/201609/cpp11-atomic-and-memory-model.html</id>
    <published>2016-09-23T09:02:40.000Z</published>
    <updated>2016-12-18T08:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>　　原子操作在多线程开发中经常用到，比如在计数器，序列产生器等地方，这类情况下数据有并发的危险，但是用锁去保护又显得有些浪费，所以原子类型操作十分的方便。<br>　　原子操作虽然用起来简单，但是其背景远比我们想象的要复杂。其主要在于现代计算系统过于的复杂：多处理器、多核处理器、处理器又有核心独有以及核心共享的多级缓存，在这种情况下，一个核心修改了某个变量，其他核心什么时候可见是一个十分严肃的问题。同时在极致最求性能的时代，处理器和编译器往往表现的很智能，进行极度的优化，比如什么乱序执行、指令重排等，虽然可以在当前上下文中做到很好的优化，但是放在多核环境下常常会引出新的问题来，这时候就必须提示编译器和处理器某种提示，告诉某些代码的执行顺序不能被优化。<br>　　所以这里说到的原子操作，基本都包含我们三个方面所关心的语义：操作本身是不可分割的(Atomicity)，一个线程对某个数据的操作何时对另外一个线程可见(Visibility)，执行的顺序是否可以被重排(Ordering)。<br><img src="/post_images/images/201609/1a568a5bae9b5dba290855689577f81f.png" alt="lockfree"></p>
<h1 id="一、legacy_GCC___sync">一、legacy GCC __sync</h1><p>　　据说在C++11标准出来之前，大家都诟病C++标准没有一个明确的内存模型，随着多线程开发的普及这个问题显得越来越迫切。当然各个C++编译器实现者也是各自为政，GCC自然是实用主义当道，于是根据Intel的开发手册老早就搞出了一系列的__sync原子操作函数集合，这也是被广大程序员最为熟悉常用的操作了吧，罗列如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>sync_fetch_and_OP (type *ptr, type value, ...)</div><div class="line">type <span class="number">__</span>sync_OP_and_fetch (type *ptr, type value, ...)</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>sync_bool_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line">type <span class="number">__</span>sync_val_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line"><span class="number">__</span>sync_synchronize (...)</div><div class="line"></div><div class="line">type <span class="number">__</span>sync_lock_test_and_set (type *ptr, type value, ...)</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>sync_lock_release (type *ptr, ...)</div></pre></td></tr></table></figure></p>
<p>　　上面的OP操作包括add、sub、or、and、xor、nand这些常见的数学操作，而type表示的数据类型Intel官方允许的是int、long、long long的带符号和无符号类型，但是GCC扩展后允许任意1/2/4/8的标量类型；CAS的操作有两个版本分别返回bool表示是否成功，而另外一个在操作之前会先返回ptr地址处存储的值；__sync_synchronize直接插入一个full memory barrier，当然你也可能经常见到像asm volatile(“” ::: “memory”);这样的操作。前面的这些原子操作都是full barrier类型的，这意味着：任何内存操作的指令不允许跨越这些操作重新排序。<br>　　__sync_lock_test_and_set用于将value的值写入ptr的位置，同时返回ptr之前存储的值，其内存模型是acquire barrier，意味着该操作之后的memory store指令不允许重排到该操作之前去，不过该操作之前的memory store可以排到该操作之后去，而__sync_lock_release则更像是对前面一个操作锁的释放，通常意味着将0写入ptr的位置，该操作是release barrier，意味着之前的memory store是全局可见的，所有的memory load也都完成了，但是接下来的内存读取可能会被排序到该操作之前执行。可以这里比较绕，翻译起来也比较的拗口，不过据我所见，这里很多是用在自旋锁类似的操作上，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> <span class="number">_</span>sync;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span>(<span class="number">__</span>sync_lock_test_and_set(&amp;<span class="number">_</span>sync, <span class="number">1</span>));</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">unlock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="number">__</span>sync_lock_release(&amp;<span class="number">_</span>sync);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其实这里的1可以是任何non-zero的值，主要是用作bool的效果。<br><a id="more"></a></p>
<h1 id="二、C++11_新标准中的内存模型">二、C++11 新标准中的内存模型</h1><p>　　上面GCC那种full barrier的操作确实有效，但是就像当初系统内核从单核切换到多核用大颗粒锁一样的简单粗暴，先不说这种形势下编译器和处理器无法进行优化，光要变量使其对他处理器可见，就需要在处理间进行硬件级别的同步，显然是十分耗费资源的。在C++11新标准中规定的内存模型(memory model)颗粒要细化的多，如果熟悉这些内存模型，在保证业务正确的同时可以将对性能的影响减弱到最低。<br>　　原子变量的通用接口使用store()和load()方式进行存取，可以额外接受一个额外的memory order参数，而不传递的话默认是最强模式Sequentially Consistent。<br>　　根据执行线程之间对变量的同步需求强度，新标准下的内存模型可以分成如下几类：</p>
<h2 id="2-1_Sequentially_Consistent">2.1 Sequentially Consistent</h2><p>　　该模型是最强的同步模式，参数表示为std::memory_order_seq_cst，同时也是默认的模型。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">-Thread <span class="number">1</span>-       -Thread <span class="number">2</span>-</div><div class="line">y = <span class="number">1</span>            <span class="keyword">if</span> (x.load() == <span class="number">2</span>)</div><div class="line">x.store (<span class="number">2</span>);        assert (y == <span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>　　对于上面的例子，即使x和y是不相关的，通常情况下处理器或者编译器可能会对其访问进行重排，但是在seq_cst模式下，x.store(2)之前的所有memory accesses都会happens-before在这次store操作。<br>另外一个角度来说：对于seq_cst模式下的操作，所有memory accesses操作的重排不允许跨域这个操作，同时这个限制是双向的。</p>
<h2 id="2-2_Acquire/Release">2.2 Acquire/Release</h2><p>　　GCC的wiki可能讲的不太清楚，查看下面的典型Acquire/Release的使用例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; a&#123;<span class="number">0</span>&#125;;</div><div class="line"><span class="keyword">int</span> b = <span class="number">0</span>;</div><div class="line"></div><div class="line">-Thread <span class="number">1</span>-</div><div class="line">b = <span class="number">1</span>;</div><div class="line">a.store(<span class="number">1</span>, memory_order_release);</div><div class="line"></div><div class="line">-Thread <span class="number">2</span>-</div><div class="line"><span class="keyword">while</span> (a.load(memory_order_acquire) != <span class="number">1</span>)  <span class="comment">/*waiting*/</span>;</div><div class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; b &lt;&lt; <span class="string">'\n'</span>;</div></pre></td></tr></table></figure></p>
<p>　　毫无疑问，如果是seq_cst，那么上面的操作一定是成功的(打印变量b显示为1)。<br>　　a. memory_order_release保证在这个操作之前的memory accesses不会重排到这个操作之后去，但是这个操作之后的memory accesses可能会重排到这个操作之前去。通常这个主要是用于之前准备某些资源后，通过store+memory_order_release的方式”Release”给别的线程；<br>　　b. memory_order_acquire保证在这个操作之后的memory accesses不会重排到这个操作之前去，但是这个操作之前的memory accesses可能会重排到这个操作之后去。通常通过load+memory_order_acquire判断或者等待某个资源，一旦满足某个条件后就可以安全的“Acquire”消费这些资源了。</p>
<h2 id="2-3_Consume">2.3 Consume</h2><p>　　这是一个相比Acquire/Release更加宽松的内存模型，对非依赖的变量也去除了happens-before的限制，减少了所需同步的数据量，可以加快执行的速度。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">-Thread <span class="number">1</span>-</div><div class="line">n = <span class="number">1</span></div><div class="line">m = <span class="number">1</span></div><div class="line">p.store (&amp;n, memory_order_release)</div><div class="line"></div><div class="line">-Thread <span class="number">2</span>-</div><div class="line">t = p.load (memory_order_acquire);</div><div class="line">assert( *t == <span class="number">1</span> &amp;&amp; m == <span class="number">1</span> );</div><div class="line"></div><div class="line">-Thread <span class="number">3</span>-</div><div class="line">t = p.load (memory_order_consume);</div><div class="line">assert( *t == <span class="number">1</span> &amp;&amp; m == <span class="number">1</span> );</div></pre></td></tr></table></figure></p>
<p>　　线程2的assert会pass，而线程3的assert可能会fail，因为n出现在了store表达式中，算是一个依赖变量，会确保对该变量的memory access会happends-before在这个store之前，但是m没有依赖关系，所以不会同步该变量，对其值不作保证。<br>　　Comsume模式因为降低了需要在硬件之间同步的数量，所以理论上其执行的速度会比之上面的内存模型块一些，尤其在共享内存大规模数据量情况下，应该会有较明显的差异表现出来。<br>　　在这里，Acquire/Consume~Release这种线程间同步协作的机制就被完全暴露了，通常会形成Acquired/Consume来等待Release的某个状态更新。需要注意的是这样的通信需要两个线程间成对的使用才有意义，同时对于没有使用这个内存模型的第三方线程没有任何作用效果。</p>
<h2 id="2-4_Relaxed">2.4 Relaxed</h2><p>　　最宽松的模式，memory_order_relaxed没有happens-before的约束，编译器和处理器可以对memory access做任何的re-order，因此另外的线程不能对其做任何的假设，这种模式下能做的唯一保证，就是一旦线程读到了变量var的最新值，那么这个线程将再也见不到var修改之前的值了。<br>　　这种情况通常是在需要原子变量，但是不在线程间同步共享数据的时候会用，同时当relaxed存一个数据的时候，另外的线程将需要一个时间才能relaxed读到该值，在非缓存一致性的构架上需要刷新缓存。在开发的时候，如果你的上下文没有共享的变量需要在线程间同步，选用Relaxed就可以了。</p>
<h2 id="2-5_小结">2.5 小结</h2><p>　　看到这里，你对Atomic原子操作，应当不仅仅停留在indivisable的层次了，因为所有的内存模型都能保证对变量的修改是原子的，C++11新标准的原子应该上升到了线程间数据同步和协作的问题了，跟前面的LockFree关系也比较密切。<br>　　手册上也这样告诫菜鸟程序员：除非你知道这是什么，需要减弱线程间原子上下文同步的耦合性增加执行效率，才考虑这里的内存模型来优化你的程序，否则还是老老实实的使用默认的memory_order_seq_cst，虽然速度可能会慢点，但是稳妥些，万一由于你不成熟的优化带来问题，是很难去调试的。</p>
<h1 id="三、C++11_GCC___atomic">三、C++11 GCC __atomic</h1><p>　　GCC实现了C++11之后，上面的__sync系列操作就变成了Legacy而不被推荐使用了，而基于C++11的新原子操作接口使用__atomic作为前缀。<br>　　对于普通的数学操作函数，其函数接口形式为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>atomic_OP_fetch (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line">type <span class="number">__</span>atomic_fetch_OP (type *ptr, type val, <span class="keyword">int</span> memorder);</div></pre></td></tr></table></figure></p>
<p>　　除此之外，还根据新标准提供了一些新的接口：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>atomic_load_n (type *ptr, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_store_n (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line">type <span class="number">__</span>atomic_exchange_n (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_compare_exchange_n (type *ptr, type *expected, type desired, <span class="keyword">bool</span> weak, <span class="keyword">int</span> success_memorder, <span class="keyword">int</span> failure_memorder);</div><div class="line"> </div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_test_and_set (<span class="keyword">void</span> *ptr, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_clear (<span class="keyword">bool</span> *ptr, <span class="keyword">int</span> memorder);</div><div class="line"> </div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_thread_fence (<span class="keyword">int</span> memorder);</div><div class="line"> </div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_always_lock_free (<span class="keyword">size_t</span> size, <span class="keyword">void</span> *ptr);</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_is_lock_free (<span class="keyword">size_t</span> size, <span class="keyword">void</span> *ptr);</div></pre></td></tr></table></figure></p>
<p>　　从函数名，看起来意思也很明了吧，上面的带_n的后缀版本如果去掉_n就是不用提供memorder的seq_cst版本。最后的两个函数，是判断系统上对于某个长度的对象是否会产生lock-free的原子操作，一般long long这种8个字节是没有问题的，对于支持128位整形的构架就可以达到16字节无锁结构了。</p>
<p>　　Boost.Asio这里就不在罗列了，不过其中有一些例子比较好，基于内存模型的Wait-free的ring buffer、producer-customer的例子，可以去看看。</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="http://theboostcpplibraries.com/boost.atomic" target="_blank" rel="external">Chapter 45. Boost.Atomic</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/atomic.html" target="_blank" rel="external">Chapter 5. Boost.Atomic</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html" target="_blank" rel="external">6.52 Built-in Functions for Memory Model Aware Atomic Operations</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html" target="_blank" rel="external">6.51 Legacy __sync Built-in Functions for Atomic Memory Access</a></li>
<li><a href="https://fotisl.com/blog/2009/11/concurrent-programming-the-fast-and-dirty-way/" target="_blank" rel="external">Concurrent programming the fast and dirty way!</a></li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf" target="_blank" rel="external">n3337.pdf</a></li>
<li><a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync" target="_blank" rel="external">GCC wiki on atomic synchronization</a></li>
<li><a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="external">Double-Checked Locking is Fixed In C++11</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　原子操作在多线程开发中经常用到，比如在计数器，序列产生器等地方，这类情况下数据有并发的危险，但是用锁去保护又显得有些浪费，所以原子类型操作十分的方便。<br>　　原子操作虽然用起来简单，但是其背景远比我们想象的要复杂。其主要在于现代计算系统过于的复杂：多处理器、多核处理器、处理器又有核心独有以及核心共享的多级缓存，在这种情况下，一个核心修改了某个变量，其他核心什么时候可见是一个十分严肃的问题。同时在极致最求性能的时代，处理器和编译器往往表现的很智能，进行极度的优化，比如什么乱序执行、指令重排等，虽然可以在当前上下文中做到很好的优化，但是放在多核环境下常常会引出新的问题来，这时候就必须提示编译器和处理器某种提示，告诉某些代码的执行顺序不能被优化。<br>　　所以这里说到的原子操作，基本都包含我们三个方面所关心的语义：操作本身是不可分割的(Atomicity)，一个线程对某个数据的操作何时对另外一个线程可见(Visibility)，执行的顺序是否可以被重排(Ordering)。<br><img src="/post_images/images/201609/1a568a5bae9b5dba290855689577f81f.png" alt="lockfree"></p>
<h1 id="一、legacy_GCC___sync">一、legacy GCC __sync</h1><p>　　据说在C++11标准出来之前，大家都诟病C++标准没有一个明确的内存模型，随着多线程开发的普及这个问题显得越来越迫切。当然各个C++编译器实现者也是各自为政，GCC自然是实用主义当道，于是根据Intel的开发手册老早就搞出了一系列的__sync原子操作函数集合，这也是被广大程序员最为熟悉常用的操作了吧，罗列如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>sync_fetch_and_OP (type *ptr, type value, ...)</div><div class="line">type <span class="number">__</span>sync_OP_and_fetch (type *ptr, type value, ...)</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>sync_bool_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line">type <span class="number">__</span>sync_val_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line"><span class="number">__</span>sync_synchronize (...)</div><div class="line"></div><div class="line">type <span class="number">__</span>sync_lock_test_and_set (type *ptr, type value, ...)</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>sync_lock_release (type *ptr, ...)</div></pre></td></tr></table></figure></p>
<p>　　上面的OP操作包括add、sub、or、and、xor、nand这些常见的数学操作，而type表示的数据类型Intel官方允许的是int、long、long long的带符号和无符号类型，但是GCC扩展后允许任意1/2/4/8的标量类型；CAS的操作有两个版本分别返回bool表示是否成功，而另外一个在操作之前会先返回ptr地址处存储的值；__sync_synchronize直接插入一个full memory barrier，当然你也可能经常见到像asm volatile(“” ::: “memory”);这样的操作。前面的这些原子操作都是full barrier类型的，这意味着：任何内存操作的指令不允许跨越这些操作重新排序。<br>　　__sync_lock_test_and_set用于将value的值写入ptr的位置，同时返回ptr之前存储的值，其内存模型是acquire barrier，意味着该操作之后的memory store指令不允许重排到该操作之前去，不过该操作之前的memory store可以排到该操作之后去，而__sync_lock_release则更像是对前面一个操作锁的释放，通常意味着将0写入ptr的位置，该操作是release barrier，意味着之前的memory store是全局可见的，所有的memory load也都完成了，但是接下来的内存读取可能会被排序到该操作之前执行。可以这里比较绕，翻译起来也比较的拗口，不过据我所见，这里很多是用在自旋锁类似的操作上，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> <span class="number">_</span>sync;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span>(<span class="number">__</span>sync_lock_test_and_set(&amp;<span class="number">_</span>sync, <span class="number">1</span>));</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">unlock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="number">__</span>sync_lock_release(&amp;<span class="number">_</span>sync);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其实这里的1可以是任何non-zero的值，主要是用作bool的效果。<br>]]>
    
    </summary>
    
      <category term="开发基础" scheme="https://taozj.org/tags/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发基础" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[多线程开发中无锁队列的设计和实现]]></title>
    <link href="https://taozj.org/201609/lockless-in-multi-thread.html"/>
    <id>https://taozj.org/201609/lockless-in-multi-thread.html</id>
    <published>2016-09-22T10:51:40.000Z</published>
    <updated>2016-12-18T08:48:46.000Z</updated>
    <content type="html"><![CDATA[<p>　　首先，本人对多核编程的了解还不深入，也不知道等待无关(Wait-Free)、锁无关(Lock-Free)、基于锁(Lock-Based)这些高端的东西，其实原本我只是想接触一个不用锁的数据结构这么个意思，没想到lockfree还有这么大的一个坑。</p>
<p>　　现在熟悉多线程开发的人，都知道多线程开发环境下的利器就是：互斥锁、条件变量、任务队列。<br>　　条件变量主要是用于异步唤醒的，当资源不满足的时候线程挂起睡眠，当别的线程修改条件后通知唤醒该进程；任务队列是实现生产者消费者数据交互和缓冲的主要通道，通常使用固定长度的数组做round-robin Ring数组或者采用链表的方式进行管理。当然，在实践中，除了使用经典的条件变量唤醒的方式，还有就是通过管道：生产者向管道写命令，消费者在管道阻塞的读命令，这种方式可以天然的使用read/write阻塞和非阻塞行为，同时也很方便融入现在大量的异步框架中，这是在memcached中发现的，也算是一个编程的小技巧吧。<br>　　对于单个生产者和单个消费者的情况比较的简单，每一端自身不存在竞争条件，使用round-robin Ring数组本身就可以实现无锁队列了，而链表因为元素和其前后驱有耦合性，所以问题要复杂一些。其他的数据结构还需要看底层的容器类型，比如std::queue就是个适配器类，底层的容器类型可以是std::deque或者std::list。反正这种情况下锁的竞争不会十分的激烈，在此就不再讨论了。</p>
<p>　　对于成百上千的同构生产者和消费者，锁的竞争就会比较的激烈。提出这个问题的原因，是看到附录总的文章，mutex作为多线程最常用的同步手段，底层是用futex系统调用实现的，作者测试发现通过这种方式同步，大部分的时间都被浪费到了futex系统调用的开销上面了，其原理是通过系统调用陷入内核态，将当前线程放入到mutex的等待队列上面去，然后调度其它线程执行。不过我对作者第一篇测试99%的时间用于futex系统调用甚是怀疑，因为系统调用还涉及到信号处理、内核抢占等东西，把这笔账全部算在mutex很不公平。不过，系统调用陷入内核态，以及线程切换的过程中会有上下文的保存和加载，同时伴随着大量的缓存失效等，这算是连锁带来的实实在在巨大开销。同时，这也让我感觉到当前很多系统架构，动辄开很多的线程池是否真的值得有效：虽然线程池的创建的开销少了，但是线程间频繁切换以及带来的缓存失效，也会对性能造成巨大的负面影响。<br><img src="/post_images/images/201609/638cbc55ae6b218c9f18fdcd278be833.png" alt="lockfree"></p>
<p>　　所以，锁不是多线程开发的金钥匙，大量使用锁总是有害的(死锁、活锁、持锁线程挂起)，同时也是程序的性能杀手，在所以在实践中除了小心使用、缩小锁保护的临界区之外，能使用无所的数据结构当然是最有效的提高性能的方法了。<br><a id="more"></a><br>　　通过附录中的文章，基本对无锁队列的原理有一个大概的了解了，同时也意识到这类高性能的开发需要CPU架构、CPU缓存、编译器的特性、语言的特定模型等诸多知识，是同平台、编译器紧密相关的知识，但是抛却极致方面的最求，基本的思路都比较一致：<br>　　a. 使用round-robin Ring数组而非链表作为存储结构，一方面如我所说元素之间耦合性低，涉及到的修改很少；二来数组这种顺序存储类型对CPU和缓存机制是十分友好的，同时不会频繁的申请和释放节点，不会有内存碎片的问题。<br>　　b. 同步需求包括生产者之间、消费者之间以及队列饥饿和队列饱和的情况。同质者之间的竞争基本是采用“先占坑再埋坑”的思路，确保一个线程占用一个slot，做出修改之后再发布这个slot使其它线程可见，而具体实现有附录中用CAS的，也有用其他复杂检测的机制来实现的。关于队列饥饿和队列饱和，这种情况在实践中会经常的出现，因为生产者和消费者阻抗匹配是十分理想的情况，现实情况或多或少会有生产快于消费以及生产慢于消费的情况，而且这种差异会慢慢累积下去，所以对于round-robin Ring这种空队列和满队列需要格外考虑。</p>
<p>　　参考文件中关于<a href="http://ifeve.com/disruptor/" target="_blank" rel="external">并发框架Disruptor译文</a>我觉得还是很值的一读的，先不讨论Disruptor的实现原理，单单就高性能开发方面，就看着让人觉得大开眼界的感觉：<br>　　a. 新名词，锁分为悲观锁和乐观锁，悲观锁是独占锁也就是常常遇到的独占锁，当一个线程获得该锁会阻止所有其他线程得到锁；乐观锁是当线程需要写入的时候会请求锁，检查上次读完后目标数据是否已经修改了，如果修改了会重新读取并比较，其行为很像CAS，但是让我感兴趣的是还没接触过CAS形式的锁。<br>　　b. 处理器的缓存都是按照缓存行的形式组织的，一般一个缓存行64字节(或32-256字节)，所以如果数组元素不大，那么缓存行对数组是十分友好的(后续元素预加载的效果)，可以将数组接下来的元素都加载到缓存行中，而链表就没有这个优势了，相邻的元素很可能都无法命中缓存。但是结构中的数据，head和tail通常都是连续定义的，这导致的一个问题是head、tail常常会在同一个缓存行中，这时候修改了一个端会使缓存行失效，另外一段也就被“失效”了，称之为“伪缓存”，这里等于加剧了生产者和消费者的竞争，解决的方法是在两者之间添加一个cache line padding，迫使两者在不同的缓存行中。<br>　　c. Disruptor的设计感觉对读描述的较少，用了ConsumerBarrier等于起到一个代理的作用，这个代理顺序分配当前的对象，同时也知道Producer当前已经发布的cursor位置，但是消费者消费完空出slot的信息不知道是怎么通知ProducerBarrier的，文中没有提到；同时消费者的速度有差异，慢的消费者处理完后可以跳过前面已经被消费的元素。这里看来，怎么维持一个全局最小的消费者cursor是个关键。<br>　　d. 生产者采用了“先占坑再埋坑”的思路，先申请一个空闲的位置，然后填充对应的书，完成后提交这个数据称为消费者可见。生产者维持了一个全局的cursor，而提交更新这个cursor必须是顺序提交的，也就是即使前面的生产者已经完成了生产，也必须等待后面的生产者提交之后才能提交。</p>
<p>　　附录文章<a href="http://www.linuxjournal.com/content/lock-free-multi-producer-multi-consumer-queue-ring-buffer?page=0,0" target="_blank" rel="external">Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer</a>则是实现的一个生产者消费者对称设计的无锁任务队列，基本数据结构是round-robin Ring数组，同时也是“先占坑再埋坑”的思路，不过“埋坑”的时候没有采用顺序提交的情况，而是每个生产者和消费者维持了自己的生产或者消费位置，最后程序可以协调让cursor快进，这在很大程度上减少的多个生产者、消费者空等待的情况。</p>
<p>　　说了这么多的基础知识，然后就是的进行了一个简单的实现，借鉴了前面两者采用了最简单的实现方式：生产者和消费者对称设计、顺序提交的模式，使用CAS进行无锁同步。然后呢，我也像模像样地测试了一下，结果让我大跌眼镜：在16对生产者、消费者进行一千万次请求下，使用mutex和条件变量耗时3s，而我的无锁队列为18s，慢了整整6倍！！！</p>
<p>　　后面看了下别人评论，现在CAS有被滥用的趋势，很多成熟的Lockfree方案在并发量大的时候会遇到瓶颈，甚至性能会急剧恶化下去。然后告诫就是：只有确定需要无锁结构，并且知道你在干什么的时候，才使用无锁结构！！！<br>　　代码在<a href="https://github.com/taozhijiang/learncpp/tree/master/lockless" target="_blank" rel="external">lockless</a>，忘大拿帮我看看有啥问题没？还是本身就应该是这么慢！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.linuxjournal.com/content/lock-free-multi-producer-multi-consumer-queue-ring-buffer?page=0,0" target="_blank" rel="external">Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer</a></li>
<li><a href="http://www.searchtb.com/2012/10/introduction_to_disruptor.html" target="_blank" rel="external">一种高效无锁内存队列的实现</a></li>
<li><a href="http://ifeve.com/disruptor/" target="_blank" rel="external">并发框架Disruptor译文</a></li>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/lockfree.html" target="_blank" rel="external">Chapter 18. Boost.Lockfree</a></li>
<li><a href="http://coolshell.cn/articles/8239.html" target="_blank" rel="external">无锁队列的实现</a></li>
<li><a href="http://www.intel.cn/content/www/cn/zh/processors/architectures-software-developer-manuals.html" target="_blank" rel="external">英特尔® 64 和 IA-32 架构软件开发人员手册合并版</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　首先，本人对多核编程的了解还不深入，也不知道等待无关(Wait-Free)、锁无关(Lock-Free)、基于锁(Lock-Based)这些高端的东西，其实原本我只是想接触一个不用锁的数据结构这么个意思，没想到lockfree还有这么大的一个坑。</p>
<p>　　现在熟悉多线程开发的人，都知道多线程开发环境下的利器就是：互斥锁、条件变量、任务队列。<br>　　条件变量主要是用于异步唤醒的，当资源不满足的时候线程挂起睡眠，当别的线程修改条件后通知唤醒该进程；任务队列是实现生产者消费者数据交互和缓冲的主要通道，通常使用固定长度的数组做round-robin Ring数组或者采用链表的方式进行管理。当然，在实践中，除了使用经典的条件变量唤醒的方式，还有就是通过管道：生产者向管道写命令，消费者在管道阻塞的读命令，这种方式可以天然的使用read/write阻塞和非阻塞行为，同时也很方便融入现在大量的异步框架中，这是在memcached中发现的，也算是一个编程的小技巧吧。<br>　　对于单个生产者和单个消费者的情况比较的简单，每一端自身不存在竞争条件，使用round-robin Ring数组本身就可以实现无锁队列了，而链表因为元素和其前后驱有耦合性，所以问题要复杂一些。其他的数据结构还需要看底层的容器类型，比如std::queue就是个适配器类，底层的容器类型可以是std::deque或者std::list。反正这种情况下锁的竞争不会十分的激烈，在此就不再讨论了。</p>
<p>　　对于成百上千的同构生产者和消费者，锁的竞争就会比较的激烈。提出这个问题的原因，是看到附录总的文章，mutex作为多线程最常用的同步手段，底层是用futex系统调用实现的，作者测试发现通过这种方式同步，大部分的时间都被浪费到了futex系统调用的开销上面了，其原理是通过系统调用陷入内核态，将当前线程放入到mutex的等待队列上面去，然后调度其它线程执行。不过我对作者第一篇测试99%的时间用于futex系统调用甚是怀疑，因为系统调用还涉及到信号处理、内核抢占等东西，把这笔账全部算在mutex很不公平。不过，系统调用陷入内核态，以及线程切换的过程中会有上下文的保存和加载，同时伴随着大量的缓存失效等，这算是连锁带来的实实在在巨大开销。同时，这也让我感觉到当前很多系统架构，动辄开很多的线程池是否真的值得有效：虽然线程池的创建的开销少了，但是线程间频繁切换以及带来的缓存失效，也会对性能造成巨大的负面影响。<br><img src="/post_images/images/201609/638cbc55ae6b218c9f18fdcd278be833.png" alt="lockfree"></p>
<p>　　所以，锁不是多线程开发的金钥匙，大量使用锁总是有害的(死锁、活锁、持锁线程挂起)，同时也是程序的性能杀手，在所以在实践中除了小心使用、缩小锁保护的临界区之外，能使用无所的数据结构当然是最有效的提高性能的方法了。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[开发中IO分离设计的重构杂谈]]></title>
    <link href="https://taozj.org/201609/talk-about-io-seperation-design.html"/>
    <id>https://taozj.org/201609/talk-about-io-seperation-design.html</id>
    <published>2016-09-20T08:34:54.000Z</published>
    <updated>2016-12-18T08:51:39.000Z</updated>
    <content type="html"><![CDATA[<p>　　需求的变更和增加是程序员永远挥之不去的阴影，不过这也是保证程序员饭碗之所在，否则一个系统设计开发后就一直运行下去，那估计程序员都会成为项目制聘用了，公司才不会一直花钱把你养着供着呢。<br>　　这不，之前开发的人工座席<a href="/201605/auto-answer-recommend-conclusion.html">答案自动推荐模块项目小结</a>，经过接近两个月的线上调试修BUG，算是挺稳定的了，现在出的新需求是：将数据暴露到后台，可以网页修改数据。这一下折腾的有点大法了，听我慢慢道来。</p>
<p>　　之前没有考虑到会有这种需求，而且整体设计和实现都是我一人操办，所以项目架构、数据库设计都是自己任着性质来的：<br>　　a. 主系统因为数据量比较大，所以是站点按区域分库、每个库中按时间后缀分表存储的；<br>　　b. 我这里因为查询需要检索连续的时间、且总体数据量还不是很大，还有权限等乱七八糟的原因，所以我用的方案是：只在一个库中分表，用站点编号与16取余映射到这十六个分表中，这样可以隔时间把一部分旧数据导出到别的表，保证工作的数据表在一定时间段中连续，数据表也不过于膨胀下去。同时，还因为我的客户端设计用的数据库连接池，对同库使用十分方便，而跨库异构连接处理就有些麻烦。</p>
<p>　　如果要让我解决这个问题，那从我的角度最省事的方式，就是在当前库中额外添加一个表，每次处理坐席请求有新数据的时候，额外增加一次他们要求的入库操作，这样他们要的信息一次查表就可以，不用做跨表和连表的复杂查询了。</p>
<p>　　这样我是爽了，不过前端可能不哈皮了。因为之前相似的业务，都是基于主库那种分库和时间后缀表写的，即使我这种单表最简单的操作，前端也需要修改部分的代码和逻辑。结果就是前端设计跟主业务一样的分库和时间后缀表，让我这里填充这个表供他们访问。<br><a id="more"></a><br>　　这样，我操作起来就会有些麻烦：我需要在处理自己业务逻辑，写自己的单库分表的同时，还需要处理其它几个分库时间后缀表，如果在当前线程位置直接插入，那同步保护将会复杂很多。当时看陈硕的《Linux 多线程服务器端编程》的时候，告诉我们如果有较多的IO任务，可以将IO任务单独开辟一个线程，把工作线程的任务都通过队列发送到单独的线程去负责IO操作，不要让IO操作降低工作线程的效率。借助这个思路，我可以做的思路是：工作线程把数据库执行语句格式化好，然后插入到队列当中，然后IO线程不断从队列中取出语句逐个执行就可以了，而IO线程是顺序执行的，可以无锁使用每个分库的连接。</p>
<p>　　上面的思路已经算是可以了，不过还可以把思路更扩宽一些。其实很多公司的系统增长模式就是：开始在系统中慢慢增加功能，导致一个很大很复杂的系统出现，后续发现越来越难维护，也越来越难扩展的时候，再进行解耦分割成一个个单独的模块工作，模块之间通过某种方式去通信，这样不仅可以拆解成简单模块易于维护，还可以单机多进程、多级多进程随意扩展。</p>
<p>　　于是，我也按捺不住想要尝试一下这种模式，当然还有一个原因是原先的系统是用C写的，最近对C++比较的钟爱，即使当前生产机GCC-4.4.7并不完全支持C++11(-std=c++0x)，但是结合Boost库发现C++写起来还是比C要轻松很多。系统中总共有已有前端增加的网络工作线程、新开发的后端包括数据接收主线程和分库数据相等的SQL执行线程三个角色，整体的设计思路是这样的：<br>　　a. 前面还是像上面描述的一样，libmicrohttpd工作线程在有满足条件的数据出现时候，组合需要执行的SQL语句，然后将SQL语句压入到一个任务队列中就立即返回；<br>　　b. 开辟一个网络工作线程，负责将队列中的SQL语句不断发配给后端处理进程；<br>　　c. 处理进程包括数据接收主线程和SQL执行线程，SQL执行线程跟分库的数量一致，同时维持一个对目标分库的数据库长连接；<br>　　d. 数据接收主线程负责IO接收数据，得到完成数据包后，解析规定的包头得到站点号，依据规则发配到SQL执行线程的执行队列中去。</p>
<p>　　这种非开放的后台服务端编写，还有些额外的事项需要注意和处理：<br>　　a. 由于非开放业务，数据通信在内网自己使用，这种情况下各个模块之间的通信肯定是长连接更高效，同时也不必考虑网络安全等问题；<br>　　b. 网络工作线程发现传输错误之后，会自动断开当前连接，并按照之前的地址不断重新尝试连接后端的处理进程，未能发送的数据在最大容量范围内还是会堆积在队列当中；<br>　　c. 由于连接有限，所以后端的处理进程没有异步化处理，是one connection per thread且采用阻塞方式读取处理；当错误之后服务端断开当前连接，销毁错误线程，此时同上面所描述的机制，网络工作线程会自动重新连接；此处也不必过于关心性能问题，因为这个线程只负责进行IO，人家说很多情况下单线程也能把网络带宽跑满，只负责数据转发应该是比较高效的；<br>　　d. 长连接的通信要能处理数据拆包和粘包问题，增加了复杂度。我在每个包的头部封装了两个uint32_t类型网络字节序的整数，分别是当前包的长度和对应的站点号，然后解析字段知道当前包的结束位置，同时后面分派线程的处理也容易了。其实，如果是本地回环和网络传输还是有差异的，比如之前用async_read_some，回环可以接收很长的数据，但是一旦上线，这个函数基本就只能接收一个MTU的长度。粘包测试也很简单：可以在网络工作线程堆积两个包，然后包分块慢慢发送(比如每次发64个字节等),然后查看后端主线程接收和解析包是否正常。<br>　　e. 不怕一万就怕万一，万一由于某些因素导致连续的解析失败了(不仅仅是程序的原因)，错误累积漂移会导致后面的所有业务失常。所以还需要额外增加一个检测机制作为看门狗的作用：一旦有错误发生就断开这个链接，比如解析开头的MAGIC_NUMBER、累积收到的数据大于某个值、累积接收了多少次数据包，但是这些数据包没法被消耗，就说明缓存区的包头有问题了，这个时候就应当主动断开这个链接了。<br>　　f. 最后还有一点可以优化的是，让后端开一个网络端口后门(陈硕说过少用信号)，当检测到这个后门连接并发送约定的命令时候，后端关闭侦听套接字和所有和前面网络线程的连接，等待一段时间当SQL处理线程消耗完队列中的数据后，就可以安全kill掉服务了。而前端网络线程会不断尝试连接，前面SQL处理线程可在限制的缓存数量中将请求堆积，不会造成严重的数据丢失，两者耦合性大大降低了。</p>
<p>　　慢慢优化吧，程序员的事情是永远都做不完滴。其实项目中构架、设计还是要随大流，自我创造就是跟自己挖坑啊。。。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　需求的变更和增加是程序员永远挥之不去的阴影，不过这也是保证程序员饭碗之所在，否则一个系统设计开发后就一直运行下去，那估计程序员都会成为项目制聘用了，公司才不会一直花钱把你养着供着呢。<br>　　这不，之前开发的人工座席<a href="/201605/auto-answer-recommend-conclusion.html">答案自动推荐模块项目小结</a>，经过接近两个月的线上调试修BUG，算是挺稳定的了，现在出的新需求是：将数据暴露到后台，可以网页修改数据。这一下折腾的有点大法了，听我慢慢道来。</p>
<p>　　之前没有考虑到会有这种需求，而且整体设计和实现都是我一人操办，所以项目架构、数据库设计都是自己任着性质来的：<br>　　a. 主系统因为数据量比较大，所以是站点按区域分库、每个库中按时间后缀分表存储的；<br>　　b. 我这里因为查询需要检索连续的时间、且总体数据量还不是很大，还有权限等乱七八糟的原因，所以我用的方案是：只在一个库中分表，用站点编号与16取余映射到这十六个分表中，这样可以隔时间把一部分旧数据导出到别的表，保证工作的数据表在一定时间段中连续，数据表也不过于膨胀下去。同时，还因为我的客户端设计用的数据库连接池，对同库使用十分方便，而跨库异构连接处理就有些麻烦。</p>
<p>　　如果要让我解决这个问题，那从我的角度最省事的方式，就是在当前库中额外添加一个表，每次处理坐席请求有新数据的时候，额外增加一次他们要求的入库操作，这样他们要的信息一次查表就可以，不用做跨表和连表的复杂查询了。</p>
<p>　　这样我是爽了，不过前端可能不哈皮了。因为之前相似的业务，都是基于主库那种分库和时间后缀表写的，即使我这种单表最简单的操作，前端也需要修改部分的代码和逻辑。结果就是前端设计跟主业务一样的分库和时间后缀表，让我这里填充这个表供他们访问。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="工作相关" scheme="https://taozj.org/tags/%E5%B7%A5%E4%BD%9C%E7%9B%B8%E5%85%B3/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Google Protobuf数据交换格式的使用方法]]></title>
    <link href="https://taozj.org/201609/learn-note-of-protobuf.html"/>
    <id>https://taozj.org/201609/learn-note-of-protobuf.html</id>
    <published>2016-09-10T01:11:17.000Z</published>
    <updated>2016-12-18T08:43:31.000Z</updated>
    <content type="html"><![CDATA[<p>　　现今，如果问什么格式的数据交互最红火，非Google家的protobuf莫属了。相比XML、Json，其有点就是使用接口简单、序列化和解析速度快、数据小传输效率高，同时其还具有向后兼容、跨平台、以及丰富的语言支持接口(居然js都支持，看来直逼Json了啊)的优势。当然，其缺点是不像XML、Json那种可读性和自解释性强，特别是在网络通信时候调试起来比较麻烦。<br>　　翻墙照着Google的文档，把protobuf走了一遍，总体感觉不愧是大厂的作品，考虑到的是效率、多语言支持、兼容性以及分布式系统中多版本的兼容和演进，同时其内部是使用C++实现的，在proto“语法”设计上也会让C++用户感觉十分亲切。<br>　　老习惯还是顺便做个笔记吧。<br><img src="/post_images/images/201609/0ea1b617424d9f2e8cd77b6dbc5dadfd.png" alt="protobuf"></p>
<h1 id="一、从例子说起">一、从例子说起</h1><p>　　protobuf的使用，需要事先写好.proto文件，这个文件规定了数据传输和接受方交换数据的字段、类型等信息。然后使用编译器protobuf-compiler编译这个文件，就可以产生指定语言类型所需的辅助性文件(比如C++的.h和.cc，然后对每一个message都会产生一个类进行描述)了，然后方便的集成到项目代码中使用，当然除了命令行模式的编译，也可以在源代码中读取.proto文件进行动态编译。</p>
<h2 id="1-1_-proto文件的格式">1.1 .proto文件的格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">message Person &#123;</div><div class="line">  required string name = 1; // Your name</div><div class="line">  required int32 id = 2;      // Your ID</div><div class="line">  optional string email = 3;</div><div class="line"></div><div class="line">  enum PhoneType &#123;</div><div class="line">    option allow_alias = true;</div><div class="line">    MOBILE = 0;</div><div class="line">    CELLPHONE = 0;</div><div class="line">    HOME = 1;</div><div class="line">    WORK = 2;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  message PhoneNumber &#123;</div><div class="line">    required string number = 1;</div><div class="line">    optional PhoneType type = 2 [default = HOME];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  repeated PhoneNumber phone = 4;</div><div class="line"></div><div class="line">  reserved 2, 15, 9 to 11; // reserved保留</div><div class="line">  reserved &quot;foo&quot;, &quot;bar&quot;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>　　(1) 每个字段前面都必须有required、optional、repeated，分别表示后面的字段出现1次、0或1次、0或多次，对于repeated字段，其相同类型字段多个值出现的顺序会被保留。<br>　　(2) 数据类型可以是整形、string类型(支持的类型主要有float、double、[s|u| ]int[32|64]、bool、string)，同时还支持自定义类型的嵌套。每一个字段后面都有一个唯一的数字标号(number tag)，为了提高效率，1-15是用一个字节编码，16-2047是用的两个字节编码，所以根据霍夫曼编码的愿意应该把常用的字段用小于15的数字标号。<br>　　(3) 同一个.proto文件中可以定义多个message，尤其当他们在业务上逻辑相关时候更应该这样。.proto文件的注释支持用C/C++的//风格注释。<br>　　(4) 后续更新的时候，可能某些字段不想要了。为了兼容性起见，不应当仅仅注释或者删除掉，而应该用reserved字段尤其对数字标号进行保留，防止被别人再次使用，然后让老的程序错误解析这些字段。<br>　　(5) 对于optional的字段，可以使用default提供对应的默认值，这样当message解析发现没有这个字段时候，那么就会：如果设定有默认值，就使用这个默认值；否则其值是类型相关的——0、false、空string、枚举的第一个元素。<br>　　(6) enum枚举类型有一个选项allow_alias，打开它的时候，允许同一个枚举值有多个枚举的名字(比如上文的MOBILE和CELLPHONE)。<br><a id="more"></a></p>
<h2 id="1-2_-proto文件其它相关">1.2 .proto文件其它相关</h2><p>　　(1) 导入定义<br>　　import可以将别的文件的定义导入到当前文件，默认的import行为是只能使用导入文件中的直接定义，如果需要嵌套使用导入文件的内容，达到类似递归的应用效果，可以使用import public语句。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// old.proto</span></div><div class="line">import <span class="keyword">public</span> <span class="string">"new.proto"</span>;</div><div class="line">import <span class="string">"other.proto"</span>;</div><div class="line"></div><div class="line"><span class="comment">// client.proto</span></div><div class="line">import <span class="string">"old.proto"</span>; </div><div class="line"> <span class="comment">//此时可以使用old.proto和new.proto中的内容，但是看不到other.proto内容</span></div></pre></td></tr></table></figure></p>
<p>　　protobuf-compiler编译器对.proto文件搜索路径默认是执行protoc的当前路径，当然命令行可以使用-I/–proto_path来添加搜索路径。</p>
<p>　　(2) 嵌套类型<br>　　可以使用Parent.Type这种语法来实现嵌message的使用，而且不限制嵌套的层次深度<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">message SearchResponse &#123;</div><div class="line">    message Result &#123;</div><div class="line">        required <span class="built_in">string</span> url = <span class="number">1</span>;</div><div class="line">        optional <span class="built_in">string</span> title = <span class="number">2</span>;</div><div class="line">    &#125;</div><div class="line">    repeated Result result = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">message SomeOtherMessage &#123;</div><div class="line">    optional SearchResponse.Result result = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(3) 更新消息类型<br>　　从整个文档看来，Google对于这种向后兼容性看的很重要，这也是一个大型系统逐渐演进所必需的。如果要修改一个.proto文件，那么需要遵守以下的一些守则和约定：<br>　　a. 对于一个已经存在的字段不要修改其数字标号；<br>　　b. 新增加的字段应该是optional或者repeated的；<br>　　c. 不再使用的字段，可以用OBSOLETE_等前缀命名表示废弃，但是绝对不要重用其数字标号，记得使用上面的reserved对这些数字标号保护起来；<br>　　d. 非required可以转为extension(保留给第三方在他们自己的.proto文件中使用)；<br>　　e. int32、uint32、int64、uint64、bool是兼容的，客户端可以进行结果的强制转换；<br>　　f. 修改default默认值是允许的，因为默认值不会真正的传输，只跟程序使用的.proto文件有关；</p>
<p>　　(4) extension<br>　　上面的方式可以把特定的数字标号区域保留给扩展，扩展在自己的.proto文件中，先import原有的.proto，然后再次打开message，添加扩充自己的字段，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// foo.proto</span></div><div class="line">message Foo &#123;</div><div class="line">    <span class="comment">// ...</span></div><div class="line">    extensions <span class="number">100</span> to <span class="number">199</span>; &#125;</div><div class="line"></div><div class="line"><span class="comment">// your.proto</span></div><div class="line">import foo.proto;</div><div class="line">extend Foo &#123;  optional int32 bar = <span class="number">126</span>; &#125;</div></pre></td></tr></table></figure></p>
<p>但是跟前面基本字段不同，extension的访问需要使用特殊的接口来操作，比如设置值，需要调用<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">foo.SetExtension(bar, <span class="number">15</span>);</div><div class="line">其它这类操作接口包括：HasExtension()、ClearExtension()、GetExtension()、MutableExtension()、AddExtension()。</div><div class="line"></div><div class="line">　　(<span class="number">5</span>) oneof</div><div class="line">　　类似于C/C++中的<span class="keyword">union</span>类型，当oneof包围多个可选字段的时候，至多只能给一个字段赋值，当给某个字段设置的时候，会自动清除已存其它字段的值，因为这些字段都是共享同一内存的，为的就是节省内存。</div><div class="line">```cpp</div><div class="line">message SampleMessage &#123;</div><div class="line">    oneof test_oneof &#123;</div><div class="line">        <span class="built_in">string</span> name = <span class="number">4</span>;</div><div class="line">        SubMessage sub_message = <span class="number">9</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">SampleMessage message;</div><div class="line">message.set_name(<span class="string">"name"</span>);</div><div class="line">CHECK(message.has_name());</div></pre></td></tr></table></figure></p>
<p>　　oneof中的字段定义不能有require、optional、repeated，然后具体使用的时候可以当作optional一样来使用了。<br>还有，如果一个message中有多个同名的oneof，只有最后一个可见的会被实际使用；extensions不支持oneof；oneof不能被repeated；C++中支持swap两个oneof，交换后可访问字段变成互为对方的那个。</p>
<p>　　(6) maps<br>　　proto支持相关性容器map，其定义的格式是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">map</span>&lt;key_type, value_type&gt; map_field = N;</div></pre></td></tr></table></figure></p>
<p>　　其中的key_type除了不能是浮点和bytes，其它类型(整形、string)都可以作为key；针对map其wire format的排序和迭代顺序是未定义的，用户不应当依赖其顺序；当将其转成文本类型的时候，是按照整形从小到大或者字符串的升序来排序的；当解析或者合并map的时候，如果有重复的key，那么只有最后看见的那个key被使用，而当从文本中解析的时候，如果有重复的key会做报错处理。</p>
<p>　　(7) Packages<br>　　proto的名字查找类似于C++，从最内层的类依次向外查找。有时候为了防止名字冲突，可以在.proto文件的开头声明package，起到类似名字空间的效果(实际上产生C++辅助代码的时候就是放到对应的namespace中的，比如foo.bar生成了foo::bar)。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">package foo.bar; <span class="comment">//namespace foo::bar</span></div><div class="line">message Open &#123; ... &#125;</div><div class="line"></div><div class="line"><span class="comment">// 另外一个proto中使用</span></div><div class="line">message Foo &#123;</div><div class="line">    required foo.bar.Open open = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-3_将上面的例子用起来">1.3 将上面的例子用起来</h2><p>　　针对上面的.proto文件，使用protoc编译，可以根据语言产生对应的源代码文件(比如C++的.h和.cc)。实测发现，当前很多发行版还是默认打包的protobuf-compiler-2.6甚至更旧的版本，所以建议在GitHub上面下载源代码自己编译安装最新的3.0版本。<br>　　然后，3.0的版本今年才正式发布的，语法跟之前稳定版2.6差异还是挺大的，总体的感觉是让protobuf使用更简洁了。具体的修改日志可以看参考列表中的Release Note，包括：不再区分optional、required，默认都是optional；需要指定syntax版本，默认是proto2；不支持default默认值等。编译的格式，和上面实际用到的编译命令是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR path/to/file.proto</div><div class="line"></div><div class="line">➜  ~ protoc --cpp_out=./ msg.proto</div></pre></td></tr></table></figure></p>
<p>　　如果DST_DIR使用.zip结尾，那么产生的文件会自动用.zip打包，同时输入的.proto文件可以一次指定一个或者多个。<br>　　编译结束后会生成msg.pb.cc和msg.pb.h两个文件，然后就可以轻松应用了！</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"msg.pb.h"</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span></div><div class="line">&#123;</div><div class="line">    Person person;</div><div class="line">    person.set_name(<span class="string">"Nicol TAO"</span>);</div><div class="line">    person.set_id(<span class="number">1234</span>);</div><div class="line">    person.set_email(<span class="string">"taozhijiang@126.com"</span>);</div><div class="line">    <span class="function">fstream <span class="title">output</span><span class="params">(<span class="string">"myfile"</span>, ios::out | ios::binary)</span></span>;</div><div class="line">    person.SerializeToOstream(&amp;output);</div><div class="line">    output.close();</div><div class="line"></div><div class="line">    <span class="function">fstream <span class="title">input</span><span class="params">(<span class="string">"myfile"</span>, ios::in | ios::binary)</span></span>;</div><div class="line">    Person person2;</div><div class="line">    person2.ParseFromIstream(&amp;input);</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Name: "</span> &lt;&lt; person2.name() &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"E-mail: "</span> &lt;&lt; person2.email() &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Test Finished!"</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>　　然后，在命令行编译执行，就该得到你想要的结果了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ g++ -c msg.pb.cc &amp;&amp; g++ -c main.cc                                         </div><div class="line">➜  ~ g++ msg.pb.o main.o -lprotobuf -o msg                                      </div><div class="line">➜  ~ ./msg</div><div class="line">Name: Nicol TAO</div><div class="line">E-mail: taozhijiang@126.com</div><div class="line">Test Finished!</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h1 id="二、CPP使用接口">二、CPP使用接口</h1><p>　　protobuf的手册中有一章是说Encoding的，主要是从原理说protobuf的编码效率为什么会这么高。因为这对用户来说是无所谓的，所以就跳过了，感兴趣的可以去瞄。其中128-Variant变长编码的思路还是不错的。</p>
<h2 id="2-1_Messages">2.1 Messages</h2><p>　　上面使用message Foo生成的消息，最终都会产生一个public继承自google::protobuf::Message的类Foo，默认protobuf会以生成最快速度的版本，如果在.proto中设置了option optimize_for = CODE_SIZE;，就会实现最少必须函数，然后用反射的机制生成其它的；option optimize_for = LITE_RUNTIME;选项将会派生出google::protobuf::MessageLite的类型，只提供比原Message较少的一个操作子集，同时链接的库也是libprotobuf-lite.so。<br>对于嵌套类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">message Foo &#123; message Bar &#123; &#125; &#125;</div></pre></td></tr></table></figure></p>
<p>　　在生成的代码中会有Foo和Foo_Bar两个类，同时还会自动生成typedef Foo_Bar Bar;的别名。可以使用Foo::Bar访问，但是C++不允许带作用域的前向声明，所以如果要前向声明，记得有Foo_Bar这个类。</p>
<h2 id="2-2_Fields">2.2 Fields</h2><p>　　由于protobuf在传输的时候是使用数字的，所以在protobuf解码的时候，自动为这些数子生成了camel-case驼峰模式的常量，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">optional int32 foo_bar = <span class="number">5</span>;</div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> kFooBarFieldNumber = <span class="number">5</span>;</div></pre></td></tr></table></figure></p>
<p>　　对于Field的访问器accessor，如果得到的是const reference类型的，在下次modify access作用于这个message的时候，访问器可能会失效，尤其是调用了non-const的访问器类型；当accessor返回的是指针，记住：任何两次不同的accessor调用，返回的指针值都可能是不同的。<br>　　(1) Singular单个数字类型(枚举类型也跟此类似)<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int32 foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line">int32 foo() <span class="keyword">const</span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(int32 value)</span></span>;</div><div class="line"><span class="function">oid <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//清除，下次调用foo()会返回0</span></div></pre></td></tr></table></figure></p>
<p>　　(2) Singular单个字符串类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">string</span> foo = <span class="number">1</span>;</div><div class="line">bytes foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="built_in">string</span>&amp; foo() <span class="keyword">const</span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* value, <span class="keyword">int</span> size)</span></span>;</div><div class="line"><span class="function"><span class="built_in">string</span>* <span class="title">mutable_foo</span><span class="params">()</span></span>; <span class="comment">//返回一个可以修改string值的指针</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_allocated_foo</span><span class="params">(<span class="built_in">string</span>* value)</span></span>; <span class="comment">//吧value设置到foo，如果foo之前有string，则释放掉之前的string</span></div><div class="line">                       <span class="comment">//如果value==NULL，则等同于clear_foo()</span></div><div class="line"><span class="function"><span class="built_in">string</span>* <span class="title">release_foo</span><span class="params">()</span></span>; <span class="comment">//调用后foo释放string的控制权</span></div></pre></td></tr></table></figure></p>
<p>　　(3) Singular嵌入message类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">message Bar &#123;&#125;</div><div class="line">Bar foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">bool</span> has_foo(); <span class="comment">//检查foo是否已经set</span></div><div class="line"><span class="function"><span class="keyword">const</span> Bar&amp; <span class="title">foo</span><span class="params">()</span></span>; <span class="comment">//返回值，如果没有set，就返回一个没有设置的Bar，Bar::default_instance()</span></div><div class="line"><span class="function">Bar* <span class="title">mutable_foo</span><span class="params">()</span></span>; <span class="comment">//返回mutable指针，如果没有set，内部就会newly-allocated Bar并返回</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_allocated_foo</span><span class="params">(Bar* bar)</span></span>; <span class="comment">//如果bar==NULL，等同于clear_foo()</span></div><div class="line"><span class="function">Bar* <span class="title">release_foo</span><span class="params">()</span></span>;</div></pre></td></tr></table></figure></p>
<p>　　(4) Repeated数字类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">repeated int32 foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">int</span> foo_size() <span class="keyword">const</span>; <span class="comment">//元素的个数</span></div><div class="line"><span class="function">int32 <span class="title">foo</span><span class="params">(<span class="keyword">int</span> index)</span> <span class="keyword">const</span></span>; <span class="comment">//0-based索引对应的值</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">int</span> index, int32 value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_foo</span><span class="params">(int32 value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//清除所有的元素</span></div></pre></td></tr></table></figure></p>
<p>　　对于枚举、字符串、嵌入message，也有对应的repeated版本，可以参阅其手册，很容易理解和想到。</p>
<p>　　(5) Oneof数字类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">oneof oneof_name &#123;</div><div class="line">    int32 foo = <span class="number">1</span>;</div><div class="line">    ... &#125;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">bool</span> has_foo() <span class="keyword">const</span>; <span class="comment">//检查当前oneof类型是kFoo</span></div><div class="line"><span class="function">int32 <span class="title">foo</span><span class="params">()</span> <span class="keyword">const</span></span>; <span class="comment">//如果当前是kFoo，返回其值，否则返回0</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(int32 value)</span></span>; <span class="comment">//如果当前不是kFoo，调用clear_oneof_name()，然后设置其值，并且oneof_name_case()会返回kFoo</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//如果当前不是kFoo，则什么也不做；否则，清除其值，然后has_foo()==false，foo()==0，同时oneof_name_case()返回ONEOF_NAME_NOT_SET。</span></div></pre></td></tr></table></figure></p>
<p>　　对于枚举、字符串、嵌入message，也有对应的Oneof版本，可以参阅其手册，很容易理解和想到。</p>
<p>　　(6) Map类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">map</span>&lt;int32, int32&gt; weight = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">const</span> google::protobuf::Map&lt;int32, int32&gt;&amp; weight();</div><div class="line">google::protobuf::Map&lt;int32, int32&gt;* mutable_weight();</div></pre></td></tr></table></figure></p>
<p>　　上面的weight()和mutable_weight()会得到可修改和不可修改两个map，其可以支持std::map和std::unorderd_map中常用的函数接口，包括：迭代器、元素访问、查找、修改(添加和删除)、拷贝等。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//这种插入会被insert要好，免除可能的元素深度拷贝</span></div><div class="line">(*my_enclosing_proto-&gt;mutable_weight())[my_key] = my_value;</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">map</span>&lt;int32, int32&gt; standard_map(message.weight().begin(),</div><div class="line">                                    message.weight().end());</div></pre></td></tr></table></figure></p>
<p>　　同时如上面所示，如果不想用protobuf::Map的接口，可以像上面一样创建标准的std::map，不过构造这个map会产生所有元素的深度拷贝。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="external">protocol-buffers</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/overview" target="_blank" rel="external">protocol-buffers/docs/overview</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/reference/cpp-generated" target="_blank" rel="external">C++ Generated Code</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/encoding" target="_blank" rel="external">Encoding</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/reference/arenas" target="_blank" rel="external">C++ Arena Allocation Guide</a></li>
<li><a href="https://github.com/google/protobuf/releases" target="_blank" rel="external">protobuf-3-releases</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　现今，如果问什么格式的数据交互最红火，非Google家的protobuf莫属了。相比XML、Json，其有点就是使用接口简单、序列化和解析速度快、数据小传输效率高，同时其还具有向后兼容、跨平台、以及丰富的语言支持接口(居然js都支持，看来直逼Json了啊)的优势。当然，其缺点是不像XML、Json那种可读性和自解释性强，特别是在网络通信时候调试起来比较麻烦。<br>　　翻墙照着Google的文档，把protobuf走了一遍，总体感觉不愧是大厂的作品，考虑到的是效率、多语言支持、兼容性以及分布式系统中多版本的兼容和演进，同时其内部是使用C++实现的，在proto“语法”设计上也会让C++用户感觉十分亲切。<br>　　老习惯还是顺便做个笔记吧。<br><img src="/post_images/images/201609/0ea1b617424d9f2e8cd77b6dbc5dadfd.png" alt="protobuf"></p>
<h1 id="一、从例子说起">一、从例子说起</h1><p>　　protobuf的使用，需要事先写好.proto文件，这个文件规定了数据传输和接受方交换数据的字段、类型等信息。然后使用编译器protobuf-compiler编译这个文件，就可以产生指定语言类型所需的辅助性文件(比如C++的.h和.cc，然后对每一个message都会产生一个类进行描述)了，然后方便的集成到项目代码中使用，当然除了命令行模式的编译，也可以在源代码中读取.proto文件进行动态编译。</p>
<h2 id="1-1_-proto文件的格式">1.1 .proto文件的格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">message Person &#123;</div><div class="line">  required string name = 1; // Your name</div><div class="line">  required int32 id = 2;      // Your ID</div><div class="line">  optional string email = 3;</div><div class="line"></div><div class="line">  enum PhoneType &#123;</div><div class="line">    option allow_alias = true;</div><div class="line">    MOBILE = 0;</div><div class="line">    CELLPHONE = 0;</div><div class="line">    HOME = 1;</div><div class="line">    WORK = 2;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  message PhoneNumber &#123;</div><div class="line">    required string number = 1;</div><div class="line">    optional PhoneType type = 2 [default = HOME];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  repeated PhoneNumber phone = 4;</div><div class="line"></div><div class="line">  reserved 2, 15, 9 to 11; // reserved保留</div><div class="line">  reserved &quot;foo&quot;, &quot;bar&quot;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>　　(1) 每个字段前面都必须有required、optional、repeated，分别表示后面的字段出现1次、0或1次、0或多次，对于repeated字段，其相同类型字段多个值出现的顺序会被保留。<br>　　(2) 数据类型可以是整形、string类型(支持的类型主要有float、double、[s|u| ]int[32|64]、bool、string)，同时还支持自定义类型的嵌套。每一个字段后面都有一个唯一的数字标号(number tag)，为了提高效率，1-15是用一个字节编码，16-2047是用的两个字节编码，所以根据霍夫曼编码的愿意应该把常用的字段用小于15的数字标号。<br>　　(3) 同一个.proto文件中可以定义多个message，尤其当他们在业务上逻辑相关时候更应该这样。.proto文件的注释支持用C/C++的//风格注释。<br>　　(4) 后续更新的时候，可能某些字段不想要了。为了兼容性起见，不应当仅仅注释或者删除掉，而应该用reserved字段尤其对数字标号进行保留，防止被别人再次使用，然后让老的程序错误解析这些字段。<br>　　(5) 对于optional的字段，可以使用default提供对应的默认值，这样当message解析发现没有这个字段时候，那么就会：如果设定有默认值，就使用这个默认值；否则其值是类型相关的——0、false、空string、枚举的第一个元素。<br>　　(6) enum枚举类型有一个选项allow_alias，打开它的时候，允许同一个枚举值有多个枚举的名字(比如上文的MOBILE和CELLPHONE)。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="分布式" scheme="https://taozj.org/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[《Linux多线程服务端编程》读摘]]></title>
    <link href="https://taozj.org/201609/read-(linux-mulit-thread-server-develop).html"/>
    <id>https://taozj.org/201609/read-(linux-mulit-thread-server-develop).html</id>
    <published>2016-09-09T05:11:22.000Z</published>
    <updated>2016-12-18T08:51:15.000Z</updated>
    <content type="html"><![CDATA[<p>　　花了几天的时间，把陈硕老师的《Linux多线程服务端编程》给看完了。<br>　　其实就是当初冲着网上的评价很高，号称为国人难得的C++开发之佳作，这本书很早之前就已经买了。当时一开卷就是C++中各种构造析构安全，复杂隐晦的多线程间的竞争条件，尤其当时对C++忘光了，而Boost、C++11、异步原理又不太熟悉，再加上工作上没有相关的任务做驱动，所以被唬住后也就将其搁在一边了。刚好最近在做C++的服务端开发，虽然用的是Boost.asio现成的异步框架，但是拿来看看，收获还是不少的。这本书总体内容显得还是比较“杂”的，包括了作者muduo异步库的设计思路、使用方法、实现过程和细节，还有其它跟muduo无关的，比如一些工程实践和开发经验，对C/C++语言的原理的解析，Ｃ++面向对象设计方式的评判等，相比起来显得更加的宝贵。<br>　　书中关键点都用红笔标记下了，为了后面温习查阅方便，本篇用以记录相关摘要。可能略显零碎，但也会是字字珠玑。</p>
<h1 id="第一部分_多线程编程系统">第一部分 多线程编程系统</h1><h2 id="1-1_对象构造线程安全">1.1 对象构造线程安全</h2><p>　　在对象构造期间不要泄露this指针，也不要在构造函数中注册回调函数，不要把this传递给跨进程对象，主要是确保在对象构造完成之前没有别的途径可以调用产生不确定行为。通常采用的是构造函数+initialize()的两段式构造，将复杂的工作放到构造完对象之后再初始化一次，这样缩短构造函数的时间，同时也不必在构造函数中做复杂的异常处理。</p>
<h2 id="1-2_析构对象线程安全">1.2 析构对象线程安全</h2><p>　　对象的成员mutex可以保护对象的运行，但是析构却不行，因为mutex的生命周期最多和类的生命周期一样长，根本无法保护。根本方法还是智能指针，确保对象最后引用结束的时候，对象资源被自动释放掉。</p>
<h2 id="1-3_智能指针">1.3 智能指针</h2><p>　　shared_ptr对象的引用计数本身是安全且无锁的，但是智能指针对象本身的读写(包括析构操作)却不是，如果要多个线程同时读写同一个shared_ptr对象，需要加锁。<br>　　这里的技巧是：可以在临界加锁区中将全局的shared_ptr复制成一个局部变量，后面操作局部变量，减少临界区；函数传参采用reference to const的方式传递，减少拷贝操作，也能提高性能；析构的时候不要在临界区reset()，而是在临界区中用局部变量swap，然后在临界区外部进行对象析构，减少临界区的范围。<br>　　对于析构任务重的情况，可以再开一个单独的线程，通过BlockingQueue<shared_ptr<void>&gt;把析构任务都提交到那个线程，减少对关键线程的影响。<br>　　shared_ptr还需要注意避免循环引用，对于对象周期和程序生命周期一样长的无所谓，否则交叉share_ptr在析构时候会发生问题。这时候应该owner持有指向child的shared_ptr，而child拥有指向owner的weak_ptr。</shared_ptr<void></p>
<h2 id="1-4_线程同步的原则">1.4 线程同步的原则</h2><p>　　a. 尽量最低限度的共享对象，尽量共享immutable对象，减少需要同步的情况；一旦产生了写，其他所有的读操作也都变成不是线程安全的了。<br>　　b. 使用高级的并发编程构建，比如TaskQueue、Producer-CustomerQueue、CountDownLatch等；<br>　　c. 只使用非递归的互斥器和条件锁，不用读写锁；<br>　　d. 使用atomic；<br>　　e. C的很多库函数都不是线程安全的，因为用到了静态空间，需要使用_r的版本，C++的容器是不安全的，C++的算法库大多是安全的，因为他们大多是没有状态的虚函数。<br>　　f. 多个锁操作很容易导致死锁，有些时候可以考虑比较锁地址，让地址小的先锁，以保证锁的顺序。<br><a id="more"></a></p>
<h2 id="1-5_互斥器Mutex">1.5 互斥器Mutex</h2><p>　　使用非递归的mutex，不手动lock()/free()，采用RAII机制的Guard对象自动加锁和解锁；不要使用跨进程的mutex，跨进程通信采用sockets；加锁和解锁必须在同一个线程中。</p>
<h2 id="1-6_条件变量和CountDownLatch">1.6 条件变量和CountDownLatch</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>;</div><div class="line"><span class="keyword">while</span>(<span class="built_in">queue</span>.empty()) &#123; <span class="comment">//防止spurious wakeup</span></div><div class="line">    cond.wait();&#125;</div><div class="line">    </div><div class="line">&#123; <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>; </div><div class="line"> <span class="built_in">queue</span>.push_back(x);&#125;   </div><div class="line"> cond.notify();</div></pre></td></tr></table></figure>
<p>CountDownLatch比如可以用于主线程等待多个子线程初始化完毕<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>;</div><div class="line"><span class="keyword">while</span>(count_ &gt; <span class="number">0</span>) &#123; cond.wait();&#125;</div><div class="line">    </div><div class="line">&#123; <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>; </div><div class="line">    count_ --;</div><div class="line">    <span class="keyword">if</span>( count_ == <span class="number">0</span>) cond.notifyAll();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-7_多进程和fork">1.7 多进程和fork</h2><p>　　只有单线程的程序才可以fork()，如果多线程执行了fork()，那么只会fork()当前运行的线程，其它线程都会消失掉。一般可以在程序的开始，先fork出一个看门狗进程，看门狗进程需要是单进程的。<br>　　多进程的程序如果大量共享数据，就需要大规模的共享内存，而且进程间的通信同步都比较麻烦，而且一旦一个进程在临界区内阻塞或者crash，其他进程也会被锁死，这种情况还不如使用多线程，多进程并不会增加多少程序的稳定性。</p>
<h2 id="1-8_将IO操作剥离给单独的线程">1.8 将IO操作剥离给单独的线程</h2><p>　　无论SSD和RAID怎么样，还是在传统的思路上考虑文件IO和数据库操作会比较慢，比如日志的写或者简单逻辑的数据库的更新，可以考虑到放到一个BlockingQueue队列上，那么请求线程就可以立即返回，而这些工作由单独的后台线程去处理（不过需要考虑后台线程的处理能力，否则BlockingQueue会越来越大）。</p>
<h2 id="1-9___thread线程局部变量">1.9 __thread线程局部变量</h2><p>　　<strong>thread关键字是GCC支持的局部存储措施，其可以修饰全局变量或者函数中的静态变量(对于类类型只支持POD类)，其在初始化只能使用编译期间的常量值。</strong>thread变量是针对每个线程一份独立实体，各个线程的变量值互不干扰。<br>　　C++11标准中引入了新的关键字thread_local，而Boost的thread库提供了thread_specific_ptr，采用类似智能指针的方式实现了线程本地存储机制。</p>
<h2 id="1-10_多线程与signal">1.10 多线程与signal</h2><p>　　signal本身就比较复杂，在信号处理函数中只能调用异步信号安全的函数，即可重入函数；同时如果修改全局变量也是比较危险的，因为编译器可能将其认为不会改变而优化掉信号处理的修改。<br>　　不要在多线程中使用信号，不用SIGUSR1触发服务端行为，采用增加监听端口的方式进行通信；不要使用基于信号的定时函数，其是不可靠的；不主动处理信号的行为，使用其默认语义，除了PIPE信号；如果要处理，使用signalfd的方式，把信号转化成文件描述的方式，杜绝直接使用signal handler。<br>　　现在看来内核很多操作都fd化，比如signalfd，timerfd，eventfd等，好处就是可以用相同的接口，同时也更容易整合到各种异步框架下面去。</p>
<h1 id="第二部分_moduo网络库">第二部分 moduo网络库</h1><h2 id="2-1_TCP连接不主动关闭">2.1 TCP连接不主动关闭</h2><p>　　TCP本身是一个全双工协议，同一个描述符可以读也可以写。通常在服务端，需要的时候对socket关闭写方向的连接，保留读方向的连接，称为TCP half-close，这样的好处是如果关闭的同时对端还在传输数据过来，就不会漏收这些数据。同时习惯上，对端程序在read()返回0之后，会主动关闭自己的写端，此时服务端的读端就会被被动关闭了。当然对于恶意不关闭的，通过time_wheel回收不活跃的连接，也不会有太大的问题。</p>
<h2 id="2-2_TCP分包">2.2 TCP分包</h2><p>　　对于短链接的TCP服务，一般发送方会主动关闭连接，表示一条消息传送完毕了，自然就意味着消息的结尾，就没有分包的问题。对于长连接服务，分包的形式有：<br>　　a. 约定固定长度的消息；<br>　　b. 使用特殊字符或者字符串作为消息的边界，比如HTTP中的\r\n；<br>　　c. 每条消息的头部约定一个字段，表示消息体的长度(hton_32)；<br>　　d. 利用消息本身来进行分包，比如json的{}配对。</p>
<h2 id="2-3_限制并发连接数目">2.3 限制并发连接数目</h2><p>　　默认情况下Linux一个进程最大打开的文件数目是1024，受到/etc/security/limits.conf中的nofile设置的限制，如果需要突破这个限制可以修改这个文件。<br>　　当然如果程序达到这个限制，行为会变的很被动，一般都是自己设置一个soft limit，一旦接受的到的连接数到达这个限制，就在accept后立即关闭新拿到的socket连接，让程序进入拒绝服务状态。</p>
<h2 id="2-4_time_wheel踢掉空闲连接">2.4 time wheel踢掉空闲连接</h2><p>　　对于一个连接如果若干秒没有数据，就被认为是空闲连接，应该被处理掉。书中用到的circlur_buffer无锁结构，将时间分片轮寻，书中的方式每次收到数据都会向队列尾部添加活动链接的弱引用，然后事件切换的时候检查头部的连接。当然这样做是没什么问题的，但是操作的代码比较的高。<br>　　我用的方式比较粗，每次建立新连接的时候，会把连接的weak_ptr保存在当前的时间片上，同时每个连接带有一个touch_time事件戳，当有数据交换时候更新这个时间戳。后面在时间片切换的时候，检查每个连接是否存在(提升为shared_ptr)，如果存在检查时间戳是否超时，然后决定是否删除连接。因为不每次添加和修改连接到时间片，所以处理速度比较快，但是缺陷是超时的时间不一定，根据socket的行为为[n, 2n-1]。</p>
<h2 id="2-5_小杂项">2.5 小杂项</h2><p>　　SIGPIPE信号处理是需要忽略的，因为这个信号的默认行为是终止进程，但是网络中对方断开连接而本地继续写入的话，会触发这个信号，所以必须要忽略掉。<br>　　TCP No Delay和TCP keepalive是两个比较重要的TCP选项，前者是禁用Nagle算法，避免连续发报出现延时，对编写低延时以及特殊的程序比较重要(当时开发socket代理的时候不知道这个选项，然后被折磨惨了，估计我会终生记住这个家伙)；TCP keepalive是定期探测TCP连接是否还存在，保持一个心跳的作用。</p>
<h2 id="2-6_处理自连接">2.6 处理自连接</h2><p>　　一般程序如果先bind，就会占用端口和套接字，是没有问题的。但是当程序没有显式bind的时候，如果连接的客户端和服务端都在同一个IP主机上，而且服务端端口在local_port_range的范围内，连接的过程中客户端端口有很小几率的可能和服务端端口是一致的，此时用netstat -an会发现源端口和目的端口都是一样的，对于TCP三次握手是符合协议的，但是这样的连接无法正常通信，需要重启。</p>
<h1 id="第三部分_工程实践部分">第三部分 工程实践部分</h1><h2 id="3-1_编译选项">3.1 编译选项</h2><p>　　C++的机制比较的复杂，所以推荐代码中使用严格的编译选项，排除可能的隐式规则和实际期望行为之间的差异。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-Wall -Wextra -Werror -Wconversion -Wno-unused-parameter -Wold-style-cast -Woverloaded-virtual -Wpointer-arith -Wshadow -Wwrite-strings -march=native</div></pre></td></tr></table></figure></p>
<p>而对于有些代码中如果需要临时忽略一些错误，可以采用下面语句：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__GNUC__)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">pragma</span> GCC diagnostic <span class="meta-keyword">warning</span> <span class="meta-string">"-Wunused-function"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">...</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__GNUC__)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">pragma</span> GCC diagnostic <span class="meta-keyword">error</span> <span class="meta-string">"-Wunused-function"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div></pre></td></tr></table></figure></p>
<h2 id="3-2_前向声明">3.2 前向声明</h2><p>　　前向声明可以减少头文件的包含，自然也降低了编译期间的循环依赖，加快编译速度。<br>　　对于class Foo，以下的几种使用不需要看到其完整的定义：<br>　　a. 定义或者声明Foo *和Foo &amp;，包括用于函数参数、返回类型、局部变量、类成员变量等。这是因为C++的内存模型是flat的，Foo的定义无法改变Foo的指针和引用的含义；<br>　　b. 声明一个以Foo为参数或者返回类型的函数，如果代码里面调用了这个函数，就需要提供这个类型的完整定义了，因为编译器需要使用Foo的拷贝构造函数和析构函数，需要看到类的完整声明。</p>
<h2 id="3-3_模版实例化膨胀">3.3 模版实例化膨胀</h2><p>　　虽然传统上说模板的定义需要放到头文件中，其实实际上是发生链接错误。工程上，可以把模板的实现放到库或者源代码中，二头文件中只放声明，这就是事先进行显式实例化。<br>　　还有对于private类型的成员模板，其实现也不需要放到头文件中，可以只在代码文件中实现，因为private类型只有类实现的本身会用到它。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://segmentfault.com/a/1190000002396411" target="_blank" rel="external">tcp自连接问题</a></li>
<li><a href="http://blog.csdn.net/justlinux2010/article/details/20947609" target="_blank" rel="external">源目的IP和端口都相同的连接出现的原因</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　花了几天的时间，把陈硕老师的《Linux多线程服务端编程》给看完了。<br>　　其实就是当初冲着网上的评价很高，号称为国人难得的C++开发之佳作，这本书很早之前就已经买了。当时一开卷就是C++中各种构造析构安全，复杂隐晦的多线程间的竞争条件，尤其当时对C++忘光了，而Boost、C++11、异步原理又不太熟悉，再加上工作上没有相关的任务做驱动，所以被唬住后也就将其搁在一边了。刚好最近在做C++的服务端开发，虽然用的是Boost.asio现成的异步框架，但是拿来看看，收获还是不少的。这本书总体内容显得还是比较“杂”的，包括了作者muduo异步库的设计思路、使用方法、实现过程和细节，还有其它跟muduo无关的，比如一些工程实践和开发经验，对C/C++语言的原理的解析，Ｃ++面向对象设计方式的评判等，相比起来显得更加的宝贵。<br>　　书中关键点都用红笔标记下了，为了后面温习查阅方便，本篇用以记录相关摘要。可能略显零碎，但也会是字字珠玑。</p>
<h1 id="第一部分_多线程编程系统">第一部分 多线程编程系统</h1><h2 id="1-1_对象构造线程安全">1.1 对象构造线程安全</h2><p>　　在对象构造期间不要泄露this指针，也不要在构造函数中注册回调函数，不要把this传递给跨进程对象，主要是确保在对象构造完成之前没有别的途径可以调用产生不确定行为。通常采用的是构造函数+initialize()的两段式构造，将复杂的工作放到构造完对象之后再初始化一次，这样缩短构造函数的时间，同时也不必在构造函数中做复杂的异常处理。</p>
<h2 id="1-2_析构对象线程安全">1.2 析构对象线程安全</h2><p>　　对象的成员mutex可以保护对象的运行，但是析构却不行，因为mutex的生命周期最多和类的生命周期一样长，根本无法保护。根本方法还是智能指针，确保对象最后引用结束的时候，对象资源被自动释放掉。</p>
<h2 id="1-3_智能指针">1.3 智能指针</h2><p>　　shared_ptr对象的引用计数本身是安全且无锁的，但是智能指针对象本身的读写(包括析构操作)却不是，如果要多个线程同时读写同一个shared_ptr对象，需要加锁。<br>　　这里的技巧是：可以在临界加锁区中将全局的shared_ptr复制成一个局部变量，后面操作局部变量，减少临界区；函数传参采用reference to const的方式传递，减少拷贝操作，也能提高性能；析构的时候不要在临界区reset()，而是在临界区中用局部变量swap，然后在临界区外部进行对象析构，减少临界区的范围。<br>　　对于析构任务重的情况，可以再开一个单独的线程，通过BlockingQueue<shared_ptr<void>&gt;把析构任务都提交到那个线程，减少对关键线程的影响。<br>　　shared_ptr还需要注意避免循环引用，对于对象周期和程序生命周期一样长的无所谓，否则交叉share_ptr在析构时候会发生问题。这时候应该owner持有指向child的shared_ptr，而child拥有指向owner的weak_ptr。</p>
<h2 id="1-4_线程同步的原则">1.4 线程同步的原则</h2><p>　　a. 尽量最低限度的共享对象，尽量共享immutable对象，减少需要同步的情况；一旦产生了写，其他所有的读操作也都变成不是线程安全的了。<br>　　b. 使用高级的并发编程构建，比如TaskQueue、Producer-CustomerQueue、CountDownLatch等；<br>　　c. 只使用非递归的互斥器和条件锁，不用读写锁；<br>　　d. 使用atomic；<br>　　e. C的很多库函数都不是线程安全的，因为用到了静态空间，需要使用_r的版本，C++的容器是不安全的，C++的算法库大多是安全的，因为他们大多是没有状态的虚函数。<br>　　f. 多个锁操作很容易导致死锁，有些时候可以考虑比较锁地址，让地址小的先锁，以保证锁的顺序。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="互联网" scheme="https://taozj.org/tags/%E4%BA%92%E8%81%94%E7%BD%91/"/>
    
      <category term="架构" scheme="https://taozj.org/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Boost.Coroutine协程库的简单使用]]></title>
    <link href="https://taozj.org/201609/usage-of-boost-coroutine.html"/>
    <id>https://taozj.org/201609/usage-of-boost-coroutine.html</id>
    <published>2016-09-08T06:35:05.000Z</published>
    <updated>2016-12-18T08:13:42.000Z</updated>
    <content type="html"><![CDATA[<p>　　绕了很久，看了很多的资料，总算对协程(coroutine)是有点眉目了。</p>
<p>　　由于C++原生支持多进程多线程，可以被操作系统直接调度，所以感觉对协程的支持没有那么的急迫，不过现在网上搜到很多资料，说是建议要把协程推到标准库中，可见协程还是蛮有用的。从原理上看，协程保存了执行当前位置，后续可以切换回来，像是一个用户态的线程，但是和一般的线程不同的是不是抢占式的(pre-emptive)切换，而是一种协作式的(cooperative)推拉；而对于用户来说，可以类似用符合思维习惯的同步手法，写出具有异步功能的高效代码，而不用像传统异步开发设置各种回调函数把代码割离弄的支离破碎的；最后还是得意于协程比线程更加的轻量级，切换过程也不会陷入内核态，增加系统的运行效率。<br><img src="/post_images/images/201609/5c2a3f22e3c744f8f3f7f67b39bfcc97.png" alt="coroutine"><br>　　同时最近发现了Tecent Phxteam开源出来的<a href="https://github.com/tencent-wechat/phxsql" target="_blank" rel="external">phxsql</a>项目，里面就有协程相关的使用，可见协程是可以用在高性能需求的生产环境上的。</p>
<p>　　Boost库中的协程支持两种方式：一种是封装了Boost.Coroutine的spawn，是一个stackful类型的协程；一种是asio作者写出的stackless协程。下面就两类分别罗列出相关特性。<br><a id="more"></a></p>
<h1 id="一、stackless协程">一、stackless协程</h1><p>　　在C++中有函数对象的概念后，只要类提供operator()的接口，那么类对象就可以当作函数调用，同时类的其他成员可以保存相关的状态信息。其实stackless就是通过class coroutine这个类本身来实现当前协程的状态保护的，其实其内部就是用的一个int来保留下次resume的行号的，同时提供is_child()、is_parent()、is_complete()三个函数来辅助控制协程的行为。<br>　　要支持协程的函数类必须是可拷贝构造和赋值构造的，其既可以作为实现类的基类派生，也可以作为实现类的一个成员变量，甚至是lambda、bind的参数。其定义了几个C++标准之外的伪关键字方便使用，通过包含<boost asio="" yield.hpp="">就可以使用。<br>(1) reenter<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">reenter(<span class="keyword">this</span>) &#123;&#125; <span class="comment">//继承形式</span></div><div class="line">reenter(coro_) &#123;&#125; <span class="comment">//成员变量形式</span></div></pre></td></tr></table></figure></boost></p>
<p>　　当reenter被执行的时候，控制流会跳转到最后yield或者fork的位置。<br>　　需要注意的是reenter宏是通过switch实现的，意味着当在协程体中使用局部变量的时候，当重入协程体时候不能忽略局部变量的定义。如果当前需要局部变量，那么用下面的方式使用符合的语句块。<br>(2) yield statement<br>　　常常用在异步操作的时候，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yield socket_-&gt;async_read_some(buffer(*buffer_), *<span class="keyword">this</span>);</div></pre></td></tr></table></figure></p>
<p>　　其执行的逻辑为：yield保存了当前协程的状态；其表达式初始化了异步操作；定义恢复点为statement后的一条语句；控制流被转移到了协程体的结尾。<br>　　当异步操作结束的时候，函数对象重新被唤醒，然后reenter使得执行流转移到了恢复点。当然statement表达式也可以是复合表达式，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">yield&#123; </div><div class="line">    mutable_buffers_1 b = buffer(*buffer_);</div><div class="line">    socket_-&gt;async_read_some(b, *<span class="keyword">this</span>); </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>(3) yield return expression ;<br>　　通常用于生成器的环境下使用，其return后面的值作为函数的返回值传递出来，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> interleave : coroutine</div><div class="line">&#123;</div><div class="line">  istream&amp; is1; istream&amp; is2;</div><div class="line">  <span class="function"><span class="keyword">char</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</div><div class="line">    reenter (<span class="keyword">this</span>) <span class="keyword">for</span> (;;) &#123;</div><div class="line">      yield <span class="keyword">return</span> is1.get();</div><div class="line">      yield <span class="keyword">return</span> is2.get();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　上面的例子会交替的从is1和is2中产生字符，其会使得return后面表达式的值被返回。<br>(4) yield ;<br>　　用于显式的控制执行的流程，通常在多个协程交替的运行完成协作工作。<br>(5) yield break ;<br>　　主要用来终止协程的，yield首先设置协程的终止状体，然后流程被转移到了协程体的结尾。<br>　　一旦终止，使用is_complete()就会返回true，同时协程不能够被再次reenter了。当然不一定要yield break，当流程执行到了协程体结尾，这些协程也会自动terminate了。<br>　　突然意识到为啥要break了，因为reenter本来就是用switch实现的嘛。<br>(6) fork statement<br>　　可以创建多个协程的拷贝，常用的情况是在服务端，协程被fork出来用于处理客户端的请求。父协程和子协程通过is_parent()、is_child()进行界定。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">reenter (<span class="keyword">this</span>) &#123;</div><div class="line">    <span class="keyword">do</span>&#123;</div><div class="line">        socket_.reset(<span class="keyword">new</span> tcp::socket(io_service_));</div><div class="line">        yield acceptor-&gt;async_accept(*socket_, *<span class="keyword">this</span>);</div><div class="line">        <span class="function">fork <span class="title">server</span><span class="params">(*<span class="keyword">this</span>)</span><span class="params">()</span></span>;</div><div class="line">  &#125; <span class="keyword">while</span> (is_parent());</div><div class="line">  ... client-specific handling follows ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其fork语句会创建当前协程的一个拷贝，然后可能会立即执行或者被后面再调度执行，或者使用io_service::post()调度执行。<br>　　关于stackless协程的设计和实现思路，可以查看参考文献的第一篇文章的介绍，其内部真的是用一个switch实现，使用一个变量记录代码行号的哦！</p>
<h1 id="二、stackful协程">二、stackful协程</h1><p>　　其实现使用的Boost.Context来进行上下文的切换。使用需要包含头文件<boost coroutine="" all.hpp="">，位于名字空间boost::coroutines。<br>　　其实现原理是每个协程都有自己的stack和control-block(boost::contexts::fcontext_t)，在协程需要暂停的时候，当前协程的所有非易失的寄存器(包括ESP、EIP)都会被保存在control-block当中，而新激活的协程会从其相关的control-block中加载回复相关的寄存器信息，称之为上下文切换，相关的上下文切换不需要系统特权。<br>　　Boost.Context提供的协程包括两类：非对称型协程asymmetric_coroutine的和对称型协程symmetric_coroutine，前者协程知道唤醒自己的协程，当需要暂停的时候控制流转换给那个特定的协程；对称协程中所有的协程都是相等的，协程可以把控制流给任何一个其它的协程。所以对称协程主要是表达并发编程中的多个独立的执行单元，而非对称协程常常用于对数据进行顺序处理的过程。<br>　　stackful协程可以从嵌套的stackframe中暂停执行，在恢复的时候可以在其暂停的地方继续执行，而stackless协程只有顶层的函数(top-level routine)可以被暂停，所有顶层函数调用的函数都不允许被暂停，也就是不允许嵌套使用携程。<br>　　stackful的协程可以被嵌套使用，但是要求协程是可移动(move)但不可拷贝(copy)的，因为其为RAII实现的，结束的时候资源会被自动清理释放，但是拷贝会导致内部的状态不可控。同时使用时候在context_switch切换到正在执行的相同协程的行为是未定义的。</boost></p>
<h2 id="2-1_Asymmetric_coroutine">2.1 Asymmetric coroutine</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">asymmetric_coroutine&lt;&gt;::pull_type</div><div class="line">asymmetric_coroutine&lt;&gt;::push_type</div></pre></td></tr></table></figure>
<p>　　其提供了单向的数据传输操作，在数据传输的过程中伴随着Context的切换。模板参数的类型决定了数据传输的类型，如果不需要传递数据只进行Context切换，可以使用void。<br>(1) pull_type<br>　　从另外的一个context获取数据，其构造函数的参数是一个cor-function函数对象，cor-function的参数是一个push_type的引用。初始化pull_type的时候，执行流被切换到了cor-function，并且synthesize一个push_type并将引用传递给协程函数。其同时还提供operator()，只进行context切换，不传输数据(即构造函数参数为空而不是模板类型指定的实参)。<br>　　pull_type提供迭代器和std::begin()、std::end()重载，从而可以增量的切换context并进行数据的传输。pull_type的提供的成员函数get()可以从别的context中拉取数据，但是不会造成context切换，如需切换需要手动调用operator()。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">pull_type <span class="title">source</span><span class="params">(</span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::push_type&amp; sink)&#123;</div><div class="line">        <span class="keyword">int</span> first=<span class="number">1</span>, second=<span class="number">1</span>;</div><div class="line">        sink(first); sink(second);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">8</span>;++i)&#123;</div><div class="line">            <span class="keyword">int</span> third=first+second;</div><div class="line">            first=second; second=third;</div><div class="line">            sink(third);</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"> </div><div class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i:source)</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt;  <span class="string">" "</span>;</div></pre></td></tr></table></figure></p>
<p>(2) push_type<br>　　用于将数据传输到别的执行context，其构造函数接收的cor-function参数类型是pull_type类型的引用。在初始化push_type的时候，不同的是执行流没有转移到cor-function，而是先执行push_type::operator()去synthesize一个pull_type并将其引用传递给协程函数。其push_type::operator(T)成员函数用于推送数据给对应的context。<br>(3) coroutine-function<br>　　通过pull_type::operator bool可以判断协程是否还有效(即协程函数是否已经terminated)，除非第一个模板参数是void，否则返回true的同时也意味着其还可以提供数据的。<br>　　从pull-coroutine向main-context传递数据的例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">pull_type <span class="title">source</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::push_type&amp; sink)&#123;</div><div class="line">        sink(<span class="number">1</span>); <span class="comment">// push &#123;1&#125; back to main-context</span></div><div class="line">        sink(<span class="number">2</span>); <span class="comment">// push &#123;2&#125; back to main-context</span></div><div class="line">    &#125;);</div><div class="line"></div><div class="line"><span class="keyword">while</span>(source)&#123;            <span class="comment">// test if pull-coroutine is valid</span></div><div class="line">    <span class="keyword">int</span> ret=source.get(); <span class="comment">// access data value</span></div><div class="line">    source();             <span class="comment">// context-switch to coroutine-function</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　从main-context向push-coroutine传递数据的例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// constructor does NOT enter cor-function</span></div><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">push_type <span class="title">sink</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::pull_type&amp; source)&#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i:source) &#123;</div><div class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt;  <span class="string">" "</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">13</span>,<span class="number">21</span>,<span class="number">34</span>,<span class="number">55</span>&#125;;</div><div class="line"><span class="keyword">for</span>( <span class="keyword">int</span> i:v) &#123;</div><div class="line">    sink(i); <span class="comment">// push &#123;i&#125; to coroutine-function</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-2_Symmetric_coroutine">2.2 Symmetric coroutine</h2><p>　　其caller和callee的关系是不固定的，symmetric的协程可以把执行控制转移给任意的symmetric协程，而不一定是自己的caller。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">symmetric_coroutine&lt;&gt;::call_type</div><div class="line">symmetric_coroutine&lt;&gt;::yield_type</div></pre></td></tr></table></figure></p>
<p>(1) call_type<br>　　call_type其构造函数是一个coroutine-function函数对象，协程函数接受一个yield_type的引用作为参数。实例化call_type不会将执行流传递到协程函数，其会先调用operator()去强制合成一个yield_type并将其引用传递给协程函数。<br>　　call_type不提供get()成员函数，即不可以从其他的执行context中获取数据。<br>(2) yield_type<br>　　通过调用yield_type::operator()并使用其它call_type对象作为参数，可以把数据和执行流传递给其他的context。<br>　　其模板参数规定了传输的数据类型，通过yield_type::get()可以访问该数据。如果实例化模板使用void类型，那么可以只用作控制流传递，而不进行数据的传递。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::symmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">call_type <span class="title">coro</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::symmetric_coroutine&lt;<span class="keyword">int</span>&gt;::yield_type&amp; yield)&#123;</div><div class="line">        <span class="keyword">for</span> (;;) &#123;</div><div class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; yield.get() &lt;&lt;  <span class="string">" "</span>;</div><div class="line">            yield(); <span class="comment">// jump back to starting context</span></div><div class="line">         &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">coro(<span class="number">1</span>); <span class="comment">// transfer &#123;1&#125; to coroutine-function</span></div><div class="line">coro(<span class="number">2</span>); <span class="comment">// transfer &#123;2&#125; to coroutine-function</span></div></pre></td></tr></table></figure></p>
<h2 id="2-3_spawn">2.3 spawn</h2><p>　　如果是这么写程序，不是蛋疼，而是要蛋碎了。幸好Boost.Coroutine库给了一个高度的封装，其使用yield_context来保存协程的运行环境，然后允许程序以同步的方式执行各种异步函数操作，而这个yield_context对象是spawn函数自动产生的。当然要想知道其内部封装的实现，还是需要另外花一份功夫的。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Function&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawn</span><span class="params">(boost::asio::io_service::strand strand, Function function)</span></span>;</div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Function&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawn</span><span class="params">(boost::asio::io_service &amp; io_service, Function function)</span></span>;</div><div class="line"></div><div class="line"><span class="comment">// Function需要的签名</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">coroutine</span><span class="params">(boost::asio::yield_context yield)</span></span>;</div></pre></td></tr></table></figure></p>
<p>　　要求spawn的第二个参数Function的签名必须是上面的类型，如果不符合，需要使用bind/lambda方式来包装。<br>　　此后，对于所有的异步操作，只需要把yield作为参数传递在原来需要callback的位置就可以了，当异步操作完成的时候，此处的程序会resume继续执行。<br>对于异步操作的函数，其前面可能是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">handler</span><span class="params">(boost::system::error_code ec)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">handler</span><span class="params">(boost::system::error_code ec, result_type result)</span></span>;</div><div class="line"><span class="comment">//  std::size_t length =  my_socket.async_read_some( boost::asio::buffer(data), yield);</span></div><div class="line"><span class="comment">//  boost::system::error_code ec;</span></div><div class="line"><span class="comment">//  std::size_t length =  my_socket.async_read_some( boost::asio::buffer(data), yield[ec]);</span></div></pre></td></tr></table></figure></p>
<p>　　对于有result_type的类型，其result的值已经作为参数返回了（比如上面的std::size_t），而如果出错，下面的调用方法会直接抛出异常，如果想使用原先返回错误的方式而不是抛出system_error异常的方式，可以使用yield[ec]的方式调用，operator[]用于外部获取发生的错误码。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_echo</span><span class="params">(boost::asio::yield_context yield)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">char</span> data[<span class="number">128</span>];</div><div class="line">    <span class="keyword">for</span> (;;)</div><div class="line">    &#123;</div><div class="line">      <span class="built_in">std</span>::<span class="keyword">size_t</span> length = my_socket.async_read_some(</div><div class="line">          boost::asio::buffer(data), yield);</div><div class="line"></div><div class="line">      boost::asio::async_write(my_socket,</div><div class="line">          boost::asio::buffer(data, length), yield);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">boost::asio::spawn(my_strand, do_echo);</div></pre></td></tr></table></figure>
<h2 id="2-4_再举个栗子">2.4 再举个栗子</h2><p>　　下面写一个小例子，看看封装后的协程写异步程序是多么爽的一件事，至于为什么爽是因为同步编程才是符合人类的思维习惯的。以前设置异步读取操作后，数据的处理都必须在回调函数中处理，现在可以直接在异步操作后接着处理啦！<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">#include &lt;boost/asio.hpp&gt;</div><div class="line">#include &lt;boost/asio/spawn.hpp&gt;</div><div class="line">#include &lt;boost/bind.hpp&gt;</div><div class="line">#include &lt;boost/shared_ptr.hpp&gt;</div><div class="line">#include &lt;boost/make_shared.hpp&gt; </div><div class="line">#include &lt;string&gt;</div><div class="line">#include &lt;ctime&gt;</div><div class="line">#include &lt;iostream&gt;</div><div class="line">#include &lt;boost/enable_shared_from_this.hpp&gt;</div><div class="line"></div><div class="line">using namespace boost::asio;</div><div class="line">using std::cerr; using std::endl;</div><div class="line"></div><div class="line">io_service io_service_;</div><div class="line"></div><div class="line">class session: public boost::enable_shared_from_this&lt;session&gt;</div><div class="line">&#123;</div><div class="line">public:</div><div class="line">    explicit session(ip::tcp::socket socket):</div><div class="line">    sock_(std::move(socket)),</div><div class="line">    strand_(io_service_),</div><div class="line">    uuid_(std::rand())</div><div class="line">    &#123;&#125;</div><div class="line">    </div><div class="line">    ~session() &#123; cerr &lt;&lt; "~sessoin -&gt;" &lt;&lt; uuid_ &lt;&lt; endl; &#125;</div><div class="line">    </div><div class="line">    void go()</div><div class="line">    &#123;</div><div class="line">        auto self(shared_from_this());</div><div class="line">        boost::asio::spawn(strand_, </div><div class="line">                boost::bind(&amp;session::do_echo, self, _1));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    void do_echo(yield_context yield)</div><div class="line">    &#123;</div><div class="line">        char data[128];  </div><div class="line">        std::size_t n = sock_.async_read_some(boost::asio::buffer(data), yield);</div><div class="line">        cerr &lt;&lt; "RECVED:【" &lt;&lt; data &lt;&lt; "】-&gt;" &lt;&lt; uuid_ &lt;&lt;endl;</div><div class="line">        std::time_t now = std::time(nullptr);</div><div class="line">        std::string time_str = std::ctime(&amp;now);</div><div class="line">        async_write(sock_, buffer(time_str), yield);</div><div class="line">        sock_.shutdown(ip::tcp::socket::shutdown_send);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">private:</div><div class="line">    ip::tcp::socket sock_;</div><div class="line">    io_service::strand strand_;</div><div class="line">    std::size_t  uuid_;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"></div><div class="line">void start_accept(yield_context yield)</div><div class="line">&#123;</div><div class="line">    ip::tcp::acceptor acceptor(io_service_, ip::tcp::endpoint(ip::tcp::v4(), 2016));</div><div class="line">    </div><div class="line">    for (;;) &#123;</div><div class="line">        boost::system::error_code ec;</div><div class="line">        ip::tcp::socket socket(io_service_);</div><div class="line">        </div><div class="line">        acceptor.async_accept(socket, yield[ec]);</div><div class="line">        if(!ec)</div><div class="line">            boost::make_shared&lt;session&gt;(std::move(socket))-&gt;go();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char* argv[])</div><div class="line">&#123;</div><div class="line">    boost::asio::spawn(io_service_, start_accept);</div><div class="line">    io_service_.run();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>编译后就可以看出运行效果了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  ~ g++ -std=c++11 test.cpp -lboost_system -lboost_coroutine -lboost_context -o <span class="built_in">test</span></div></pre></td></tr></table></figure></p>
<p>　　其实，感觉现实中协程更多的是对编程方式的改变，对控制流的操控可以用同步的结构写出异步的效果，但是协程是用户态的而不是原生的多线程，所以并不能并行执行提高并发率。但是协程能够在各个协程间进行高效的切换，这一点可以做到比传统依赖于异步调度的效率更高，这才体现出协作的本质吧！</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="https://msdn.microsoft.com/en-us/magazine/jj553509.aspx" target="_blank" rel="external">Windows with C++ - Lightweight Cooperative Multitasking with C++</a></li>
<li><a href="http://blog.csdn.net/cchd0001/article/details/50717525" target="_blank" rel="external">boost::asio::coroutine 文档翻译 + 源码解析</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/libs/coroutine/doc/html/index.html" target="_blank" rel="external">Coroutine</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/reference/coroutine.html" target="_blank" rel="external">coroutine</a></li>
<li><a href="http://www.boost.org/doc/libs/1_54_0/doc/html/boost_asio/overview/core/spawn.html" target="_blank" rel="external">Stackful Coroutines - spawn</a></li>
<li><a href="http://theboostcpplibraries.com/boost.asio-coroutines" target="_blank" rel="external">Coroutines</a></li>
<li><a href="https://avlog.avplayer.org/3597082/%E5%8D%8F%E7%A8%8B.html" target="_blank" rel="external">协程</a></li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>　　绕了很久，看了很多的资料，总算对协程(coroutine)是有点眉目了。</p>
<p>　　由于C++原生支持多进程多线程，可以被操作系统直接调度，所以感觉对协程的支持没有那么的急迫，不过现在网上搜到很多资料，说是建议要把协程推到标准库中，可见协程还是蛮有用的。从原理上看，协程保存了执行当前位置，后续可以切换回来，像是一个用户态的线程，但是和一般的线程不同的是不是抢占式的(pre-emptive)切换，而是一种协作式的(cooperative)推拉；而对于用户来说，可以类似用符合思维习惯的同步手法，写出具有异步功能的高效代码，而不用像传统异步开发设置各种回调函数把代码割离弄的支离破碎的；最后还是得意于协程比线程更加的轻量级，切换过程也不会陷入内核态，增加系统的运行效率。<br><img src="/post_images/images/201609/5c2a3f22e3c744f8f3f7f67b39bfcc97.png" alt="coroutine"><br>　　同时最近发现了Tecent Phxteam开源出来的<a href="https://github.com/tencent-wechat/phxsql">phxsql</a>项目，里面就有协程相关的使用，可见协程是可以用在高性能需求的生产环境上的。</p>
<p>　　Boost库中的协程支持两种方式：一种是封装了Boost.Coroutine的spawn，是一个stackful类型的协程；一种是asio作者写出的stackless协程。下面就两类分别罗列出相关特性。<br>]]>
    
    </summary>
    
      <category term="后台开发" scheme="https://taozj.org/tags/%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    
      <category term="C++与Boost" scheme="https://taozj.org/tags/C-%E4%B8%8EBoost/"/>
    
      <category term="分布式" scheme="https://taozj.org/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="开发进阶" scheme="https://taozj.org/categories/%E5%BC%80%E5%8F%91%E8%BF%9B%E9%98%B6/"/>
    
  </entry>
  
</feed>
