<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[后台开发那些常用技术再次小结（五）：消息队列]]></title>
      <url>https://taozj.org/201702/study-note-of-scalable-backend-(5)-message-queue.html</url>
      <content type="html"><![CDATA[<h1 id="一、消息队列简介">一、消息队列简介</h1><p>　　消息队列本质上是一个缓冲并分发请求的组件，消息队列工作的上下文中假定消息为单向流动，拥有着“发射后不用管”的特性。消息由消息生产者产生、消息队列缓冲、消息消费者消费信息执行操作，生产者和消费者之间彼此独立的工作，之间只会通过消息格式和消息队列产生耦合，这样就实现了生产者和消费者业务的解耦和异步化操作：之后生产者和消费者可以独立部署、独立伸缩，并且生产者向队列提交完消息之后就可以立即响应客户的请求。</p>
<h2 id="1-1_消息队列中的角色">1.1 消息队列中的角色</h2><p>　　<strong>消息生产者</strong><br>　　消息生产者也叫作消息发布者，其属于客户端代码的一部分，其只需要负责创建一条合法消息，并发送到消息队列中即可。应用通常有多个生产者，所有发步的消息被排队并异步处理。<br>　　<strong>消息队列</strong><br>　　消息队列本身起着向消费者递交消息的缓冲作用，消息队列可以是一个具有权限控制、路由、持久化、失败恢复等多种职责的独立组件，所以通常也被作为一个独立应用程序提供服务，称作消息代理或者面向消息的中间件。<br>　　<strong>消息消费者</strong><br>　　消息消费者主要从消息队列中接收并处理消息，是实际处理异步请求的组件。消息消费者不应当知道生产者的情况，其应该只依赖于消息队列中的合法消息做出行动。<br>　　消息消费者通常具有周期模式和守护模式进行工作：<strong>周期模式 | 拉模式</strong>，消费者定期连接到消息队列检查队列状况，如果有消息才消费，这种模型在诸如PHP、Perl等动态语言中比较常见，可以用在队列消息较少或者网络不稳定的场景；<strong>守护模式 | 推模式</strong>，消息消费者和消息代理通常用一个持久连接进行无限循环方式运行，消费者阻塞在取消息的操作上，这种模式在持久化应用容器的语言中更常见，比如Java、Nodejs；还有结合两种，采用推拉结合的形式进行工作的。<a id="more"></a><br>　　从消费者向消息队列取消息的不同订阅方法，也派生出了消息的不同路由方法：<br>　　a. 直接工作队列模型<br>　　该模式下队列由生产者和消费者所周知，多个生产者可以在任意时间点向队列的一端发送消息，而另一端可以有一个或者多个消费者竞争消费消息，但每条消息只会被路由到一个消费者。这种情况下消费者是无状态的，因此失效节点的替换、处理性能的可伸缩性将极为的简单。<br>　　b. 发布订阅模型<br>　　该模式实际是设计模式中观察者模式的变体，此模式下消息可能被发送到不止一个消费者。生产者产生的消息不再是发送给一个队列，而是发送到一个主题；消费者使用的时候必须连接到消息代理，并声明自己所感兴趣的主题；消息到达主题后，会被克隆给每个订阅了该主题的消费者，消费者接受一份消息的拷贝并复制到自己的私有队列中。在实现上，如果在发消息的时间点没有消费者订阅到该主题，通常这个消息会被丢弃掉。<br>　　这种模式的一个实例，就是电商在购物操作被确认后，会将购物事件发送给消息队列的某个主题，那么后续对这个主题感兴趣的消费者就可以收到消息后进行相关事务处理，比如通知供货商、消费者风控规则、消费者积分奖励等。<br>　　c. 定制路由规则<br>　　主要是各种消息路由规则的定制，消费者可以选择灵活的方式决定消息如何路由到自己的队列中。比如日志消息可以根据日志错误等级进行特定方式的路由。</p>
<h1 id="二、消息队列的好处">二、消息队列的好处</h1><p>　　<strong>实现异步处理</strong><br>　　使用消息队列可以推迟耗时的操作而不必阻塞客户端，消息添加到队列后就可以返回客户端让客户端继续执行。<br>　　异步处理的另外好处，就是保护系统的核心业务和关键特性，比如下单、产品检索、处理支付，如果将非核心业务同核心业务耦合起来，就会引入新的失效点影响核心业务的可用性，这些非核心业务请求都可以放到消息队列中进行异步处理。同时，对于那些消耗计算资源的操作、低价值的操作类型也都可以隔离到消息队列中处理。<br>　　<strong>更好的伸缩性</strong><br>　　生产者和消费者可以独立进行伸缩操作，理想情况下只需要简单添加机器联系到消息代理就可以完成伸缩。<br>　　<strong>平衡流量峰值</strong><br>　　即便业务流量持续增长，系统仍然可以持续高频接收请求，虽然消息产生的速率比消费速率快，但是可以持续高速的将消息送入队列中。虽然消息生产速率比消费速率会快，会导致整个队列不断增长，消息从发出到处理的延时也会不断变长，但是当峰值过后生产速率比消费速率低，整个系统就会慢慢趋于正常水平。<br>　　<strong>失败隔离和自我修复</strong><br>　　消息队列容许从关键路径上删除一些非核心功能，那么通过生产者、消费者的角色隔离就可以提高系统的健壮性和容错性，消费者系统错误就可以同生产者系统隔离。不仅在消费者遇到问题的时候体现出这样的价值，这也意味着消费者可以在任意时刻停止消息的处理，那么对于消费者端软件的维护、升级都是大有裨益的，只要消息被保存好就可以了。<br>　　<strong>解耦</strong><br>　　通过消息队列可以让生产者和消费者从不互相直接交互，甚至感知不到对方的存在，他们的行为只依赖于事先约定的消息格式。消费者和生产者可以独立开发、独立维护，甚至可以由不同的团队完成，从而在架构上实现了业务的高度解耦。</p>
<h1 id="三、消息队列的挑战">三、消息队列的挑战</h1><p>消息队列在上述描述的好处之外，带来的挑战和代价主要有：<br>　　<strong>消息无序</strong><br>　　在大多数情况下为了实现业务的伸缩性，消息消费者都是并行执行而且没有同步机制的，虽然这样可以最大化消费性能，但是某些情况下会出现消息无序的状况，消息处理的顺序取决于每个消费者处理能力的大小以及本身处理消息所需要的计算量。比如创建账户和发送邮件两个消息，这两个消息是有顺序依赖的，但是可能会被并行执行；某些情况下消息处理失败，消息队列基础架构会让该消息重回队列，然后被发送给其他消费者，那么就有可能出现消息的倒序执行、消息的多次执行问题。  针对上面的问题，可能的解决方式有：<br>　　a. 如果只有一个消费者(单线程)，每次只消费一条消息，那么可以保证消息严格按照入队的顺序进行有序消费，但是这种方式缺乏伸缩性。<br>　　b. 由应用程序保证消息顺序，整个消息系统仍然是不受消息顺序影响的。比如业务只发送创建账户的消息，而等消费者创建完账户后，该消费者负责创建发送Email的消息。<br>　　c. 某些消息代理可以支持部分消息顺序保证，这类组件主要是进行消息组机制，当消息发送的时候带有一个分组ID的标签，该分组ID可以由应用程序定义，消息代理能够保证同一组的所有消息能够按照发布的顺序被消费。其实内部是进行路由映射的策略，将同一个组ID的消息都发送给同一个消费者，这样就能够保证被顺序消费，但是不利于负载均衡。<br>　　<strong>消息重新入队列</strong><br>　　某些失败的场景下可能导致消费的信息被重新入队列。如果这种情况下需要系统健壮，那么就需要保证消费者的操作具有幂等性，但这种幂等性的实现根据业务类型可易可难，通常是在应用程序中增加一个操作跟踪和持久层来解决。<br>　　还有需要注意的是，幂等操作和顺序依赖往往是相互制约的，比如两条消息：一条将价格设置为55美元，一条将价格设置为60美元，那么这样的消息具有幂等性，但是最终结果严格依赖执行顺序；如果改为价格增加5美元，虽然对顺序无依赖，但是操作不具有幂等性。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://tech.meituan.com/mq-design.html" target="_blank" rel="external">消息队列设计精要</a></li>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[后台开发那些常用技术再次小结（四）：缓存部分]]></title>
      <url>https://taozj.org/201702/study-note-of-scalable-backend-(4)-cache.html</url>
      <content type="html"><![CDATA[<p>　　缓存技术在计算机体系中使用的极为广泛：CPU内部多级缓存、硬盘缓存、Linux文件系统缓存、数据库查询缓存、DNS解析缓存、浏览器和应用APP缓存等，缓存在加快系统响应的同时，也降低了对某些资源的消耗，善用缓存会整个系统的性能将会有极大的改善。<br>　　因为缓存通常可以从源头重建，所以即使被删除或者丢失了也不会产生太大的问题，不过也有一些诸如缓存失败导致服务器雪崩的问题。缓存最主要考量的是命中率，这个指标收到缓存键集合大小、内存空间大小和缓存寿命相互制约。</p>
<h1 id="一、基于HTTP缓存">一、基于HTTP缓存</h1><p>　　HTTP层的缓存一个重要特性就是其为通读缓存，通读缓存通常作为中介(代理)的角色，透明地给HTTP链接添加缓存功能，他可以拦截客户端请求并用缓存对象返回给客户端作为响应，只有当缓存没有合适的数据的生活，才会链接到原始服务器并转发客户端请求给他。因为服务和通读缓存的接口是一样的，这种情况下客户端也可以直接连接到原始服务器而跳过缓存。通读缓存很具有吸引力，因为他的存在对客户端来说是透明的，客户端无法区分响应来自缓存还是原始服务器，所以通读缓存扮演着可插拔的角色，客户端无须因为他的存在与否而做任何修改。</p>
<h2 id="1-1_HTTP规范的缓存头">1.1 HTTP规范的缓存头</h2><p>　　HTTP协议虽然广为使用，而且其可被缓存特性也广受赞誉，不过协议上其相关选项和实现缺较为的混乱。HTTP协议中和缓存相关的参数有：<br>　　<strong>Cache-Control</strong><br>　　private: 指出请求结果对请求用户是特定的，响应不能提供给其他用户。该用法也就意味着只有浏览器可以缓存响应，因为中间缓存无法识别特定用户。<br>　　public: 只要它为过期，指示响应可以在用户间被共享。注意这个选项和private是互斥的。<br>　　no-store: 指示响应不能被任何中间缓存存储到磁盘上，即响应可以被缓存在内存，但是不能持久化到磁盘。当你在响应中包含用户敏感信息的时候应该包含这个选项，使得缓存信息不回存储这些数据到磁盘上。<br>　　no-cache: 指示响应不能被缓存，更精确的意思是针对这个请求，缓存在每次用户请求相同资源的时候都需要询问服务器此时是否仍然合法，其效果和 Cache-Control:max-age=0相当。<a id="more"></a><br>　　max-age: 指示响应在缓存失效前，客户端可以保持缓存多少秒(即响应的TTL)。作者推荐不适用该选项，因为它向后兼容不好，而且还依赖Expires这个HTTP头。<br>　　no-transform: 指示响应不做任何修改直接用缓存提供。比如CDN的提供商可能通过对图片转码来减少大小，降低质量或者改变压缩算法。<br>　　must-revalidate: 指示一旦响应过于陈旧，不重新验证就不能返回给客户端。出现这个参数主要是客户端可以允许返回陈旧信息，此时通过这个参数告知缓存必须停止提供陈旧响应数据，每当客户端请求陈旧对象，缓存会强制向原始服务器请求数据。<br>　　<strong>Expires</strong><br>　　指定一个缓存对象失效的绝对时间点，超过这个时间点缓存对象就“陈旧”了。这个头其实同Cache-Control:max-age有些重复的，参考说Cache-Control 中指定的缓存过期策略优先级会高于Expires，不过同时定义两个变量可能会导致潜在不一致行为，建议只用一个并固定使用它。<br>　　<strong>Vary</strong><br>　　这个头告知缓存你需要基于某些HTTP请求头，生成响应的多个变体。</p>
<p>　　除此之外，还可以在Web页面中使用meta标签控制Web页面缓存，但是书的作者不推荐使用，因为他们不能用来控制中间缓存，而且容易引起混乱，经验不足还是使用HTTP头来控制缓存。</p>
<h2 id="1-2_HTTP的缓存类型">1.2 HTTP的缓存类型</h2><p>　　因为HTTP缓存是通读缓存，在客户端和服务端交互中的任何环节都可以插入中间缓存因而比较灵活。HTTP缓存常见于四种形式：浏览器本地缓存、缓存代理、反向代理和CDN。<br>　　<strong>浏览器缓存</strong><br>　　浏览器缓存和本机的内存、文件系统协同工作，当HTTP请求将要发出的时候，浏览器会检查缓存是否具有该资源的合法版本，如果响应存在于缓存中并且仍然有效，浏览器就可以直接重用之而不用发出一个HTTP请求。<br>　　<strong>缓存代理</strong><br>　　通常由大公司或者ISP作为通读缓存部署，用于加快用户响应的同时降低网络流量。但是近些年本地代理的做法有所限制，一方面是网络带宽变便宜了，二则越来越多的Web站点采用HTTPS部署，客户端和服务器之间的通信无法被识别和拦截，缓存也就无从谈起了(一大批运营商的缓存服务器要吃灰了)。<br>　　<strong>反向代理</strong><br>　　其工作方式和常见的缓存代理差不多，不过是开发者自己部署和控制的，具有极大的灵活性。反向代理本身可以缓存页面缓存，降低对后端Web服务器的请求压力；还可以在反向代理中覆盖HTTP头，更好的控制请求的缓存策略和有效时间。<br>　　<strong>CDN</strong><br>　　CDN在之前也说的比较多了，其是基于智能DNS解析+缓存技术实现的分布式网络加速。<br>　　现在较好的CDN提供商可以通过配置，同时提供网站的静态内容和动态内容，这样客户端就可以不用直接向数据中心或者原始服务器发送请求而直接向CDN的地址请求，动态内容的请求可以穿透CDN缓存服务器回源到原始服务器。即使看似有些麻烦，但是这一方面可以隐藏原始服务器的地址，而且可以减轻DDoS攻击力度，再则某些动态的内容也是可以被CDN缓存的。<br>　　在我之前体验的几家国内的CDN提供商，在提供HTTP服务的同时还提供HTTPS类型的服务，不过后者的费用会高一些。CDN会要求用户提供域名证书，所以相比于缓存代理而言，他们是完全可以缓存HTTPS加密通信的内容的</p>
<h1 id="二、缓存应用对象">二、缓存应用对象</h1><p>　　对象缓存区别于HTTP缓存，其为旁路缓存类型。旁路缓存中，应用需要意识到缓存对象的存在，而不是透明的存在于应用和数据源之间。<br>　　旁路缓存会应用视为一个独立的键值存储服务，应用程序代码会询问需要的对象是否存在，如果存在就获取之，否则(不存在或者已过期)则需要从头构建该对象，并将结果保存在缓存中以便将来使用。使用这种缓存的动机就是节省对象从头构建所化的时间和资源。</p>
<h2 id="2-1_对象的缓存类型">2.1 对象的缓存类型</h2><p>　　<strong>客户端缓存</strong><br>　　主要还是浏览器的，据说用JS玩起来比较溜。<br>　　<strong>本地缓存</strong><br>　　本地缓存是相对于原始服务器而言的，其常见的本地缓存形式有：<br>　　(1) 对象直接缓存在应用内存<br>　　应用可以创建一个缓存对象池并不在释放分配的内存，这种缓存的速度最快，因为是以执行代码相同的格式存储在进程的内存空间中的。<br>　　(2) 对象存储在共享内存<br>　　这种形式主要是方便同一台机器的多个进程可以同时访问的需要。<br>　　(3) 缓存服务器作为独立应用部署在Web服务器上<br>　　这种形式的缓存服务器，需要应用程序使用专门的接口与之交互，而不能直接访问内存。虽然和上面的形式相比有一定的性能消耗，但好处是可以使用统一的访问接口，后续进行伸缩也较为的方便。这里讨论的本地缓存强调的是应用服务和缓存服务服务在同一台机器上，这种样式的缓存也有一定的问题：a. 如果在多个机器组成的应用环境中，各个机器上的缓存没有联系，也就可能同一个缓存对象会被缓存成多个副本；b. 这种分散式的缓存管理起来也比较麻烦，比如要更新或者删除某条缓存记录的话，要通知到所有的缓存服务器将会非常的棘手。<br>　　<strong>分布式缓存</strong><br>　　其实就是相对于上面描述的本地缓存中，将缓存服务器和应用服务器进行分离，通过网络接口的方式进行交互，可为所有的应用服务提供一个集中的缓存服务(变更和删除缓存条目比上面多个本地缓存类型要方便的多)。这样的缓存服务具有很强的伸缩性，管理的方式也多种多样，而且通常也会提供多种语言的访问接口库，是近年来开发和研究的热点，老牌的缓存服务如Memcached和Redis使用非常广泛。</p>
<h2 id="2-2_对象缓存的伸缩">2.2 对象缓存的伸缩</h2><p>　　针对上面描述的对象缓存类型，通常只有分布式缓存才具有伸缩的价值和可行性。常见的Memecached可以采用Ketama一致性hash算法算法的客户端库实现水平伸缩(再次提到last.fm的<a href="http://www.last.fm/zh/user/RJ/journal/2007/04/10/rz_libketama_-_a_consistent_hashing_algo_for_memcache_clients" target="_blank" rel="external">这个C库</a> )，这里强调一下Memcached一致性hash实现的伸缩性是在客户端一侧实现的；而Redis允许进行主从复制部署，对某些高热度的数据可以采用读副本的形式增加并发访问量。</p>
<h1 id="三、缓存使用的经验法则">三、缓存使用的经验法则</h1><p>　　<strong>缓存整个调用栈</strong><br>　　通常一个请求从客户端到最终服务端之间会经历多个角色，在整个调用栈中任意部分都可以考虑插入缓存，而且缓存的调用栈越高，能节省的资源也就越大，响应这个请求的代价也就越小。<br>　　<strong>用户间缓存重用</strong><br>　　缓存使用的另外一个要点就是尽可能多地在不同请求或者用户之间重用相同的缓存对象！<br>　　比如下面的例子，通过经度、维度数据查询某个结果，此时过高精度的参数将导致几乎每个调用都是不相同的，而如果将请求参数进行精度降低，那么很多请求就可以共享结果，也就增加了缓存的命中率。<br>　　<strong>缓存的入手点</strong><br>　　缓存的实施不是凭感觉的，通常的2-8定律也可以用在这里：可以通过日志查看访问量高的页面或者接口，然后从这些位置入手看是否能通过缓存改善性能，在重要、热点页面上的改进带来收益的提升可能性更大。<br>　　<strong>缓存失效的困难</strong><br>　　可以说缓存失效的问题是缓存体系中的大难题，虽然这也同业务类型具有比较大的相关性。<br>　　首先缓存服务可以设置在整个调用栈的任何可能位置，要让整个调用链在最大化缓存命中率的同时还能及时感知缓存失效是比较困难的；再则有些缓存的结果是通过多个数据源进行计算得来的，当最初的某个或者某些数据源变更将会导致该缓存失效，但是怎么样跟踪这种依赖关系是个难点。<br>　　缓存失效简单的方案就是对重要缓存对象上设置一个较短的TTL，这样可以保证数据不会过于的陈旧；为了降低数据库和服务的压力，某些动态数据的展示仍然是可以使用缓存的，只是在最终产生业务的时候进行实际的数据校验操作(虽然体验上不见得多好，比如12306的那种缓存，但至少可以帮助服务器抗住强大的访问压力)。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="http://mp.weixin.qq.com/s/qOMO0LIdA47j3RjhbCWUEQ" target="_blank" rel="external">彻底弄懂 Http 缓存机制 - 基于缓存策略三要素分解法</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MzIwODA4NjMwNA==&amp;mid=2652897955&amp;idx=1&amp;sn=de2d8984f6d0f9e061d1da35df84b182" target="_blank" rel="external">聊聊高并发系统之HTTP缓存</a></li>
<li><a href="http://tech.meituan.com/avalanche-study.html" target="_blank" rel="external">Cache应用中的服务过载案例研究</a></li>
<li><a href="http://mogu.io/cheetah-101" target="_blank" rel="external">静态化技术在蘑菇街的应用</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&amp;mid=404087915&amp;idx=1&amp;sn=075664193f334874a3fc87fd4f712ebc" target="_blank" rel="external">缓存架构设计细节二三事</a></li>
<li><a href="http://coolshell.cn/articles/17416.html" target="_blank" rel="external">缓存更新的套路</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[CMake工具使用手册]]></title>
      <url>https://taozj.org/201702/cmake-cheatsheet.html</url>
      <content type="html"><![CDATA[<p>　　之前自己的小项目都是直接手动人肉Makefile，因为项目的文件不是很多，发现以前写的那个Makefile模板增增改改还是挺够用的。但现在发现CMake真是越来越流行了，不知道是不是借着QT/KDE等项目的东风，越来越多的C++开源项目开始使用CMake工具来用作管理项目了。此外，著名IDE Clion和CMake也集成的很好，只不过我现在已经不用IDE进行调试了，因为命令行的GDB更方便。<br><img src="/post_images/images/201702/4a3b2635.png" alt="cmake"><br>　　这次在一个项目中使用了CMake，简单直白的几行命令，就可以快速生成Makefile，相比Makefile晦涩的语法和隐暗的规则，可以说是懒人(对我来说主要是弱鸡)用的Makefile。除了辅助生成编译用的Makefile，CMake还集成安装、测试、打包等功能，同时跟Boost库的单元测试框架也很好的集成，Bingo！<br>　　注意：CMake工具的实现主要是由一系列的命令构成，同时还有大量的预定义变量，正是他们的存在使得用户可以用极少的语句生成功能丰富的Makefile文件。现在CMake官方最新发布版本是v3.8，但是在CentOS-7系列的机器上最新的CMake版本仍然是v2.8分支，由于代码的部署环境所限，本篇文档还是针对CMake v2.8.12老版本操作实验的结果，有时候同最新CMake可能会有所差异，建议查看查看老版本的文档。<br>　　CMake中有很多涉及到文件、目录的相关命令或者变量，在作为参数的时候有时可以使用相对路径，有时可以使用绝对路径；在使用相对路径的时候，有时候是相对于项目的源代码路径，有时候是相对于编译路径，还有些时候相对路径参考于某些预制变量，这些东西如果被搞糊涂了还是建议查看相关文档。<br>　　本文档不求最全，够用即可！</p>
<h1 id="一、起步">一、起步</h1><p>　　凡是手动安装过CMake管理的软件的同学，都知道CMake的用法。通常会在项目路径下面建立一个build目录，然后进入build目录使用<code bash="">➜  build git:(master) ✗ cmake ../ </code>命令就可以生成Makefile文件，接下来的操作想必大家就都知道了。额外创建build路径进行项目外编译，就是可以保护你的源代码路径整洁干净。<br>　　所以开发者就是要编写这个CMakeLists.txt文件，方便自己的同时也方便了用户。<a id="more"></a><br>　　CMakeLists.txt文件使用#打头的是注释，项目根目录CMakeLists.txt所必须行如下，前者规定了可以使用该文件的最低版本CMake版本，后者指明了项目名称。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cmake_minimum_required (VERSION 2.8.11)</div><div class="line">project (aimlsrvd)</div></pre></td></tr></table></figure></p>
<p>　　如果你的项目是比较简单的结构，所有源代码都放在source/目录下面，而根目录包含一个main.cpp入口函数，则只需要再添加如下两行，就可以编译产生可执行文件了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">aux_<span class="built_in">source</span>_directory( <span class="built_in">source</span>/ DIR_SRCS )</div><div class="line">add_executable( aimlsrvd main.cpp <span class="variable">$&#123;DIR_SRCS&#125;</span> )</div></pre></td></tr></table></figure></p>
<p>　　aux_source_directory 命令的作用就是将指定目录下的文件名收集起来并保存到指定变量中。这个命令原本不是专门为上面这种情况使用的，因为CMake只会检查CMakeLists.txt文件的时间戳来决定是否执行cmake更新编译环境，那么当你在指定目录下添加了新的源代码文件的时候而没有更新过CMakeLists.txt，那么CMake可能就不能感知到该目录下源文件增删的变化，此时你必须手动执行cmake命令进行刷新。<br>　　add_executable 命令用于指定生成可执行文件，该名字必须在整个项目中相对其他可执行文件必须是全局唯一的。不仅仅是可执行文件，通过add_library还可以生成库类型的目标。</p>
<h1 id="二、自定义库">二、自定义库</h1><p>　　将所有的源代码都丢在一个目录下“扁平化”管理是很糟糕的，现在的软件工程都讲求模块化设计，所以通常的手段是将模块的代码单独放在一个文件夹，将模块编译成库，一方面方便代码(库)的重用，而来对于整个项目的管理、调试都是大有裨益的。<br>　　CMake支持这种递归形式的处理，只需要在项目根目录的CMakeLists.txt通过add_subdirectory命令添加你模块所在的源代码目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">add_subdirectory( <span class="built_in">source</span>/Netd/ )</div></pre></td></tr></table></figure></p>
<p>　　然后调到你模块所在的源代码目录(比如上面例子的source/Netd/)，再新建一个CMakeLists.txt文件，通过上面提到的add_library命令指定所需生成的库名称，生成的库还可以指定生成动态库SHARED还是静态库STATIC的类型。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">aux_<span class="built_in">source</span>_directory(. DIR_LIB_SRCS)</div><div class="line">add_library (Netd SHARED <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</div><div class="line">add_library (Netd_static STATIC <span class="variable">$&#123;DIR_LIB_SRCS&#125;</span>)</div><div class="line">install (TARGETS Netd Netd_static</div><div class="line">            RUNTIME DESTINATION bin</div><div class="line">            LIBRARY DESTINATION lib</div><div class="line">            ARCHIVE DESTINATION lib/static )</div></pre></td></tr></table></figure></p>
<p>　　后面那个install是在安装的时候需要使用到的。因为CMake有个问题，就是安装必须在当前目录下指明，所以该库的安装命令不能在顶层的CMakeLists.txt文件中去设定，虽然麻烦，但是设计如此。<br>　　一旦可执行程序使用了连接库(无论是自己生成的还是其他外部组件的)，都需要在CMakeLists.txt中指明这种依赖关系。如果你想让自己的CMakeLists.txt看得优雅一些，推荐set个变量来慢慢收集，而且有时候你还不得不这么做。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; pthread hiredis iconv)</div><div class="line">set (EXTRA_LIBS $&#123;EXTRA_LIBS&#125; boost_system boost_thread boost_date_time boost_log boost_log_setup boost_regex)</div><div class="line">set ( EXTRA_LIBS $&#123;EXTRA_LIBS&#125; Netd )</div><div class="line">target_link_libraries( aimlsrvd $&#123;EXTRA_LIBS&#125; )</div></pre></td></tr></table></figure></p>
<h1 id="三、宏变量和编译选项">三、宏变量和编译选项</h1><h2 id="3-1_编译命令行选项">3.1 编译命令行选项</h2><p>　　通过add_definitions函数可以设置编译时候命令行的宏定义，比如gcc的-D和巨硬的/D。一个常用的例子就是assert的NDEBUG宏开关了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">add_definitions (-DBOOST_LOG_DYN_LINK -DNDEBUG)</div></pre></td></tr></table></figure></p>
<p>　　除了这个，CMake还有很多内置的变量和可以设置，比如Debug/Release便宜版本，编译参数的设置等(比如c++11标准必须显式设定)，在此罗列出来供大家参考。Debug版本和Release版本编译出来的可执行程序的尺寸相差巨大啊！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS <span class="string">"<span class="variable">$&#123;CMAKE_CXX_FLAGS&#125;</span> -std=c++11 "</span> )</div><div class="line"><span class="comment">#set(CMAKE_CXX_FLAGS "-Wall -Wconversion -Woverloaded-virtual -Wpointer-arith -Wshadow -Wwrite-strings -march=native " )</span></div><div class="line"><span class="built_in">set</span>(CMAKE_BUILD_TYPE Debug)</div><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS_DEBUG   <span class="string">"<span class="variable">$ENV</span>&#123;CXXFLAGS&#125; -O0 -g"</span>)</div><div class="line"><span class="built_in">set</span>(CMAKE_CXX_FLAGS_RELEASE <span class="string">"<span class="variable">$ENV</span>&#123;CXXFLAGS&#125; -O2 "</span>)</div></pre></td></tr></table></figure></p>
<h2 id="3-2_通过文件配置宏定义">3.2 通过文件配置宏定义</h2><p>　　通过configure_file这个命令，CMake可以将输入配置文件进行处理，并转换成可用的C/C++头文件，而且在配置文件模板中使用的@VAR@变量会被在CMakeLists.txt中定义的值所替换，这样就提供了CMakeLists.txt-配置模板-应用程序三者交换数据的通道。对此，在CMake手册中最经典不过的例子就是软件版本号了。下面是在CMakeLists.txt定义的主、次两个版本号信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> (AIMLSRV_VERSION_MAJOR 0)</div><div class="line"><span class="built_in">set</span> (AIMLSRV_VERSION_MINOR 85)</div><div class="line">configure_file ( <span class="string">"include/config.h.in"</span>   <span class="string">"../include/config.h"</span> )</div></pre></td></tr></table></figure></p>
<p>　　然后在模板配置文件config.h.in中定义两个变量，变量的值可以引用之前在CMakeLists.txt中定义的变量：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _CONFIG_H_</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> _CONFIG_H_</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> aimlsrv_VERSION_MAJOR @AIMLSRV_VERSION_MAJOR@</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> aimlsrv_VERSION_MINOR @AIMLSRV_VERSION_MINOR@</span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">// _CONFIG_H_</span></span></div></pre></td></tr></table></figure></p>
<p>　　正常使用cmake命令，就会发现可被C/C++引用的指定头文件config.h生成了，其中的两个宏aimlsrv_VERSION_MAJOR、aimlsrv_VERSION_MINOR的值已经被正常替换，在C/C++源代码中可以像普通的宏一样被使用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"      VERSION: "</span>  &lt;&lt; aimlsrv_VERSION_MAJOR &lt;&lt; <span class="string">"."</span> &lt;&lt; aimlsrv_VERSION_MINOR &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div></pre></td></tr></table></figure></p>
<h2 id="3-2_定义选项开关">3.2 定义选项开关</h2><p>　　option命令可以提供类似选项开关(ON、OFF)的效果，而且在使用ccmake的时候可以提供ncurses库支持的图形化选择效果，不过<strong>需要特别注意</strong>使用该命令的时候，其设置结果会被缓存起来，如果你最开始生成CMake的缓存文件之后，如果修改了其取值后直接运行cmake，那么该新值是没有生效的，只有当你删除build目录下缓存文件之后再次生成，才会实际的生效。<br>　　我有个库AiSQLpp在当前的项目中还没有完成调试，所以其选项设置为OFF，该变量会影响到下面的编译和生成过程：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">option(USE_AISQLPP <span class="string">"Currently not work with aisqlpp, so must be disabled!"</span> OFF)</div><div class="line"><span class="keyword">if</span> (USE_AISQLPP)</div><div class="line">  add_subdirectory( <span class="built_in">source</span>/Aisql/ )</div><div class="line">endif (USE_AISQLPP)</div><div class="line"><span class="keyword">if</span> (NOT USE_AISQLPP)</div><div class="line">  <span class="built_in">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> mysqlclient z m ssl crypto dl)</div><div class="line"><span class="keyword">else</span> (NOT USE_AISQLPP)</div><div class="line">  <span class="built_in">set</span> (EXTRA_LIBS <span class="variable">$&#123;EXTRA_LIBS&#125;</span> Aisql mysqlcppconn)</div><div class="line">endif (NOT USE_AISQLPP)</div></pre></td></tr></table></figure></p>
<p>　　上面定义了名称为USE_AISQLPP的开关选项，其ON和OFF的选项值决定了程序是使用AiSQLpp库还是使用原生的mysqlclient来访问数据库。我们在之前的config.h.in配置模板文件中可以使用cmakedefine来声明这个宏：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#cmakedefine USE_AISQLPP</span></div></pre></td></tr></table></figure></p>
<p>　　如果USE_AISQLPP的值是ON，那么在生成的config.h中就会有<code cpp="">#define USE_AISQLPP</code>这个宏定义的存在，如果该选项是OFF，那么就将没有这个宏的定义，因此这个选项的定义还可以控制程序源代码的行为。</p>
<h1 id="四、单元测试">四、单元测试</h1><p>　　CMake自带单元测试工具ctest，更令我高兴的是可以和Boost.Test单元测试框架无缝结合，这样单元测试的代码也可以使用CMakeLists.txt文件进行管理了。当然，根据网上的资料看来，集成gtest和CMake使用也不是难事，不过个人来说还是倾向于喜欢Boost全家桶。<br>　　单元测试的目录的CMakeLists.txt跟项目差不多，只不过需要额外的添加enable_testing()命令，在文件的末尾对于每个测试用例，都要使用add_test()命令添加到测试用例集中去。按照下面的步骤编译测试用例：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  <span class="built_in">test</span> git:(master) ✗ mkdir build &amp;&amp; <span class="built_in">cd</span> build</div><div class="line">➜  build git:(master) ✗ cmake ..</div><div class="line">➜  build git:(master) ✗ cmake --build .</div><div class="line">➜  build git:(master) ✗ ctest</div></pre></td></tr></table></figure></p>
<p>　　下面是执行单元测试的效果：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">➜  build git:(master) ✗ ctest </div><div class="line">Test project /home/taozj/remote_build/aimlsrvd/<span class="built_in">test</span>/build</div><div class="line">    Start 1: dividewordtest</div><div class="line">1/3 Test <span class="comment">#1: dividewordtest ...................   Passed    0.20 sec</span></div><div class="line">    Start 2: aisqlpptest</div><div class="line">2/3 Test <span class="comment">#2: aisqlpptest ......................   Passed    0.41 sec</span></div><div class="line">    Start 3: utfgbktest</div><div class="line">3/3 Test <span class="comment">#3: utfgbktest .......................   Passed    0.38 sec</span></div><div class="line"></div><div class="line">100% tests passed, 0 tests failed out of 3</div><div class="line"></div><div class="line">Total Test time (real) =   1.42 sec</div><div class="line">➜  build git:(master) ✗</div></pre></td></tr></table></figure></p>
<p>　　如果想要更详细的输出，比如想在测试的过程中查看测试用例和应用程序代码中的打印信息，可以使用<code bash="">ctest –verbose</code>命令，虽然现实的东西比较多额多，但是总体输出格式还是非常友好第。</p>
<h1 id="五、安装和打包">五、安装和打包</h1><h2 id="5-1_安装">5.1 安装</h2><p>　　通过install命令可以安装编译产物——可执行文件、动态|静态库、头文件、配置文件等，默认情况下CMake还是比较保守的，全部都安装到/usr/local/{bin,lib,include}目录下。对于可执行文件和头文件可以按照下面的方式进行设置，而对于动态和静态库文件，由于CMake的限制必须在当前目录进行安装，所以需要在对应的子文件下进行安装，其代码已经在上面自定义库的段落进行了示范。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">install (TARGETS aimlsrvd DESTINATION bin )</div><div class="line">install (DIRECTORY include/ DESTINATION include/aimlsrvd)</div></pre></td></tr></table></figure></p>
<p>　　设置好之后，使用<code bash="">➜  build git:(master) ✗ sudo make install</code>就可以进行实际的安装。不过，默认情况下CMake不提供uninstall目标，虽然从官方的手册上面可以在配置模板文件中添加uninstall目标的支持，其实安装文件都记录在了install_manifest.txt文件中，只需要执行下面一行命令就可以搞定删除操作：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">➜  build git:(master) ✗ xargs rm &lt; install_manifest.txt</div><div class="line">➜  build git:(master) ✗ cat install_manifest.txt | sudo xargs rm</div></pre></td></tr></table></figure></p>
<h2 id="5-2_软件打包">5.2 软件打包</h2><p>　　如果上面的安装配置好了，那么软件打包也极为的简单，只需要将下面几行代码粘贴到根目录的CMakeLists.txt文件的末尾，然后使用cpack工具就可以进行可执行文件、源代码文件的打包操作。<br>　　不过我个人而言觉得不是很必要，因为：线上的项目基本都是编译玩直接在当前目录启动运行，不会发布给其他人使用，也就没有了软件打包的需要；如果需要打包，各大发行版有更专业的打包工具(比如rpmbuild)，使用cpack打包成一个.sh的安装文件总感觉显得比较的业余。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">include (InstallRequiredSystemLibraries)</div><div class="line"><span class="built_in">set</span> (CPACK_PACKAGE_VERSION_MAJOR <span class="string">"<span class="variable">$&#123;AIMLSRV_VERSION_MAJOR&#125;</span>"</span>)</div><div class="line"><span class="built_in">set</span> (CPACK_PACKAGE_VERSION_MINOR <span class="string">"<span class="variable">$&#123;AIMLSRV_VERSION_MINOR&#125;</span>"</span>)</div><div class="line">include (CPack)</div></pre></td></tr></table></figure></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/25751686/" target="_blank" rel="external">Mastering CMake</a></li>
<li><a href="https://cmake.org/cmake-tutorial/" target="_blank" rel="external">CMake Tutorial</a></li>
<li><a href="https://cmake.org/cmake/help/v2.8.12/cmake.html" target="_blank" rel="external">CMake 2.8.12 Documentation</a></li>
<li><a href="http://www.boost.org/doc/libs/1_63_0/libs/test/doc/html/boost_test/section_faq.html" target="_blank" rel="external">Boost.Test FAQ</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[后台开发那些常用技术再次小结（三）：存储部分]]></title>
      <url>https://taozj.org/201702/study-note-of-scalable-backend-(3)-storage.html</url>
      <content type="html"><![CDATA[<p>　　原书对于存储模块，主要就是描述的数据库的设计和优化，和我通常想到的文件系统的存储有点差异，其实数据库的底层还是放在文件系统上面的(原谅我又不禁想到了GitLab删库事件)，只不过随着数据量增加数据库文件的尺寸会不断的变大(在mysql中查找datadir的变量就可以看见数据文件的位置)。<br>　　互联网公司很多数据都塞在数据库中的，而且数据库这一模块的使用和优化经验也比较的丰富，更加有文章可做吧！</p>
<h1 id="一、文件存储">一、文件存储</h1><p>　　在绝大多数情况下磁盘一直都被诟病是拖慢整个系统的罪魁祸首，现在看来网络速度都会比磁盘要快得多。<br>　　如果是自己的服务器托管，建议尽可能的增加物理内存(云主机就算了，增加内存配置价格贼贵)，因为操作系统的缓存机制，较大的物理内存能减少IO操作，从而改善文件系统访问性能。<br>　　现在优化磁盘效率的方法除了操作系统和文件系统的参数调优之外，最直接的方法就是上SSD。想到前些年很多人对SSD还是持观望态度，时常会有SSD无故掉盘、数据无法恢复的情况，不过从这些年看来随着SSD技术的完善，各大厂商和数据中心都以SSD硬盘作为主机的卖点了，可见SSD还是接受住了现实的考验了(虽然现在随着工艺水平的提高和TLC的推广，据称SSD的寿命甚至还不如之前)，工业上通过SSD将业务性能提高几倍甚至几十倍的案例数见不鲜。其实，现实世界没有什么硬件是绝对可靠的，所谓的可靠性缺陷可以用软件来弥补。想当初我在2012年花了六百多大洋买了Crucial 64GB m-sata接口的固态硬盘，该硬盘作为系统盘现在仍然工作的杠杠地，所以增加内存和上固态硬盘是任何工作或者生产机器实现“垂直扩展“的最佳捷径了。对于固态硬盘如果是SATA3接口，其最高速率是6Gbps，而现在很多SSD的传输速度已经受限于该接口速率了，那么你可以考虑采用PCI-E接口的SSD存储来获取更高的性能了。<br>　　如果你对SSD的可靠性还是不放心的话，将SSD作为一个缓存介质而不做数据持久化的存储，也可以极大增加IOPS的性能指标，对随机化IO密集型的服务优化效果十分明显。虽然某些情况下SSD中的数据没有写回之前挂掉，还是会有丢数据的风险，但是相比之前安全系数已经高了好多。各个大厂针对此种情形的<a href="http://mogu.io/Facebook_flashcache-81" target="_blank" rel="external">解决方案</a>貌似很多啊！<br>　　RAID(独立冗余磁盘阵列)算是一个历史悠久但却极为有用的存储技术了，通过多个廉价独立的磁盘进行组合达到多种组合，将IO操作分散到多个物理磁盘上去，同时具有增加副本备份恢复的功能，让整个存储系统在可靠性、性能、成本之间做出权衡，RAID技术算是在存储最底层层次上所做出的备份和优化操作。RAID的类别可分为几十种，比如：RAID0是把数据切成块，分别存储在两个或者多个磁盘上，虽然读写性能都增加了N倍，但是安全性最低，任何一块磁盘挂掉数据就无法恢复了；RAID1是做的存储冗余镜像，读性能能增加N倍，但是写操作需要在多块磁盘上写出完整副本，性能可能会有所降低，而且磁盘空间利用率最低；RAID5和RAID6也是将数据分块，同时将可恢复的校验数据也作为一个数据块，他们依次分布在不同的磁盘上，这样在增加读写性能的同时，也允许少量磁盘坏掉后可以恢复原来的数据，工业上使用的较多；RAID10和RAID01算是RAID1和RAID0的合体也比较流行(两者镜像和条带操作的顺序不同)，虽然磁盘利用率低，但是大家觉得在可靠性和性能都能达到较好的效果(也不一定，工业上不都是认为3-5份的数据备份才是比较安全的嘛)。<a id="more"></a><br>　　让我印象最深刻的，还是当时在《<a href="https://book.douban.com/subject/24335672/" target="_blank" rel="external">淘宝技术这十年</a>》这本书里面看到的关于淘宝自建存储部分的章节。对于一般规模的公司觉得数据库的问题显得更为突出，而文件存储的需求只有特定业务类型公司才会比较急切。比如淘宝、腾讯、Facebook这类公司对于自身海量级别的数据，基本都不约而同地开发了适合自己的文件系统应对存储问题。<br>　　现在各大云厂商也提供了对象存储技术，除了在可靠性方面达到了99.9999999%的可用性，还提供水平弹性扩充、异地容灾、权限控制、线路优化、冷热存储、标准RESTful接口等各种特色服务，达到了开箱既用的便捷性。其实从硅谷的那些独角兽公司来说，基本初始阶段都使用Amazon这类成熟的云服务，等到自己的业务发展的比较规模后，再考虑自建数据中心节省成本，不过也有失败的案例(请原谅我在此又一次联想到了GitLab)。</p>
<h1 id="二、关系型数据库伸缩性">二、关系型数据库伸缩性</h1><p>　　数据库虽然是一个再常见不过的组件了，但是其中学问大的很。在保证可靠性的同时，其性能直接关系到业务的可用性，同时作为有状态的存储部件也不像较上层的业务容易扩展，更可怕的是如果开始设计不够充分或是没有好好规划，那将会是埋下的一个巨坑，对后续维护、扩展来说后患不已、贻害无穷。</p>
<h2 id="2-1_复制">2.1 复制</h2><p>　　MySQL自带同步机制，在一台主机作为主节点的时候，可以将主节点的修改同步到多台从节点。<br>　　对于数据库的修改命令，都应该在主节点上面操作，主服务器将这些修改操作记录到binlog日志文件中，一旦操作被记录到binlog日志中，那么主节点就可以向从节点发送了。MySQL的同步操作是异步的，所以主服务执行完更改后会立即返回给客户端响应，而不用等待从服务日志复制过程，从服务器可以在任意时刻连接到主服务器上，同时从服务器和主服务器可以快速进行增量更新，同时任何一个新的从服务器都可以连接到主服务器上面去。其好处有：<br>　　(1) 增加副本，那么只读操作就可以分布在多个从服务器上面，进而减轻主库的负载，而且这样的从服务器可以添加多个副本，不仅是水平的，在垂直的方向上海可以进行多层次的同步。<br>　　(2) 可以针对不同类型的查询使用不同的从数据库，比如将过慢的、对数据更新要求不高的查询放到单独的从数据库上面。因为数据库同步的异步性，从服务器的数据副本很可能不是最新的，所以对于数据更新需求强的读请求应该被路由到主库上面以确保得到最新的副本。<br>　　(3) 根据同步的异步性，可以在某个时间将从服务器停止同步，然后就可以对数据库进行完整的冷备份，而主库的对外服务不受影响。这种操作有时候是必须的，因为MySQL不支持从一个空数据库上启动一个从服务器，所以经常对数据库进行完整备份，可以提高下次增加或替换从服务器的速度。<br>　　(4) 如果主服务器失效，MySQL不支持自动失效转移的功能，即不能自动将一台从服务器提升为主服务器。这需要手动更改配置才能生效，而且由于同步的异步性，往往还需要检查将要提升为主服务器的binlog是否是最新的。</p>
<p>　　<strong>主-主同步拓扑</strong><br>　　针对主服务器挂掉，从服务器不能自动提升为主服务器的情况，有提出主-主同步的架构，两个主服务器是对等的角色，在一台挂掉的情况下应用程序可以快速切换到另外一台服务器进行正常工作。因为MySQL的binlog日志会记录执行的主机信息，所以在主-主同步拓扑的情况下，服务器A发送给服务器B的日志不会再由服务器B发送回服务器A，虽然理论上可以同时向两台服务器进行写入操作，但是为了降低数据冲突的风险，通常也都是向一条服务器进行写入。不仅仅是2，还可以有多个主服务器之间进行同步，总体来说就是在增加可用性的同时，数据的一致性和冲突的问题就越严重，所以现实环境下慎重使用。</p>
<p>　　<strong>复制的问题和挑战</strong><br>　　虽然使用副本的方法来进行伸缩的时候，只是对读操作进行了伸缩，其写入能力并没有得到改善(主要是处于数据一致性的考虑)，这对于读操作多的程序是一种很好的伸缩手段，可以大大增加客户端只读的并发读和QPS指标。增加副本对增加数据规模也没有任何帮助，任何一个主、从服务器都包含了完整的数据副本，其存储能力没有得到任何提升。<br>　　再次强调数据库同步是异步操作，正常情况下主-从的同步延时不会超过500ms，但是也有非正常情况。MySQL的复制是从服务器上单线程独立完成的，而主服务器上的更新操作是多线程并发执行的，很有可能从服务器跟不上主服务器的更新步骤，尤其当执行表结构更新等复杂的操作时，会阻塞之后所有的同步请求。解决这种问题的思路有：a.对数据敏感的请求直接发送到主服务器上面；b.尽量降低复制延迟，比如将服务器上更新表结构的操作binlog关闭，这类操作在从服务器上面手动执行，那么更新表结构和数据同步就可以并行完成了。<br>　　MySQL的复制还可能遇到其他问题导致数据不一致，比如使用生成随机数的功能(还有时间函数？)等，导致主服务器和从服务器的数据不一样，一旦主从服务器同步出现差错，后面的更新操作很可能会得到不一致的结果，这种问题就大发了！<br>　　现在想想，终于知道数据库专家的工资那么高了，数据库对于一个产品和公司的发展至关重要，而其相关技术专业性强，需要大量的经验和积累！</p>
<h2 id="2-2_数据分片">2.2 数据分片</h2><p>　　数据分片是将数据通过某种方式进行切分，以便将他们分散存储在多台服务器上，这也是我们通常听到的数据库分表分库，是除了功能分隔、增加副本之外的第三种伸缩性手段。这里说的数据库分片是针对数据库本身不支持分片，在应用层实现的数据分片。<br>　　数据分片首先需要选择分片键，通过分片键和某种映射算法可以快速定位路由对应记录在哪个服务器上，而不需要获取记录时候同所有的服务器进行通信，分片键和映射算法的选择，最好能让各个分片中的记录能够均匀分布。数据分区是突破数据量、并发链接数、服务器IO限制的有效手段。</p>
<p>　　<strong>数据分片的问题挑战</strong><br>　　应用层数据分片的主要假定分片键之间是彼此独立没有联系的，这也就制约了无法执行多个分片的联合查询，如果有这种需求只能在各个分片上执行对应操作后再在应用层进行合并后返回结果。而有些情况这种执行甚至是不可能的，比如按照用户ID分片的数据库，如果要执行销售量最多的产品ID，那甚至要对绝大多数记录进行整理，因为那些分布均匀看似普通的产品，可能累计值是最大的。还有，某些以年月为后缀的分表操作，跨月份查询也是个痛点。<br>　　数据分片还导致数据库的ACID特性难以得到满足。MySQL支持单个数据库的ACID，那么上面的例子对某个用户的所有数据执行更新就是可行的，但是如果针对某个产品进行更新就需要横跨多个数据库操作，MySQL是不支持分布式事务的。<br>　　数据分片还可能涉及到一致性HASH类似的问题，绝大多数情况下通过机器数目取模的方式进行定位的算法是极度不推荐的(不过也不是绝对的，比如可以采用逻辑数据库概念分布，然后将逻辑数据库映射到物理主机上面去)，因为一旦这样定位就意味着接下来没有第二次伸缩的可能性了。在定位算法中可以简单的在数据库或者配置文件中配置定位关系(比如用户ID在哪个区段定位到哪个数据库)，这样不仅不会影响到新增记录，而且数据迁移也十分方便：只需要将对应记录锁住，然后进行实际数据的迁移，接着更改他们的映射关系，最后解锁记录就完成了。映射关系的这种定位还可以增加灵活性，比如把某些活跃用户，或者优质用户映射到配置高、线路好的机器上面去，以实现差异化运营。<br>　　数据分片还有个问题就是生成唯一性键约束。在MySQL有两个变量：auto_increment_offset和auto_increment_increment，数据库在这两个变量上实现的自增的逻辑是：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">auto_increment_offset + N × auto_increment_increment</div></pre></td></tr></table></figure></p>
<p>　　所以分区的数据库通过设置这两个变量就可以产生不重复的唯一性键了；另外的一种方式就是借助外部第三方组件生成唯一性键值，比如Redis。这种唯一性键的特性还常常用在主-主同步的环境中。<br>　　下面这个图是把上面技术都用到的样子。<br><img src="/post_images/images/201702/ec6594c2.jpg" alt="mysql"></p>
<h2 id="2-3_其他">2.3 其他</h2><p>　　<strong>数据的冷热存储</strong><br>　　世界万事万物都是相互制约、相生相克的，在限制成本因素的时候数据存储的性能和容量是相互制约的，因此如果业务模型可以清晰的分离出冷热数据(比如交易类型的数据按照创建日期进行划分)，那么冷热数据分开处理也将是个存储上的优化。冷数据一般来说具有数据量大、通常只有简单的查询操作、对性能要求不高的特点，所以可以对低频数据分配性能、线路较差的机器负责(而且由于其访问和操作少，所以低配的机器响应也不一定会差)。现在的云计算厂商也提供不同特性的存储服务类型，自建数据中心的也可以借鉴之。</p>
<p>　　当然，上面的水平伸缩虽然在系统设计之初的时候就应当考虑，不过也不要忽视各个独立服务器的性能优化，否则就有一种舍本取末的感觉，毕竟数据分区会在运维、业务处理上带来很多的麻烦，常常感觉有那么一种不得已而为之。在独立服务器本身的性能没有被压榨到极限的时候，你集群的规模可能会成为你的谈资，但是你为此所付出的确是白花花的银子。<br>　　所以，一方面还是要对数据库单表、单库优化做到心中有数，比如索引、数据库引擎、缓存；而对于开发人员来说SQL语句的使用也要养成良好的习惯，多看看数据库的慢查询日志再对应做出优化，不要让宝贵的资源被自己的不成熟代码白白吞噬了。建议查看下面两篇文章：<br>　　<a href="https://segmentfault.com/a/1190000006158186" target="_blank" rel="external">《MySQL大表优化方案》</a><br>　　<a href="https://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="external">《Top 20+ MySQL Best Practices》</a></p>
<h1 id="三、NoSQL数据库伸缩性">三、NoSQL数据库伸缩性</h1><p>　　关于NoSQL这里就不多说了，因为没有支持SQL的存储都把自己叫做NoSQL，概念显得比较宽泛和模糊，就像是要有意要和SQL传统数据库划清界限以凸显自己似的。<br>　　觉得大家讲到的NoSQL很多时候都是KV键值类存储(比如Amazon Dynamo)，这类存储设计之初就想到高性能和灵活的扩展性，因此两者最大的差异性就体现在可扩展性上。其实两者对比来说也没有绝对的优劣，毕竟SQL是标准性的，这么悠久的历史大家玩起来更有经验，各种优化和扩展方案也十分丰富；NoSQL是伴随着大数据成长起来的一个新概念，因为其横向扩展性优秀，对于数据量大、数据类型简单的存储需求乃是如鱼得水，因此才得以倍受追捧吧。还是那句话，符合业务需求的技术才是好技术！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://mogu.io/Facebook_flashcache-81" target="_blank" rel="external">Facebook flashcache介绍与使用</a></li>
<li><a href="https://book.douban.com/subject/24335672/" target="_blank" rel="external">淘宝技术这十年</a></li>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="http://www.d1net.com/datacenter/tech/256374.html" target="_blank" rel="external">SQL vs Nosql ：优劣大对比</a></li>
<li><a href="https://segmentfault.com/a/1190000006158186" target="_blank" rel="external">MySQL大表优化方案</a></li>
<li><a href="https://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="external">Top 20+ MySQL Best Practices</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[后台开发那些常用技术再次小结（二）：Web服务层]]></title>
      <url>https://taozj.org/201702/study-note-of-scalable-backend-(2)-web-service.html</url>
      <content type="html"><![CDATA[<p>　　Web服务部分应当算是整个服务端开发中最重要、最复杂、同时也最具可玩性的部分了。业务逻辑的处理主要分布在Web服务层，这样一方面可以让其上层展示层不必关心业务逻辑，只专心负责展示和用户输入部分(也让其具有强大的伸缩性)，而Web服务层本身也可以通过功能分割(增加副本、功能分割和数据分片是实现伸缩性的三大利器)，以及单个服务自身的伸缩设计，最终构建一个功能强大的Web服务层。<br>　　Web服务层采用一定的设计模式为上层提供调用接口，同时这些年来，跟随者移动互联网和与计算的大潮，各大厂商也喜欢将自己的服务通过接口的方式免费或者收费的形式提供给第三方使用，这也就是所谓的Web服务和前端应用平行部署的现象，在这种环境下的服务接口设计就显得会比以往更加的重要，当时那种裸socket之上自定义数据帧的时代显然是跟不上了。尤其这些年来，关于RESTful接口设计风格可谓是如日中天，无论是Google、Amazon这些互联网大佬，还是几个人组成的互联网创业公司，都号称自己开放的服务是符合RESTful风格的接口，但是正如我在V2ex论坛上看到大家所争论(《 <a href="https://www.v2ex.com/t/340607" target="_blank" rel="external">RESTful 有用吗？ HTTP 有 GET POST 就足够了？</a>》)的一样：绝对纯正的RESTful风格接口的设计和实现在当下是不可能实现的，大家开放出来的接口要么就是根据实践情况有所妥协，要么就是封装了一个简易外壳的“伪RESTful接口”而已。<br>　　这里看到一本《<a href="https://book.douban.com/subject/25786076/" target="_blank" rel="external">服务设计模式</a>》，虽然后面的内容看的不是很明白，但是前面对于服务设计的总结还是不错的，在此进行归纳总结！归咎来说，Web服务主要是为集成不同的系统提供相应地方法，并通过HTTP来输出可重用业务功能，他们或者将HTTP作为一种简单的信息传输工具来承载数据传输(比如SOAP/WSDL服务)，或者将HTTP作为一种完整的应用控制协议，将HTTP协议的内容定义服务的各种行为和语义(RESTful服务)，前者被定义为以功能为中心的服务，后者被定义为以资源为中心的服务。<br>　　<strong>以功能为中心的服务</strong>：该种风格的服务是指能够调用远程机器上的功能或者对象方法，而无需知道这些功能或者对象是如果实现的，因此这种框架技术需要处理跨编程语言、跨CPU构架、跨运行时环境的问题，同时对调用参数的约定、变量转换、错误处理还必须进行明确的规范。以功能为中心的服务现在基本是SOAP一枝独秀，其基本使用XML作为服务描述和消息编码方式，通过HTTP在客户端和服务端之间传递请求和响应。<a id="more"></a><br>　　以功能为中心的服务基本不会用在动态语言中，因为这些动态语言和SOAP服务集成会比较困难，基本都是Java、C/C++这类静态语言。此外，由于SOAP请求是通过XML进行发送的，请求参数和方法名都通过XML封装了，URL里面没有远程调用需要的全部信息，所以对于HTTP层面基于URL的缓存就没法实现，使得伸缩性变差。<br>　　<strong>以资源为中心的服务</strong>：以资源为中心的服务作为新一代的服务设计构架，已经成为Web应用集成事实上的标准，这种设计就是以资源为中心代表一类对象，在对象上只能执行有限的操作(比如创建、删除、更新、获取资源等)，将和资源(对象)之间的交互标准化了。跟上面对应，利用HTTP缓存是可伸缩RESTful Web服务的一项重要技术，当设计的方法严格准守HTTP方法语义约束的生活，重要的GET方法的响应就应该是可缓存的，如果确保所有GET方法是只读且不会导致状态变化和数据更新，那么就可以安全的缓存该HTTP GET请求。当然，具体的业务类型可能也不允许这种形式的缓存。</p>
<h1 id="一、Web服务API设计风格">一、Web服务API设计风格</h1><p>　　Web服务API设计风格包含：RPC API、消息API、资源API三种类型。</p>
<h2 id="1-1_RPC_API">1.1 RPC API</h2><p>　　RPC API的核心概念是远程过程调用的思想，通过RPC客户端首先向远程服务器发进程发送消息，再阻塞自己，等待接收响应，请求的消息可以标识要执行的过程，同时也包括一组固定的参数映射作为远程过程的参数；远程服务收到消息时候会进行检查，并根据消息中的过程名称及其参数调用相关过程(服务)；如果需要，服务器将对应的响应结果返回给客户端，客户端提取结果并继续执行。<br>　　这是我们所最熟悉的服务设计风格，因为其历史悠久并被广泛使用，相对容易理解而且使用简单(有大量现成的服务框架可用)。这种风格API通常使用XML定义数据类型和消息，使用WSDL(Web Service Description Language)进行服务描述，用WS-Policy/WS-Security等规范来定义对客户端的授权、加密等规则；当然也可以使用非XML的方法，比如JSON-RPC这类的规范来实现。<br>　　<strong>考虑因素</strong><br>　　(1) 因为RPC和本地方法很相像，所以通常会像声明本地方法签名的方式来创建服务签名，这样的话客户端必须严格按照参数的顺序、类型来发送参数，导致使用不灵活。所以通常建议将服务签名设计为单个参数类型，或者多个可选参数类型的服务。<br>　　(2) RPC API的特点是位置透明性，服务的真实位置应该是完全隐藏的，即客户端开发者调用本地过程和调用远程过程的代码都应该大致相同，这样服务就可以按照需要进行自由移动，然后通过其他方法通知客户端服务的具体位置，比如存储在配置文件或者数据库中供客户端查询。<br>　　(3) 除了默认的请求-响应模式，RPC API还可以使用请求-确认的交互模式。这种情况下服务端收到请求后会将消息转发到一个异步后台进程，并向客户端返回一个简单确认。通常消息首先存储在消息队列或者固化到数据库中，通过这种消息接收和消息处理时间分离，系统就可以更好的处理负荷峰值，控制消息处理速率。<br>　　(4) 使用RPC API的客户端在发送消息后，也可以不需要阻塞，而采用异步响应处理器的方式提高效率。<br>　　(5) RPC API通常使用XML或者JSON进行编码，也可以采用二进制数据编码，从而压缩网络传输、节省带宽、减少延迟，不过副作用就是二进制编码会增加客户端、服务器端的计算量。</p>
<h2 id="1-2_消息API">1.2 消息API</h2><p>　　RPC API的服务端和客户端是强耦合的，无论调用名、调用签名、数据结构发生变化，都需要两方面的协调完成。<br>　　基于消息API(文档API)的服务，会在一个给定的URI上收到一个或者多个自描述的消息，消息体包含主要的数据，同时还可以附加一些标头用于身份验证、请求有效截止日期等信息。消息API通常手法表转化的消息格式(比如SOAP)。当客户端向一个指定URI发送消息后，客户端可以选择阻塞来等待响应，当消息到达服务器时候Web服务执行反序列化处理，检查消息并选择适当的处理器来处理请求，通过将客户端和真正的处理器(远程过程)进行隔离，Web服务提供了一个间接层的作用。<br>　　这种模式意在情调是基于消息设计的，API提供一个接收断点，而Web服务则扮演者分发器的角色，客户端的消息通常包括命令消息、事件消息、文档消息类型。<br>　　<strong>考虑因素</strong><br>　　(1) 消息API通常使用WSDL描述符，依赖框架辅助生成客户端服务连接器代码。具体的消息再通过某种特定的传输协议(比如HTTP)进行绑定，并在指定URI上输出其内容。<br>　　(2) 下次API的服务通常采用请求-确认模式，而不是请求-响应模式。</p>
<h2 id="1-3_资源API">1.3 资源API</h2><p>　　这种方式是对所有资源(比如文本文件、媒体文件、数据库表中的数据、业务过程等)分配一个URI，使用HTTP作为一种完整的应用协议以定义标准的服务行为，采用标准化的媒体类型和可能获得的状态码来交换信息。这样资源API的服务通过使用请求的URI、客户端发起的HTTP方法、一同提交来的请求信息及媒体类型等既可以判断客户端的意图，可以将这个规则表达为表述性状态转移(Representational State Transfer, REST)原则，因为客户端和服务端之间交换消息的生活，资源的状态发生了转变。<br>　　资源API中的URI是一个逻辑意义上的地址，通过向这个URI发送请求就可以调用对应服务或获得相应地资源，而实际的资源和URI可能存在一对多的关系，但是一个URI应该只能用于引用一个逻辑资源。资源API通过如下HTTP标准方法来访问资源：</p>
<ul>
<li>PUT：用于创建或者更新资源；</li>
<li>GET：用于检索资源的表述；</li>
<li>DELETEL：用于删除一个资源；</li>
<li>POST：该行为多样性，作为以上相对而言非标准行为，同时当服务器禁用了PUT、DELETE或者防火墙阻塞了这两种方法时候，可以用POST作为一种替代方法(隧道化执行)。很多REST的倡导者不支持使用POST隧道化的行为，因为这模糊了请求的目的，而且实现上也不利于对结果进行缓存；</li>
<li>OPTIONS：用于发现目标URI所支持的HTTP方法；</li>
<li>HEAD：用于获取URI上交换的与媒体类型有关的元数据，类似于GET只是不返回资源的表述。</li>
</ul>
<p>　　上面最常用的PUT、GET、DELETE基本可以映射为CURD(Create、Update、Retrieve、Delete)操作，而POST可以用于其他无法映射的行为。由于HTTP协议将这些行为预先定义好了，所以客户端不必学习特殊的API，而只需要知道每个URI上面可以使用的方法，以及每种方法使用时机就可以了，服务开发人员会按照标准来实现对应的功能。<br>　　HTTP规范定义了那些方法是安全的(Safe)和幂等(Idempotent)的，如果操作不会产生副作用就被认为是安全的，其不会触发创建、更新、删除操作，GET、HEAD、OPTIONS方法可以实现为安全的操作；幂等性指的无论调用同一个过程多少次，只要参数相同，那么就应该返回相同的结果(出错、超时等情况不考虑)，GET、HEAD、PUT、DELETE、OPTIONS都是幂等的，但是POST不是幂等的。POST方法也可以实现为幂等的，比如在客户端请求中插入一个唯一的标识符，服务在执行它的时候进行逻辑检查，如果已经被处理则拒绝这个请求。<br>　　资源URI会利用标准HTTP状态码，向客户端提供处理结果，通常可以返回最小量的数据表示结果因而优化了网络利用率。不过有时候响应码也会有含糊不清的意义，这也是RESTful在实现中缺陷之所在，否则那些号称符合RESTful风格的开放接口都不会另外列出一大串HTTP错误码对应的实际错误描述了。<br>　　<strong>考虑因素</strong><br>　　(1) 使用不同类型的客户端，这时候资源API是最好的选择，因为HTTP协议的广泛流行使得资源API可以得到最广泛的支持。<br>　　(2) 可寻址能力，因为资源API的设计上，URI通常是有意义的信息(比如账号ID)，那么这些信息很可能被恶意挖掘和使用。可以使用UUID映射将这些信息进行隐藏，或者采用身份验证和逻辑授权机制，确认调用者身份、限制每个调用者可执行的操作，以起到对应保护的作用。<br>　　(3) 客户端一般没有代码自动生成能力，即无法自动产生服务的客户端连接器，客户端必须采用标准的HTTP进行请求。<br>　　(4) 面向资源的服务通常使用请求-响应模式，但也可以使用请求-确认交互模式。服务可以将请求转发到异步后台进程，而向客户端立即返回一个确认消息(HTTP状态202)。<br>　　(5) 资源API通常会为同一个逻辑资源提供多种表现形式，不必为每种表现形式使用不同的URI，这通常使用媒体类型协商来满足客户端的偏好的。<br>　　(6) 资源API风格可以天生有效利用针对HTTP专门设计的缓存技术(比如反向代理缓存)，以减小队原始服务器的压力，资源API尤其适合读操作较多的场景。</p>
<h1 id="二、客户端和服务端之间的交互风格">二、客户端和服务端之间的交互风格</h1><p>　　客户端和Web服务之间基本通信模式是点对点的链接，在连接建立后通常在多次交换数据中采用同一个连接，这样有助于最小化建立和释放连接所带来的延迟。但是在实际上，网络流量在传输的过程中总要通过各种中介，比如防火墙、反向代理等，这些中介一方面可以实现安全功能，过滤或者阻止某些请求，实现负载均衡及周边缓存的功能。</p>
<h2 id="2-1_请求-响应模式">2.1 请求-响应模式</h2><p>　　该模式下客户端发给服务端的请求，会被立即执行处理，并通过同一个客户端链接返回处理结果，是客户端和服务端最常见、最易于理解的交互模式。这种客户端和服务端之间的交互是同步的，会按照严格的顺序发生，通常客户端提交请求后不能继续做其他的操作，直到请求的服务提供了响应，所以要求这种服务没有或者尽小的延迟。<br>　　<strong>考虑因素</strong><br>　　(1) 请求-响应模式是高时间耦合度的交互，因为客户端的请求都需要立即得到处理，所以大量并发的请求可能会耗尽系统的处理能力。服务架构师必须理解服务的典型工作负载，并依据期望的负载来调整服务器、数据库、网络资源的容量，包括“垂直扩展”和“水平扩展”提高性能。通过将服务有请求-响应模式修改为请求-确认-轮训或者请求-确认-回调的模式，在时间上将接收请求、处理请求、发送响应进行分离，前者让客户端空闲时候轮训响应，后者要求客户端提供自己的服务以便接收回调消息，可以缓解服务器峰值压力的风险，但是实现和调试的复杂度较高。<br>　　(2) 默认情况下，请求-响应服务的客户端会阻塞以等待响应，通过异步响应处理器可以改善客户端的性能。<br>　　(3) 请求-响应在客户端和服务端之间可以插入中介者，比如代理服务器可以缓存查询结果，防火墙可以阻止或者过滤网络流量，检查证书等功能。</p>
<h2 id="2-2_请求-确认模式">2.2 请求-确认模式</h2><p>　　请求-确认模式是可以使Web服务免受负载峰值影响，虽然通过异步响应处理器器可以缓解这个问题，但是在总体处理能力有限的情况下，如果请求的处理时间过长，那么客户端连接就会超时，这种情况通常会导致丢失响应。<br>　　传统上可以采用网络可寻址的消息队列技术(面向消息的中间件)，这样无论目标系统的运行状况如何，客户端都可以随时将消息发送给远程系统，即使无法连接远程队列基础构架也可以将消息先保存在本地，然后不断尝试发送直至成功。消息到达远程队列后会慢慢发送到目标系统，中间可以通过节流或控制处理请求速率保护远程系统。<br>　　简单的队列具有发射后不管的特点，服务会接收请求、处理请求，但是不会发送响应，客户端无法感知服务是否被接收、是否被处理、处理的结果如何。解决的方法是对请求生成特定的标识符或者URI以作为唯一性的键值，将来所有参与会话的各方都可以引用这个键值，以形成一个特定请求的上下文处理逻辑。<br>　　<strong>考虑因素</strong><br>　　请求-确认模式的难点是提供更新或者最终处理结果，通常实现的方法有：<br>　　(1) 轮训：该模式实现简单，客户端定期轮训另外一个Web服务以获取更新信息或者最终处理结果。要实现这个功能客户端必须先得到一些轮训的先决条件，资源API通常返回客户端轮序的URI地址，而RPC API和消息API通常提供查询的标识符。<br>　　请求-确认-轮序的缺点是客户端效率不高，如果轮训频率不高那么得到更新、处理结果就会有明显的延时滞后，如果轮序太过频繁也会对Web服务器带来负载，浪费网络流量。<br>　　(2) 回调和转发：这种模式下客户端不会轮训另外一个服务获取结果，而由请求处理器主动将信息推送回客户端或者其他参与者(请求-确认-转发模式)，此时客户端和服务器就互相交换角色了。这种模式下Web服务端必须获得一个回调服务列表，这可以由资源API客户端在请求中包含回调URI，或者RPC API和消息API通过WS-Addressing标识头提供，也可以是通过某种标识在数据库中查询回调信息。<br>　　这种模式实现起来比轮训更具挑战性，但是如果原始客户端不能或者不愿意提供一个可以公开寻址的回调服务，那么该种方式就不能使用。</p>
<h2 id="2-3_媒体类型协商模式">2.3 媒体类型协商模式</h2><p>　　比如在使用资源API服务的不同客户端通常可以有不同的媒体偏好，比如有的喜欢XML而有的客户端好JSON。指明客户端偏好的方法很多，比如可以将媒体类型作为最终URI的一部分或者文件资源的扩展名，这种方式简单直观而且可以被浏览器等客户端支持，但是：客户端必须知道如何对每个资源构造正确的URI，显然增加了客户端和服务端的耦合和复杂度。<br>　　解决的最好方法是使用标准HTTP协议的进行内容协商，客户端可以在HTTP请求头中指定一种或者多种媒体类型首选项，那么服务端可以参考按照预设的格式生成响应。实现的方法有：<br>　　(1) 服务器驱动的协商是最常用的一种协商方式，客户端通过Accept Request标头来提供自己的媒体偏好，可以一次提供多个偏好，也可以指明媒体类型的优先级，没有提供的话服务端可以默认选择一个，常见的媒体类型比如：application/xml、application/json、text/plain、text/html等，这些流行的类型会被自动序列化反序列化，而自定义类型可以需要自己编写对应的序列化器了。<br>　　(2) 客户端驱动的协商方式中，在客户端在发送请求的时候还是通过HTTP的Accept Request标头来携带它的媒体偏好，Web服务端收到请求后在响应中提供一组客户端可以考虑使用的URI，然后客户端根据这个响应来选择特定的URI发起真正的资源请求。<br>　　<strong>考虑因素</strong><br>　　(1) 服务器与客户端驱动的协商中，当服务拥有者期望为客户端提供选择，同时又需要维持对类型选择过程的控制时候，采用服务器驱动的协商比较合适，这有助于简化客户端逻辑，减少往返协商的流量，只是此时如果客户端没有提供明确偏好时，服务器的响应就可能不合适客户端；当期望客户端可以更多控制接收到的类型可以选择客户端驱动的协商，缺点是客户端必须发起两次请求-响应的数据交换，依次用于查询服务地址列表，另一次用于获得最终响应。<br>　　两种方法比较而言，服务端驱动协商因为是同一个URI返回多种类型的资源，不利于中介缓存，而客户端驱动的协商可以最好的利用中介缓存，因为URI和特定的媒体资源存在一对一的关系。<br>　　(2) 请求处理器中的代码应该可能会被复制，这时候应该考虑使用设计模式中的命令模式，可以降低复制代码维护的痛点。</p>
<h2 id="2-4_链接服务">2.4 链接服务</h2><p>　　通过Web服务可以将其他的服务信息输出给客户端，通常只需要发布几个根Web服务的地址作为最初的访问点，此后在每个响应中包含相关服务的地址信息，客户端解析响应之后就可以发现后续服务URI，那么客户端根据服务列表有选择的使用其他服务了。该方式的优点有：<br>　　(1) 响应可以只是提供一组对最近请求有上下文意义的服务地址，对客户端完成正确的工作流转换具有指导意义；<br>　　(2) 由于服务的地址是服务端返回的，可以确保这些地址是有效的，如果依赖客户端构造服务地址通常会出现各种各样的问题；<br>　　(3) 增加、减少、修改服务变得更加容易，只需要在响应中做出相应修改就可以了，客户端需要修改识别新的服务，对于旧的不可用服务服务端返回404就可以了；<br>　　<strong>考虑因素</strong><br>　　(1) 这种模式主要同上述的资源API一起使用；<br>　　(2) 这种服务容易遭受中间人攻击，因为中间人可以截获响应或者构造响应指向一个恶意服务。通常需要采用TLS安全传输，也可以采用数字签名保护消息不被篡改。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="https://book.douban.com/subject/25786076/" target="_blank" rel="external">服务设计模式</a></li>
<li><a href="http://www.drdobbs.com/web-development/restful-web-services-a-tutorial/240169069" target="_blank" rel="external">RESTful Web Services: A Tutorial</a></li>
<li><a href="http://docs.aws.amazon.com/AmazonS3/latest/API/Welcome.html" target="_blank" rel="external">Amazon S3 REST API Introduction</a></li>
<li><a href="http://blog.igevin.info/posts/restful-architecture-in-general/" target="_blank" rel="external">RESTful 架构风格概述</a></li>
<li><a href="http://blog.igevin.info/posts/restful-api-get-started-to-write/" target="_blank" rel="external">RESTful API 编写指南</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[后台开发那些常用技术再次小结（一）：前端部分]]></title>
      <url>https://taozj.org/201702/study-note-of-scalable-backend-(1)-front.html</url>
      <content type="html"><![CDATA[<p>　　回家的路途上看了一下《<a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a>》这本书，该书是使用开发者头条积分兑换的第二本书，而且出版的时间还比较新。看了之后感觉还是比较有收的，至少感觉有了这个视野之后，再观网上那些所谓的高并发、高性能、高扩展性的网站架构，会有一种豁然开朗的感觉。其实怎么说呢，现在强调的高性能、可扩展系统的各套花样本质上也就那么几种模式，大家都是在实际项目中根据自身的业务规模、业务特点做相应的选型、裁剪、适配、调优而已。<br>　　想想其实也不难理解，毕竟我们已经进入后互联网时代这么久了，大规模互联网系统开发中的各种问题、各种坑点想必大家都遇到过了，解决方案也十分成熟可靠，甚至各大云平台都把你所考虑的东西都帮你做完了，你只需要专注自己的业务开发和运维就可以了！或许真如之前别人所对我所说：这些互联网时代听起来高大上的技术，如果不是作为专家深入研究，而是仅仅当做一个现成的组件使用，那么你所“了解”的这些技术，充其量就是跟别人之间多出来的那几分谈资而已，任何一个程序员在对应的环境下都可以快速掌握的。说说也是，毕竟上面说的那本书俺一天不到的时间就看完了，这么看来，感觉操作系统、数据结构和算法、计算机网络、软件调试和优化等看似不起眼的东西，此时便显得更为地重要！<br>　　不过话又说回来，上面的意思并不是说这类知识不重要，即使你不去做他，但是对他的全局观的理解和把控也会影响到自身的业务设计和实现。于是后面将根据书中内容的主线，总体描述现在互联网系统的开发过程中，为了达到构建高性能、可扩展的架构，从前端层、Web应用层、Web服务层、数据存储层部分，配合缓存、异步这些组件进行设计和实现的相关事项，同时配合其他文献分类别进行整理归纳和扩充，算是做一个自我普及的作用吧。<br><img src="/post_images/images/201702/ae1f1917.jpg" alt="struct"><br><a id="more"></a><br>　　首先开篇是与前端相关的。说实话对上面列出的那些内容，后端部分个人还是在不同程度上比较了解和清楚的，但是前端部分确实接触不多，而且前端本身也有流行的开发模式和开发框架，在此就不再深入挖掘了，此处就关于一些零碎的知识点进行总结吧。<br>　　一般来说，前端部分作为应用栈上的最顶层，包含了直接与用户交互的一些组件，他们不应当包含业务逻辑，可以最大限度的使用CDN、缓存进行优化；在这之下通常还会有Web应用层，他们通常用轻量级的动态语言和框架实现最小的业务逻辑，主要用于帮助生成用户界面，而具体业务逻辑应该放置到下面的Web服务层完成，这一方面是因为该部分通常变更会比较频繁，而且最好设计成无状态的，以方便实现弹性伸缩。</p>
<h1 id="一、状态管理">一、状态管理</h1><p>　　HTTP最早是被设计成无状态、请求-应答模型的协议用于在客户端和服务端传送数据的，这种模式在网站上用于进行文字、图片资源的传输是合适的，在现代互联网的开发中，越来越多的应用场景也都基于HTTP协议进行传输，主要是因为HTTP具有广泛的跨平台、跨网络、多客户端支持，同时传输中的各项细节也都在协议中进行规范明确了，否则如果直接在socket层面上面进行业务开发，就需要处理太多细节方面的东西，而如果重新设计一套协议也不是一件容易的事情。<br>　　可是，HTTP设计之初主要是用于文件资源类传输的，显然不适合当下的各种应用数据的传输，其中最主要的因素是HTTP是无状态(Stateless)模式的，各个请求之间都相互独立，服务器不会保留相关状态信息，所以每个请求都会被认为是一个新的请求；但是现在应用程序的数据大多都是有状态(Stateful)模式，需要维护一种状态来进行相关的业务处理。为此，解决这个问题的方案有:<br>　　<strong>将会话状态存储在cookie中</strong><br>　　Session和Cookie机制是HTTP用于维持状态的主流方式。HTTP的协议是无状态的，所以必须在其之上维护形成一个逻辑上的“有状态”连接，当用户第一次连接到服务端的时候，就会建立一个相关的会话，在会话中可以存储或简单、会复杂的任意的信息。通过Session，服务器就可以识别同一个用户的各个请求，并为这些请求创建一个复杂持久的上下文，以便实现诸如购物车、wizard-style配置等有状态的应用效果了，虽然通信的各个HTTP请求严格上说仍然是无状态的。不过会话有一个时效性的问题，服务端不可能永远维护一个不活跃的会话，否则会严重影响服务端的并发量和处理能力。<br>　　Cookie可以用于处理上面的问题。Cookie是服务端产生的(通过返回头中使用Set-Cookie:添加)，可以被浏览器保存，并在之后的所有HTTP请求中浏览器都会自动发送给服务端(通过Cookie头)的数据。cookie是和域名相关联的，在浏览器向服务端传输数据的时候回自动将对应域名中的cookie数据放入HTTP Header中传输给服务端，所以服务端的开发者可以方便的提取这些cookie数据。在了解Cookied额机制后，几乎现在所有的现代服务端程序都会对新连接生成”session ID”字段并将其作为cookie内容传递给浏览器，浏览器保存了该内容之后，及时该会话结束了，下次重连的时候也可以在服务端查找到对应的session ID，从而实现一种有状态的效果。<br>　　在业务开发过程中，服务端就必须要检查每个请求，看其是否具有会话标识；如果存在会话标识，还必须根据业务检查该会话是否过期；在实际的使用中，还需要根据该会话ID调取其管理的相关资源。如果需要存储的数据比较的少，那么所有的状态数据完全都可以放置在Cookie当中，而如果会话的数据比较的多，通常会话数据需要额外存储在外部存储系统中。<br>　　<strong>将会话数据存储在外部数据存储系统中</strong><br>　　这种情况更为的常见，因为cookie会在每次请求中传输，如果保存的东西太多显然降低了通信的效率和安全性。该情况下cookie中就只需要保存sessionID、会话令牌等简短的数据当做索引，真正会话数据不需要在请求响应之间传递，而是直接从外部存储(比如内存、数据库、文件系统等)直接加载就可以了，常用的外部存储比如Memcached、Redis、DynamoDB，都是根据key-value读写低延迟的优化存储服务。<br>　　<strong>ASP的VIEWSTATE机制</strong><br>　　这个我还不太好归类，主要是之前爬虫的时候，在一些基于Windows/ASP构建的网站中<a href="https://github.com/taozhijiang/dust_repos/blob/master/crawl_laws/chongqing/chongqing_request_law.py" target="_blank" rel="external">遇到</a>的。在第一次使用GET方式请求网站的时候，在返回的页面中会嵌入一些’VIEWSTATE’的字段，后面的页面都是使用POST方法请求的，每次得到的页面都会更新’VIEWSTATE’字段，而且在下一个页面的请求中需要添加这个不断变化的’VIEWSTATE’。<br>　　既然大家都是做基于Linux平台下的开发的，相比这个VIEWSTATE机制遇到的也比较少，其实还真不知道巨硬公司的这个字段是干吗用的。</p>
<p>　　虽然在业务上(而不是协议上)实现有状态逻辑显得比较麻烦，但这反而也是HTTP的优势所在，因为在无状态的情况下客户端可以访问任意事例而不用担心结果会有差异，因此这样的应用具备了强大的可伸缩性。</p>
<h1 id="二、智能DNS、CDN和负载均衡">二、智能DNS、CDN和负载均衡</h1><p>　　前端优化主要有智能DNS、CDN和负载均衡扩充的方式。</p>
<h2 id="2-1_智能DNS和CDN">2.1 智能DNS和CDN</h2><p>　　在国内，电信行业的历史渊源造就了对骨干网南电信、北联通、其他运营商忽略的格局，虽然电信和联通的网络高速互联不会有什么技术上的问题，但实际的效果确实互访的延时很大，于是在买虚拟主机和服务器的时候，双线网络都会作为一个卖点列出来。大家会发现当访问一些老网站、某些下载资源的网站时候，那时候智能DNS解析还没有普及开来，所以网站会给出电信、联通的链接让你去点击，以便让用户有较好的网络体验，不过以我们现在的情商看来，这种让用户手动选择线路的体验真是太差了。<br>　　智能DNS就是把上面手动选择的操作智能化，因为域名的访问最终都是转化成IP地址才能直接使用的，所以智能DNS就会根据用户所在的网络返回适宜的IP地址。因为朋友的信任，自己手头有好几天服务器，前段时间还折腾过<a href="https://www.cloudxns.net/" target="_blank" rel="external">cloudxns</a>的智能解析的，可以细分到各个省份的各个线路解析成什么IP地址，不过国内网络环境复杂，到底某个地区的某个线路访问自己的某个主机比较快，测试起来比较麻烦，最后也作罢了。在书中提的较多的是GeoDNS，其号称是一种基于客户地理位置进行域名解析的DNS服务，其实按照上面的运维方式手动设置各个地区各个线路的DNS记录的话会累趴，如果能做到给出所有目的主机IP列表，服务商自动给予最优化将会是多么美好的事情！书中还提到了Amazon的Route 53解析服务，其解析的结果不是基于地理位置，而是根据响应延迟来决断的，可见这算是非常先进的智能<br>DNS解析了。<br>　　现在的机房也讲求BGP(边界网关协议)，其实际是实现线路的智能路由的功能，其实现成本较高。不过这都是机房和运营商相互合作的，对于我们普通用户可玩性不大。<br>　　CDN从本质上来说就是智能DNS+缓存结合的产物。CDN对网站的优化效果十分显著，当访问静态内容的时候不仅可以加快用户的响应时间，而且可以大大减少后端服务器的压力和带宽/流量消耗(CDN提供商的带宽费用肯定比自己服务器带宽费用便宜很多)，一定程度上还能起到抗攻击的效果。不过CDN的只对静态资源加速效果较好，动态内容很多还是需要访问原始服务器才可以，实践的时候可以根据业务特点将某些动态资源静态化，以此可以享受CDN带来的好处。</p>
<h2 id="2-2_负载均衡">2.2 负载均衡</h2><p>　　通过DNS轮训机制本身就自带负载均衡的效果，比如我们每次PING百度的IP地址都不一样。不过基于DNS的负载均衡问题比较多，比如DNS是一个分布式的系统，在本地主机到各层次的服务器都有缓存效应，这使得服务器的管理和变更时效性很差，所以实践中使用的较少。负载均衡还可以通过硬件实现，这里复杂均衡器性能较好，但是专业性太强，而且售价很高。<br>　　其实，现在各大云计算厂商也提供负载均衡的服务，我查阅了<a href="https://www.qcloud.com/product/clb?idx=2" target="_blank" rel="external">qcloud的CLB服务</a>，其实很多都跟Nginx的负载均衡功能类似，说明负载均衡已经是一项十分成熟的技术了。负载均衡现在比较有意思的东西是和弹性按需计算相结合，比如CLB可以根据业务的负载进行自动的横向扩展，自动的创建和释放CVM实例，而Amazon的ELB也有这样的功能，可以自动增加和删除EC2运算实例。这种方式的确可以自动优化资源利用从而节省成本，但是这样的弹性运算实例不能再上面存储任何数据，至少保证数据是一次性的(比如缓存)，而且删除和销毁实例的时候要保证运算实例是真正空闲的才可以；其次这种弹性机制存在着“预热”的问题，对于网站流量爆发的情况，自动伸缩往往不能立刻响应，从而影响服务的可用性。<br>　　一般的用户使用的都是软件负载均衡，其中最著名的就是Nginx和HAProxy两个开源软件，他们都支持三层负载均衡和七层负载均衡，HAProxy本人没有接触过所以不太了解，Nginx本身就是一个HTTP服务器，所以可以预见对HTTP的七层代理支持会比较完善。负载均衡通常都能实现很大的并发量和很快的数据包处理，但是单机也会有性能极限的时候，水平扩展负载均衡通常采用DNS轮训的方式，因为负载均衡器不会做业务处理，通常服务比较稳定，同时也不会频繁的增加删除负载均衡器实例，而且负载均衡器本身也是无状态的，可以进行随意互换的。<br>　　<strong>负载均衡的好处</strong><br>　　a. 安全性<br>　　负载均衡器像是个卫士一样挡在服务的最前线，所有的流量都会先经过他们，所以可以隐藏后端服务器的IP地址、网络和服务结构等信息。同时负载均衡本身还可以设置各种过滤和规则，对用户的访问进行控制，以对后端整个服务起到保护作用。<br>　　b. 服务器维护<br>　　无论是维护原因还是失效的原因，服务器都可以从负载均衡的转发对象中方便的移除。负载均衡器本身就有健康度检查机制，当请求失败率达到一定程度就认定该服务器失效并停止流量转发；同时正常工作的服务器可以配置负载均衡让其不在接收新的请求，正在服务的连接结束后服务器就可以安全下线了，对于不间断服务滚动更新等各项需求都很容易实现。<br>　　c. 无缝伸缩处理能力：<br>　　和上面说的一样，负载均衡器结合弹性计算，可以优化资源的利用率和节省成本。<br>　　d. 高效的资源管理：<br>　　负载均衡的一大功能就是SSL终结(SSL卸载)，在负载均衡器上处理所有的SSL加密解密工作，而在服务和数据中心全部采用非加密传输方式。SSL是在外网不可信环境下进行数据保护的操作，而经过负载均衡之后就是内网环境，尽早卸载SSL可以最大程度地降低对性能的影响。</p>
<h1 id="三、安全">三、安全</h1><p>　　在HTTP的开发中，会有很多安全性相关的问题，这一方面主要是之前的HTTP协议是明文传输的，可以说上个世纪的协议在当下暴露出各种各样的安全性问题。<br>　　<strong>同源策略和会话劫持</strong><br>　　同源策略(Same-origin policy)是保证同一站点的资源处于一个可信的范围内，他们之间可以相互访问而不受限制，但是会阻止不同站点对文档、资源的访问和操作(同源策略涉及到的是访问内容，比如Cookie、文档内容嵌入等，而连接可以随便插入不受此限制)。同源中相同站点的三要素是：相同的协议、相同的主机名、相同的端口号。<br>　　同源策略是增强了安全性，但是也给开发带来了麻烦，因为在现代互联网开发扩展中，资源和服务拆分到不同的主机上面十分常见，那么根据同源的三要素，这些主机之间资源将不能相互操作。不过当然针对这种情况都有相应的解决方式，对于最常见的Cookie访问和AJAX请求，可以：<br>　　<strong><em>Cookie访问</em></strong>：在相同一级域名下的Cookie共享十分简单，只需要在调用Set-Cookie的时候添加domain=.example.com进行制定就可以，后面其子域名就可以共享Cookie了；<br>　　<strong><em>AJAX请求</em></strong>：同源策略规定AJAX请求只能发给同源的网址，否则就会报错。现在解决这个的方法最常见的是跨源资源共享CORS(Cross-Origin Resource Sharing)，该方式需要浏览器和服务器端同时支持，当支持的浏览器发现AJAX请求跨源后，会自动通过添加Origin附加头信息；服务端通过检查这个字段，判断是否同意这次请求，如果不允许就返回不带Access-Control-Allow-Origin头字段的响应，这时候浏览器就知道出错了，否则返回一些额外的头部信息(Access-Control-XXX)并附带正常响应结果。</p>
<p>　　<strong>跨站脚步攻击(XSS)</strong><br>　　当允许用户输入的HTML和javascript在网站上显示的时候，极容易遭受这种攻击。<br>　　如果服务端对用户输入的内容不做检查和无害处理，这些内容嵌入到网页中进行显示的时候，就会现实和执行这些HTML和javascript代码，后果将会是不可估计的。<br>　　除了对用户的输入进行检查和无害处理外，还建议使用安全的输入格式，比如Markdown格式以提供丰富的输入格式并保证安全，这一点<a href="https://www.v2ex.com" target="_blank" rel="external">v2ex</a>做的就比较好。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26906846/" target="_blank" rel="external">互联网创业核心技术：构建可伸缩的web应用</a></li>
<li><a href="https://f5.com/resources/white-papers/cookies-sessions-and-persistence" target="_blank" rel="external">Cookies, Sessions, and Persistence</a></li>
<li><a href="http://www.kancloud.cn/kancloud/tealeaf-http/43840" target="_blank" rel="external">HTTP 下午茶</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html" target="_blank" rel="external">浏览器同源政策及其规避方法</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2016/04/cors.html" target="_blank" rel="external">跨域资源共享 CORS 详解</a></li>
<li><a href="https://help.aliyun.com/knowledge_detail/40533.html" target="_blank" rel="external">BGP高防是什么？有什么优势？</a></li>
<li><a href="http://www.cloudxns.net/Support/detail/id/2163.html" target="_blank" rel="external">智能DNS和CDN加速功能以及区别介绍</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[2017年春节返途中的两三思考]]></title>
      <url>https://taozj.org/201702/little-thoughts-at-the-begin-of-2017.html</url>
      <content type="html"><![CDATA[<p>　　2017年是中国传统农历上的鸡年，而对我来说也是注定不平凡的一年：全家终于搬迁进了久等三年的安置新房，算是终于住上一个看起来像样一点的房子了；这是我结婚后的第一个年头，名义上正式步入人生中新的阶段；这年是我老爸的本命年，我爸六十了，而我也已经三十而立了！<br>　　这是在和老婆走完娘家从汉中回深圳途中立下的提纲，这是一个没有空客320/波音737，也没有时速三百公里和谐号的旅途，我们搭乘的，是从所有南下陕西人记忆中磨灭不掉的K768。我是无座票在这人山人海中度过了漫长的28个小时（当然还是要感谢黄牛帮老婆抢了张卧铺），那种人山人海、水泄不通、吵杂闷浊的环境实在是种炼狱的感觉，而唯一带来的好处就是，没有在安然舒适的环境中看电影、耍手机来消磨时光，而是给了我多些回忆、思考的机会和生活的种种感触（悲剧是吸了好多二手烟，这点确实比较惨）！<br><img src="/post_images/images/201702/d96907d5.jpg" alt="2017-ticket"></p>
<p><strong>父母和亲人老了</strong><br>　　年底在老家办了一场简单的婚礼，算是所有的亲戚都到场了，本身我爸妈都是排行最小的，所以到场的长辈都是老头、老太级别的状态了，最长的姑妈已经84岁高龄了。虽是一眼望去满是凋零，但是堂、表兄弟姐妹的小孩很多，活蹦乱跳的小精灵为整个场地增加了不少生命的气息。在所有我这一辈的亲戚中，我是最后完婚的，不过作为我这代人婚事的收官之作，虽然简陋但也凭空流露出那么一些自豪感。<br>　　让我感到欣慰的是，全家早年虽然多灾多难、命运多舛，而且爸妈也都接近60岁高龄，但是总体来说二老的身体和精神面貌还挺不错的。自从03年上大学直到现在工作，一直未有机会在家尽孝，这点是一直让我心中愧疚不已的，自己是家中的独子，必须承担起这份义不容辞的责任。结婚本是件幸福无比的事情，但是婚后直接面临的就是孩子、房子等各种问题，身边跟我类似情况的朋友还有很多，有时候想想我们这代人活得真是无比的辛苦。<br><a id="more"></a><br><strong>人丁兴旺</strong><br>　　在婚宴上，二舅家和姨夫家的家人就能凑上一桌了，可谓是人丁兴旺、儿孙满堂啊。所以我也会想，在这样一个时代，我们追求的到底是什么？是可以让人满足的物质金钱？还是动物本能的生衍繁衍？<br>　　我把上面两个问题列出来，虽然看似不矛盾，但是放在我们现处的环境下，确实是两个相互对立的问题。我们几个朋友其实很早都可以结婚生孩的，但是一直都拖了下来：想要好一点的工作就必须去北上广深一线城市去打拼，而生小孩会涉及到户口、上学各种问题，这些问题又跟房子问题紧紧绑定，对于没有背景白手起家的我们再怎么努力也几乎这没有希望在一线城市买房，而在我们心灰意冷准备退居二线城市的时候，发现二线城市的房价也被推高到无以承受的价位了，而且同时还伴随着各种政策性的限购。各种情况交织在一起，逼着大家喘不过气来。<br>　　或许大家会觉得我们清高不愿意将就，但是上面的问题不仅是我们搞IT、搞金融所谓的白领人士遇到的问题，那些做外贸、做工厂的人也有着同样的遭遇。他们所能给出的解决方法，就是在老家生完孩子让二老抚养，然后丈夫或者夫妻一起外出打工挣钱，跟我们一样逢年过节回去个一两次。想想看来，是不是我们也会最终沦落到这个地步！<br>　　我们这一代是接收“计划生育”这一“基本国策”光辉照耀的一代，中国人口发展的历史问题再去讨论也是无意，但是作为一个独生子的经历来说，强制生一个孩子对一个家庭来说嫉妒残忍：对孩子来说成长的历程是寂寞的，而父母会穷尽所有去培育这个孩子，往往适得其反创造了一个畸形的成长环境。<br>　　这么看来，或许我们这代，可以放松一下自己的要求：工作不必是那些明星企业、房子不必是那些繁华都市、孩子也不一定要挑最好的学校……我们可以在一个自己可以承受的环境下，生个两三个健康的宝宝，营造一个和谐的家庭环境，培养好他们健全的人格和健康的喜欢，少一分攀比，多一份真切。</p>
<p><strong>男女婚姻问题</strong><br>　　感觉身边跟我同龄的大龄剩男、剩女越发的多了，当然也有可能是之前没有注意到这个问题。关于剩男的问题，中国人口男女比例本来就严重失调，在这个大前提下面就必然有人会被淘汰下来，就像是俄罗斯、乌克兰这样的国家，是个男的就可以娶个美女回家，而且很多男的可以终日酗酒不干活的说。<br>　　在农村几乎没有剩女，偶尔会有些女孩和家长极度挑剔的；剩男大多是经济条件比较弱势，或者有生理缺陷的人。但是围绕在我们身边的剩男、剩女，大多比较优秀：长得靓、工资高、有素养……每年过年都会有大批的人求回家攻略，甚至有人受不了了直接告知父母我是个Gay!(玩笑)<br>　　此时不禁要感慨下自己是多么的幸运：没有成为剩男，而且还有个比较恩爱的老婆，虽然我们彼此不算完美，也让对方遭受过不少罪，但七年的相识相伴至少说明还是可以凑活在一起过的。木讷的我自然解释不了世界上最深奥动物的这一现象，但是大家谈论的比较多的因素无外乎有：经济和生活可以完全独立了，不用找个人抱团取暖了；思想观念开放了，不觉得结婚晚了是件丢脸的事情；事业，或者网络的虚拟世界让人更容易活得存在感，相比感情的经营更容易成功；当然其中也不乏一些恨嫁的人，但是苦于工作、生活、环境方面的原因很难遇到适合的人，我觉得此时是不是可以把锅甩给网络、手机来着，它们让我们越来越不愿意走出去，生活也变得越来越单调了！</p>
<p><strong>亲情和友情</strong><br>　　由于结婚这件事，就必须牵扯到亲戚了，虽然这次没有借钱的问题，但是亲戚之间的相处一直是个热点问题。<br>　　其实平时跟爸妈电话的时候也会说，当前的一点得失不必过于的看重，吃亏也是一种福，但是他们还是为一些问题苦恼抱怨着。这个过程中我也发现了，经常外出、交流较多的人，会显得比较开明大方；而常年蹲守老家的人，思想会变得较为保守僵硬。其实爸妈年轻的时候不是这样的，他们常常教导我在外边别跟人家争利，做人要老实谦让一些，但没想到随着年龄的增长，他们居然成为了自己以前最不喜欢的人了。<br>　　其实有时候会有一种错觉，感觉自己的朋友都比自家亲戚靠谱，比如礼金、借钱啥的都大方的不得了，平时办事要帮忙也随叫随到。但是仔细想想，亲人是通过血缘关系绑定起来必须面对的，而朋友是经过选择剩余下来的，后者的水平自然会高很多。<br>　　当然有人也会说，现在的朋友很多都是利益上的伙伴，大难来个各自飞、该出卖时就出卖。其实呢，人这种动物本来就具备着很大的不确定性，父子都可能会恩断义绝，还有什么不可能的。人啊，往往还就有那么一种犯贱的感觉，越是通过亲戚的纽带绑定在一起，大家就越是嫌隙彼此；而越是天南海北不打紧的人，还越是去亲近巴结去。但是，亲情、友情谁也不能替代谁，在一定程度上只能选择去培养和保护他。想我们这些远在外边的儿女，自然希望远在故乡的父母能得到亲戚的掌故，而独在异乡的自己在巨大的工作、生活压力下，跟自己境遇相似的朋友互相鼓励、互相抱团取暖，大家才能走的更坚强一些！</p>
<p>　　<strong><em>我们到底想成为一个什么样的人？我们所追求的到底是一种什么样的生活？</em></strong><br>　　我感觉自己的优点是，在累、沮丧、无助的时候，我会静下心来去思考这些问题而有所获；但缺点是，得到的结果很难深刻的烙在今后的生活和实践中去。虽然现在某些人会耍些小聪明，但是底层的工薪族们真的很优秀，他们勤劳、质朴、拼搏，为了自己的家庭从无怨言，真心祝愿那些远在他乡的你们今年能满载而归，也希望那些有能力有责任的的人能多多帮助他们，善待这些可爱的人们！<br><img src="/post_images/images/201702/52dac91d.jpg" alt="2017-people"></p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[GNU GDB调试手册]]></title>
      <url>https://taozj.org/201701/gnu-gdb-debug.html</url>
      <content type="html"><![CDATA[<p>　　人家都说Windows平台下的程序员是幸福的，因为Visual Studio实在是太好用了。<br>　　我想一听到上面这句话，绝大多数Linux平台C/C++程序员都将会沉默，至少网上搜Linux平台下C/C++开发调试，很大一部分文章都是介绍搭建IDE的，这也侧面说明了Linux平台下没有一个占绝对主流地位好用的IDE。自己平时写程序是用的SlickEdit，这个IDE很贵，支持代码补全和跳转，调试过程也支持断点、Watch等特性，但是使用过程中还是有这样那样的小问题(比如非英文字串显式、速度比较慢)，但是总体比较而言还是比较优秀的跨平台C/C++ IDE。虽然线下编码调试使用这货当然可以，然则线上环境就无能为力了，再加上自己之前对gdb也只是了解个表明，这次就顺着gdb的文档深挖一下！<br>　　真是一看吓一跳，gdb的命令行调试要远比IDE的功能高级的多，如果只是通常的设置断点，监测变量什么的可能IDE比较方便，但是一旦上升到高级点的调试技巧，反而gdb在命令行的模式下更为的方便和高效。<br>　　前方预警：<strong>这将会是一篇很长很长的文档摘读</strong>。</p>
<h1 id="一、开始使用gdb">一、开始使用gdb</h1><h2 id="1-1_启动gdb">1.1 启动gdb</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ gdb program [core|pid]</div><div class="line">➜  ~ gdb --args g++ -O2 -o main main.cpp</div><div class="line">(gdb) shell <span class="built_in">echo</span> <span class="variable">$SHELL</span></div><div class="line">(gdb) <span class="built_in">set</span> logging on</div></pre></td></tr></table></figure>
<p>　　gdb接需要调试的程序可执行文件，后面可以附加core文件或者pid进程号(调试正在运行的进程)，如果有第三个参数gdb总是先尝试解释他为core文件，然后才是进程号。第二种格式采用–args，待调试的程序执行的时候需要额外的参数，此时可执行程序后面的参数不再被gdb解释。<br>　　组合键Ctrl-D或者输入quit可以退出调试状态，如果之前attach到一个进程上面去了，可以用detach命令释放进程，如果quit有表达式那么表达式就作为gdb的退出状态，否则是被调试的子进程的退出状态。gdb中使用Ctrl-C不会终止gdb，而是会终止gdb正在运行的调试指令返回到gdb命令状态。<br>　　在gdb中可以使用shell或者!做前导来执行shell中的命令而不用退出gdb(gdb的退出和重启动的代价是很大的)，make命令可以用来重新编译程序而不用先导shell|!符号，而gdb自动重新加载符号。<br>　　通过set logging on可以打开日志功能，默认会将日志输出追加到当前目录的gdb.txt文件中。</p>
<h2 id="1-2_gdb中的命令">1.2 gdb中的命令</h2><p>　　gdb是很智能的，所有的命令都可以使用TAB、TAB-TAB进行补齐或者提示，不输入任何命令的空换行(在可能的情况下)表示重新执行前一条指令，这节省了重复输入step|list等指令的劳动。gdb允许指令和参数的缩减输入，没有歧义的时候会运行，而在遇到歧义的时候起会提示出各个歧义的命令列表供参考。<br>　　有些命令参数中可能含有特殊的符号(比如括号)，尤其在C++允许函数重载的时候需要使用参数类型来进行区分，此时参数需要使用 ‘ 单引号来包围，而且在需要的时候gdb也会自动帮你包围并给出候选列表的。</p>
<h2 id="1-3_gdb帮助">1.3 gdb帮助</h2><p>　　gdb本身附带了很多帮助命令，比如：<br>　　<strong>help <em>command</em></strong>：显示名的帮助信息<br>　　<strong>apropos <em>args</em></strong>：会在命令名、文档中搜索指定的表达式<br>　　<strong>info <em>args|registers|breakpoints|…</em></strong>：可以显示很多状态信息，具体可以查看help info<br>　　<strong>set <em>var val</em></strong>：设置环境变量<br>　　<strong>show <em>var</em></strong>：显示环境变量的值</p>
<h2 id="1-4_调试执行程序">1.4 调试执行程序</h2><p>　　对于待调试程序编译时候，总应该使用-g选项生成调试信息。<a id="more"></a></p>
<h3 id="1-4-1_启动调试程序">1.4.1 启动调试程序</h3><p>　　<strong>run/r</strong><br>　　必须在gdb启动的时候指定调试文件，或者启动后再使用exec|exec-file指定调试文件。启动的时候gdb会创建子进程(inferior process)并在子进程中立即运行该程序。run命令后面可以接参数，所有的参数都会被传递给可执行程序，而下次调试如果直接run而不添加参数，上一轮的参数会被继承自动添加(下面的start也是一样)。<br>　　除了在调用run/start的时候指定参数，还可以单独调用set args方法设置参数。参数的展开和shell规则一样，而且支持输入输出重定向(比如&gt;aa.txt)，展开后传递给run/start使用。<br>　　<strong>start</strong><br>　　该命令会在程序入口函数的地方(C/C++默认是main)添加一个临时断点，然后程序立即运行并在入口函数的地方被暂停。<br>　　此处还需要注意，C++程序在执行main之前会创建static和全局变量，他们的构造函数会被调用，所以程序入口函数不一定会被最早执行的程序代码。</p>
<h3 id="1-4-2_调试运行的进程">1.4.2 调试运行的进程</h3><p>　　<strong>attach process-id</strong><br>　　可以用来跟踪一个已经在运行的进程，然后被跟踪的进程会暂停执行，然后可以做任何的调试操作，以及continue让程序继续执行。同时，gdb还会在当前工作路径、源代码搜索路径等地方搜索该进程的可执行文件，当然也可以使用file命令手动加载可执行文件。<br>　　<strong>detach</strong><br>　　一旦detach之后程序会继续执行，而且和gdb再无瓜葛了。如果当前有attach的进程而使用Ctrl-D退出gdb，gdb会提示是否要detach调试的进程。<br>　　<strong>kill</strong><br>　　该命令会kill掉当前调试的进程，无论是run/start创建的还是attach调试的。常用情况是修改代码后需要重新调试，此时可以先kill掉当前调试，然后编译出新的可执行程序，再使用run/start开启调试，此时gdb会发现可执行程序已经修改了，会重新读取符号表信息(但是之前的断点等信息还是得以保留的)。</p>
<h3 id="1-4-4_调试多线程程序">1.4.4 调试多线程程序</h3><p>　　线程除了共享地址空间之外，拥有自己独立的寄存器状态、执行栈和线程存储。gdb可以查看跟踪进程的所有线程的状态信息，但是只能有一个线程处于当前被跟踪的状态。<br>　　<strong>info threads [thread-id-list]</strong><br>　　显示所有(或者指定)线程的信息，带星号标识的是当前跟踪的线程。<br>　　<strong>thread thread-id</strong><br>　　切换thread-id线程为当前跟踪线程。<br>　　<strong>thread apply [thread-id-list | all] command</strong><br>　　在所有(或者指定)线程线程上执行command命令。<br>　　<strong>thread name [name]</strong><br>　　设置线程的名字(info threads中会显示)，如果不带参数，会恢复名字为操作系统默认名字。</p>
<h3 id="1-4-5_调试fork创建的多进程程序">1.4.5 调试fork创建的多进程程序</h3><p>　　GDB对fork产生新进程的调试没有特殊的支持，当使用fork产生子进程的时候，GDB会继续调试父进程，子进程不会被阻碍而是继续执行，而此时如果子进程遇到断点后，子进程会收到SIGTRAP信号，当在非调试模式下默认会导致子进程中止。如果要调试子进程，可以让子进程启动后睡眠一段时间(或者监测某个文件是否创建)，在这个空隙中使用ps查看子进程的进程号，然后再启动gdb去attach到这个进程上面去调试。<br>　　通过catch命令可以让gdb在fork/vfork/exec调用的时候暂停执行。<br>　　影响fork多进程调试还有以下几个变量：<br>　　<strong>follow-fork-mode</strong><br>　　可选值是parent或child，指明当正在被调试的进程fork出子进程的时候，如果该值是parent，那么父进程被调试子进程正常执行，这也是默认行为；而当其为child的时候，则新创建的子进程被调试，父进程正常执行。<br>　　<strong>detach-on-fork</strong><br>　　可选值是on或off，知名当被调试的进程fork出子进程后，是否detach某个进程还是调试他们俩，如果是on，那么子进程(或父进程，取决于上面follow-fork-mode的值)将会被detach正常执行，这是默认行为；否则两个进程都会被gdb控制，其中的一个进程被正常调试，另外一个进程被suspend住。<br>　　<strong>follow-exec-mode</strong><br>　　gdb对于exec调用的反应，其值可以为new或same，当值为new的时候，之前fork的子进程和exec后的进程都会被保留；如果是same，则exec的进程使用之前fork的进程，exec会用新的执行镜像替代原先的可执行程序，这是默认行为。</p>
<h3 id="1-4-6_设置书签保存历史状态">1.4.6 设置书签保存历史状态</h3><p>　　gdb可以在程序执行的过程中保留快照(状态)信息，称之为checkpoint，可以在进来返回到该处再次查看当时的信息，比如内存、寄存器以及部分系统状态。通过设置checkpoint，万一调试的过程中错误发生了但是已经跳过了错误发生的地方，就可以快速返回checkpoint再开始调试，而不用重启程序重新来过。<br>　　<strong>checkpoint</strong><br>　　对当前执行状态保存一个快照，gdb会自动产生一个对应的编号供后续标识使用。从提示信息看来，其实每建立一个checkpoint，都会fork出一个子进程，所以每个checkpoint都有一个唯一的进程ID所对应着。<br>　　<strong>info checkpoints</strong><br>　　查看所有的checkpoint，包括进程ID、代码地址和当时的行号或者符号。<br>　　<strong>restart checkpoint-id</strong><br>　　恢复程序状态到checkpoint-id指明的checkpoint，所有的程序变量、寄存器、栈都会被还原到那个状态，同时gdb还会将时钟信息回退到那个点。恢复过程中程序的状态和系统的部分状态是支持的，比如文件指针等信息，但是写入文件的数据、传输到外部设备的数据都无法被回退。<br>　　<strong>delete checkpoint checkpoint-id</strong><br>　　删除指定的checkpoint。<br>　　此外，checkpoint的作用还在于断点、观测点不是什么情况下都可用的情况下，因为Linux系统有时候为了安全考虑，会随机化新进程的地址空间，这样重启调试程序会导致之前使用绝对地址设置的断点、观测点不可用。</p>
<h1 id="二、中断和继续运行">二、中断和继续运行</h1><h2 id="2-1_断点、监视点和捕获点">2.1 断点、监视点和捕获点</h2><p>　　gdb除了普通断点，还支持检测点(watchpoint)、捕获点(catchpoint)两类特殊的断点类型，他们都能使用enable、disable、delete进行管理。检测点会在检测的变量以及使用运算符组合成的表达式的值发生改变的时候暂停程序的执行；catchpoint是在某个事件发生的时候暂停程序的执行，比如C++抛出异常、加载库的时候。</p>
<h3 id="2-1-1_断点">2.1.1 断点</h3><p>　　<strong>break [location]</strong><br>　　location可以是函数名、行号、指令地址，在程序执行到这些指定位置前会暂停下来(暂停时候这些位置的任何代码都不会被执行)。如果没有location参数，则断点会在下一条执行的指令前设置，在最内帧中gdb会在下次执行到该点的时候暂停，这种情况最常见的是在循环中使用。<br>　　<strong>break … if cond</strong><br>　　每次指定到该点的时候会先计算cond的状态，当cond!=0的时候断点生效，程序执行暂停下来。而且在同一个位置，可以使用不同的条件设置多个条件断点。<br>　　<strong>tbreak args</strong><br>　　只生效一次的临时断点，一旦断点生效程序暂定在这个断点处的时候，该断点会被自动删除掉。<br>　　<strong>rbreak regex</strong><br>　　在所有匹配regex正则表达式的函数名处都设置断点，并打印出这些新设置的断点。正则表达式的元字符含义同grep工具的含义(而同shell有所差别)。这在C++设置重载函数断点的时候十分有效。<br>　　<strong>rbreak file:regex</strong><br>　　通过一个文件名的前缀，可以缩小rbreak设置断点的范围(否则库的头文件也会被搜索并设置断点)。<br>　　<strong>info break|breakpoints</strong><br>　　查看断点(同时还包括watchpoint和catchpoint)，同时如果断点被触发了，还会显示触发的次数信息。</p>
<p>　　在一个位置上设置断点，其本质上可以对应于多个位置，比如：同名重载函数、C++合成的多个构造函数、模板函数和模板类、inline函数。对于这种单个断点多个地址的情况，gdb会自动在需要的位置插入断点，当使用info break显示的时候，会以breakpoint-number.location-number的方式显示，断点管理可以引用breakpoint-number，或者针对某个子地址的断点操作。<br>　　动态库也支持断点，不过其地址需要在加载库的时候才能解析，因此动态库中的断点在未能解析地址前都是pend状态，同时动态库在程序执行的过程中也可能进行多次加载和卸载的操作，gdb在只要有动态库加载和卸载操作的时候，都会重新计算断点的位置信息。</p>
<h3 id="2-1-2_监视点">2.1.2 监视点</h3><p>　　监视点是监视特定表达式的值是否改变而触发程序暂停执行，而不用去关心该值到底在代码的哪个位置被修改的。监视的表达式可以是：某个变量的引用、强制地址解析(比如<em>(int </em>)0x12345678，你无法watch一个地址，因为地址是永远也不会改变的)、合理的表达式(比如a-b+c/d，gdb会检测其中引用的各个变量)。<br>　　<strong>watch [-l|-location] expr [thread thread-id] [mask maskvalue]</strong><br>　　thread-id可以设置特定线程改变expr的时候触发中断，默认情况下针对硬件模式的检测点所有的线程都会检测该表达式；-location会让gdb计算expr的表达式，并将计算的结果作为地址，并探测该地址上的值(数据类型由expr计算结果决定)。<br>　　软件模式的检测点作用有限，只能当前单个线程能侦测其变化，虽然该值也可能会被其他线程修改。<br>　　watch命令还存在两个变体：rwatch当expr被程序读的时候触发中断；awatch会在程序读取或者写入expr的时候被中断。watchpoint支持软件模式和硬件模式的检测点，后者效率会比前者高很多，因为如果不支持硬件模式gdb会每次step并计算检测的表达式，x86构架支持硬件模式。rwatch和awatch只支持硬件模式的检测点。<br>　　<strong>info watchpoints</strong><br>　　查看检测点信息，和短线信息输出格式类似。<br>　　当检测点旧监测的变量或者表达式超过了其作用域的时候，gdb会自动删除失效的观测点，所以当跳出变量的作用域后又进入的话，需要重新创建检测点。尤其当调试程序重启的时候，所有局部变量的观测点都会消失，只有全局变量的检测点会保留。</p>
<h3 id="2-1-3_捕获点">2.1.3 捕获点</h3><p>　　可以让gdb在某些事件发生的时候暂停执行，比如C++异常、加载动态链接库以及某些系统调用的时候，其格式为<code bash="">catch event</code>，还有一个变体<code bash="">tcatch event</code>设置临时捕获点，其中event的参数可以为：<br>　　<strong>throw|rethrow|catch [regex]</strong><br>　　在C++异常抛出、重新抛出、捕获的时候触发，可选使用regex参数限定特定的异常类型(在gcc-4.8开始支持)，内置变量<strong>$_exception</strong>会记录在catchpoint激活时候的异常。<br>　　当异常发生时候，程序通常会停留在libstdc++的异常支持点，此时可以通过使用up命令切换帧跳转到用于异常代码处。<br>　　<strong>syscall [name | number | group:groupname | g:groupname] …</strong><br>　　在进入和/或返回系统调用的时候触发。name可以指明catch的系统调用名(定义在/usr/include/asm/unistd.h，且gdb会帮助智能补全)，group|g:groupname可以用来指定一组类别的系统调用，比如g:network，通过智能补全可以查看支持的group信息。<br>　　<strong>exec|fork|vfork</strong><br>　　<strong>load|unload [regex]</strong><br>　　加载和卸载共享库时候触发，可选regex进行过滤。<br>　　<strong>signal [signal… | ‘all’]</strong><br>　　可以在软件收到信号的时候触发。gdb本身会占用SIGTRAP和SIGINT两个信号，如果不添加额外参数，会catch除了这两个信号之外的所有信号。<br>　　使用info break命令，watchpoint的信息会被展示出来，可以像普通断点一样管理之。</p>
<h3 id="2-1-4_断点管理(删除、禁用)">2.1.4 断点管理(删除、禁用)</h3><p>　　<strong>clear</strong><br>在最内栈中，可以用来删除正在被暂停的这个断点。<br>　　<strong>clear location</strong><br>删除指定位置处的断点，可以是func、file:func、linenum、file:linenum。<br>　　<strong>delete [breakpoints] [range…]</strong><br>参数breakpoints可用可不用，可以指明breackpoints、watchpoints、catchpoints的值或者范围来删除它们，他们的编号在同一编号空间中。<br>　　<strong>disable|enable [breakpoints] [range…]</strong><br>禁用|启用某些断点，如果没有指明范围，则是针对所有的断点。<br>　　<strong>enable [breakpoints] once range…</strong><br>临时启用某些断点，一旦这些断点激活，就会被自动disable。<br>　　<strong>enable [breakpoints] count cnt range…</strong><br>　　这种情况下临时使能的断点，会在每次被激活的时候递减cnt计数，当其值为0的时候，会禁用该断点。这个count还有一个好用的方式是和ignore相结合，可以在循环中跳过cnt个循环。<br>　　<strong>enable [breakpoints] delete range…</strong><br>　　临时启用某些断点，一旦这些断点激活，就会被自动delete，跟通过tbreak设置的断点起始状态一样。</p>
<h3 id="2-1-5_条件断点">2.1.5 条件断点</h3><p>　　当指定的cond为true的时候，断点就会被触发，其可以用于普通断点，也可以用于watchpoint(虽然值一旦改变就会触发，但是可以用cond过滤得到感兴趣的值)。条件断点可以具有side-effect，比如其可以调用函数、写入日志、执行命令等操作，副作用是可控的，除非该条件断点上又设置了别的断点，而别的断点使程序暂停此时该cond可能就没有被检查调用。<br>　　普通断点和检测点可以在命令break/watch的时候使用 if关键字指明条件，但是catch不能识别if关键字；其上所有的断点都可以在创建之后使用condition关键字指明条件来创建和删除条件：<br>　　<strong>condition bnum expr</strong>、<strong>condition bnum</strong>：<br>　　创建和删除断点的条件，在expr为true的时候断点才会被触发，后者删除条件后断点就退化成非条件断点了。<br>　　<strong>ignore bnum cnt</strong>：<br>　　让断点可以忽略cnt次后生效，如果是使用continue命令恢复程序的执行，也可以使用<code bash="">continue cnt</code>的方式代替ignore指令。如果一个断点有ignore和condition两种属性，那么在ignore到达0之前是不会检查condition条件的。</p>
<h3 id="2-1-6_断点命令列表">2.1.6 断点命令列表</h3><p>　　<strong>commands [range…]</strong><br>　　<strong>… command-list …</strong><br>　　<strong>end</strong><br>　　通过command-list的方式，可以让断点(breakpoint、watchpoint、catchpoint)在暂停的时候执行一些命令串(比如用来答应表达式或者寄存器的当前值，使能其他断点等)，如果要删除断点的命令串，可以使用commands紧邻着end就可以了。如果没有range参数，该commands默认作用于最后一个创建的断点(或者命令列表，使用rbreak等条件创建的多个断点)。<br>　　在上面说的命令列表中，在执行指定操作后，可以使用标准的命令来恢复程序的执行，比如continue、step等。可以在命令列表的开头使用silent，就不会打印当前断点的额外信息，对于变量等显示，可以使用echo、output、printf等命令来查看，同时还可以使用set命令，让给部分变量赋上正确的值，然后让程序继续执行。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">break</span> 31</div><div class="line">Breakpoint 4 at 0x434c62: file ./<span class="built_in">source</span>/main.cpp, line 31.</div><div class="line">(gdb) commands</div><div class="line">Type commands <span class="keyword">for</span> breakpoint(s) 4, one per line.</div><div class="line">End with a line saying just <span class="string">"end"</span>.</div><div class="line">&gt;silent</div><div class="line">&gt;<span class="built_in">printf</span> <span class="string">"origin port is %d\n"</span>, srv_port</div><div class="line">&gt;<span class="built_in">set</span> srv_port = srv_port + 100</div><div class="line">&gt;cont</div><div class="line">&gt;end</div><div class="line">(gdb) start</div><div class="line">port number is: 8911</div></pre></td></tr></table></figure></p>
<p>　　如果此时使用info b，可以查看当前断点的命令列表的详情:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(gdb) info b</div><div class="line">Num     Type           Disp Enb Address            What</div><div class="line">4       breakpoint     keep y   0x0000000000434c62 <span class="keyword">in</span> main(int, char**) at ./<span class="built_in">source</span>/main.cpp:31</div><div class="line">        breakpoint already hit 1 time</div><div class="line">        silent</div><div class="line">        <span class="built_in">printf</span> <span class="string">"origin port is %d\n"</span>, srv_port</div><div class="line">        <span class="built_in">set</span> srv_port = srv_port + 100</div><div class="line">        cont</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<h3 id="2-1-7_动态打印">2.1.7 动态打印</h3><p>　　上面的printf可以方便的在gdb的终端界面进行打印操作，此外gdb还允许进行打印的灵活配置，该具就是<strong>dprintf</strong>。<br>　　其通过function配置可以随意调用打印函数，而channel配置可以重定向到任何输出流，dprintf的行号可以on-the-fly的任意位置插入打印语句，其格式化输出也是和上面的printf如出一辙。GDB不会检查设置function和channel的合法性，如果非法值会在调试的过程中报错。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">set</span> dprintf-style call</div><div class="line">(gdb) <span class="built_in">set</span> dprintf-function fprintf</div><div class="line">(gdb) <span class="built_in">set</span> dprintf-channel stderr</div><div class="line">(gdb) dprintf 35,<span class="string">"at line 35, the srv_port is%d\n"</span>, srv_port</div><div class="line">D<span class="built_in">printf</span> 1 at 0x434<span class="built_in">cd</span>4: file ./<span class="built_in">source</span>/main.cpp, line 35.</div><div class="line">(gdb) info b</div><div class="line">Num     Type           Disp Enb Address            What</div><div class="line">1       dprintf        keep y   0x0000000000434<span class="built_in">cd</span>4 <span class="keyword">in</span> main(int, char**) at ./<span class="built_in">source</span>/main.cpp:35</div><div class="line">        breakpoint already hit 1 time</div><div class="line">        call (void) fprintf (stdout,<span class="string">"at line 35, the srv_port is%d\n"</span>, srv_port)</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<h3 id="2-1-8_断点保存">2.1.8 断点保存</h3><p>　　<strong>save breakpoints [filename]</strong><br>　　通过上面的命令，可以将所有当前的断点定义和他们的type、commands、ignore counts等信息保存到文件中去，而source命令可以读取这些保存的结果。需要注意的是，对于引用了局部变量的watchpoints很有可能无法重建，因为无法获取当时创建时候的有效上下文信息。<br>　　保存的结果是纯文本文件，其内部实际是一系列的gdb命令列表，可以方便的编译该文件，比如移除不关心的断定定义。</p>
<h2 id="2-2_继续和单步执行">2.2 继续和单步执行</h2><p>　　<strong>continue|c|fg [ignore-count]</strong><br>　　从程序最后停止的位置继续执行，且该位置上的所有断点将会被bypassed。可选的ignore-count和ignore作用相同，该参数只有在当前停止是由于断点触发的时候才有效，否则该参数将会被忽略。<br>　　如果想从别的地方继续程序的执行(而不是当前暂停的位置)，可以选用<strong>return</strong>到函数的调用位置、<strong>jump</strong>到任意位置开始恢复执行。<br>　　<strong>step|s</strong><br>　　继续执行当前的程序直到达到一个新的代码行号后，停止程序并将控制转给GDB。step只会停留在代码行的第一条指令处，如果在当前行中有调用带有调试符号的函数，那么step会继续停留，即step会进入到带符号的函数中去，否则其行为类似于<strong>next</strong>命令而不会进入到函数中去。<br>　　说到这里，需要注意的是step命令只会停留到带有调试符号的代码中，如果在没有调试符号的函数环境中使用step，那么程序会一直执行直到到达一个含有调试信息的函数；否则，需要stepi命令。<br>　　<strong>step <em>count</em></strong><br>　　持续执行count次的step，如果在这之前遇到一个断点或者和step无关的信号，step将会停止。<br>　　<strong>next|n [count]</strong><br>　　在当前(最内层)的stack frame中执行到下一个代码行，和step不同的是代码行中的函数调用将会被直接执行而不会停止。类似的，next也只会在代码行的首个指令处停止执行。<br>　　<strong>finish|fin</strong><br>　　继续执行直到当前选定的stack frame的函数返回，如果可以打印函数的返回值，简言之就是将当前函数执行完。<br>　　和这个命令对应的是<strong>return [expr]</strong>命令，该命令是取消当前函数的后续执行直接返回，并且可选返回一个表达式作为调用结果。<br>　　<strong>until|u</strong><br>　　继续执行直到在当前stack frame中到达超过当前行号的位置，这个在循环中使用的比较多，非循代码下跟next命令比较相似，而且until命令在退出当前stack frame的时候总是会停止程序的执行。需要注意的是，编译器为了效率可能会重排循环代码，有时候until的行为可能会有些诡异。<br>　　<strong>until|u <em>location</em></strong><br>　　相比不带参数的until效率会更高(采用了临时断点方式实现)，会执行程序直到特定位置或者退出当前stack frame，所以只有location是在当前stack frame内部的时候才会到达，location可以是行号、地址等任意类型的位置信息。<br>　　该until命令的另外一个好处，是可以跳过(skip over)递归函数调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="number">4</span> <span class="function"><span class="keyword">int</span> <span class="title">factorial</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</div><div class="line"><span class="number">5</span>     <span class="keyword">if</span>( value &gt; <span class="number">1</span>)</div><div class="line"><span class="number">6</span>         value *= factorial(value - <span class="number">1</span>);</div><div class="line"><span class="number">7</span>     <span class="keyword">return</span> value;</div><div class="line"><span class="number">8</span> &#125;</div></pre></td></tr></table></figure></p>
<p>　　如果当前执行点在第5行，<code bash="">until 7</code>命令会持续整个递归调用，直到value=120的时候在第7行暂停。<br>　　<strong>advanced <em>location</em></strong><br>　　和until比较类似，但是不会跳过递归调用，同时location的位置也不需要限定在当前的stack frame。<br>　　<strong>stepi/si <em>count</em></strong><br>　　执行一条(count条)机器指令，在使用这种方式调试的时候，建议使用<code bash="">display/i $pc</code>显示机器指令的汇编代码。<br>　　<strong>nexti/ni <em>count</em></strong><br>　　和上面类似，只是在遇到函数调用指令的时候不会跟踪函数调用，会直接等待函数返回。</p>
<h2 id="2-3_跳过函数和代码文件">2.3 跳过函数和代码文件</h2><p>　　有些时候调试中可能对某个函数、某个文件中的所有函数或者特定文件中的特定函数不感兴趣。<br>　　比如：<code cpp="">foo(boring());</code>如果不想调试boring()函数，方法是先step进入boring()，然后使用finish跳出该函数，再继续调试foo()函数。使用<strong>skip</strong>命令可以设置忽略某些函数的调试达到上述的效果。<br>　　<strong>skip function [linespec]</strong><br>　　执行该命令后，linespec指定的函数名或者linespec行号所在的函数将会被跳过。如果没有指定linespec，那么当前正在被调试的函数名将会被作为参数使用。<br>　　<strong>skip file [filename]</strong><br>　　执行该命令后，所有源代码在filename中实现的函数，都会在stepping的过程中被跳过。如果没有指定filename，那么当前调试焦点所在的源代码文件将作为其参数。<br>　　<strong>skip [options]</strong><br>　　是一个基本更灵活的命令(不过测试发现极大发行版的gdb不支持该模式)，通过-file|-function可以得到上面另个子命令相同的效果，而且可以任意组合使用。更强大的是使用-gfile|-rfunction的正则表达式模式，来指定符合正则表达式的文件后者函数名。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) skip -gfile utils/*.cpp</div><div class="line">(gdb) skip -rfu ^std::(allocator|basic_string)&lt;.*&gt;::~?\1 *\(</div></pre></td></tr></table></figure></p>
<p>　　如果没有任何参数，其效果类似于命令<code bash="">skip function</code>。<br>　　<strong>info skip</strong><br>　　<strong>skip enable/disable/delete [range]</strong><br>　　常规的skip管理命令。</p>
<h2 id="2-4_信号">2.4 信号</h2><p>　　信号是操作系统定义在程序中可以异步发生的事件，有些信号是程序正常执行的一部分(比如SIGALRM)，而有些信号预示着错误甚至是致命的(比如SIGSEGV)，通常会终止程序的执行。很多信号如果没有事先设置好处理handler，默认的处理方式是终止该程序的执行。<br>　　GDB可以感知程序中任何信号的发生，可以设置对特定信号的特定处理方式。正常情况下GDB是让非错误的信号(比如SIGALRM)传递到调试的程序，而让错误信号发生的时候停止程序的执行(具体可以使用info signals查看)，可以通过<strong>handle</strong>命令修改特定信号的行为。<br>　　<strong>catch signal [sig…|’all’]</strong><br>　　给对应信号设置catchpoint。<br>　　<strong>handle <em>sig</em> [keywords…]</strong><br>　　修改GDB对信号的默认处理方式，sig参数可以是SIG打头的信号名、low-high的信号值范围、’all’所有信号；keywords可以是下面的关键字<br>　　nostop、stop：当该信号发生的时候gdb是否要停止程序的执行；stop-&gt;print<br>　　print、noprint：当该信号发生的时候是否打印相关信息；noprint-&gt;nostop<br>　　pass|noignore、nopass|ignore：GDB决定是否让你的应用程序看到该信号，即应用程序消费该信号。对于非错误信号的默认模式是nostop|noprint|pass，对于错误信号的模式是stop|print|pass。<br>　　当一个信号停止了程序的执行，被调试的应用程序在continue之前是觉察不到该信号的，在GDB报告一个信号的发生的时候，可以通过handle命令的pass|nopass来设置是否传送该信号，然后继续程序的执行。<br>　　GDB对于调试中的信号处理做了<strong>一定的优化</strong>：<br>　　如果信号是nostop的，此时使用stepi/step/next进行跟踪调试的时候，将会优先执行信号处理函数，在信号处理函数返回后再执行主线调试代码，即会step over信号处理。不过信号处理函数本身也可能有断点等因素导致执行流过早的停止。<br>　　当使用了stop的时候，并且程序设置了对应信号的信号处理函数，此时程序如果因为信号暂停的话，则使用step/stepi/next将会跳入到信号处理函数中去跟踪。</p>
<h2 id="2-5_多线程程序">2.5 多线程程序</h2><p>　　在多线程程序调试中，具有两种工作模式：all-stop和non-stop。</p>
<h3 id="2-5-1_all-stop_mode">2.5.1 all-stop mode</h3><p>　　当进程中任意线程因为某种原因停止执行的时候，所有其他线程也同时被GDB停止执行。好处是程序停止的时候所有线程的状态都被保留下来了，可以切换线程查看整个程序当时的所有状态(缺点是整个业务全部阻塞暂停了)。<br>　　在默认设置下，当恢复程序执行的时候，所有的线程也都会立即执行，即使是使用step/stepi/next这种单步跟踪的模式也是如此。线程的调度是操作系统控制的，即使单步跟踪的时候很有可能其他的线程执行了更多指令后，当前线程才执行完单步指令并停止；还有可能单步跟踪后发现自己停止在了其他的线程上面，因为任何时候任何线程因为断点、信号、异常的时候都会停止程序的执行，并且GDB会自动选定切换到该线程上面去(同时会打印Switching的切换信息)。<br>　　有些操作系统支持OS调度锁定的支持，就可以修改上述GDB的默认行为。<br>　　<strong>schedule-locking</strong><br>　　off：不会锁定，所有线程可以自由运行；<br>　　on：当程序resume的时候，只有当前线程可以运行；<br>　　step：该模式是为单步模式优化的模式，当跟踪的时候阻止其他线程抢占当前线程。当step的时候其他线程无法运行，而在使用continue、until、finish类似指令的时候其他线程可以自由运行。除非其他线程运行时候触发了断点，否则GDB不会切换当前调试的线程。<br>　　<strong>schedule-multiple</strong><br>　　该设置是针对多进程情况下的调试。<br>　　off：只有当前线程所在的进程的所有线程允许恢复执行，该off为默认值。<br>　　on：所有进程的所有线程都可以执行。</p>
<h3 id="2-5-2_non-stop_mode">2.5.2 non-stop mode</h3><p>　　当进程中任意线程停止时，在跟踪检查停止线程的时候其他的线程任然继续执行，其好处就是对线上系统进行最小化的干扰入侵，整个程序还是可以继续响应外部请求的。<br>　　通过下面的设置可以开启non-stop模式，一般都是在gdb开始的时候或者连接调试目标的时候设置才会生效，且在调试过程中不能切换该模式，不是所有平台都支持non-stop模式，所以即使设置了GDB还是有可能fallback到all-stop模式。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">set</span> pagination off</div><div class="line">(gdb) <span class="built_in">set</span> non-stop on</div></pre></td></tr></table></figure></p>
<p>　　non-stop模式的验证也十分的简单，在一个多线程的网络程序中先设置断点，此时发送一个请求那么处理线程会被停止，接下来删除该断点，再次发送一个请求，看该请求是否得到正常响应。如果non-stop正常开启生效的话，此时的info threads会显示其他线程都是running的状态。<br>　　non-stop模式下的命令默认都是针对当前线程的，如果要针对所有线程，通常需要使用-a参数，比如continue -a。</p>
<h3 id="2-5-3_线程相关的断点">2.5.3 线程相关的断点</h3><p>　　<strong>break <em>location</em> thread <em>thread-id</em> [if …]</strong><br>　　在多线程模式下，可以设置线程相关的断点(而不是默认针对所有线程)，其语法类似，只不过需要使用thread关键字指明GDB分配的线程标识符。当线程退出或者gdb在detach的时候，该线程相关联的断点会被自动删除。</p>
<h3 id="2-5-4_中断的系统调用">2.5.4 中断的系统调用</h3><p>　　使用GDB调试多线程程序的时候有一个副作用，就是当线程因为断点或其他因素暂停的时候，其他线程此时如果阻塞在系统调用上，此时的系统调用可能会过早的退出！因为多线程程序调试的时候线程之间需要可能会用信号等手段来通信。<br>　　对此，应当培养良好的系统调用使用习惯，多做系统调用返回值的判断。</p>
<h1 id="三、程序的执行的回放">三、程序的执行的回放</h1><p>　　GDB提供<em>process record and replay target</em>(后面简称R&amp;RT)的功能，可以记录程序的执行过程(execution log)，并在后续时间上进行正向、逆向的程序运行。在调试目标运行的时候，如果接下来的执行指令在log中存在，就会进入replay mode，该模式下不会真正的执行对应的指令，而是将事件、寄存器值、内存值直接从日志中提取出来；如果接下来的执行指令不在log中，GDB将会在record mode执行，所有的指令将会按照正常方式执行，GDB还会记录log方便将来reply。<br>　　进程的R&amp;RT支持正向和逆向执行，即使对应的平台底层调试不支持reverse exec，但是通过reply mode可能模拟这个功能，而record mode可能由于平台的限制不支持reverse exec。<br>　　<strong>record *method</strong><br>　　开启进程的R&amp;RT模式。默认的方法是使用full recording，其实际是GDB采用软件模拟的方式实现的，该模式支持replay reverse exec，不过不支持non-stop mode和异步执行模式的多线程调试。R&amp;RT只能调试正在执行的进程，所以事先需要先使用run|start命令开启调试进程，然后使用record method进行记录。<br>　　<strong>record stop</strong><br>　　停止进程的R&amp;RT，此时所有的log将会被删除，而调试进程将会被终止挥着保持在其最终状态。<br>　　如果是在record模式下(在log的最末尾)使用该命令，被调试的进程将会在下一个要被记录的指令处停止，即如果record了一段时间后停止record，那么调试进程将会保持在类似record从未发生过的状态；如果在replay模式(就是在log的某个中间位置而非末尾)下执行该命令，那么被调试的进程将会在那个点开始进行live正常调试；如果被调试进程退出，或者被detach，那么R&amp;RT将会自动停止。<br>　　<strong>record goto begin|start|end|<em>n</em></strong><br>　　跳转到指定的log位置，除了特殊的begin|start|end，其中的n是log中的instruction的标号。<br>　　<strong>record save|restore <em>filename</em></strong><br>　　log的保存和恢复。如果不指明文件名将会是默认的’gdb_record.process_id’。<br>　　<strong>set record full insn-number-max <em>limit</em>|unlimited</strong><br>　　设置log记录的指令的数目，默认值是200,000。如果设定的limit值是个正数，记录的指令数目超过这个限制后GDB会依次从最先的指令中删除这些旧指令以在不超过这个限制的条件下保存新指令记录，如果其参数值是0或者unlimited，那么久不会有保存数的限制，最终保存的多少将受内存大小的限制。<br>　　<strong>set record full stop-at-limit on|off</strong><br>　　设置在full方式下当保存指令数目超过限制的生活，如果ON(默认)，则GDB会在首次超过限制的生活停止调试进程，并向用户询问是否继续执行下去；如果是OFF，则GDB会自动进行上面删除最旧记录添加最新记录的行为。<br>　　<strong>info record</strong><br>　　显示record记录相关信息，包括当前是Record mode还是Replay mode、最小最大指令记录、当前保存的指令数目、可记录最大条目数限制值等信息。<br>　　<strong>record delete</strong><br>　　当在reply模式下执行该命令的时候，会删除当前所在所在指令之后的所有log记录，即丢失当前指令之后的所有记录，并开始新的record。</p>
<h1 id="四、栈信息检查和回溯">四、栈信息检查和回溯</h1><p>　　由函数调用的原理，一个运行的程序会有多层的stack frame，当被调试程序停止的时候GDB会默认选中当前执行的stack frame(当然后面可以手动选择在各个stack frame之间选择切换)，后续的操作都隐含针对当前选中的stack frame。</p>
<h2 id="4-1_栈结构">4.1 栈结构</h2><p>　　栈帧(stack frame)包含的是传递给函数的参数、函数中的局部变量、已经函数执行的地址(返回地址)信息。当程序最开始执行的时候，只有main函数的一个frame，称其为initial frame或者outermost frame，frame会在函数调用的时候创建并在函数返回的时候删除，当前正在执行的栈称为innermost frame，其地址由frame pointer register寄存器保存，从而可以方便的访问调用参数和局部变量。<br>　　GDB会从innermost开始upward，由0开始对frame进行编号，以方便对特定的stack frame进行引用。<br>　　某些编译器提供某种方法使得编译出来的函数没有stack frame，比如gcc的-fomit-frame-pointer选项，为了就是让那些大量调用的函数节省frame的建立时间，不过其缺点是栈回溯变得困难了。</p>
<h2 id="4-2_Backtrace">4.2 Backtrace</h2><p>　　从当前执行的frame(innermost, 0)开始，沿着其调用者upward的过程。<br>　　<strong>backtrace|bt [n|-n]</strong><br>　　如果没有参数，会打印整个stack，每一行代表一条frame；如果n表示打印innermost n的frame；如果-n表示只打印最outermost n的frame。<br>　　命令info stack是backtrace的别名。<br>　　<strong>backtrace|bt full [n|-n]</strong><br>　　参数和上面的类似，但是还会同时打印每frame的局部变量(调用参数会直接在frame的那一行显示出来)。<br>　　<br>　　在多线程程序的调试中，GDB默认只对当前选中的线程显示backtrace，如果要对其他的线程同样执行类似的跟踪，需要使用前缀的方式<code bash="">thread apply all backtrace</code>才能达到效果，尤其对于调试多线程程序的coredump十分有效。<br>　　backtrace中的函数参数、变量的值可能显示不完美，对于非标量类型的变量会用…显示，而有限变量可能会被优化掉(比如调用的过程中使用寄存器传参)，此时其值会被用’<optimized out="">‘代替。<br>　　默认栈完全回溯会跟踪到main这个outermost层次，如果需要跟踪启动代码，可以设置<code bash="">set backtrace past-main on</code>变量，不过我想一般都用不着这么个层次吧。<br>　　默认情况下backtrace是没有层次限制的(一直顶到main)，通过<code bash="">set backtrace limite n|0|unlimited</code>可以进行设置。</optimized></p>
<h2 id="4-3_选择栈的frame和查看frame">4.3 选择栈的frame和查看frame</h2><p>　　上面说过，很多命令都是隐含针对当前选定的frame操作的。因为GDB对frame都进行了编号，所以既可以用编号进行引用选择，也可以采用相对的up/down操作进行frame的切换。<br>　　<strong>frame|f n</strong><br>　　使用frame编号进行选择，0代表最innermost(当前正在执行)的栈，最大值就是main frame的编号值。<br>　　<strong>frame|f stack-addr</strong><br>　　在stack-addr处选择frame。这通常在frame因为bug被破坏了，导致GDB无法为frame进行编号的生活，以及当程序具有多个stacks并且在他们之间切换的时候。<br>　　<strong>up|down|up-silently|down-silently n</strong><br>　　相对形式的切换frame，参数n默认为1，其值也可以为正数或者负数。</p>
<p>　　<strong>frame|f</strong><br>　　该命令不会切换当前选择的帧，而是简洁的打印当前帧的一些信息。<br>　　<strong>info frame [addr]</strong><br>　　更加详细的打印当前选中frame的信息。<br>　　<strong>info args|locals</strong><br>　　前者打印当前frame的调用参数，后者显示所有可访问的局部变量(包括static或者automatic声明的)。</p>
<h1 id="五、调试与源代码文件">五、调试与源代码文件</h1><h2 id="5-1_打印源代码">5.1 打印源代码</h2><p>　　通过list命令可以显示源代码信息，默认情况下回显示10行源代码，这个设置可以通过变量listsize进行调整。list可以接受0、1、2个参数，使用起来较为的灵活。<br>　　<strong>list location</strong><br>　　该location参数可以是行号，也可以是函数名，表示以该行号为中心或者以该函数开始位置为中心，进行listsize代码行的打印。<br>　　<strong>list +|-</strong><br>　　向前|向后打印刚刚打印代码的位置。<br>　　<strong>list</strong><br>　　这个list会接着打印而不用理会之前的参数。但是+|-的参数会被保留，维持向前、向后的打印顺序。<br>　　**list [first],[last]<br>　　打印指定范围内的代码。</p>
<h2 id="5-2_指定位置信息">5.2 指定位置信息</h2><h3 id="5-2-1_行表示方法">5.2.1 行表示方法</h3><p>　　<strong>-|+offset</strong><br>　　指定位置是相对于当前行的偏移。不过针对不同的命令，current line的含义也有差异，对于list，表示的是最后一次打印的行，对于breakpoint表示的是在当前stack frame执行停止的位置。<br>　　<strong>filename:linenum</strong><br>　　在文件filename的linenum行，如果filename是相对路径名，那么它将会匹配所有的源代码文件。<br>　　<strong>function</strong><br>　　指代的是函数体的开始位置。<br>　　<strong>function:label</strong><br>　　在function中出现的label。<br>　　<strong>filename:function</strong><br>　　在文件filename中出现的函数体的开始位置，指明文件名主要是用于消除函数的二义性。<br>　　<strong>label</strong><br>　　在当前stack frame的label标签指定的位置，如果没有当前stack frame的环境(比如被调试的进程还没有运行)，则GDB不会去搜索label。</p>
<h3 id="5-2-2_显式的位置表示">5.2.2 显式的位置表示</h3><p>　　允许用户采用key=value的方式指明参数名和参数值，这种使用方法在函数、label、文件等具有相同名字的时候具有很大的区分性，同时准确的位置信息也会让GDB更快的定位目标。<br>　　<strong>-source filename</strong><br>　　通常单独的source没有意义，它是和下面的function、line等结合使用的。为了消除可能的文件名歧义，建议对于常用的文件名增加一些额外的路径前缀。<br>　　<strong>-function function</strong><br>　　<strong>-label label</strong><br>　　<strong>-line number</strong><br>　　这里的line既可以是绝对的行号，也可以是相对的(+|-3)行号位置。比如<code bash="">break -s main.c -li 3</code>。</p>
<h3 id="3-2-3_地址信息位置表示">3.2.3 地址信息位置表示</h3><p>　　通常的地址信息会使用<code bash=""><em>addr</em></code>的形式来表示。<br>　　<strong>expression</strong><br>　　<strong>funcaddr</strong><br>　　<em>*’filename’:funcaddr</em></p>
<h2 id="5-3_修改源代码">5.3 修改源代码</h2><p>　　<strong>edit</strong>命令可以修改源代码文件，其编辑的位置是在调用edit命令时候，调试程序中当前活动的那一行。可以通过给edit命令额外的参数确定位置：number 当前活动文件的行号，function 函数定义的开始位置。<br>　　EDITOR环境变量可以指定修改源代码所使用的编辑器名字，因此通过设置<code bash="">export EDITOR=vim</code>就可以完成默认编辑器的设定。<br>　　打印完是不是可以直接shell make编译啦！</p>
<h2 id="5-4_源代码和机器码的对应及反汇编">5.4 源代码和机器码的对应及反汇编</h2><p>　　通过info line可以建立源代码行号和程序地址之前的对应关系，而disassemble可以显示一段地址中机器指令。GDB还有一个变量’disassemble-next-line’，当打开他的时候会在程序停止的时候自动显示要执行的下一行源代码的第一条汇编代码，而如果下一条执行的指令没有调试信息，就会显示下一条机器指令的反汇编结果。<br>　　<strong>info line <em>location</em></strong><br>　　打印locatin代表的源代码行编译后的其实地址和结束地址。当然也可以进行反方向的隐射查询，通过地址查询其对应源代码的那一行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(gdb) info line 14</div><div class="line">Line 14 of <span class="string">"aa.cpp"</span> starts at address 0x4008d9 &lt;main(int, char**)+47&gt; and ends at 0x4008e2 &lt;main(int, char**)+56&gt;.</div><div class="line">(gdb) info line *0x4008e0</div><div class="line">Line 14 of <span class="string">"aa.cpp"</span> starts at address 0x4008d9 &lt;main(int, char**)+47&gt; and ends at 0x4008e2 &lt;main(int, char**)+56&gt;.</div></pre></td></tr></table></figure></p>
<p>　　<strong>disassemble [/m|/s|/r] [start, end]|[start, +len]</strong><br>　　<strong>disassemble [/m|/s|/r] <em>location</em></strong><br>　　可以显示一段地址范围的反汇编信息，或者函数名等其他代表的地址信息的反汇编结果，如果是跨文件的记住使用<code bash="">disassemble ‘foo.c’::bar</code>这样的形式。/m或者/s参数可以显示源代码和反汇编代码同时交叉显示的效果，/r还会以hex的方式显示机器码，当然这对一般人来说使用较少。<br>　　<strong>set disassembly-flavor intel|att</strong><br>　　反汇编是显示intel还是att的风格，个人比较偏向att的格式，这也是GDB的默认行为。</p>
<h1 id="六、查看数据">六、查看数据　　</h1><p>　　最常用的检查数据的命令就是<strong>print|p|inspect</strong>，其接受一个表达式作为参数，会根据调试的语言对表达式进行求值，并将其结果打印出来。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">print</span> expr</div></pre></td></tr></table></figure></p>
<p>　　一种更加底层检查数据的方式是使用<strong>x</strong>命令，该命令会检查内存中特定地址的数据并通过特定的格式显示出来。<br>　　如果想知道表达式的类型而不是关系其值的话，可以使用<strong>ptype <em>expr</em></strong>命令，就可以显示出struct、class等复杂变量的类型信息。</p>
<h2 id="6-1_表达式">6.1 表达式</h2><p>　　GDB的表达式可以支持普通表达式、条件表达式、函数调用、类型转换、字符串常量、宏等类型，同时使用’{elem1, elem2, …}’这种表达式还可以创数组常量。<br>　　<strong>@</strong> 该操作符用于将一段内存当做数组使用<br>　　<strong>::</strong> 该曹组福用于指明在文件或者函数中的变量<br>　　<strong>{type} addr</strong> addr可以是一个整形或者指针，该表达式用于将指定位置的内存引用为type类型的变量。</p>
<h2 id="6-2_二义性的表达式">6.2 二义性的表达式</h2><p>　　由于重载和模板机制，在C++这类语言中二义性的表达式非常常见，在这种情况下通常需要给出函数的参数签名’function(types)’等信息才能和其他同名对象进行区分。GDB会自动探测二义性的存在，给出所有可能性的选择列表，并最终给出’&gt;’提示符信息让用户选择，固定的选项是’[0] cancel’和’[1] all’，后面的选项是各个明细，比如<code bash="">break String::after</code>这样的命令，用空格分割的选项才会打上断点。<br>　　<strong>set multiple-symbols all|ask|cancel</strong><br>　　默认参数值是all，当某个命令的表达式有多个选项的时候，GDB会自动选择所有可能的选项，但是某些环境下必须有一个选项的时候，GDB会显示出上面所述的菜单供选择；ask表示只要二义性检测到了，就会给出菜单让做出选择；cancel表示当debuger探测到二义性的时候会当做错误，相应的命令被放弃执行。</p>
<h2 id="6-3_程序变量">6.3 程序变量</h2><p>　　程序的变量算是最常被在表达式中使用的，变量是在当前选择的stack frame中可见的，他们可以是：全局变量、file-static变量、根据变成语言语法规则可见的变量。这里有一个例外，就是你可以引用file-scope的变量或者函数，即使当前执行的上下文不在该文件当中。<br>　　各个函数中的变量，以及各个文件中的函数或者变量可能会出现重名的情况，这个时候就需要’::’操作符进行指定<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">file::variable  file::<span class="keyword">function</span></div><div class="line"><span class="keyword">function</span>::variable</div><div class="line">(gdb) p <span class="string">'aa.cpp'</span>::main::b</div></pre></td></tr></table></figure></p>
<p>　　在调试的时候，有时候会出现在函数进入作用域和返回的生活，某些局部变量的值是错误的，尤其是当进行机器指令单步的时候，因为很多机器上stack frame的建立(包括局部变量的定义)和函数返回的时候stack frame的销毁，都不是单个机器指令可以解决的，所以在stack frame完全建立和销毁的时候，检查到的变量值很可能是异常的。<br>　　一些没有被使用的变量也可能被编译器优化掉，这时候价差这些变量的值可以提示他们不存在。</p>
<h2 id="6-4_人工数组">6.4 人工数组</h2><p>　　通常用于需要打印内存中连续对象的时候以及变长数组的时候特别的有用，其语法结构是<code bash="">*addr@len</code>，在@的左边是目标数组的第一个元素，右边的操作数是数组的期望长度，所得到的结果是一个元素跟左操作数类型一样的数组。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> *arry = (<span class="keyword">int</span> *)<span class="built_in">malloc</span>(len * <span class="keyword">sizeof</span> (<span class="keyword">int</span>));</div><div class="line">p *arry@len</div></pre></td></tr></table></figure></p>
<p>　　另外一种创建人工数组的方式是使用cast类型转换，将一个值重新使用数组去解释，比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">(gdb) p/x (short[4])0x123456789AL</div><div class="line"><span class="variable">$4</span> = &#123;0x789a, 0x3456, 0x12, 0x0&#125;</div><div class="line">(gdb) p/x (short[])0x123456789AL</div><div class="line"><span class="variable">$5</span> = &#123;0x789a, 0x3456, 0x12, 0x0&#125;</div></pre></td></tr></table></figure></p>
<p>　　当然如果你不设置数组的长度，而直接使用<code bash="">(type[])value</code>，那么GDB会自动计算数组的长度<code bash="">sizeof(value)/sizeof(type)</code>。<br>　　有时候人工数组也不见得方便，比如存储的元素是有规律的但是在物理上不是连续的，那么上面的方法就没法使用了，这个时候最常用的是用convenience变量，然后直接用RET依次遍历元素：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> <span class="variable">$i</span> = 0</div><div class="line">p dtab[<span class="variable">$i</span>++]-&gt;fv</div><div class="line">RET</div><div class="line">RET...</div></pre></td></tr></table></figure></p>
<h2 id="6-5_输出格式">6.5 输出格式</h2><p>　　print默认是根据表达式的类型自动显示的，在大多数情况下都可以工作的很好，但是在print中可以指定输出格式得到个性化得显示结果。下面的格式参数通过/和print命令相连，比如<code bash="">print/x $pc</code><br>　　x 把表达式当做一个int，并使用hex方式显示该整数<br>　　d|u 作为有符号|无符号十进制整数打印<br>　　o|t 作为八进制|二进制数打印<br>　　a 在打印地址的时候，通过最近符号加偏移的方式解析这个地址，和info symbol得到的结果类似<br>　　c 以十进制和字符的方式显示<br>　　f 以浮点数的形式打印<br>　　s 如果可以以字符串的方式显示。如果只想的目标是单字节的数据，则表示为null结尾的字符串；如果是单字节的数组，则表示为定长度的字符串；其他情况正常方式显示<br>　　z 类似x以十六进制显示数据，但是头部的字符会使用0补齐</p>
<h2 id="6-6_内存检查">6.6 内存检查</h2><p>　　通过命令’x’可以进行内存数据检查。其命名格式为(nfu是控制内存显示的大小、格式等参数信息的)<br>　　<code bash="">x /nfu addr</code><br>　　<strong>n</strong>(显示数目) 默认值是1，指明需要单位内存(u指明)显示的数目。如果n的值是负数，那么将会从addr开始进行反方向的内存显示。<br>　　<strong>f</strong>(显示格式) 显示的格式参数和上面print命令的输出格式相类似(包括：x、d、u、o、t、a、c、f、s)，初次还包括i用于机器指令的显示。默认情况下是使用x进行hex显示，该值会随着x|print命令的操作而更新。<br>　　<strong>u</strong> 显示单位尺寸 b(bytes，1字节)、h(半字，2字节)、w(字，4字节)、g(gaint字，8字节)，同样该参数会随着每次使用x被自动记住并在下次命令中自动应用。对于i显示机器指令该参数会被忽略，而对于s该参数默认是b。<br>　　由于<strong>f</strong>和<strong>u</strong>两个格式参数的空间是不重叠的，所以可以以任意顺序显示，但是n必须在他俩之前。<br>　　<strong><em>addr</em></strong> 指定需要检查的起始地址位置，比如函数名等，其最终会被解析成一个整形的地址值。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) x/20i main</div><div class="line">(gdb) x/4xw <span class="variable">$sp</span></div></pre></td></tr></table></figure></p>
<h2 id="6-7_自动显示">6.7 自动显示</h2><p>　　对于需要经常查看的表达式，可以使用display命令将其添加到自动显示列表中，这样每次程序停止执行的时候，就会自动显示该表达式的值，加入的表达式会自动产生一个递增的整形编号。display也可以使用print|x命令的参数进行格式化输出控制，而且其内部如果发现格式化参数包含i|s或者数字，就会调用x；否则会调用print进行输出。<br>　　<strong>display[/fmt] expr</strong><br>　　<strong>display/fmt addr</strong> 使用’i’、’s’格式，或者指定了数字<br>　　将表达式或者要检查的内存地址添加到自动显示列表中去。<br>　　比如想要自动显示下一条要执行的指令，可以做如下添加：<code bash="">display/i $pc</code>。<br>　　<strong>undisplay dnums…</strong><br>　　将对应编号的表达式或者内存从自动显示列表中删除。列表可以使用逗号’,’进行分割，以及使用2-4这种范围表示。<br>　　<strong>info display</strong><br>　　<strong>enable|disable display dnums…</strong><br>　　查看、禁用或者使能自动显示。<br>　　<strong>display</strong><br>　　进行自动显示列表中表达式值的显示，就像程序刚停止时候自动显示的效果相同。<br>　　如果添加自动显示的表达式引用到了局部变量，GDB会自动考虑其上下文信息，如果执行的上下文中该局部变量没有定义则不会显示其值，而如果下次再次进入定义该变量的上下文，则该表达式变得有意义会再次显示其值。无论如何，info display总会显示该表达式的相关信息。</p>
<h2 id="6-8_数值历史(Value_History)">6.8 数值历史(Value History)</h2><p>　　通过使用print命令显示的值会被自动保存在GDB的数值历史当中，该值会一直被保留直到符号表被重新读取或者放弃的时候(比如使用file或symbol-file)，此时所有的值历史将会被丢弃。在使用print打印值的时候，会将值编以整形的历史编号，然后可以使用<strong>$num</strong>的方式方便的引用，单个的<strong>$</strong>表示最近的数值历史，而<strong>$$</strong>表示第二新的数值历史，<strong>$$n</strong>表示倒数第n新的数值历史(所以可以推断<code bash="">$$0==$; $$1==$$;</code>)。<br>　　比如刚刚打印了一个指向结构体的指针，那么<code bash="">print <em>$</em></code>就可以显示结构体的信息，而命令<code bash="">print $.nex</code>甚至可以显示结构体中的某些字段。</p>
<h2 id="6-9_Convenience变量">6.9 Convenience变量</h2><p>　　GDB允许自由创建便捷变量用于保存值，后续可以方便的引用该值，该类型的变量由GDB管理而与正在调试的程序没有直接的关联。便捷变量也是使用符号<strong>$</strong>打头的，可以使用任意名字(除了GDB使用的寄存器名)。<br>　　在任意时候使用一个便捷变量都会创建他，如果没有提供初始化值那么该变量就是void，直到给其进行赋值操作为止。便捷变量没有固定的类型，可以为普通变量、数组、结构体等，而且其类型可以在赋值过程中改变(为当前值的类型)。<br>　　<strong>show convenience|conv</strong><br>　　显示道目前所有的便捷变量和便捷函数，以及其值。<br>　　<strong>init-if-undefined $variable = expr</strong><br>　　如果该变量还没有被创建或初始化，则创建这个变量。如果该变量已经被创建了，则不会创建和初始化该变量，并且expr表达式也不会被求值，所以这种情况下也不会有expr的副作用发生。<br>　　便捷变量的一种经典用法，就是之前提到的连续查看变量时候用于计数作用：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">set</span> <span class="variable">$i</span> = 0</div><div class="line"><span class="built_in">print</span> bar[<span class="variable">$i</span>++]-&gt;contents</div></pre></td></tr></table></figure></p>
<p>　　下面的一些便捷变量是GDB自动创建的：<br>　　<strong>$_exitcode</strong><br>　　当调试程序终止的时候，GDB将会根据程序的退出值自动设置该变量，并且将<strong>$_exitsignal</strong>变量设置为void。<br>　　<strong>$_exitsignal</strong><br>　　当调试中的程序因为一个未捕获信号而终止，此时GDB会自动将变量<strong>$_exitsignal</strong>设置为该信号，同时重置变量<strong>$_exitcode</strong>为void。</p>
<h2 id="6-10_Convenience函数">6.10 Convenience函数</h2><p>　　便捷函数和便捷变量一样使用<strong>$</strong>打头引用，其可以像一个普通函数一样在表达式中使用，便捷函数只被GDB内部使用。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> <span class="variable">$_isvoid</span> (<span class="variable">$_exitsignal</span>)</div></pre></td></tr></table></figure></p>
<p>　　<strong>$_isvoid (expr)</strong><br>　　如果expr是void则返回1，否则返回0。<br>　　GDB还有很多的便捷函数支持，但是需要在编译GDB的时候提供Python的支持才可以使用。下面的这些函数意义显而易见，就不在啰嗦了。<br>　　<strong>$_memeq</strong>(buf1, buf2, length); <strong>$_regex</strong>(str, regex); <strong>$_streq</strong>(str1, str2); <strong>$_strlen</strong>(str)</p>
<h2 id="6-11_寄存器">6.11 寄存器</h2><p>GDB可以像普通变量一样引用机器的寄存器值，通过<strong>$</strong>打头。<br>　　<strong>info registers</strong><br>　　<strong>info all-registers</strong><br>显示机器所有寄存器的名字和其当前值信息。后者比前者会多出浮点寄存器和向量寄存器。</p>
<h2 id="6-12_操作系统信息">6.12 操作系统信息</h2><p>通过直接的info os可以显示出GDB支持的操作系统信息类别。<br>　　<strong>info os infotype</strong><br>　　files 列出目标上面打开的文件信息。<br>　　modules 列出目标上加载的内核模块信息。<br>　　msg 列出目标上所有的Sys V消息队列信息。<br>　　processes 列出目标上所有的进程信息。<br>　　semaphores 列出目标上所有Sys V信号量信息。<br>　　shm 列出目标上所有Sys V共享内存信息。<br>　　sockets 列出目标上所有Internet-domain socket信息。<br>　　threads 列出目标上所有线程信息。</p>
<h2 id="6-13_内存和文件拷贝">6.13 内存和文件拷贝</h2><p>　　通过dump、append、restore命令可以在目标机之间传递数据和内存信息。dump命令和append命令将数据写入(追加)到文件中，而restore会读取文件内容并将其加载到调试进程的指定内存位置中。GDB默认使用binary的文件格式，推荐使用该格式。<br>　　<strong>dump|append memory <em>filename</em> <em>start_addr</em> <em>end_addr</em></strong><br>　　<strong>dump|append value <em>filename</em> <em>expr</em></strong><br>　　<strong>restore <em>filename</em> binary <em>bias</em> <em>start</em> <em>end</em></strong><br>　　其中一个比较重要的参数是bias，如果其值为非0，那么这个值将会作为偏移添加到文件中所有地址值上面。因为二进制文件总是从地址0开始，所以在恢复的时候需要添加这个偏移值。</p>
<h2 id="6-14_产生core文件">6.14 产生core文件</h2><p>　　core文件是运行进程的内存镜像和运行状态信息(比如寄存器等)的集合。通过配置，操作系统可以在程序挂掉的时候自动产生coredump文件，而在GDB调试的时候，也支持使用命令方式手动创建coredump文件，这样就可以快速创建一个程序在当时的快照。<br>　　<strong>generate-core-file|gcore [file]</strong><br>　　如果没有提供名字，那么默认将产生core.pid文件名格式的dump文件。</p>
<h2 id="6-15_内存查找">6.15 内存查找</h2><p>　　使用命令find可以对内存进行序列字节的查找操作。<br>　　<strong>find [/sn] start_addr, +len, val1 [, val2, …]</strong><br>　　<strong>find [/sn] start_addr, end_addr, val1 [, val2, …]</strong><br>　　该命令会在内存中搜索var1、var2…字符序，其范围从start_addr开始，以结束地址或者长度结束。<br>　　参数s表示搜索的大小，可以是b、h、w、g(跟之前的x命令一样)，如果该参数没有指定，GDB会考虑当前调试程序的语言环境确定，比如0x43这种整数就默认为w(4字节)类型；n表示打印最大搜索命中数量，默认行为是全部打印。该命令还可以搜索字符串，字符串使用双引号括住。<br>　　对于查找结果，命中数目保存在变量<strong>$numfound</strong>中，而最后一个值命令的地址保存在<strong>$_</strong>中。</p>
<h1 id="七、跟踪点(Tracepoint)">七、跟踪点(Tracepoint)</h1><p>　　有些情况不适合把线上的业务停下来，进行长时间的跟踪和调试；还有些行为只有在线上实时运行的环境才能重现，延时或者线下环境无法复现的问题，针对这种类型的情况，需要不打断程序的运行去观察程序的行为。<br>　　通过GDB的<strong>trace</strong>和<strong>collect</strong>命令，可以在程序中设置跟踪点，然后在跟踪点到达(命中hit)的时候计算事先构造的表达式的值；接下来，通过<strong>tfind</strong>命令，可以检查这些跟踪点中表达式在当时所记录下来的值。当前跟踪点的功能值在remote target的情况下支持，该功能是在remote stub中实现的，但是当前情况下的GDB还没有实现，目前主要使用的方式是使用文件的方式操作。</p>
<h2 id="7-1_设置跟踪点">7.1 设置跟踪点</h2><p>　　跟踪点实际上是一种特殊的断点，所以可以使用任何标准断点的命令来操作跟踪点，和断点不同的是不支持ignore count、不支持针对特定于线程的跟踪点。对于每一个跟踪点，可以事先指明到达的时候所需要搜集的数据，包括寄存器、局部变量和全局变量，之后可以使用GDB的命令来检查这些在当时收集到的数据值。<br>　　跟踪点是动态跟踪工具，意味着这些跟踪点可以被插入在目标的任何位置。<br>　　静态跟踪点暂且不表。</p>
<h3 id="7-1-1_创建和删除跟踪点">7.1.1 创建和删除跟踪点</h3><p>　　<strong>trace location</strong><br>　　**其中的location可以是和break命令参数一样的任意有效位置，通过trace命令可以创建一个跟踪点，当debuger遇到的时候会暂停，收集完相应地数据后继续执行。GDB还支持pending tracepoint，类似于断点的原理，表示在一些共享库还没有加载的时候地址无法解析。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">trace foo.c:121 trace *0x12322 trace +2</div><div class="line">trace my_<span class="keyword">function</span> //函数的第一行</div><div class="line">trace *my_<span class="keyword">function</span> //函数的准确起始地址</div></pre></td></tr></table></figure></p>
<p>　　<strong>trace location if <em>cond</em><br>　　带有条件的，只有当cond取值为true(非零)的时候，才会进行数据的收集，避免每次到达跟踪点都收集数据导致数据量暴增，而往往很多情况下的数据是没有价值的。<br>　　条件跟踪点既可以在创建的时候使用if进行限定，也可以后续使用类似breakpoint情况下的condition命令进行设定修改。和断点不同的是，GDB不会自己去对条件表达式进行取值，而是将该表达式编码给agent(独立于GDB)。
　　</strong>delete tracepoint [num]<strong><br>　　永久性地删除一个或者所有(不带参数)的跟踪点。
　　</strong>disable|enable tracepoint [num]<strong><br>　　禁用|使能某个或者所有的跟踪点。
　　</strong>info tracepoints [num…]**<br>　　显示某个或者全部跟踪点的信息，使用方法和info breakpoints相同。</p>
<h3 id="7-1-2_跟踪点计数">7.1.2 跟踪点计数</h3><p>　　<strong>passcount [n [num]]</strong><br>　　passcount是一种自动停止trace experiment的方式，当tracepoint被命中n次之后trace experiment会自动停止。<br>　　当使用passcount带有n但是不带num参数的时候，n将会作用于最近添加的跟踪点。如果不适用passcount进行设定，默认行为跟踪点将会一直运行直到被用户显式地停止。</p>
<h3 id="7-1-3_跟踪状态变量">7.1.3 跟踪状态变量</h3><p>　　trace state variable是一种特殊类型的变量，它是在target-side创建和管理的(但是对GDB可见)，和GDB的convenience变量语法相同，必须采用tvariable命令显式创建，并且总是64位的整形。<br>　　虽然trace state variable是被target端管理的，但是可以在GDB中像使用convenience variable一样使用它们，GDB会在trace experiment运行的时候从target端获取该变量的当前值。该变量也是使用符号<strong>$</strong>打头的，和GDB其他变量在同一个名字空间中，所以需要注意不能重名。<br>　　<strong>tvariable $name [ = expr]</strong><br>　　创建名为<strong>$name</strong>的trace state variable，并且可选地给其一个初始值。初始值得表达式expr是在该变量创建的时候就进行取值的，得到的结果将会转换成64位整形类型。后续再使用tvariable接上已经存在的变量名的时候，实际不会进行创建操作，而是将之前的变量进行重新赋值。如果没有提供初始值，默认初始值是0。<br>　　<strong>info tvariable
　　</strong>delete tvariable [ $name … ]**<br>　　如果没有提供额外参数，将会删除所有的变量。</p>
<h3 id="7-1-4_跟踪点行为列表">7.1.4 跟踪点行为列表</h3><p>　　<strong>actions [num]</strong><br>　　用于指明在跟踪点被命中的时候所需要执行的操作，如果没有提供num参数，那么该设置默认针对于最新创建的跟踪点。<br>　　这些行为列表中的命令一行一个，通过单个end标示着结束，当前所支持的行为包括collect、teval和while-stepping，其实使用起来跟command命令十分的类似，只不过其命令的内容只能是上面允许的，而不能是其他的GDB调试命令。要想删除跟踪点的actions，则提供空的end就可以了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">(gdb) trace sum</div><div class="line">Tracepoint 1 at 0x4008a4: file aa.cpp, line 5.</div><div class="line">(gdb) actions</div><div class="line">Enter actions <span class="keyword">for</span> tracepoint 1, one per line.</div><div class="line">End with a line saying just <span class="string">"end"</span>.</div><div class="line">&gt;collect a, b</div><div class="line">&gt;collect <span class="variable">$regs</span></div><div class="line">&gt;<span class="keyword">while</span>-stepping 4  <span class="comment">#single step 4 times, collect data</span></div><div class="line"> &gt;collect c</div><div class="line"> &gt;end</div><div class="line">&gt;end</div><div class="line">(gdb)</div></pre></td></tr></table></figure></p>
<p>　　<strong>collect [/mods] expr1, expr2, …</strong><br>　　收集用逗号分隔的各个表达式的值。收集的对象除了全局变量、静态变量、局部变量，还可以包含：<br>　　<strong>$regs</strong> 所有的寄存器<br>　　<strong>$args</strong> 函数的所有调用参数<br>　　<strong>$locals</strong> 所有局部变量<br>　　<strong>$_ret</strong> 函数的返回地址<br>　　<strong>teval expr1, expr2, …</strong><br>　　当跟踪点被命中的生活，计算表达式的值，该命令接收使用逗号风格的多个表达式。取值表达式的结果将会被丢弃，所以该命令的主要用处是在不添加这些值在trace buffer的同时，将表达式计算并赋值给trace state variable。<br>　　<strong>while-stepping n</strong><br>　　在跟踪点之后进行n步的单步调试，并且在每次单步执行后进行数据的搜集，需要收集的数据在while-stepping后使用collect表示，并使用end结尾。<br>　　<strong>set default-collect expr1, expr2</strong><br>　　该变量可以是使用逗号分隔的一大串表达式表明默认需要收集的值，表明在每个跟踪点默认都要搜集的数据。注意的是这个表达式是在每个跟踪点独立解析的，所以相同的表达式、名字在各个跟踪点可能被解析为不同对象。</p>
<h3 id="7-1-5_开始和停止跟踪执行">7.1.5 开始和停止跟踪执行</h3><p>　　<strong>tstart</strong><br>　　该命令启动trace experiment并且开始搜集数据，该命令的副作用是丢弃所有在trace buffer中的已经存在的历史数据。如果给该命令提供了参数，他们将会被视为note并被存储起来。<br>　　<strong>tstop</strong><br>　　该命令会停止trace experiment，如果<strong>某个跟踪点</strong>已经达到其passcount，或者trace buffer的缓冲区已经满了，那么trace experiment会自动停止。如果给该命令提供了参数，他们将会被视为note并被存储起来。<br>　　<strong>tstatus</strong><br>　　用于显示跟踪和收集到的数据信息。</p>
<h3 id="7-1-6_Tracepoints的限制">7.1.6 Tracepoints的限制</h3><p>　　因为收集数据的行为是在target自动进行的，所以GDB无法做出细致的控制，而且后续检查数据的时候也仅基于已经收集到的历史数据。<br>　　(1) 因为跟踪点的首要目标是收集作值，所以GDB的复杂表达式往往是不可用的。在收集的过程中不能调用函数、进行类型转换、访问convenience变量、修改变量值等操作。</p>
<h2 id="7-2_使用跟踪记录的数据调试">7.2 使用跟踪记录的数据调试</h2><p>　　当trace experiment结束后，可以使用GDB命令来查看已经收集到的数据，这些收集的数据都是每次命令跟踪点收集到数据的快照。所有GDB的命令(比如print、info registors、backtrace等)的请求，都会像当时跟踪点命中时候的状态值进行对应返回，而请求那些没有收集到的数据将会失败。</p>
<h2 id="7-2-1_tfind">7.2.1 tfind</h2><p>　　通过使用命令<strong>tfind <em>n</em></strong>可以查看缓冲区中第n个快照，缓冲区中的快照都是从0开始编号的，如果tfind你没有接参数，将会依次访问下一个快照。<br> 　　<strong>tfind start</strong><br> 　　<strong>tfind none|stop</strong><br> 　　<strong>tfind -</strong><br> 　　<strong>tfind tracepoint num</strong><br> 　　<strong>tfind pc addr</strong><br> 　　<strong>tfind line [file:]n</strong></p>
<h2 id="7-2-2_tdump">7.2.2 tdump</h2><p>　　该命令不接受任何参数，其用于打印当前trace snapshot所收集到的所有数据。tdump通过扫描跟踪点的当前收集行为，然后按照其行为打印对应每个表达式的值。</p>
<h2 id="7-3_使用Trace_Files">7.3 使用Trace Files</h2><p>　　可以将线上收集到的数据保存到文件当中，后续可以通过target tfile进行加载，就像使用原始的trace数据一样访问。<br>　　<strong>tsave [-r] filename</strong><br>　　默认的情况下该命令保存在host的文件系统中，所以GDB将会从target上面拷贝对应的数据到本地保存。如果target支持的话，可以通过’-r’参数，直接将数据保存在target的文件系统上面，这样在收集到的数据量很大的时候会更加的高效。<br>　　<strong>target tfile filename</strong><br>　　加载tfile数据，使后面可以感觉和target在线访问的效果，只不过只能访问历史数据而不能进行任何新的trace experiment。</p>
<h1 id="八、GDB对编程语言的支持">八、GDB对编程语言的支持</h1><h2 id="8-1_GDB对C/C++语言的支持">8.1 GDB对C/C++语言的支持</h2><h3 id="8-1-1_GDB对C/C++语言的支持">8.1.1 GDB对C/C++语言的支持</h3><p>　　因为总所周知的原因，GCC和GDB对C/C++的支持一直很不错，包括在gdb命令行中的表达式、操作符的使用就可见一斑了。C++要比C复杂的多，所以下面罗列了一些GDB和C++调试的一些东西。<br>　　C++成员函数的调用是支持的，形如:<code cpp="">count = aml-&gt;GetOriginal(x, y);</code>；<br>　　当成员函数正在被调试(作为选中的stack frame)的时候，调试的表达式具有和成员函数一样的名字空间；<br>　　在某种程度上支持C++重载函数的调用，GDB会进行解析并指向正确的函数调用。但是限制是：GDB不支持用户定义类型转换所支撑的函数重载，以及调用不纯在的构造函数，没有对应类型实例化的模板函数，也不能处理省略的和默认的函数参数。对于数值类型转换、类型提升都是正常支持的。函数重载默认是使能的，除非使用<code bash="">set overload-resolution off</code>关闭之，然后就可以显式调用重载版本的重载函数了：<code bash="">p’foo(char,int)’(‘x’,13)，自然GDB的补全功能不会让你输的很累的。<br>　　GDB支持C++的::名字解析操作符，正如同函数代码中使用方式一样。</code></p>
<h3 id="8-1-2_针对C++的其他GDB特性">8.1.2 针对C++的其他GDB特性</h3><p>　　针对C++的重载特性，GDB可以自动补全所有的重载版本列表，方便识别和选择；<strong>rbreak <em>regex</em></strong>这种正则形式的断点，可以在所有重载版本的函数上实现添加。<br>　　<strong>catch throw|rethrow|catch</strong> 可以提供C++异常处理的监测支持。<br>　　<strong>ptype <em>typename</em></strong> 可以显示该类型的继承关系，同时其成员变量和成员函数也显示的较为详细。<br>　　<strong>info vtbl <em>expr</em></strong> 对多态机制虚函数表的支持。</p>
<h2 id="8-2_C语言预处理宏">8.2 C语言预处理宏</h2><p>　　宏本身是个比较麻烦的东西，因为可以某些点定义、某些点取消定义、某些点重新定义，GDB支持对含有宏的表达式进行展开并显示展开后结果的功能。如果要让编译后的程序具有宏调试功能，需要额外的编译参数-gdwarf-2和-g3(-g是不够的)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  gdb gcc -gdwarf-2 -g3 sample.c -o sample</div></pre></td></tr></table></figure></p>
<p>　　上面的gdwarf-2具有gdwarf-3、gdwarf-4等版本，推荐支持的情况下使用最新版本的调试格式。<br>　　<strong>macro exp|expand <em>expression</em></strong><br>　　显示expression中所有宏被展开后的结果。因为GDB只会进行宏展开而不会对表达式取值，所以这里的expression不需要是合法的表达式。<br>　　<strong>info macro [-a|-all] [–] <em>macro</em></strong><br>　　显示当前的或者全部的macro宏定义，同时显示该宏定义所在的源代码文件及其所在行号位置信息。其中的–表示参数列表结束，因为C中有些宏是可以使用-开头的，这里用于消除歧义作用。<br>　　<strong>info macros <em>location</em></strong><br>　　显示所有在location位置有效的宏定义及他们的位置信息。(显示结果有点多哦)<br>　　<strong>macro define <em>macro</em> <em>replacement-list</em></strong><br>　　<strong>macro define <em>macro</em>(<em>arglist</em>) <em>replacement-list</em></strong><br>　　自定义宏及其展开式，通过该命令创建的宏会在GDB求值的每个表达式中都会生效(只对GDB本身作用，与代码中使用的宏无关)，直到其显式使用macro undef进行删除，同时该宏还会覆盖程序中同名宏的展开(有点诡异)。<br>　　<strong>macro undef <em>macro</em></strong><br>　　只会删除上面使用macro define定义的宏，而不会删除程序代码中定义的宏。<br>　　<strong>macro list</strong><br>　　显示所有通过macro define定义的宏。<br>　　除了通常在源代码中执行宏定义，还可以在编译的时候在命令行中通过<code bash="">‘-Dname=value’</code>的方式定义，这样的宏也支持使用info macro命令查看，不过其行号信息显示为0。</p>
<h1 id="九_修改调试程序的执行">九 修改调试程序的执行</h1><p>　　例如在程序调试的过程中发现了明显的错误，想要验证修改该简单错误后程序执行会不会得到正确结果的时候，GDB的alter execution功能就会比较的好用，支持比如：修改某个寄存器、变量、内存的值，向程序发送某个信号，从不同的地方重新执行，直接跳出函数执行等操作。</p>
<h2 id="9-1_给变量重新赋值">9.1 给变量重新赋值</h2><p>　　下面都是将变量x修改为新值，区别是使用print会同时打印这个变量的值，同时还会降其放入历史记录中去。在使用set的时候还需注意，因为gdb中有很多变量也是使用set设置更新的(比如width)，此时就应该使用set variable|var而不能使用set简写了，并且使用后者总是一个好习惯，可以防止莫名其妙的修改了环境变量值而不知。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> x=8</div><div class="line">(gdb) <span class="built_in">set</span> x=8</div></pre></td></tr></table></figure></p>
<p>　　GDB中对于变量类型的转换要比C/C++语言宽松的多，比如可以把整数当做指针使用等，也可以直接将值放到指定内存位置上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">(gdb) <span class="built_in">print</span> &amp;a</div><div class="line"><span class="variable">$2</span> = (int *) 0x7fffffffe1ec</div><div class="line">(gdb) <span class="built_in">set</span> &#123;int&#125;0x7fffffffe1ec = 9789</div><div class="line">(gdb) <span class="built_in">print</span> a</div><div class="line"><span class="variable">$3</span> = 9789</div></pre></td></tr></table></figure></p>
<h2 id="9-2_从不同位置恢复执行">9.2 从不同位置恢复执行</h2><p>　　默认使用continue恢复程序执行的时候，会从之前停止的位置继续执行，而使用jump命令可以指定程序恢复执行的位置。该命令很多时候是调回已经执行的代码，重新设置某些变量，然后再次执行下来。<br>　　<strong>jump|j <em>location</em></strong><br>　　在location的位置恢复执行，如果该处有断点则会立即停止，而且有时候为了达到这个效果会同tbreak组合使用。jump除了修改程序计数器之外，<strong>不会修改</strong>当前stack frame、stack pointer、内存信息和其他的寄存器信息，所以如果使用jump调到别的函数位置开始执行，那么结果将会变得十分离奇，因此如果location的地址不在当前执行函数范围内，GDB会给出信息要求确认。<br>　　将<strong>$pc</strong>直接设置新值，然后运行continue也会得到相同的效果。</p>
<h2 id="9-3_向程序发送信号">9.3 向程序发送信号</h2><p>　　<strong>signal <em>sig</em></strong><br>　　恢复程序的执行并立即给予其sig信号。如果sig为0，程序将不会收到信号并恢复执行，这常常用于程序因为收到某个信号而停下来，该信号原本会传递给应用程序的时候，通过’signal 0’可以让程序不收到该信号而继续执行。注意在多线程的环境下，当恢复执行程序的时候信号会被传送到当前选定的线程(而可能不是最后停止下来的线程)，因此如果要使用’signal 0’屏蔽信号，必须先选中对应正确的线程，否则GDB也会探测并给出确认提示。<br>　　此处的signal发送信号和命令kill发送信号是不同的，后者仍然会通过GDB根据handle觉得过滤处理，而signal会直接将信号传递给调试的应用程序。<br>　　<strong>queue-signal <em>sig</em></strong><br>　　将sig信号排队给当前线程，并在程序恢复执行的时候立即发送，要求sig的handle必须是pass的，否则GDB会报错。<br>　　sig参数还可以是0，起效果是当前线程所有排队的信号将会被清空，程序恢复执行的时候将没有信号发给该线程。该命令和上面signal不同的是signal会导致程序的恢复执行，再则queue-signal发送的信号必须是pass处理的信号。</p>
<h2 id="9-4_函数中返回">9.4 函数中返回　</h2><p>　　<strong>return [expr]</strong><br>　　该命令可以取消一个函数的执行，如果提供了expr表达式，则该表达式的值将会作为函数的返回值。<br>　　当使用了该命令，GDB会放弃当前选定的stack frame及其包含在其内部的所有stack frame，使得该函数的调用者作为最内层stack frame。return命令不会恢复程序的执行，而是使得程序的状态处于函数刚刚返回的状态，与其不同的是finish命令，会恢复函数的执行直到函数函数的正常范围时停止。</p>
<h2 id="9-5_调用程序的函数">9.5 调用程序的函数</h2><p>　　<strong>print <em>expr</em></strong><br>　　对表达式expr求值，并打印显示结果，其表达式可以包含对被调试程序中的函数的调用。<br>　　<strong>call <em>expr</em></strong><br>　　同样对表达式expr求值，但是不显示void返回函数的结果，如果调用的函数本身会返回值，那么该返回的值还是会被打印，并添加到值历史记录中去。</p>
<h1 id="十、调试目标和远程调试">十、调试目标和远程调试</h1><p>　　GDB的调试目标可以是process(进程)、exec file、core file、recording sessions，以及突破单机限制采用串口线、网络相连的remote调试目标。调试目标可以使用target命令进行设置，target+TAB可以查看当前gdb所支持的调试目标的种类。<br>　　<strong>target <em>type</em> <em>parameters</em></strong><br>　　参数<em>type</em>常见的有exec|core，这种方式也可以使用exec-file、core-file方式指定，甚至在gdb启动的时候就作为启动参数附加上去。target工具最常用的，还是在于对远程调试的支持上。远程调试，是主要在于一些运行程序的远程操作系统的限制(比如内核限制、内存限制)导致无法全功能运行gdb调试器的情况下尤为的有用，此外就是gdbsever和gdb规定了一套通信协议，而前者尺寸比后者要小的多，运行起来更轻便的同时，也容易在一个新平台上面进行快速的移植和支持。</p>
<h2 id="10-1_连接到远程调试目标">10.1 连接到远程调试目标</h2><h3 id="10-1-1_两种远程连接模式">10.1.1 两种远程连接模式</h3><p>　　GDB支持两种模式的远程调试连接：remote和extend-remote，两者基本功能相同，但是在处理出错、退出等细节性的方面差异很大。<br>　　<strong>target remote</strong><br>　　当调试的程序退出或者detach后(还比如在gdb中使用kill主动杀死正在调试的进程)，target将会断开连接，当使用了gdbserver的时候，gdbserver也会自动退出。<br>　　gdbserver的启动模式有三种：PROG、–attach、–multi，前两者是在gdbserver启动的时候指定调试的二进制程序或者要attach的调试进程，在remote模式下只能连接这两种模式的gdbserver。<br>　　不支持run命令，连接到远程后被调试程序已经运行了，此时可以使用step、continue等各项调试指令。<br>　　不支持attach命令，必须在启动的时候通过–attach参数指定。<br>　　<strong>target extend-remote</strong><br>　　当调试的程序退出或者detach后，target任然保持着和gdbserver连接(此时只有gdb退出后，gdbserver才会reopen侦听)，即使当前没有调试程序在运行。使用–once参数可以让gdbserver在第一个连接断开后退出，否则如果需要使远程的gdbserver退出，可以使用monitor exit命令。<br>　　extend-remote除了上面PROG、–attach外，还可以连接使用–multi模式启动的gdbserver，连接后在使用命令设置远程调试文件或者远程attach进程。<br>　　支持使用run命令，启动的程序是通过set remote exec-file的方式指定的。如果gdbserver启动的时候指明了调试文件，那么也不需要使用run命令了，可以类似使用step、continue等命令恢复程序执行。<br>　　支持attach命令。</p>
<h3 id="10-1-2_指明Host和Target文件">10.1.2 指明Host和Target文件</h3><p>　　具有调试符号的执行文件才可以用于调试。在远程调试模式下，允许GDB通过建立的调试连接访问远程的程序文件(remote program file access)。<br>　　我们将运行gdb的成为Host，运行gdbserver的称为Target，如果远程程序文件访问是支持的，那么允许Target调试的程序是stripped之后的(确实调试符号)，只需要Host加载的程序是带有调试符号的就可以了，除此之外还需要使用set sysroot的方式指明其他组件和库的调试信息。即使此时Host和Target的程序不一致，但是也必须保证后者是前者strip得到的，否则调试将会有异样的结果。</p>
<h3 id="10-1-3_一些远程调试相关命令">10.1.3 一些远程调试相关命令</h3><p>　　<strong>target remote|extended-remote <em>serial-device</em></strong><br>　　<strong>target remote|extended-remote <em>[tcp:]host:port</em></strong><br>　　host主机可以是主机名或者IP地址，如果host和target运行在同一台主机上，则host字段可以被省略(:占位还是需要保留)。<br>　　<strong>target remote|extended-remote <em>udp:host:port</em></strong><br>　　<strong>target remote|extended-remote | <em>command</em></strong><br>　　在后台运行command，并通过管道与之通信，command必须是shell的命令并使用/bin/sh进行解析。</p>
<p>　　<strong>detach</strong><br>　　当完成调试的时候，可以使用该命令进行对GDB控制的释放，当使用remote模式连接的时候，此时GDB可以自由连接其他的target了；而如果使用extend-remote连接的时候，此时GDB仍然处于和target连接状态。<br>　　<strong>disconnect</strong><br>　　断开和target的连接，此时GDB可以自由连接其他的target了。<br>　　<strong>monitor <em>cmd</em></strong><br>　　允许想远程发送任意命令，被远程monitor所解析。motinor exit可以让gdbserver立即退出，通常在disconnect命令之后使用，而monitor set debug|remote-debug 0|1还可以设置后续描述到的这两个调试参数。</p>
<p>　　gdb允许想远程目标上传、接收、删除文件，这对于嵌入式调试(已占用串口线)十分方便，命令如下：<br>　　<strong>remote put <em>hostfile</em> <em>targetfile</em></strong><br>　　<strong>remote get <em>targetfile</em> <em>hostfile</em></strong><br>　　<strong>remote delete <em>targetfile</em></strong></p>
<h2 id="10-2_gdbserver程序">10.2 gdbserver程序</h2><p>　　如前面所说，gdbserver运行的Target端可以是strip后没有调试符号的运行程序，而在Host端负责符号相关的支持。OPTIONS参数选项比较重要的有–debug，可以显示一些额外的调试信息，而–remote-debug会显示一些远程调试协议相关的信息，主要是gdbserver本身开始调试使用的。<br>　　<strong>gdbserver [OPTIONS] COMM PROG [ARGS …] </strong><br>　　命令中的COMM是串口设备字段或者TCP/IP的网络字段，ARGS是作为给PROG的运行参数使用。<br>　　<strong>gdbserver [OPTIONS] –attach COMM PID </strong><br>　　调试一个运行着的进程的时候，不需要指明运行的二进制程序的位置。在extended-remote模式下还允许使用attach命令进行进程指定。pid可以使用pidof工具辅助查找(有多个同名运行的进程的话会一并全部返回，使用-s可以返回单个PID)。<br>　　<strong>gdbserver [OPTIONS] –multi COMM </strong><br>　　允许gdbserver在不指定调试程序、调试进程的情况下启动，后续通过extended-remote连接后再行设定。</p>
<h1 id="十一、GDB_TUI(Text_User_Interface)调试界面">十一、GDB TUI(Text User Interface)调试界面</h1><p>　　就像之前说到的，Windows下面的程序员是幸福的，因为他们有着号称最好用的IDE——Visual Studio。其实内行看门道，到这里发现GNU GDB也是当之无愧的程序调试利器，只不过像通常Linux平台下的软件一样擅长功能而不善于表达，导致给外人看来一种很难用的“假象”。<br>　　GDB内部集成了一个TUI的用户界面，在启动GDB的时候可以使用<code bash="">gdb -tui</code>参数的方式使能，该模式是使用的curses库实现的一个建议UI界面。这个界面基本只是显示的基本功能，远远达不到IDE效果，不过它的好处是比较的易用(因为他没啥功能……)，只需要在command窗口进行常规的gdb调试，分割出来的其他窗口可以自动显示源代码、反汇编、寄存器等信息，操作要有好许多。<br>　　在Linux下面还有一个十分常用的gdb调试外壳，就是DDD，感兴趣的也可以去了解一下。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.cs.swarthmore.edu/~newhall/unixhelp/howto_gdb.html" target="_blank" rel="external">Debugging C and C++ programs with gdb and ddd</a></li>
<li><a href="https://www.ibm.com/developerworks/library/l-gdb/" target="_blank" rel="external">Linux software debugging with GDB</a></li>
<li><a href="https://chromium.googlesource.com/chromium/src/+/master/docs/linux_debugging.md" target="_blank" rel="external">Tips for debugging on Linux</a></li>
<li><a href="http://www.cprogramming.com/debugging/segfaults.html" target="_blank" rel="external">Debugging Segmentation Faults and Pointer Problems</a></li>
<li><a href="http://www.cprogramming.com/gdb.html" target="_blank" rel="external">A GDB Tutorial with Examples</a></li>
<li><a href="https://blogs.msdn.microsoft.com/vcblog/2015/11/18/announcing-the-vs-gdb-debugger-extension/" target="_blank" rel="external">Announcing the VS GDB Debugger extension</a></li>
<li><a href="https://book.douban.com/subject/4111413/" target="_blank" rel="external">软件调试的艺术</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HTTPS原理简单介绍]]></title>
      <url>https://taozj.org/201701/https-principle.html</url>
      <content type="html"><![CDATA[<p>　　HTTPS在今后的互联网中必将扮演者越来越重要的角色了，国外互联网大佬对https部署也是竭力鼓吹呐喊，HTTP/2协议的推广更是逼着你不上也得上！在HTTPS普及化过程中，必然会损害某些集团的利益，但是这是互联网的趋势，历史的洪流是谁也阻挡不了的！<br>　　这篇文章就是对HTTPS的大概做一个了解，力图宏观上掌握其基本原理和流程，而其中涉及到的具体加密算法的细节之流就留给那些博士title的人研究去吧！<br>　　还是一样，要用Wireshark抓取和分析SSL/TLS的数据包，需要设置电脑的SSLKEYLOGFILE环境变量才可以。在Windows上面搞了好久，发现抓到的数据包还是不能解密，最后在Ubuntu下一次就完成了，看来搞开发的话还要Linux算是神器啊！抓取的数据包和Master-Secret也打包<a href="/upload/taozj.ssl.pcapng.zip">共享</a>给大家了。此外为了简单起见，客户端请求禁用了Diffie Hellman支持，这个算法是为了提高安全性考虑的，好处就是密钥可以独立于服务器的私钥，所以历史数据即使在私钥被窃取的情况下，会话的内容也无法被破解。<br><img src="/post_images/images/201701/538d95ba.png" alt="https"><br>　　上面展现的客户端和服务器整个通信过程尽收眼底：首先三次握手建立TCP连接，然后客户端发起HTTP请求并得到302跳转，客户端进行ACK确认后，转而向443端口进行TCP三次握手连接，接下来就是TLS协商，加密信道建立后采用加密方式进行数据的传输。流程中夹杂着TLS和TCP的数据包，这一点也不奇怪，因为ACK是TCP协议的特性哦！<br><a id="more"></a></p>
<h1 id="一、HTTPS和TLS简介">一、HTTPS和TLS简介</h1><p>　　说到HTTPS，其实他代表着运行在SSL/TLS之上的HTTP，TLS是把SSL标准化之后的产物，因为SSL 3.0有安全漏洞，所以互联网大佬们都提倡禁用SSL 3.0，因此推荐在你的Apache/Nginx等ssl_protocols的配置中，取消对于SSLv3及其更低版本SSLv2的支持。在协议中，TLS 1.0通常被标示为SSL 3.1，TLS 1.1为SSL 3.2，TLS 1.2为SSL 3.3，这点在抓取的数据包的头部可以看出来。<br>　　TLS协议的一个优势，就是它是与应用层协议独立无关的，他的目的就是在通信双方在不可信的网络之上建立一个加密的通道用来安全地传输数据，因此上层的HTTP、FTP、SMTP和IMAP(使用STARTTLS)等应用层协议都可以透明的建立在TLS之上以满足可信通信的需求。<br>　　互联网是开放的但也是不安全的，尤其是上个世纪设计出来的大量网络应用协议都是text模式的，这让心怀不轨的人随便截获数据包就可以查看分析，作恶的成本十分的低。曾经在以前公司做入职培训作业的时候，发现公司Exchange邮件服务器+Foxmail客户端的通信都是明文的，抓包中可以看到同网段中其他同事的邮箱账户和密码(不相信做网络的公司运维水平会如此之差，或者是某些目的故意而为之吧)。HTTP协议也是text模式的，所以如果你不用HTTPS上网，可能遇到的问题有：<br>　　(1). <strong>上网过程裸奔</strong>：你的上网记录可以被监控，HTTP头部信息和Cookie被一览无余，如果传输的内容没有经过加密处理，那么你的东西也会被别人截获查看，帐号密码啥的全都不保，而且你对此丝毫没有察觉。还有些防火墙样的东西，一旦发现你想看不该让你看到的东西，就可以直接把你的连接掐掉。<br>　　(2). <strong>返回数据被篡改</strong>：不知道这锅该不该甩给运营商，很多时候请求的资源总会弹出些乱七八糟的东西，下载个东西有时候是比葫芦娃还恐怖的木马，这点尤其在移动端更为的猖獗。因为HTTP的协议就这样，你给服务端一个请求，服务端就给你一个返回，而对返回的内容根本无法辨识和校验，就这么个东西爱要不要，这样在网页中插入几段广告，或者把下载的文件中途给换掉，你根本无法辨别。<br>　　不过有一点，HTTP请求的话很方便做缓存，好的缓存对大家都有益处，可以节省带宽，同时也加快访问者的响应速度；还有比如中间传递者可以针对访问用户进行特定的转码优化。不过这一切都基于良性驱动的，恶意插入和推广的行径应当被谴责！<br>　　所以负责任的网站在提供文件的下载连接的同时，还要提供MD5/SHA1散列码给用户验证，甚至对其进行数字签名。<br>　　(3). <strong>中间人攻击</strong>：这个就更恶劣了，你甚至不知道是不是在和真正的主机在通信，你只是发出请求然后接受应答，数据包通过明文不知中转了多少台设备，任何环节中间插入个第三者帮你和服务器之间中间传话，听着是不是就惊悚？<br>　　对此，你能做的就是保护自己，所有的网络通信都要加密：HTTP要加密，邮件本身要加密，邮件的传输也要加密，DNS也要加密……为的不是防君子，而是防小人。</p>
<h1 id="二、TLS认证过程">二、TLS认证过程</h1><p>　　这个过程首先普及一点加密的知识。就像当初在GnuPG中描述的一样，加密机制可以分为非对称加密和对称加密两种：<br>　　<strong>非对称加密</strong>：会产生一对公钥和私钥，公钥公开发布到网上，私钥锁在自己保险柜中，用公钥加密的东西只能由私钥解密，用私钥签名的东西只能用公钥验证，注意我的措辞也概括了公钥和私钥的使用方式。一把非对称密钥只能实现一个方向的加密通信，要想实现双向加密通信，就必须通信的双方分别使用对方的公钥进行加密，然后再由对方用自己的私密接钥来实现。<br>　　<strong>对称加密</strong>：双方拥有相同的密钥，该密钥可以用于加密，也可以用于解密，所以这个密钥是不能被公开或者猜测到的。对称加密又分为块加密和流加密，前者只能对定长的数据块进行加密，所以通常要对待加密数据进行padding操作；流加密可以对任意长的数据进行加密，一般明文和加密结果是一样的长度。两者比较块加密的效率要高得多，可以使用CPU的高级指令高效运算，但是padding就需要记录原始数据的长度，实现起来麻烦一些。<br>　　老实说来，当时我一看完openssl支持的加密种类中，就<a href="https://raw.githubusercontent.com/taozhijiang/st_utils/master/source/st_openssl.c" target="_blank" rel="external">知道</a>先用非对称加密传输对称密钥，后续的通信使用对称加密(AES)的方式进行，后者的运算效率会比前者高很多(在一台每秒可进行千万次对称加密计算的电脑上，只能支持每秒几千次的非对称加密计算)，只要保证在每次会话中产生强随机性的密钥，就能让通信的可靠性大大的增加。如果通信双方都采用非对称加密的方式进行，那么服务端要收集庞大的用户公钥，这显然是不现实的。<br>　　下面这张图是从RFC中拷贝过来的，描述了TLS加密通信建立的过程：<br><img src="/post_images/images/201701/c934edcb.png" alt="https-step"><br>　　(1). <strong>Client Hello</strong><br>　　这个是客户端主动向服务端发送的第一个消息，主要产生的信息：Version、Random、Session ID、Cipher Suites、Compression Methods。<br><img src="/post_images/images/201701/33152673.png" alt="https-step"><br>　　Random由一个4字节的GMT Unix Time和28字节的随机串组成，前者是从Jan 1, 1970, UTC开始到现在所经过的秒数，不过奇怪的是访问我的Apache服务器返回的时间都像是随机的，而Google的服务器返回的值是正常的(不过RFC不强制该时间是准确的)，请忽略图中值，他们共同组成一个32位的随机串供后面使用；如果短时间之前连接过相同服务器，Session ID可以帮助快速恢复连接，或者根据当前连接快速创建新的连接，因为有了之前的基础只需修改会话随机部分就可以了，效率会高很多，但是这个Session ID的传输是没有加密的哦，这里是空的；Cipher Suites列出客户端支持的加密方式，使用4字节进行编码的，如前面说所我把高安全的Diffie Hellman禁用了，所以只支持上面三种方式；Compression基本都是空的。既然这个过程是两者协商的，所以恶意情况下中间人可以进行干扰，让加密通信回退到最差安全协议的情况下进行通信。<br>　　此处还需要注意扩展中有个server_name，SSL在最早的时候需要每个站点有不同的IP，但是在同一个IP下运行多个虚拟主机的情况下显然不合适，所以后面就增加了这个扩展来标识需要访问的主机域名。<br>　　(2). <strong>Server Hello</strong><br>　　服务端收到上述消息后，会进行一个回应，主要是根据客户端的情况，选择合适的协议版本和Cipher Suite。<br><img src="/post_images/images/201701/017b2915.png" alt="https-step"><br>　　上面服务端确认采用TLS 1.2，同时采用TLS_RSA_WITH_AES_128_CBC_SHA；除此之外，服务端跟客户端类似，也产生了一个总共长度32字节的随机串。TLS_RSA_WITH_AES_128_CBC_SHA称之为Cipher Suite，RSA用于签名校验和加密、AES_128_CBC用于对称数据加密解密、SHA用于消息完整性校验，openssl集成了大量的算法支持，所以这里的组合种类可能很多，但最终服务端会和客户端达成某种一致的Cipher Suite，而且往往服务端也不一定决定要用最安全的套件，因为越安全的算法往往对服务器性能消耗越大。<br>　　如果Client Hello的Session ID不为空，此时服务端可以在缓存的会话中进行校验，如果OK会恢复相同的Session ID进行确认；服务器也可以产生一个新的Session ID，表明后续有缓存该对话的意图；或者服务器返回空，表示不会缓存对话。<br>　　(3). <strong>CertificateServer Hello Done</strong><br>　　TLS握手过程中一个过程可能有多条消息构成，在上面的Server Hello发送完后，接下来服务端还会发送自己的数字证书，证书的信息通过浏览器上面的那把锁点击也可以查看详情。<br><img src="/post_images/images/201701/e6719e16.png" alt="https-step"><br>　　证书中包含了颁发者、使用域名、有效时间、公钥等重要信息。然后服务端通过Server Hello Done结束发送。<br><img src="/post_images/images/201701/eb4dc437.png" alt="https-step"><br>　　(4). <strong>Client Key Exchange, Change Cipher Spec, Encrypted Handshake Message</strong><br>　　客户端收到证书后，就开始忙活了：证书有效期限、域名匹配、是否被吊销了比较简单，关键怎么验证服务器传送过来的证书是否有效呢，毕竟这个数字证书中包含了服务端的公钥，涉及到后面的非对称加密数据的传输的？<br>　　在通信的双方不能完全相信彼此的情况下，只能通过引入权威第三方进行协调，就像是支付宝的原理样的。从之前的非对称加密原理可知，密钥可以对消息、文件进行数字签名，所以只要可信机构(CA)确认过我的身份可靠后，使用他们的私钥对我的公钥和附加信息进行数字签名，那么任何相信该可信机构的人，都可以使用可信机构的公钥来对我的证书进行验证以实现对我身份的校验了。<br>　　不过我们如何获得可靠的第三方公钥呢，通过每层结构都用自己的私钥对自己颁发出去的公钥及其拥有者进行签名，可以自上而下形成一个信任层次，但是顶级证书谁来信任呢，这不是个鸡与蛋的问题么？所以第三方可信结构的证书都是预置在浏览器和操作系统里面的，他们的证书是自签名的，对他们的信任是无条件的，所以从WoSign作恶被曝光后，Firefox、Chrome都声称停止相信WoSign的证书了，众目睽睽之下证书颁发机构才能得到有效的监督。还有，证书的等级分为DV、OV、EV，这也体现在签发的时候证书机构对申请者审查的程度不同，DV只要能验证域名所有权就可以签发，而EV还需要很多的书面文件审核才可以颁发的。<br><img src="/post_images/images/201701/fa957bfb.png" alt="https-step"><br>　　证书通过验证后，后面就可以使用其中的公钥来加密敏感消息发送给服务端了。<br>　　在上面两个Hello中总共产生了2个32字节的随机数，并且通过明文的方式发送给了对方，此时Client端再产生一个48字节的pre_master_secret随机数，该随机数通过上面的公钥和协定的加密算法(RSA)加密后发送给服务端，只有持有私钥的服务端才可以解密得到内容。这样，客户端和服务端都共有三个随机数，可以用算法产生一个对称加密密钥了。<br>　　这里只使用服务器的公钥将pre_master_secret加密后就发送出去了，设想黑客记录了通信过程中的所有数据包，那么他可以得到handshake Hello过程中的随机数(明文的)以及加密后的pre_master_secret，如果有一天服务器的私钥被泄露，黑客就可以用私钥解密得到pre_master_secret，采用周知的方法得到session key，后续所有通信的数据内容都可以被解密了，即使此时证书过期了或者被吊销了，也于事无补，所以单纯的RSA handshake是不安全的。而上文中提到被禁用的Diffie Hellman就是为了解决这个问题而被提出来的，该算法被设计出来进行密钥的安全交换，原理上就没深究了。<br>　　接下来Client发送一个Change Cipher Spec消息，该消息只有一个字节，其值为1，后面服务端也会向客户端发送，主要作用是告知对端后续的通信将会使用之前协商的CipherSpec和密钥对进行通信。<br>　　客户端发送的最后一个消息是Encrypted Handshake Message，也叫做Finished消息，其内容是之前所有消息(不包括Hello消息)的内容+handshake_messages(“client finished”)等消息产生verify_data，然后通过各种计算操作产生64字节加密结果发送给服务端，服务端对其解密和校验，这个过程主要就是验证客户端和服务端之前商定的Cipher Spec和密钥是否生效。<br>　　(5). <strong>New Session Ticket, Change Cipher Spec, Encrypted Handshake Message</strong><br><img src="/post_images/images/201701/4e7e2040.png" alt="https-step"><br>　　服务端也会有类似的Change Cipher Spec和Encrypted Handshake Message消息，不过这里还有一个New Session Ticket。<br>　　这又是另外一个RFC5077了，其实跟上面的Session ID起到类似的作用，都是通过历史会话快速生成新会话的功能(Session Resumption)。在HandShake过程中，Server发送一个加密的session ticket(包含session key)给客户端，当恢复一个对话的时候客户端返回该加密的key，服务端解密后就可以在不需要私钥的情况下快速恢复对话了。该特性由Firefox、Chrome主要支持，其他浏览器多使用Session ID的方式恢复对话。<br>　　Session ID是TLS内置的功能，而session ticket是一个扩展，其两者的区别是：前者需要在客户端和服务端都缓存该Session ID，服务端的缓存导致该情况下恢复对话功能不能跨主机；session ticket只会将加密的会话保存在客户端，当客户端需要恢复对话的时候，直接将会话数据发送给服务端，服务端解密就可以了，所以所有能够解密该session ticket的服务器多可以用来恢复对话，在免除服务端缓存Session信息压力的同时，更具有灵活性。采用会话恢复机制，能显著减轻服务端的压力以及客户端的连接速度。<br>　　(6). <strong>Application Data</strong><br>　　自此，TLS handshake完成，后继的通信都采用对称加密方式进行加密保护，尽请放心使用。<br><img src="/post_images/images/201701/f1ded92d.png" alt="https-step"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://stormpath.com/blog/why-http-is-sometimes-better-than-https" target="_blank" rel="external">Why HTTP is Sometimes Better than HTTPS</a></li>
<li><a href="http://www.codecompiled.com/understanding-https-protocol/" target="_blank" rel="external">Understanding HTTPS Protocol</a></li>
<li><a href="https://https.cio.gov/" target="_blank" rel="external">The HTTPS-Only Standard</a></li>
<li><a href="http://www.moserware.com/2009/06/first-few-milliseconds-of-https.html" target="_blank" rel="external">The First Few Milliseconds of an HTTPS Connection</a></li>
<li><a href="http://security.stackexchange.com/questions/20803/how-does-ssl-tls-work" target="_blank" rel="external">How does SSL/TLS work?</a></li>
<li><a href="http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html" target="_blank" rel="external">数字证书原理</a></li>
<li><a href="https://engineeringblog.yelp.com/2016/09/great-https-migration.html" target="_blank" rel="external">The Great HTTPS Migration</a></li>
<li><a href="https://www.v2ex.com/t/255600" target="_blank" rel="external">运营商进行网络劫持的前生今世+劫持的危害</a></li>
<li><a href="https://tools.ietf.org/html/rfc5246" target="_blank" rel="external">The Transport Layer Security (TLS) Protocol Version 1.2</a></li>
<li><a href="https://blog.cloudflare.com/keyless-ssl-the-nitty-gritty-technical-details/" target="_blank" rel="external">Keyless SSL: The Nitty Gritty Technical Details</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[RPC设计和使用中的一些杂谈]]></title>
      <url>https://taozj.org/201701/rpc-principle-and-tips.html</url>
      <content type="html"><![CDATA[<p>　　RPC当前在大公司的开发中越来越流行了，各大厂的开源RPC框架也呈百花开放的状态。在通过前面的<a href="/201612/learn-note-of-google-grpc.html">文章</a>做了一个对Google出品之gRPC的使用手册，也算是在使用方面有了一个基本的了解。恰巧最近逛别人博客的时候，看到几篇关于RPC原理和设计方面的文章，觉得十分不错，于是这里就将这些文章进行整理，对RPC设计、使用和实现中的那些乱七八糟的问题进行一个归纳总结。</p>
<h1 id="一、RPC的原理和关键点">一、RPC的原理和关键点</h1><h2 id="1-1_RPC的原理">1.1 RPC的原理</h2><p><img src="/post_images/images/201701/796a12cc.png" alt="rpc"><br>　　RPC的原理可以说是再简单不过了，一张图足以说明问题，总体来说会经历以下的步骤：<br>　　(1). client代码像普通函数调用一样调用client stub函数，这个调用是本地调用，调用参数会和平常函数调用一样进行返回地址和调用参数压栈操作；<br>　　(2). client stub会把调用参数和其它信息(比如调用方法名、调用属性等，可以称为metadata)进行打包封装成message，然后通过系统调用发送该message，这个打包的过程是个序列化的过程；<br>　　(3). client寻求到服务端的地址，然后通过本地操作系统经由某种协议，将上述message发送给server端；<br>　　(4). server端的操作系统接收message后将其传递给server stub；<a id="more"></a><br>　　(5). server stub将message解包，得到原始传递过来的各项调用参数，解包的过程是反序列化的过程；<br>　　(6). server stub调用server端的本地函数，然后将得到的结果按照上述类似的步骤反向传递给client作为结果返回。当然整个过程也可能不那么顺利，那么也应该产生合适的状态码、异常信息作为返回。<br>　　所以RPC实际是通过client stub和server stub起到一个代理的作用，将client的请求转发到server端去操作，并将操作得到的结果回传，因为传递是跨进程、跨主机的，所以必须进行序列化和反序列化的过程来保证消息的正确性。</p>
<h2 id="1-2_RPC设计中的要点">1.2 RPC设计中的要点</h2><p>　　相比于当前流行的HTTP/JSON开发，RPC等同于在实现相同功能的前提下将服务和传输等细节封装好，实现一种业务代码对特定服务开箱即用的效果。针对上面的RPC工作的流程看来，下面的几点是RPC设计实现中的几点要素：<br>　　(1). <strong>调用接口设计</strong><br>　　调用接口是客户端和服务端的一种约定，接触到的RPC框架大多都是服务于C/C++的，这类静态语言需要在编译期间确定调用接口，而且现在许多主流的编程语言都没有内置stub生成的支持，所以通常的解决方式都是用一种IDL(Interface Definition Language)的方式来描述调用接口，然后通过对应的功能辅助生成stub代码，这一点无论是上个世纪的Sun RPC(rpcgen)还是当下的gRPC(protobuf)、Thrift(thrift)都是这么干的。同时，想做到客户端和服务端跨语言的支持，也可以通过IDL然后生成特定语言种类的辅助代码来屏蔽差别性。<br><img src="/post_images/images/201701/780cf908.png" alt="idl"><br>　　(2). <strong>序列化和网络传输</strong><br>　　序列化的技术当前十分成熟了(json、msgpack、protobuf、xml……)，而且大多序列化库能够保证序列化和反序列化后能够生成特定于语言、字节序、架构的数据正确表示，现在序列化库所最求的极致，除了立志于多平台多语言支持外，就是序列化和反序列过程的速度和数据压缩效率，从这一点说Google的protobuf有着很明显的优势，看看其流行程度就知道了。<br>　　还值得一提的是，序列化还可以对数据结构进行序列化，比如C的结构体、指针等信息，感兴趣的可以参看这个小库<a href="http://www.happyponyland.net/cserialization/readme.html" target="_blank" rel="external">C serialization library</a>！但是在RPC中要实现调用参数Call-by-ref一定要谨慎，通常不要这么干。<br>　　RPC的好处就是对底层传输协议没有任何细节要求，承载client-server主机的通信协议可以选用诸如UDP、TCP、HTTP、MessageQueue甚至自设计协议，当然这也跟业务需求密切相关的，通用的RPC库通常会提供多个传输协议可供自由选择使用。<br>　　(3). <strong>RPC服务发布</strong><br>　　<strong>rpcbind</strong>：最初的Sun RPC就是这么干的，RPC服务提供者启动后将自己绑定到随机端口上，然后向rpcbind注册告知自己提供的服务和侦听的端口，而当客户端发起RPC调用的时候会首先联系rpcbind服务(周知111端口)以寻求提供服务的主机端口，然后再向这个地址发起真正的RPC请求。不过观当前流行的RPC框架，都是服务端直接绑定到某个约定的端口上面～<br>　　<strong>名字服务</strong>：这个就厉害了，前面的<a href="/201701/learn-note-of-distributed-system-%286%29-application.html">文章</a>介绍了zookeeper可以做很多事情，其中RPC服务可以方便的采用zookeeper进行发布：RPC的名字可以定义为ZNode，然后在其子节点上创建提供服务的主机信息，就可以实现诸如负载均衡、地址变更、主备冗余切换等功能。<br>　　(4). <strong>错误和异常处理</strong><br>　　RPC过程涉及到的过程和细节众多，客户端、服务端、网络传输都有可能出问题，为此gRPC为可能的情况都定义了对应的出错码，但是除了OK之外感觉其他提示都是不可靠，针对这种问题，会有一种<em>调用语义</em>的概念。<br>　　<strong>调用语义</strong>：诸如RPC这种跨网络的服务，要达到像本地函数调用那种exactly once semantic是理想化而不可能实现的，通常只能实现at least once和at most once两种调用语义，这之中的权衡一方面需要考虑具体业务的特点和需求，再则需要查看RPC所执行的任务是否是幂等(idempotent)的。</p>
<h1 id="二、RPC和MessageQueue的联系区别">二、RPC和MessageQueue的联系区别</h1><p>　　这两种方式都是企业用来进行业务解耦的重要手段，比如在经历多个项目后，发现有些服务或者功能可以独立出来给大家分享，这种情况就派上了用场了。RPC和MessageQueue虽然功能类似，但是使用手法还是有所区别的：<br>　　<strong>同步和异步</strong>：RPC模拟远程函数作为一个本地函数调用，所以函数调用上特别适合于Request/Response同步交互方式的使用场景，业务开发使用起来也更为的简单和直观；MessageQueue会将发送的消息进行排队处理，所以天然支持异步的工作模式，反而在需要同步返回结果的情况下MessageAQueue会比较麻烦。<br>　　同步方式使用的最大痛点就是并发量无法做的很高(针对那些使用线程处理请求的模式，协程另说)，而这一点MessageQueue可以将请求放入队列中，起到了错峰流控的作用。虽然gRPC、Thrift等开源RPC框架也提供异步使用方式，但是又额外多出来了CompleteQueue、CallBack之类的东西，每个调用还需要使用requestID/tag之类的东西进行标识，增加了RPC框架使用的复杂度，有违RPC简化业务实现的初衷，尤其是那种原本本地调用的业务代码向RPC迁移的时候，异步化过程中大动干戈的修改代码是比较忌讳的。<br>　　大家对这样的使用如此的一致，以至于默认就认为RPC是同步类型的调用，消息队列是异步类型的调用了。<br>　　<strong>固化</strong>：MessageQueue的一个好处就是可以将收到的消息立即固化到磁盘上，然后再进行消息的处理和应答工作，所以即使这个过程中有意外情况发生，消息也不会丢失，从某中程度上提供了一种更可靠的通信，此外这种固化还起到生产者和消费者长时间间隔完全解耦、接收端不可用的情况下针对发送端的可用性、备份等作用。这点对RPC的方式来说是很难实现的，RPC一般不会暂存请求。<br>　　<strong>消费模式</strong>：RPC只是Client和Server之间的一对一的关系，而MessageQueue通常采用Sender-Broker-Receiver的方式构成，这三者的联系可以出演化出各种各样的消费模式，尤其对于类似于“一对多”的使用场景只有MessageQueue才能支持。<br>　　<strong>静态语言的接口限制</strong>：对于C/C++这类强制性静态语言来说，调用接口需要在编译期间确定，基于Protobuf实现的RPC需要修改proto接口定义文件然后重新生成特定语言的辅助代码，对于客户端和服务端这种频繁升级都将是灾难性的。通过MessageQueue的方式就没有这么多的问题，MessageQueue的主体是消息，而Protobuf就是用于定义消息格式的，Google对Protobuf消息的向后兼容性是着重考虑的，所以软件的平滑升级是可行的。<br>　　不过也有大侠指出，一般开发环境都不会这么裸露地直接使用RPC开发业务的，通常会在业务层和RPC层中间做个隔离层，让变化性强的代码不侵入到业务当中，减少RPC频繁变动对业务代码的影响。<br>　　<strong>易用性</strong>：上面比较起来RPC对比于MessageQueue性能低、资源占用多、灵活性和扩展性不太方便，似乎是一无是处。我感觉RPC的最大优势就是简单易用(所以常常这点会作为RPC框架评价的重要指标)，程序开发充斥着无数函数调用，能把远程服务作为像函数调用一样使用真是让程序员再开心不过了。还有，比如RPC-&gt;RPC-&gt;RPC这样的嵌套调用场景，其中任何一个步骤发生了问题，调用过程都可以失败方式返回，业务上的错误处理和回滚等操作也直接明了一些吧，但是如果在异步模式下的开发，除非记录相关状态，否则这种回溯是很麻烦的！</p>
<p>　　当然，本文还是恪守于传统的RPC，所以只需要定位到函数名就可以了；对于支持面向对象的编程来说，还有RMI(Remote Method Invoke)远程方法调用，使用过程中还要找到特定的对象然后再调用该对象上的方法，通常可以通过url、名字服务等方式定位远程对象，不知道现在用的多不多，就没深究下去了。<br>　　RPC的使用的话，PhxSQL项目里面有个PhxRPC，而Raft协议实现中，各个节点的消息传递也是采用的RPC的方式进行的。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="external">Remote procedure call</a></li>
<li><a href="https://www.qcloud.com/community/article/164816001481011874" target="_blank" rel="external">如何设计一个RPC系统</a></li>
<li><a href="https://yq.aliyun.com/articles/3229?spm=5176.100239.bloglist.84.IZX9xy" target="_blank" rel="external">你应该知道的RPC原理</a></li>
<li><a href="http://www.cnblogs.com/metoy/p/4321311.html" target="_blank" rel="external">RPC原理详解</a></li>
<li><a href="http://ternarysearch.blogspot.com/2013/01/message-queues-and-rpc.html" target="_blank" rel="external">Message Queues and RPC</a></li>
<li><a href="http://www.happyponyland.net/cserialization/readme.html" target="_blank" rel="external">C serialization library</a></li>
<li><a href="https://www.cs.rutgers.edu/~pxk/417/notes/08-rpc.html" target="_blank" rel="external">Remote Procedure Calls</a></li>
<li><a href="http://www.grpc.io/docs/guides/error.html" target="_blank" rel="external">gRPC Error Handling</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（六）：基于ZooKeeper的分布式系统的应用场景]]></title>
      <url>https://taozj.org/201701/learn-note-of-distributed-system-(6)-application.html</url>
      <content type="html"><![CDATA[<p>　　至此，Paxos、Raft、ZAB代表着分布式系统中最常见的一致性协议都有所了解，但是除了PaxSql之外，对于分布式系统一致性原理的实际应用还处于一脸懵逼的状态中。此处于是主要借着<a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">《从Paxos到Zookeeper:分布式一致性原理与实践》</a>中的案例，依靠ZooKeeper分布式系统组建，对分布式系统的使用情境做一个简单的了解。毕竟嘛，我又不是做学术的，了解原理后不知道现实有什么用处又有啥意义…<br>　　ZooKeeper扮演者分布式系统的管理和协调框架的作用，通过前面对ZAB和ZooKeeper的了解，ZooKeeper通过ZNode数据模型和序列号、持久和临时节点分类，以及Watcher事件通知机制，可以快速构建分布式应用的核心功能，看看Apache旗下那么多基于ZooKeeper的分布式项目就可晓而知了。ZooKeeper的集群达到3台就可以正常工作了，但是工业上通常认为至少达到5台才是合适的，一方面机器增多集群的可靠性增加了，再次集群工作过程中常常会有机器下线维护的情况，这样在一台机器下线的时候集群还可以容易一台机器宕机而不停止服务。<br><img src="/post_images/images/201701/3ac72ee6.jpg" alt="zookeeper"><br>　　再次说明，个人没什么分布式系统的经验，这些都是查阅资料摘抄得来，如果错误尽请指正，被我误导概不负责！</p>
<p><strong>一、数据发布/订阅(配置中心)</strong> - Publish/Subscribe<br>　　发布/订阅模式不仅仅会出现在这里，通常消息队列的设计中会更加常用到这种模式。发布/订阅模式功能可以分为这几种模式：<br>　　(1). Push模式是服务器主动将数据更新发送给所有订阅的客户端，优点是实时性好，但是服务端的工作比较繁重，常常需要记录各个客户端的状态信息，甚至要考虑消费者的消费能力实现流量控制工作；<br>　　(2). Pull模式则是由客户端主动发起请求来获取最新数据，通常采用定时机制轮训拉取的方式进行，所以实时性较差，但好处是实现简单；<br>　　(3). 还有就是结合两者进行推拉相结合的方式，客户端向服务端注册自己关心的主题，一旦主题数据有所更新，服务端会向对应订阅的客户端发送事件通知，客户端接收到事件通知后主动向服务器拉取最新的数据。<a id="more"></a><br>　　在系统开发中通常会遇到机器列表信息、运行时开关配置、数据库配置等信息，这些数据的特点是<strong>数据规模比较小</strong>、<strong>数据内容在运行时候常常发生动态变更</strong>、<strong>相同的数据在多个机器中共享</strong>。在单机的情况下，可以通过共享内存，或者统一配置文件(可以使用文件系统的特性监测文件变更iNotify)来满足这个需求，但是如果配置需要跨主机，尤其机器规模大且成员会发生变动的情况下共享这些动态信息就较为困难。<br>　　基于ZooKeeper的配置中心方案可以这样设计：首先运行一个ZooKeeper服务器集群，然后在其上面创建周知路径的ZNode；专用的配置管理程序可以修改ZNode上的配置信息，作为用户更新配置的操作接口；关心这些配置的分布式应用启动时候主动获取配置信息一次，然后对ZNode注册Watcher监听，那么当ZNode的数据内容发生变化后，ZooKeeper就可以将这个变更通知发送给所有的客户端，客户端得知这个变更通知后就可以请求获取最新数据。通过这种手段，就可以实现配置信息的集中式管理和动态更新部署的功能了。</p>
<p><strong>二、负载均衡</strong> - Load Balance<br>　　负载均衡在前面的Nginx中也介绍过了，Nginx支持3层和7层软件负载均衡，对用户看来这实际上是实现的基于服务端的负载均衡操作。其实负载均衡还可以在客户端实现，之前介绍的memcached的负载均衡基本都是在客户端通过一致性hash原理实现的。<br>　　通过ZooKeeper实现的负载均衡也是通过客户端来实现的：ZooKeeper创建一个周知路径的ZNode，其数据内容包含了可以提供服务的服务器地址信息，接收服务的客户端在该ZNode上注册Watcher以侦听它的改变。在工作的时候客户端获取提供服务的服务器列表，在接收到修改事前之前可以缓存该列表提高性能，然后服务调用者可以采用自己某种特定负载均衡算法(比如Round Robin、HASH、响应时间、最少连接等算法)选取机器获取服务。<br>　　为了使用方便，服务机器列表的配置可以采用全自动的方式，这也涉及到机器健康度检测问题。可以设计一个健康度探测服务端，并负责更新ZNode中的机器列表：健康度探测服务端可以同机器中的列表建立TCP长连接，健康度探测服务端采用Ping-Pong心跳监测的方式进行健康度监测；也可以机器每隔一定的时间向这个健康度探测服务端发送数据包，如果健康度探测在某个超时时间后仍未收到某机器的数据包，就认定其不可用而将其从机器列表中进行删除。(呃，后面想想，每个服务端机器把自己作为临时ZNode创建在某个路径下，这样的侦测操作不是更加的方便？和集群管理重了)</p>
<p><strong>三、命名服务</strong> - Name Service<br>　　命名服务其实是指明了一种映射关系，在分布式开发中有很多的资源需要命名，比如主机地址，RPC服务列表等，客户端根据名字可以获取资源的实体、服务地址和提供者等信息。<br>　　ZooKeeper提供了方便的API，可以轻松的创建全局唯一的path，这个path就可以作为名称使用，所以ZooKeeper的Name Service是开箱即用的。而且ZNode支持SEQUENTIAL属性，通过创建顺序节点的手法就可以创建具有相同名字但带顺序后缀的这样很具有规则性的名字，这样的命名服务显然在保证命名唯一性的同时更具有解释意义。</p>
<p><strong>四、分布式协调/通知</strong> - Coordinator<br>　　得益于ZooKeeper特有的Watcher注册和异步通知的机制，可以实现分布式环境下不同机器，甚至是不同系统之间的通知和协调工作，以应对于数据变更的实时快速处理，这是和观察者类似的工作模式。而且通过ZooKeepr作为一个事件的中介者，也起到了业务之间解除耦合的效果。</p>
<p><strong>五、集群管理</strong> - Management<br>　　用于对集群中的机器进行监控的情况，主要包括对集群运行状态的收集，以及对集群和集群成员进行操作和控制。<br>　　传统的运维都是基于Agent的分布式集群管理模式，通过在集群成员上部署该类服务软件，该软件负责主动向集群控制中心汇报机器的状态信息。这种方式虽然直接，但是具有着固有的缺陷：很难实现跟业务相关的细化监控，通常都是对CPU、负载等通用信息进行监测；如果整个集群环境一致还可以，否则就必须面对集群中的异构成员进行兼容和适配的问题。<br>　　如果运行一个ZooKeeper集群，不仅通过临时节点在会话结束后会自动消失的特性，可以快速侦测机器的上下线，而且可以通过创建特定的ZNode，集群中的机器就可以向控制中心报告更多主机相关甚至业务相关的信息，而且这一切操作都极为便利，只需要在业务端和控制中心进行适配就可以了。</p>
<p><strong>六、Master选举</strong> - Election<br>　　可以应用于那些只需要一个主节点做特殊的工作，其他节点做普通的工作或者候命作为冗余节点的情况，比如数据库的读写分离可以让Master处理所有的写任务，而剩余的读请求由其他机器负载均衡完成，借此提供整个数据库性能；类似的Master可以单独处理一些复杂的逻辑或者计算，而将计算结果同步共享给集群中的其他主机使用，以此减少重复劳动提高资源利用率。<br>　　传统情况下的选主可以使用数据库唯一性索引简单实现，在此约束下所有的机器创建同一条记录时候只能有一个机器成功，那么可以让这个独一无二的机器作为Master，但是这种方法只是解决了竞争冲突问题，无法解决Master单点故障后整个系统不可用的问题，即不能实现高效快速的动态Master选举功能。<br>　　对此，ZooKeeper的强一致性可以天然解决Master选举的问题(注意这里的选主是客户端的Master，和ZAB协议中的Leader没有关系)：首先ZooKeeper保证在多个客户端请求创建同一路径描述的ZNode的情况下，只会有一个客户端的请求成功；其次创建ZNode可以是临时ZNode，那么一旦创建这个临时ZNode的Master挂掉后会导致会话结束，这个临时ZNode就会自动消失；在之前竞争Master失败的客户端，可以注册该ZNode的Watcher侦听，一旦接收到节点的变更事件，就表示Master不可用了，此时大家就可以即刻再次发起Master选举操作了，以实现了一种高可用的automatic fail-over机制，满足了机器在线率有较高要求的应用场景。<br>　　除了上面的方式，各个主机还可以通过创建临时顺序ZNode的方式，每个主机会具有不同的后缀，一旦当前的Master宕机之后自动轮训下一个可用机器，而下线的机器也可以随时再次上线创建新序列号的临时顺序节点。</p>
<p><strong>七、分布式锁</strong> - Lock<br>　　主要用来进行分布式系统之间的访问资源的同步手段。在使用中分布式锁可以支持这些服务：保持独占、共享使用和时序访问。虽然关系数据库在更新的时候，数据库系统会根据隔离等级自动使用行锁、表锁机制保证数据的完整性，但是数据库通常都是大型系统的性能瓶颈之所在，所以如果使用分布式锁可以起到一定的协调作用，那么可以期待增加系统的运行效率。<br>　　<strong>保持独占</strong>，就是当多个客户端试图获取这把锁的时候，只能有一个可以成功获得该锁，跟上面的Master选举比较类似，当多个竞争者同时尝试创建某个path(例如”_locknode_/guid-lock-“)的ZNode时候，ZooKeeper的一致性能够保证只有一个客户端成功，创建成功的客户端也就拥有了这把互斥锁，此时其他客户端可以在这个ZNode上面注册Watcher侦听，以便得到锁变更(如持锁客户端宕机、主动解锁)的情况采取接下来的操作。<br>　　<strong>共享使用</strong>类似于读写锁的功能，多个读锁可以同时对一个事务可见，但是读锁和写锁以及写锁和写锁之间是互斥的。锁的名字按照类似”/share_lock/[Host]-R/W-SN”的形式创建临时顺序节点，在创建锁的同时读取/share_lock节点下的所有子节点，并注册对/share_lock/节点的Watcher侦听，然后依据读写所的兼容法则检查比自己序号小的节点看是否可以满足当前操作请求，如果不满足就执行等待。当持有锁的节点崩溃或者释放锁之后，所有处于等待状态的节点就都得到了通知，实际中这会产生一个“惊群效应”，所以可以在上面注册/share_lock/的Watcher事件进行细化，只注册比自己小的那个子节点的Watcher侦听就可以了，以避免不必要的唤醒。<br>　　<strong>时序访问</strong>的方式，则是在这个时候每个请求锁的客户端都可以创建临时顺序ZNode的子节点，他们维系着一个带有序列号的后缀，同时添加对锁节点(或者像上面类似优化，只注册序列号比自己小的那个子节点)的Watcher侦听，这样前面的客户端释放锁之后，后面的客户端会得到事件通知，然后按照一定顺序接下来的一个客户端获得锁。该模式能够保证每个客户端都具有访问的机会，但是其是按照创建临时顺序子节点的顺序按次序依次访问的。</p>
<p><strong>八、分布式队列</strong> - Queue<br>　　说到分布式队列，目前已有相当多的成熟消息中间件了。在ZooKeeper的基础上，可以方便地创建先进先出队列，以及对数据进行聚集之后再统一安排处理的Barrier的工作模式。<br>　　先入先出之FIFO队列算是最常见使用的数据模型了，类似于一个生产者-消费者的工作模型。生产者会创建顺序ZNode，这些顺序ZNode的后缀表明了创建的顺序，消费者获得这些顺序ZNode后挑出序列号最小的进行消费，就简单的实现了FIFO的数据类型。<br>　　对于另外一种Barrier(叫做屏障)工作模式，是需要把数据集聚之后再做统一处理，通常在大规模并行计算的场景上会使用到。这种队列实现也很简单，就是在创建顺序ZNode的时候记录队列当前已经拥有的事务数目，如果达到了Barrier的数目，就表示条件就绪了于是创建类似“/synchronizing/start”的ZNode，而等待处理的消费者之前就侦听该ZNode是否被创建，如果侦测到一旦创建了就表明事务的数目满足需求了，于是可以启动处理工作。</p>
<p><strong>小结</strong><br>　　其实，通过上面的查看，基于ZooKeeper实现特定需要的分布式应用是比较方便的，而且更可贵的是，上面的应用都是反反复复基于ZooKeeper的那几条性质实现的！ZooKeeper真是个好东西！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="http://www.ibm.com/developerworks/library/bd-zookeeper/" target="_blank" rel="external">ZooKeeper fundamentals, deployment, and applications</a></li>
<li><a href="http://zookeeper.apache.org/doc/trunk/recipes.html" target="_blank" rel="external">ZooKeeper Recipes and Solutions</a></li>
<li><a href="https://my.oschina.net/galenz/blog/315240" target="_blank" rel="external">ZooKeeper典型应用场</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-zookeeper/" target="_blank" rel="external">分布式服务框架 Zookeeper – 管理分布式环境中的数据</a> </li>
<li><a href="https://www.nginx.com/blog/nginx-and-zookeeper-dynamic-load-balancing-and-deployments/" target="_blank" rel="external">NGINX and ZooKeeper, Dynamic Load Balancing and Deployments</a></li>
<li><a href="http://www.kuqin.com/system-analysis/20111120/315148.html" target="_blank" rel="external">ZooKeeper典型使用场景一览</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（五）：ZooKeeper之ZAB一致性协议]]></title>
      <url>https://taozj.org/201701/learn-note-of-distributed-system-(5)-zab-consensus.html</url>
      <content type="html"><![CDATA[<p>　　得益于Zookeeper在生产环境的广为使用，ZAB(ZooKeeper Atomic Broadcast，ZooKeeper原子消息广播协议)可算是最广泛应用的分布式一致性协议了，其是对Paxos算法进行了大量的改进后形成的分布式系统数据一致性协议。当之前了解Paxos和Raft算法后，落下ZAB总觉得欠缺了那么点什么。查看资料发现ZooKeeper是2007年开始开发的，而Raft算法2013年才正式发布，所以Raft中的一些设计难免会借鉴ZAB，两者存在了很多相似之处，不过多了解多掌握，想必对于分布式系统原理的融汇贯通还是会大有裨益的！</p>
<h1 id="一、前言">一、前言</h1><p>　　首先强调一点，无论是ZAB还是Raft，作为生产环境都极度强调了事务严格按照客户端请求的顺序提交，这一点在<a href="https://cwiki.apache.org/confluence/display/ZooKeeper/Zab+vs.+Paxos" target="_blank" rel="external">Zab+vs.+Paxos</a>中解释的很清楚：<br>　　Paxos注重的是一个状态机模型，一致性协议保证所有的状态机副本以相同的顺序执行相同的指令，那么所有状态机可以保证以相同的状态变化进行转移。而为了性能方面的考虑，一致性算法都允许客户端提出多个提议，当客户端并行或者重叠地提出多个决议的情况。在MultiPaxos就有了提交窗口的概念，但是在某个时刻点Leader发生崩溃后，对应的提交窗口中的提案可能有的提案被提交，有提案未被提交，那么新选出来的Leader可以按照任何顺序重新组织这些提案的表决和提交顺序，甚至也有可能会被丢弃掉。所以，Paxos算法没能够保证严格的因果一致性。<br>　　ZAB和Raft注重的是主备(primary-backup)工作模式，各个副本节点会严格按照Leader接收到客户端请求的顺序进行提交，所以可以描述为一种可靠的增量状态更新。客户端可以提出多个决议，这些决议保证会按照FIFO的顺序被提交，即便在Leader崩溃后发生Leader选取的情况下也会有此保证。虽然，Paxos可以不开启提交窗口的功能，任何时候都只允许有一个未提交的决议，那么就可以得到严格序列化的状态转移，但是相比ZAB和Raft这种专门设计优化过的一致性协议，性能会大打折扣；还有就是Paxos算法可以通过将多个提案封包成batch模式，然后整体显露作为一个提案来表决处理(PhxPaxos有这么一个特性)以提高性能，但是按照Paper所述这些改进措施不见得性能会有多大的提高。<br><a id="more"></a><br>　　可能是我看的文献比较旧吧，没有介绍到ZooKeeper成员的自动变更，只能通过重启集群的方式才能变更成员。后面看手册知道3.5.0开始支持动态成员变更，不过该版本目前仍然处于alpha状态，所以生产环境目前暂且还是持观望态度吧。所以这点来说，Raft算法通过产生一个过渡一致性状态，可以在不停服务进行动态成员变更，算是做的比较好的。<br>　　从ZooKeeper官方的项目列表观来，其已经扮演者一个通用分布式系统的库或者框架的角色了，通过将分布式系统中一致性这个最复杂、最本质的问题进行实现和封装，同时向上提供简洁统一的数据模型和操作接口，就可以在该基础之上快速构建分布式应用了。</p>
<h1 id="二、ZAB协议的基本知识">二、ZAB协议的基本知识</h1><p>　　ZooKeeper对外展现的是一颗类似Unix文件系统的树形数据模型(形如/foo/path1)，其基本元素称之为数据节点(ZNode)，ZNode并不是用来存储实际的数据，而是代表着一种状态信息。ZNode可以分为持久节点和临时节点两种类型：持久节点是一旦创建后，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存；临时节点的生命周期和客户端会话相绑定的，一旦客户端会话失效，那么这个临时节点将会被自动移除。同时，ZAB还可选对每个ZNode附加一个SEQUENTIAL属性，具有这样属性的节点在创建的时候，ZooKeeper会在其尾部追加一个递增的整形数字，这样不仅可以用于创建多个ZNode，而且某种形式上保留了一种次序信息。然后通过提供ZNode的创建、删除、侦听(Watcher)等接口，加上ZNode持久性和临时性的特点，就可以实现集群选主、消息队列等各种分布式服务和模型。<br>　　ZAB也是在协议中，规定集群中只有唯一的Leader，负责处理所有客户端的变更事务请求，通过广播的形式将事务传输到其他Fellower节点上形成副本，每当Fellower接收到事务后首先将其以事务日志的形式固化保存到本地，并向Leader返回Ack确认信息；当Leader一旦收到超过半数的Fellower节点的Ack反馈后，Leader就会再次向所有的Fellower节点发送Commit消息进行事务提交。这种主备的工作形式和2PC十分相像，但是两者还是有着本质的差异。还有，ZAB保证会按照客户端的事务请求顺序执行事务提交的，因此保证了严格的因果一致性。<br>　　从Client的角度上，Client可以向集群的任何一台机器发送请求，如果该请求会引发状态机的改变(非只读请求)，就会被转发到Leader节点；而任何节点都可以直接处理Client的只读类请求，这样一定程度上保证了系统的高可用性，而Client如果想要保证只读请求事务得到的副本是最新的，可以向其直接连接的服务器发送sync请求。在ZAB中，所有更新事务都会由一个64位的事务编号ZXID来标示，这也是实现前面严格提交顺序的基础，ZXID的高32位代表了Leader的周期epoch编号而低32位是一个简单连续单调递增的计数器，Leader接收到客户端的每一个请求，在产生新事务的时候都会对该计数值+1；每当选举产生一个新的Leader的时候，就会从这个Leader服务器上取出本地日志最大事务Proposal的ZXID，并提取出周期epoch进行+1，然后低32位置零从新开始计数。<br><img src="/post_images/images/201701/f29a71e6.png" alt="p-a-c"><br>　　在工作过程中，任意时刻集群中的任意节点都可能随时崩溃退出，ZAB保证了在大多数集群成员正常工作的情况下，整个集群也能够正常工作。</p>
<h1 id="三、ZAB协议中四个Phase介绍">三、ZAB协议中四个Phase介绍</h1><p>　　ZAB协议规定了整个集群所有节点具有4个Phase阶段：在Phase0会进行Leader Election选主操作，后面会依次经历Discovery、Synchronization、Broadcast状态的迭代。集群稳定工作的时候节点会一直处于Phase Broadcast响应客户端的请求，该阶段下集群的工作模式类似于2PC两阶段提交，但是没有2PC中的中断事务的情况，即没有事务回滚情况的发生，同时ZAB也不必等待所有成员的Ack响应，只要过半服务器回复Ack应答之后就可以进行事务提交了，从而允许少部分Fellower非正常的情况下整个集群仍然工作。集群的Leader和Fellower会通过心跳信息保持相互感知，Fellower会向Leader发送心跳消息，如果Leader在指定的超时时间内不能够得到过半数目Fellower的消息，其就会终止当前任期的Leader角色，所有的Fellower也会放弃该Leader，进入到Phase 0阶段重新进行选主；而Fellower如果在超时之后没有收到Leader的消息，也会切换到Phase 0选主的状态。<br>　　对于每个节点，需要关注以下几个持久化变量的状体，他们跟节点的工作和Phase阶段的切换密切相关：<br>　　<em>history</em>：已经被接收的提案的日志信息<br>　　<em>acceptedEpoch</em>：接受到的最后一个NEWEPOCH消息的epoch<br>　　<em>currentEpoch</em>：接受到的最后一个NEWLEADER消息的epoch<br>　　<em>lastZxid</em>：history中最后一个提案的ZXID编号</p>
<h2 id="3-1_阶段0:_Leader_Election">3.1 阶段0: Leader Election</h2><p>　在ZAB中并没有强制某种Leader选取算法，只需要能够得到集群中过半数的vote选票，该节点就可以成为Leader。后面我们会看到，ZooKeeper实现了一个FLE快速选主算法。要注意，只有进入Phase3阶段，Leader的身份才真正的确定，在此之前都是每个节点记录自己所投的prospective Leader，后面要进行一个恢复状态(数据同步)的过程。</p>
<h2 id="3-2_阶段1:_Discovery">3.2 阶段1: Discovery</h2><p>　　在这个阶段，虽然prospective leader只是一种一对一的关系，但是候选Leader肯定是集群中过半数机器的prospective leader。此时所有节点会把自己的F:acceptedEpoch通过FOLLOWERINFO发送给自己的prospective leader，当那个候选Leader得到过半的FOLLOWERINFO消息时候，会在收到消息中取出所见最大的epoch并将其递增，这样之前的Leader就不能再提交新的提案了，然后该候选Leader再将这个新epoch通过NEWEPOCH消息发回给这些节点并等待确认。<br>　　在Fellower节点收到候选Leader发送NEWEPOCH后，将其与自己本地的<em>acceptedEpoch</em>对比，如果比他们大就更新自己<em>acceptedEpoch</em>，并返回ACKEPOCH消息后进入Phase 2，否则切换会Phase 0状态。候选Leader也只能在收到过半数目的ACKEPOCH才会进入Phase 2。需要注意的是这里Fellower发送的ACKEPOCH包含了额外的重要信息——自己最新提交日志，这样候选Leader在收集ACKEPOCH的同时就知道哪个Fellower具有最新提交了，选定到这个具有最新提交的Fellower后向其同步日志。<br><img src="/post_images/images/201701/82529f2f.png" alt="discovery"><br>　　可见，这个Discovery就是要在过半机器中发现最大提案，使得候选Leader在创建一个新epoch周期的同时，也向具有最新提交的Fellower节点同步得到最新提交日志，方便了下一步向其他Fellower同步日志信息。</p>
<h2 id="3-3_阶段2:_Synchronization">3.3 阶段2: Synchronization</h2><p>　　进入这个阶段后，候选Leader已经确立了最新任期号和最新提交日志，然后他会把自己的<em>history</em>通过新epoch作为NEWLEADER消息发送给所有的集群成员，集群成员更新自己<em>currentEpoch</em> 并按需同步<em>history</em>信息。完成这个步骤后候选Fellower向Leader发送ACKNEWLEADER消息，而候选Leader得到过半数目的ACKNEWLEADER消息后，会向所有的Fellower发送COMMIT并进入Phase 3，而Fellower接收到COMMIT命令而完成提交后，也会切换到Phase 3。<br><img src="/post_images/images/201701/a9bc7cc4.png" alt="sync"></p>
<h2 id="3-4_阶段3:_Broadcast">3.4 阶段3: Broadcast</h2><p>　　到达这个阶段后，所有节点检查自己的prospective leader，如果发现它是自己，就切换到正式Leader的状态，不是这种情况的节点切换到正式Fellower的状态，而一致性协议保证此时只可能会有一个Leader。这是整个集群稳定工作状态，其基本流程也类似于上面提到的Propose-ACK-COMMIT的伪2PC操作，只要。<br><img src="/post_images/images/201701/f57029c1.png" alt="broadcast"><br>　　因为只需要得到集群中过半机器的支持，Leader就可以通过上面Phase的迭代而成为新epoch的正式Leader。那些落后的Fellower也允许加入到这个新epoch中来，我们看见Leader仍然保持接受FOLLOWERINFO消息的请求，然后直接返回NEWEPOCH和NEWLEADER消息，接收到该消息的Fellower更新epoch并同步日志后ACKNEWLEADER，接着Leader发送COMMIT命令让其提交。<br>　　在这个阶段，还有一点需要额外注意的是当某个Fellower因为某种原因错过了某些提交，而当前接收到的Leader的提案和自己提交历史之间存在空洞的情况。在图上我们看到存在outstanding transaction的时候Fellower的处理的方式就是<em>Do nothing(wait)</em>，我还没看到具体的实现是什么意思，难道是要阻塞自己到超时，然后通过上面的机制进入Phase 2 Synchronization进行提交事务同步么？</p>
<h1 id="四、ZooKeeper中的FLE选主约束">四、ZooKeeper中的FLE选主约束</h1><h2 id="4-1_一致性算法的选主要求">4.1 一致性算法的选主要求</h2><p>　　分布式系统一致性协议中的重点和难点，就是在Leader崩溃后集群选举出新的Leader，在这种临界情况下对于未完成的提案的正确处理。安全的一致性协议应当保证：<br>　　(1). 确保那些已经在Leader服务器提交的事务，最终都会被所有的服务器提交。<br>　　其临界情况就是当Leader获得绝大多数Ack反馈，但是在其将Commit消息发送给所有Fellower之前崩溃了(已经发出但是Fellower没有收到)；<br>　　(2). 确保丢弃那些只在Leader服务器上仅被提出的事务。<br>　　其临界情况比如Leader在提出一个事务之后就崩溃退出了，而后来该Leader复活后再次加入集群中时候，ZAB协议需要确保丢弃这个事务；<br>　　如果集群中任意一个Fellower都可以被选取成为候选Leader，那么候选Leader就需要通过上面Phase 1 Discovery的方式搜集所有Fellower的提交信息以寻找得到具有最新提案的Fellower并与其进行同步，然后在Phase 2阶段候选Leader以自己作为标杆再将最新提交信息发送给那些落后的Fellower。而如果让选主算法能够保证新选举出来的候选Leader拥有集群中所有机器最高事务编号(ZXID)的事务，那么就可以保证新选举出来的Leader一定具有所有已经提交的提案了，则Phase 1的工作就可以被省略掉了！</p>
<h2 id="4-2_FLE选主算法下的Phase转化">4.2 FLE选主算法下的Phase转化</h2><p>　　ZAB协议没有对Phase 0选主协议具体化，通过任何方式获得绝大多数Fellower的vote都可以成为候选Leader进而进入Phase 1阶段，而由上面可知Phase 1的主要职责就是产生新的epoch，同时发现具有最新提交日志的Fellower并向其同步提交日志。在ZooKeeper的实现中，设计了一种叫做FLE的选主算法，在要求候选Leader获得绝大多数vote的同时增加了一条额外的约束：<strong>候选Leader必须在绝大多数成员中具有最新的提交历史</strong>，这种约束条件下产生Leader后就可以直接忽略Phase 1阶段的操作了(看看，这个跟Raft的选主约束是何其的相似啊！)。然后，论文中将Phase 1和Phase 2结合起来称之为Phase Recovery。<br>　　Phase Recovery的工作过程和Phase 2的情况很不相同，此时选举出来的Leader成为了正式的标杆。同样在这个阶段开始的时候，Fellower会向自己的prospective leader发送自己最新提案号<em>lastZxid</em>，候选Leader接收到该消息后同自己的<em>lastCommittedZxid</em>进行比对，并根据比对结果反馈响应的消息类型：<br>　　(1). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要大，则Leader向其发送TRUNC消息，使该Fellower中不应当被提交的议案被丢弃掉；<br>　　(2). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要小，但是比<em>oldThreshold</em>要大，则发送两者的差异DIFF消息完成同步；<br>　　(3). 如果<em>f.lastZxid</em>比候选Leader的<em>lastCommittedZxid</em>要小，而且比<em>oldThreshold</em>还要小，说明该Fellower已经太过于落后了，候选Leader直接发送完整SNAP快照给Fellower使其进行更新；<br>　　当Fellower接收到上面的消息后，根据消息类型对自己的提交进行同步更新，然后向候选Leader发送ACKNEWLEADER确认信息，自己进入Phase 3；而当候选Leader接收到过半的ACKNEWLEADER信息后，自己也进入Phase 3成为正式Leader。<br><img src="/post_images/images/201701/3939446f.png" alt="broadcast"></p>
<h2 id="4-3_ZooKeeper中FLE算法简介">4.3 ZooKeeper中FLE算法简介</h2><p>　　FLE的算法流程还是比较复杂的，这里先不细究了，后面可以找个时间单独理一下，这里先描述一下大概的思路。<br>　　使用FLE算法的目的，就是要选出具有最大提交历史的节点作为候选Leader，这样后续的日志就只需要考虑候选Leader到其他Fellower节点的单向同步就可以保证一致性了。在FLE算法中通过筛选具有最大<em>lastZxid</em>的节点作为候选Leader，因为具有最大<em>lastZxid</em>的节点肯定具有最全的提交历史。<br>　　在FLE算法中，每个节点都只能投一张选票，只有这样才能确定过半选票的统计值，其思路就是在投票的过程中，节点之间互相交换信息，然后节点根据自己获得的信息(发现更好的候选者)不断地更新自己手中的选票，更新的标准就是具有更新的提案号：要么具有更新的epoch，或者在相同epoch下具有更大的编号。那么这个迭代更新的过程什么时候结束呢？<br>　　首先，每一轮的选取会有一个递增的round number作为标识，这个值越高优先级越高；其次，每一个节点都有一个状态标识自己：election和leading/fellowing，同时每个节点都知道集群中其他节点的个数，以及和他们通信的方式。选举刚刚开始的时候，每个节点在没有先验信息的情况下都把选票投向自己，并把这个消息发送给所有的节点，然后等待其他节点们的响应，节点再收到这个消息的时候：<br>　　(1). 如果选票的round number比较旧，则忽略之；<br>　　(2). 如果选票的round number比自己新，则更新自己的round number，并清空上一轮相关的陈旧信息，开始广播自己新的选票；<br>　　(3). 如果是在同一轮投票中：如果接收到的选票的角色是election，并且该消息附带更新的提案号，则更新自己的选票并继续广播自己的选票；如果收到的选票角色是election，但是消息的提案号比自己旧或者跟自己一样，则记录这张选票，而检查发现自己得到针对某个节点超过集群半数的选票，自己切换为leading/fellowing状态，并转入Phase Recovery；<br>　　(4). 任何时候一旦收到leading/fellowing的选票，都指明当前集群中已有有效的候选Leader了，直接更新自己切换入Phase Recovery阶段；<br>　　千言万语，还是伪代码图比较的清晰明了：<br><img src="/post_images/images/201701/80a7b6ef.png" alt="FLE"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到ZooKeeper:分布式一致性原理与实践</a></li>
<li><a href="http://www.ibm.com/developerworks/library/bd-zookeeper/" target="_blank" rel="external">ZooKeeper fundamentals, deployment, and applications</a></li>
<li><a href="https://cwiki.apache.org/confluence/display/ZOOKEEPER/Zab+vs.+Paxos" target="_blank" rel="external">Zab+vs.+Paxos</a></li>
<li><a href="http://www.tcs.hut.fi/Studies/T-79.5001/reports/2012-deSouzaMedeiros.pdf" target="_blank" rel="external">ZooKeeper’s atomic broadcast protocol: Theory and practice</a></li>
<li><a href="https://distributedalgorithm.wordpress.com/2015/06/20/architecture-of-zab-zookeeper-atomic-broadcast-protocol/" target="_blank" rel="external">Architecture of ZAB – ZooKeeper Atomic Broadcast protocol</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[【置顶】博客资源收录大全]]></title>
      <url>https://taozj.org/201701/blog-collection.html</url>
      <content type="html"><![CDATA[<p>　　虽然当下微信公众号席卷自媒体之势如火如荼，但是文章展示个人还是偏向于独立博客的方式，主要是因为个人可以控制的东西比较多。我想，对于我来说，这个时代没有什么比个性和自由更为重要的了吧。<br>　　下面是一些网络知名人士的博客，以及在搜索资料过程中遇到的好站点。除了不感兴趣的前端、移动端外，过于Java/Nodejs等语言化的博客也被KO了，希望平时没事多看看吧！<br><a id="more"></a></p>
<h1 id="一、技术大拿">一、技术大拿</h1><ol>
<li><a href="http://coolshell.cn" target="_blank" rel="external">Coolshell</a></li>
<li><a href="https://timyang.net/" target="_blank" rel="external">后端技术 by Tim Yang</a></li>
<li><a href="http://blog.codingnow.com/" target="_blank" rel="external">云风的 BLOG</a></li>
<li><a href="http://blog.csdn.net/solstice" target="_blank" rel="external">陈硕的Blog</a></li>
<li><a href="http://www.ruanyifeng.com/blog/" target="_blank" rel="external">阮一峰的网络日志</a></li>
<li><a href="http://calvin1978.blogcn.com/" target="_blank" rel="external">花钱的年华</a></li>
<li><a href="http://blog.csdn.net/myan" target="_blank" rel="external">孟岩</a></li>
<li><a href="http://purecpp.org/" target="_blank" rel="external">知行一</a></li>
<li><a href="http://www.yanmingming.net/" target="_blank" rel="external">心静志远</a></li>
<li><a href="http://jinnianshilongnian.iteye.com/" target="_blank" rel="external">开涛的博客</a></li>
<li><a href="http://www.liaoxuefeng.com/" target="_blank" rel="external">廖雪峰的官方网站</a></li>
</ol>
<h1 id="二、团队博客">二、团队博客</h1><ol>
<li><a href="https://yq.aliyun.com/" target="_blank" rel="external">云栖</a></li>
<li><a href="http://tech.meituan.com/" target="_blank" rel="external">美团技术团队</a></li>
<li><a href="http://mogu.io/" target="_blank" rel="external">蘑菇街技术博客</a></li>
<li><a href="http://jm.taobao.org/" target="_blank" rel="external">阿里中间件团队博客</a></li>
<li><a href="http://wetest.qq.com/lab" target="_blank" rel="external">腾讯质量开放平台</a></li>
<li><a href="http://kernel.taobao.org/index.php" target="_blank" rel="external">淘宝内核组</a></li>
<li><a href="https://www.oschina.net/translate/list?type=2&amp;p=57" target="_blank" rel="external">oschina 翻译</a></li>
<li><a href="https://theboostcpplibraries.com/" target="_blank" rel="external">The Boost C++ Libraries</a></li>
<li><a href="http://githubengineering.com/" target="_blank" rel="external">GitHub Engineering</a></li>
<li><a href="https://blogs.dropbox.com/tech/" target="_blank" rel="external">Dropbox Tech Blog</a></li>
<li><a href="http://aosabook.org/en/index.html" target="_blank" rel="external">The Architecture of Open Source Applications</a></li>
</ol>
<h1 id="三、博客推荐">三、博客推荐</h1><ol>
<li><a href="https://akrzemi1.wordpress.com/" target="_blank" rel="external">Andrzej’s C++ blog</a></li>
<li><a href="http://www.lenky.info/" target="_blank" rel="external">Lenky个人站点</a></li>
<li><a href="https://imququ.com" target="_blank" rel="external">Jerry Qu的小站</a></li>
<li><a href="http://www.lenky.info/" target="_blank" rel="external">Dev Articles - C++</a></li>
<li><a href="http://natsys-lab.blogspot.com/" target="_blank" rel="external">High Performance Linux</a></li>
<li><a href="http://blog.csdn.net/hsly_support" target="_blank" rel="external">白水煮鸡蛋</a></li>
<li><a href="http://microcai.org/" target="_blank" rel="external">菜菜博士 - 博士在网络的家</a></li>
<li><a href="http://aosabook.org/en/index.html" target="_blank" rel="external">The Architecture of Open Source Applications</a></li>
<li><a href="http://proprogramming.org/category/cpp-codes/" target="_blank" rel="external">Pro Programming - C++</a></li>
<li><a href="http://blog.brucefeng.info/" target="_blank" rel="external">brucefeng</a></li>
<li><a href="http://www.ideawu.net/" target="_blank" rel="external">idea’s blog</a></li>
</ol>
<h1 id="四、友情链接">四、友情链接</h1><ol>
<li><a href="http://www.lxy520.net/" target="_blank" rel="external">东方星痕</a></li>
<li><a href="https://wujunze.com/" target="_blank" rel="external">吴钧泽博客</a></li>
<li><a href="http://www.vitah.net/" target="_blank" rel="external">Vitah’s Blog</a></li>
<li><a href="http://littlewin.info/" target="_blank" rel="external">LITTLEWIN’S BLOG</a></li>
<li><a href="https://www.liurongxing.com/" target="_blank" rel="external">刘荣星的博客</a></li>
<li><a href="http://littlewin.info/" target="_blank" rel="external">LITTLEWIN’S BLOG</a></li>
</ol>
<p>持续更新中，同时欢迎投递收录……</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux服务器的那些性能参数指标]]></title>
      <url>https://taozj.org/201701/linux-performance-basic.html</url>
      <content type="html"><![CDATA[<p>　　一个基于Linux操作系统的服务器运行的同时，也会表征出各种各样参数信息。通常来说运维人员、系统管理员会对这些数据会极为敏感，但是这些参数对于开发者来说也十分重要，尤其当你的程序非正常工作的时候，这些蛛丝马迹往往会帮助快速定位跟踪问题。<br>　　这里只是一些简单的工具查看系统的相关参数，当然很多工具也是通过分析加工/proc、/sys下的数据来工作的，而那些更加细致、专业的性能监测和调优，可能还需要更加专业的工具(perf、systemtap等)和技术才能完成哦。毕竟来说，系统性能监控本身就是个大学问。<br><img src="/post_images/images/201701/76667dfc.png" alt="linux-performance"></p>
<h1 id="一、CPU和内存类">一、CPU和内存类</h1><h2 id="1-1_top">1.1 top</h2><p>　　<code bash="">➜  ~ top</code><br><img src="/post_images/images/201701/bbbd0eb3.png" alt="linux-top"><br>　　第一行后面的三个值是系统在之前1、5、15的平均负载，也可以看出系统负载是上升、平稳、下降的趋势，当这个值超过CPU可执行单元的数目，则表示CPU的性能已经饱和成为瓶颈了。</p>
<p>　　第二行统计了系统的任务状态信息。running很自然不必多说，包括正在CPU上运行的和将要被调度运行的；sleeping通常是等待事件(比如IO操作)完成的任务，细分可以包括interruptible和uninterruptible的类型；stopped是一些被暂停的任务，通常发送SIGSTOP或者对一个前台任务操作Ctrl-Z可以将其暂停；zombie僵尸任务，虽然进程终止资源会被自动回收，但是含有退出任务的task descriptor需要父进程访问后才能释放，这种进程显示为defunct状态，无论是因为父进程提前退出还是未wait调用，出现这种进程都应该格外注意程序是否设计有误。<br><a id="more"></a><br>　　第三行CPU占用率根据类型有以下几种情况：<br>　　(us) user: CPU在低nice值(高优先级)用户态所占用的时间(nice&lt;=0)。正常情况下只要服务器不是很闲，那么大部分的CPU时间应该都在此执行这类程序<br>　　(sy) system: CPU处于内核态所占用的时间，操作系统通过系统调用(system call)从用户态陷入内核态，以执行特定的服务；通常情况下该值会比较小，但是当服务器执行的IO比较密集的时候，该值会比较大<br>　　(ni) nice: CPU在高nice值(低优先级)用户态以低优先级运行占用的时间(nice&gt;0)。默认新启动的进程nice=0，是不会计入这里的，除非手动通过renice或者setpriority()的方式修改程序的nice值<br>　　(id) idle: CPU在空闲状态(执行kernel idle handler)所占用的时间<br>　　(wa) iowait: 等待IO完成做占用的时间<br>　　(hi) irq: 系统处理硬件中断所消耗的时间<br>　　(si) softirq: 系统处理软中断所消耗的时间，记住软中断分为softirqs、tasklets(其实是前者的特例)、work queues，不知道这里是统计的是哪些的时间，毕竟work queues的执行已经不是中断上下文了<br>　　(st) steal: 在虚拟机情况下才有意义，因为虚拟机下CPU也是共享物理CPU的，所以这段时间表明虚拟机等待hypervisor调度CPU的时间，也意味着这段时间hypervisor将CPU调度给别的CPU执行，这个时段的CPU资源被”stolen”了。这个值在我KVM的VPS机器上是不为0的，但也只有0.1这个数量级，是不是可以用来判断VPS超售的情况？<br>　　CPU占用率高很多情况下意味着一些东西，这也给服务器CPU使用率过高情况下指明了相应地排查思路：<br>　　(a) 当user占用率过高的时候，通常是某些个别的进程占用了大量的CPU，这时候很容易通过top找到该程序；此时如果怀疑程序异常，可以通过perf等思路找出热点调用函数来进一步排查；<br>　　(b) 当system占用率过高的时候，如果IO操作(包括终端IO)比较多，可能会造成这部分的CPU占用率高，比如在file server、database server等类型的服务器上，否则(比如&gt;20%)很可能有些部分的内核、驱动模块有问题；<br>　　(c) 当nice占用率过高的时候，通常是有意行为，当进程的发起者知道某些进程占用较高的CPU，会设置其nice值确保不会淹没其他进程对CPU的使用请求；<br>　　(d) 当iowait占用率过高的时候，通常意味着某些程序的IO操作效率很低，或者IO对应设备的性能很低以至于读写操作需要很长的时间来完成；<br>　　(e) 当irq/softirq占用率过高的时候，很可能某些外设出现问题，导致产生大量的irq请求，这时候通过检查/proc/interrupts文件来深究问题所在；<br>　　(f) 当steal占用率过高的时候，黑心厂商虚拟机超售了吧！</p>
<p>　　第四行和第五行是物理内存和虚拟内存(交换分区)的信息:<br>　　total = free + used + buff/cache，现在buffers和cached Mem信息总和到一起了，但是buffers和cached<br>Mem的关系很多地方都没说清楚。其实通过对比数据，这两个值就是/proc/meminfo中的Buffers和Cached字段：Buffers是针对raw disk的块缓存，主要是以raw block的方式缓存文件系统的元数据(比如超级块信息等)，这个值一般比较小(20M左右)；而Cached是针对于某些具体的文件进行读缓存，以增加文件的访问效率而使用的，可以说是用于文件系统中文件缓存使用。<br>　　而avail Mem是一个新的参数值，用于指示在不进行交换的情况下，可以给新开启的程序多少内存空间，大致和free + buff/cached相当，而这也印证了上面的说法，free + buffers + cached Mem才是真正可用的物理内存。并且，使用交换分区不见得是坏事情，所以交换分区使用率不是什么严重的参数，但是频繁的swap in/out就不是好事情了，这种情况需要注意，通常表示物理内存紧缺的情况。</p>
<p>　　最后是每个程序的资源占用列表，其中CPU的使用率是所有CPU core占用率的总和。通常执行top的时候，本身该程序会大量的读取/proc操作，所以基本该top程序本身也会是名列前茅的。<br>　　top虽然非常强大，但是通常用于控制台实时监测系统信息，不适合长时间(几天、几个月)监测系统的负载信息，同时对于短命的进程也会遗漏无法给出统计信息。</p>
<h2 id="1-2_vmstat">1.2 vmstat</h2><p>　　vmstat是除top之外另一个常用的系统检测工具，下面截图是我用-j4编译boost的系统负载。<br><img src="/post_images/images/201701/86dda451.png" alt="linux-vmstat"><br>　　r表示可运行进程数目，数据大致相符；而b表示的是uninterruptible睡眠的进程数目；swpd表示使用到的虚拟内存数量，跟top-Swap-used的数值是一个含义，而如手册所说，通常情况下buffers数目要比cached Mem小的多，buffers一般20M这么个数量级；io域的bi、bo表明每秒钟向磁盘接收和发送的块数目(blocks/s)；system域的in表明每秒钟的系统中断数(包括时钟中断)，cs表明因为进程切换导致上下文切换的数目。<br>　　说到这里，想到以前很多人纠结编译linux kernel的时候-j参数究竟是CPU Core还是CPU Core+1？通过上面修改-j参数值编译boost和linux kernel的同时开启vmstat监控，发现两种情况下context switch基本没有变化，且也只有显著增加-j值后context switch才会有显著的增加，看来不必过于纠结这个参数了，虽然具体编译时间长度我还没有测试。资料说如果不是在系统启动或者benchmark的状态，参数context switch&gt;100000程序肯定有问题。</p>
<h2 id="1-3_pidstat">1.3 <strong>pidstat</strong></h2><p>　　如果想对某个进程进行全面具体的追踪，没有什么比pidstat更合适的了——栈空间、缺页情况、主被动切换等信息尽收眼底。这个命令最有用的参数是-t，可以将进程中各个线程的详细信息罗列出来。<br>　　-r： 显示缺页错误和内存使用状况，缺页错误是程序需要访问映射在虚拟内存空间中但是还尚未被加载到物理内存中的一个分页，缺页错误两个主要类型是<br>　　(a). minflt/s 指的minor faults，当需要访问的物理页面因为某些原因(比如共享页面、缓存机制等)已经存在于物理内存中了，只是在当前进程的页表中没有引用之，这种情况下MMU只需要设置对应的entry就可以了，这个代价是相当小的；<br>　　(b). majflt/s 指的major faults(hard page fault)，MMU需要在当前可用物理内存中申请一块空闲的物理页面(如果没有可用的空闲页面，则需要将别的物理页面切换到交换空间去以释放得到空闲物理页面)，然后从外部低速设备加载数据到该物理页面中，并设置好对应的entry，这个代价是相当高的，和前者有几个数据级的差异；如果发生较多的major faults，虽然可以将交换分区建立在高速设备(比如PCI-E SSD)上改善性能，但主要是提示你缺物理内存了；<br>　　(c). 还有一种情况有人也归结进来，就是invalid fault，指的进程要访问的地址不在其虚拟空间内部，属于越界访问。这是比较严重的错误，通常会报段错误并终止程序的执行。<br>　　-s：栈使用状况，包括StkSize为线程保留的栈空间，以及StkRef实际使用的栈空间。使用ulimit -s发现CentOS 6.x上面默认栈空间是10240K，而CentOS 7.x、Ubuntu系列默认栈空间大小为8196K<br><img src="/post_images/images/201701/e41c6480.png" alt="pidstat"><br>　　-u：CPU使用率情况，参数同前面类似<br>　　-w：线程上下文切换的数目，还细分为cswch/s因为等待资源等因素导致的主动切换，以及nvcswch/s线程CPU时间导致的被动切换的统计<br>　　如果每次都先ps得到程序的pid后再操作pidstat会显得很麻烦，所以这个杀手锏的-C可以指定某个字符串，然后Command中如果包含这个字符串，那么该程序的信息就会被打印统计出来，-l可以显示完整的程序名和参数<br><code bash="">➜  ~  pidstat -w  -t -C “ailaw”  -l </code><br>　　这么看来，如果查看单个尤其是多线程的任务时候，pidstat比常用的ps更好使！</p>
<h2 id="1-4_其他">1.4 <strong>其他</strong></h2><p>　　当需要单独监测单个CPU情况的时候，除了htop还可以使用mpstat，查看在SMP处理器上各个Core的工作量是否负载均衡，是否有某些热点线程占用Core。Linux中还有一个工具taskset，可以设置后面运行的命令的CPU affinity。<br><code bash="">➜  ~ mpstat -P ALL 1</code><br>　　如果想直接监测某个进程占用的资源，既可以使用<code bash="">top -u taozj</code>的方式过滤掉其他用户无关进程，也可以采用下面的方式进行选择，ps命令可以自定义需要打印的条目信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> :; <span class="keyword">do</span> ps -eo user,pid,ni,pri,pcpu,psr,comm | grep <span class="string">'ailawd'</span>; sleep 1; <span class="keyword">done</span></div></pre></td></tr></table></figure></p>
<p>　　如想理清继承关系，下面一个常用的参数可以用于显示进程树结构，显示效果比pstree详细美观的多<br><code bash="">➜  ~ ps axjf</code></p>
<h1 id="二、磁盘IO类">二、磁盘IO类</h1><p>　　iotop可以直观的显示各个进程、线程的磁盘读取实时速率；lsof不仅可以显示普通文件的打开信息(使用者)，还可以操作/dev/sda1这类设备文件的打开信息，那么比如当分区无法umount的时候，就可以通过lsof找出磁盘该分区的使用状态了，而且添加+fg参数还可以额外显示文件打开flag标记。</p>
<h2 id="2-1_iostat">2.1 iostat</h2><p><code bash="">➜  ~ iostat -xz 1</code><br>　　其实无论使用<code bash="">iostat -xz 1</code>还是使用<code bash="">sar -d 1</code>，对于磁盘重要的参数是：<br>　　avgqu-sz: 发送给设备I/O请求的等待队列平均长度，对于单个磁盘如果值&gt;1表明设备饱和，对于多个磁盘阵列的逻辑磁盘情况除外；<br>　　await(r_await、w_await): 平均每次设备I/O请求操作的等待时间(ms)，包含请求排列在队列中和被服务的时间之和；<br>　　svctm: 发送给设备I/O请求的平均服务时间(ms)，如果svctm与await很接近，表示几乎没有I/O等待，磁盘性能很好，否则磁盘队列等待时间较长，磁盘响应较差；<br>　　%util: 设备的使用率，表明每秒中用于I/O工作时间的占比，单个磁盘当%util&gt;60%的时候性能就会下降(体现在await也会增加)，当接近100%时候就设备饱和了，但对于有多个磁盘阵列的逻辑磁盘情况除外；<br>　　还有，虽然监测到的磁盘性能比较差，但是不一定会对应用程序的响应造成影响，内核通常使用I/O asynchronously技术，使用读写缓存技术来改善性能，不过这又跟上面的物理内存的限制相制约了。<br>　　上面的这些参数，对网络文件系统也是受用的。</p>
<h1 id="三、网络类">三、网络类</h1><p>　　网络性能对于服务器的重要性不言而喻，工具iptraf可以直观的现实网卡的收发速度信息，比较的简洁方便通过<code bash="">sar -n DEV 1</code>也可以得到类似的吞吐量信息，而网卡都标配了最大速率信息，比如百兆网卡千兆网卡，很容易查看设备的利用率。<br>　　通常，网卡的传输速率并不是网络开发中最为关切的，而是针对特定的UDP、TCP连接的丢包率、重传率，以及网络延时等信息。</p>
<h2 id="3-1_netstat">3.1 netstat</h2><p><code bash="">➜  ~ netstat -s</code><br>　　显示自从系统启动以来，各个协议的总体数据信息。虽然参数信息比较丰富有用，但是累计值，除非两次运行做差才能得出当前系统的网络状态信息，亦或者使用watch眼睛直观其数值变化趋势。所以netstat通常用来检测端口和连接信息的：</p>
<blockquote>
<p>netstat –all(a) –numeric(n) –tcp(t) –udp(u) –timers(o) –listening(l) –program(p)</p>
</blockquote>
<p>　　–timers可以取消域名反向查询，加快显示速度；比较常用的有<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">➜  ~ netstat -antp  <span class="comment">#列出所有TCP的连接</span></div><div class="line">➜  ~ netstat -nltp   <span class="comment">#列出本地所有TCP侦听套接字，不要加-a参数</span></div></pre></td></tr></table></figure></p>
<h2 id="3-2_sar">3.2 sar</h2><p>　　sar这个工具太强大了，什么CPU、磁盘、页面交换啥都管，这里使用-n主要用来分析网络活动，虽然网络中它还给细分了NFS、IP、ICMP、SOCK等各种层次各种协议的数据信息，我们只关心TCP和UDP。下面的命令除了显示常规情况下段、数据报的收发情况，还包括<br>　　<strong>TCP</strong><br>　　<code bash="">➜  ~ sudo sar -n TCP,ETCP 1 </code><br><img src="/post_images/images/201701/3df5f810.png" alt="tcpstat"><br>　　active/s：本地发起的TCP连接，比如通过connect()，TCP的状态从CLOSED -&gt; SYN-SENT<br>　　passive/s：由远程发起的TCP连接，比如通过accept()，TCP的状态从LISTEN -&gt; SYN-RCVD<br>　　retrans/s(tcpRetransSegs)：每秒钟TCP重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据TCP的确认重传机制会发生重传操作<br>　　isegerr/s(tcpInErrs)：每秒钟接收到出错的数据包(比如checksum失败)<br>　　<strong>UDP</strong><br>　　<code bash="">➜  ~ sudo sar -n UDP 1 </code><br>　　noport/s(udpNoPorts)：每秒钟接收到的但是却没有应用程序在指定目的端口的数据报个数<br>　　idgmerr/s(udpInErrors)：除了上面原因之外的本机接收到但却无法派发的数据报个数<br>　　当然，这些数据一定程度上可以说明网络可靠性，但也只有同具体的业务需求场景结合起来才具有意义。</p>
<h2 id="3-3_tcpdump">3.3 tcpdump</h2><p>　　tcpdump不得不说是个好东西。大家都知道本地调试的时候喜欢使用wireshark，但是线上服务端出现问题怎么弄呢？附录的参考文献给出了思路：复原环境，使用tcpdump进行抓包，当之前的问题复现(比如通过观察日志显示或者某个状态显现)的时候，就可以结束抓包了。而且tcpdump本身带有-C/-W参数，可以限制抓取包存储文件的大小，当达到这个这个限制的时候保存的包数据自动rotate，所以抓取的数据包的数量总体还是可控的。此后将线上数据包拿下线来，用wireshark想怎么看就怎么看，岂不乐哉！tcpdump虽然没有GUI界面，但是抓包的功能丝毫不弱，线上服务器的流量可能会很大，但是通过指定网卡、主机、端口、协议等各项过滤参数，抓下来的包完整又带有时间戳，可以结合时间点进行推测就可以大大缩小可疑数据包的范围，所以线上程序的数据包分析也可以这么简单。<br>　　下面就是一个小的测试，可见Chrome启动时候自动向Webserver发起建立了三条连接，由于这里限制了dst port参数，所以服务端的应答包被过滤掉了，拿下来用wireshark打开，SYNC、ACK建立连接的过程还是很明显的！在使用tcpdump的时候，需要尽可能的配置抓取的过滤条件，一方面便于接下来的分析，二则tcpdump开启后对网卡和系统的性能会有影响，进而会影响到在线业务的性能。<br><img src="/post_images/images/201701/e123717e.jpg" alt="tcpdump"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://techblog.netflix.com/2015/11/linux-performance-analysis-in-60s.html" target="_blank" rel="external">Linux Performance Analysis in 60,000 Milliseconds</a></li>
<li><a href="http://man7.org/linux/man-pages/man5/proc.5.html" target="_blank" rel="external">Linux Programmer’s Manual PROC-5 </a></li>
<li><a href="http://www.tecmint.com/command-line-tools-to-monitor-linux-performance/" target="_blank" rel="external">20 Command Line Tools to Monitor Linux Performance</a></li>
<li><a href="http://books.gigatux.nl/mirror/linuxperformanceguide/0131486829/" target="_blank" rel="external">linuxperformanceguide</a></li>
<li><a href="http://blog.scoutapp.com/articles/2015/02/24/understanding-linuxs-cpu-stats" target="_blank" rel="external">Understanding Linux CPU stats</a></li>
<li><a href="https://www.qcloud.com/community/article/164816001481011819" target="_blank" rel="external">Linux性能监控——CPU,Memory,IO,Network</a></li>
<li><a href="https://yq.aliyun.com/articles/6047" target="_blank" rel="external">Linux系统性能指标</a></li>
<li><a href="https://wiki.mikejung.biz/Performance_Analysis" target="_blank" rel="external">Performance Analysis</a></li>
<li><a href="https://www.socallinuxexpo.org/scale11x-supporting/default/files/presentations/scalelinuxperformance-130224171331-phpapp01.pdf" target="_blank" rel="external">Linux Performance Analysis and Tools</a></li>
<li><a href="https://www.linux.com/learn/uncover-meaning-tops-statistics" target="_blank" rel="external">Uncover the Meaning of top’s Statistics</a></li>
<li><a href="https://yq.aliyun.com/articles/27461" target="_blank" rel="external">tcpdump 和 wireshark组合拳，揪出有问题的机器</a></li>
<li><a href="http://www.cnblogs.com/maifengqiang/p/3863168.html" target="_blank" rel="external">超级详细Tcpdump 的用法</a></li>
<li><a href="http://www-05.ibm.com/de/events/linux-on-system-z/downloads/Tools-MK2-V7-Web.pdf" target="_blank" rel="external">How to surprise by being a Linux-performance “know-it-all”</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[文本处理利器sed与awk使用总结]]></title>
      <url>https://taozj.org/201612/cmd-tools-sed-awk.html</url>
      <content type="html"><![CDATA[<p>　　 在整理为知笔记的时候，发现很久以前写的awk、sed学习笔记，这不禁然让我回想起自己最开始接触Linux的情形。那时候还在江安校区东五宿舍，一天晚上打开水瞄到了一张海报——“你想了解让微软感到畏惧的操作系统么？”虽然这个讲座最后我也没听成，但也自从那时起Linux就在我心中烙下了深深的印记。上学的时候家里真的很穷，学费也是申请的助学贷款，自认自己从小开始还是比较懂事的，也不知道那时什么勇气让我跟父母开口要四千多块钱买电脑的，但父母还是爽快地支持了我，放假前入手了当时乞丐版ThinkPad R60e，这台电脑用的Celeron处理器(后面手动升级成了Core Solo单核处理器)，1024x768的LCD显示器，80G的硬盘居然也装了双系统，虽然烂但是陪我度过了好几个年头，直到我研究生实习后用自己的实习工资换了另外一台联想笔记本(现在还在给我老婆用)它才下岗，当然这已是后话了！<br>　　 做的这个笔记，是在放暑假前从图书馆借的那本蓝皮《Unix Shells by Example》，暑假过程中自己折腾的产物，其实当时根本不知道学习这个有什么用。sed、awk当然不会用来单独开发程序，但是在命令行处中理文本，字段切割，分析日志，写一些shell脚本(比如数据库patch)的时候，还有就是在自动化做软件、服务配置文件更新的时候，还是非常好用的。</p>
<h1 id="一、sed_-_stream_editor_for_filtering_and_transforming_text">一、sed - stream editor for filtering and transforming text</h1><p>　　 <strong>sed的操作格式</strong></p>
<blockquote>
<p>➜  ~ sed -opts ‘command’ filename(s)<br>➜  ~ … | sed -opts ‘command’  # 管道输入</p>
</blockquote>
<p>　　 <strong>sed的opts选项</strong></p>
<blockquote>
<p>-n 取消默认打印。默认情况下会全文打印，因此会重复打印匹配的记录，而这个选项用来只打印匹配记录<br>-e 多个command可以用这个连接，比如 sed -n -e ‘cmd1’ -e ‘cmd2’ files<br>-i 使sed的编辑保存。默认sed操作没有破坏性(不会对原文件修改)，但是确实要编辑原文件时候可以加上该参数</p>
</blockquote>
<p>　　 这里实验使用《UNIX shell by example》里面的datafile文件作为数据集。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"> ➜  ~ cat datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15</div><div class="line">southeast       SE      Patricia Hemenway       4.0     .7      4       17</div><div class="line">eastern         EA      TB Savage               4.4     .84     5       20</div><div class="line">northeast       NE      AM Main Jr.             5.1     .94     3       13</div><div class="line">north           NO      Margot Weber            4.5     .89     5        9</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line"> ➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="1-1_删除_d">1.1 删除 d</h2><p>注意，和通常的法则不一样，下面的行号都是从1开始计数的。<br>(a) <code> ➜  ~ sed ‘3d’ datafile</code><br>删除第3行，其余行打印到屏幕上。再次强调sed默认没有破坏性，原文件datafile没有改变。<br>(b) <code> ➜  ~ sed ‘3,$d’ datafile</code><br>删除第3行到文件的末尾记录，只打印剩余的第1,2两行。$代表文件或者记录的最后一行<br>(c) <code> ➜  ~ sed ‘$d’ datafile </code><br>删除最后一行。<br>(d) <code> ➜  ~ sed ‘/north/d’ datafile</code><br>删除匹配north的行，其余记录都被打印。<br> <a id="more"></a></p>
<h2 id="1-2_替换_s">1.2 替换 s</h2><p>标志g表示是对行内所有匹配记录都进行替换，否则只对行内首次出现的记录进行替换<br>(a) <code> ➜  ~ sed -n ‘s/^west/north/p’ datafile</code><br>替换所有west打头记录，这里用了-n选项和p命令，只打印替换的记录<br>(b) <code> ➜  ~ sed ‘s/[0-9][0-9]$/&amp;.5/‘ datafile</code><br>符号$表示行末尾，符号&amp;在替换中用于表示前面匹配的内容，上面表示行结尾为2位数的数字，添加.5成为xx.5。如果要用到&amp;的字面意思，需要使用\&amp;转意方可。<br><code>  ➜  ~ sed -n ‘s/[0-9][0-9]$/&amp;.5\&amp;/p’ datafile</code><br>(c) 标记符号()，可以复用前面的内容<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="string">'s/\(Mar\)go\(t\)/\1ianne\2/p'</span> datafile</div><div class="line">north           NO      Mariannet Weber            4.5     .89     5        9</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里\1复用了前面标记的Mar，而\2复用了t。<br>(d)　默认的替换分隔符是/，其实sed可以使用任何分隔符，就是紧跟着s的那个符号。使用自定义的符号对于操作日期、路径等特殊记录很有效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  nginx <span class="built_in">pwd</span></div><div class="line">/home/v5kf/nginx</div><div class="line">➜  nginx <span class="built_in">pwd</span> | sed <span class="string">'s#v5kf/nginx#ztao#g'</span></div><div class="line">/home/ztao</div><div class="line">➜  nginx</div></pre></td></tr></table></figure></p>
<h2 id="1-3_行范围_,">1.3 行范围 ,</h2><p>行范围的表示是双闭合的，就是包含匹配开始的行、匹配结束的行，以及两者之间的所有行: 5,10  /Dick/,/Joe/  /north/,$<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="string">'/south/,/theast/s/$/**TTT**/p'</span> datafile</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18**TTT**</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15**TTT**</div><div class="line">southeast       SE      Patricia Hemenway       4.0     .7      4       17**TTT**</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里将从south匹配行，到第一个theast匹配行结束，将每条匹配记录的$结尾替换(实际追加)成<strong>TTT</strong>。如果出现south，但是没有出现theast，就默认匹配到文件结尾的地方</p>
<h2 id="1-4_多次编辑_-e">1.4 多次编辑 -e</h2><p><code> ➜  ~ sed -e ‘1,3d’ -e ‘s/north/NORTH/‘ datafile</code><br>多个-e其操作是依次进行的，所以顺序还是有讲究的，不同的顺序对最终的结果可能会有影响<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed -n <span class="_">-e</span> <span class="string">'s/thw/THW/p'</span> <span class="_">-e</span> <span class="string">'s/west/WEST/p'</span> datafile </div><div class="line">norTHWest       NW      Charles Main            3.0     .98     3       34</div><div class="line">WESTern         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">souTHWest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">➜  ~ sed -n <span class="_">-e</span> <span class="string">'s/west/WEST/p'</span> <span class="_">-e</span> <span class="string">'s/thw/THW/p'</span> datafile     </div><div class="line">northWEST       NW      Charles Main            3.0     .98     3       34</div><div class="line">WESTern         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southWEST       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="1-5_文件操作">1.5 文件操作</h2><p>(a) 读文件 r<br>将一个文件的内容加到当前的位置上实际就是在所有匹配行的下面插入文件内容<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> <span class="string">"---newfile info---"</span> &gt; newfile</div><div class="line">➜  ~ sed <span class="string">'/west/r newfile'</span> datafile    </div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">---newfile info---</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">---newfile info---</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">---newfile info---</div><div class="line">southern        SO      Suan Chin               5.1     .95     4       15</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(b) 写文件 w<br>把所有匹配到的记录都写入到指定的文件当中<br><code> ➜  ~ sed ‘/south/w newfile1’ datafile</code><br>(c) 追加文本 a<br>该命令是在匹配的记录后面直接追加提供的文本内容，感觉追加的内容有strip的效果，开始的空字符会被删除<br><code> ➜  ~ sed ‘/south/a    This is the message’ datafile</code><br>(d) 插入文本 i<br>跟上面的a命令类似，只不过这个i是插在匹配记录的前面<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'/western/i   - This is the message'</span> datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">- This is the message</div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(e) 替换文本 c<br>用该字符替换匹配到的整个记录行<br><code> ➜  ~ sed ‘/north/c This is the message’ datafile </code><br>(f) 下一行 n<br>对匹配到的记录，对其下一行做某些相应的操作<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'/northwest/&#123;n; s/^\&lt;[a-z]*/XXTTZZF/; &#125;'</span> datafile </div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">XXTTZZF         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(g) 替换、转换操作 y<br>下面对第1,2两行记录中的字符做大写化转换<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ sed <span class="string">'1,2y/abcdefghigklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/'</span> datafile</div><div class="line">NORTHWEST       NW      CHARLES MAIN            3.0     .98     3       34</div><div class="line">WESTERN         WE      SHARON GRAY             5.3     .97     5       23</div><div class="line">southwest       SW      Lewis Dalsass           2.7     .8      2       18</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>(h) 退出<br>直接退出，不做接下来记录的继续处理<br><code> ➜  ~ sed ‘5q’ datafile </code><br><code> ➜  ~ sed ‘/north/{ s/north/NORTH/; q; }’ datafile </code></p>
<h2 id="1-6_sed正则表达式的元字符">1.6 sed正则表达式的元字符</h2><p>Linux平台下很多工具(sed、awk、bash、python…)，其正则表达式虽然在大体上约定类似，但是很多细节方面的东西还是有所差异，使用不确定最好事先查询一下！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">^         行首定位符</div><div class="line">$         行尾定位符</div><div class="line">.         匹配除换行之外的单个字符</div><div class="line">*         匹配0个或者多个前导字符(这里是前导字符0或者多个，任意一个或多个字符，使用 .* )</div><div class="line">[]        指定字符中的任意一个字符，比如[Ll] [a-z]</div><div class="line">[^]       上面一样，不匹配的字符</div><div class="line">\(..\)    保存匹配的字符，后面使用\1 \2..来引用，最多使用9个标签</div><div class="line">&amp;         保存查找匹配到的串，可以用在后面的替换中 s/love/**&amp;**/</div><div class="line">\&lt;        词首定位符，单词的开头</div><div class="line">\&gt;        词尾定位符</div><div class="line">x\&#123;m\&#125;    连续m个</div><div class="line">x\&#123;m,\&#125;   至少m个</div><div class="line">x\&#123;m,n\&#125;  m-n个,sed -n <span class="string">'s/[0-9]\&#123;2\&#125;$/&amp;.5/p'</span> datafile</div></pre></td></tr></table></figure></p>
<h1 id="二、awk_-_pattern_scanning_and_text_processing_language">二、awk - pattern scanning and text processing language</h1><p>注意，下面的操作都是针对gawk的。刚开始发现下面有些例程走不通，原来是Ubuntu上面默认装的个mawk，换成gawk就正常了，话说这个awk就那三个人发明的么，居然还有版本差异？<br>awk比上面的sed要复杂的多，支持运算符、逻辑判断、循环等基本操作，难怪在解释上面已经定位为一个language了。<br><strong>awk的操作格式</strong></p>
<blockquote>
<p>➜  ~ awk -opts ‘cmd’ filenames<br>➜  ~ … | awk -opts ‘cmd’  # 管道输入</p>
</blockquote>
<p>下面的实验操作默认使用《UNIX shell by example》里面的employees文件，也有很多是沿用上面的datafile。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> ➜  ~ cat employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">Sally Chang     1654      7/22/54     650000</div><div class="line">Billy Black     1683      9/23/44     336500</div><div class="line"> ➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-1_简介">2.1 简介</h2><p>awk将输入的每行作为一条记录，默认的行分隔符就是换行符。$0指代每行的整条记录，而NR将每条记录所对应的行号保存在其中。<br><code> ➜  ~ awk ‘{print NR,$0}’ employees </code><br>每条记录都是由多个字段组成的，这些字段的分隔符默认是空白字符(空格或者制表符，如果想要改变这个默认设置，可以使用-F这个参数)，每条字段都是用$1,$2…开始标号表示，而每行的字段个数保存在NF这个特殊的字段当中。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk -F: <span class="string">'&#123;print NR, $1,$7&#125;'</span> /etc/passwd </div><div class="line">1 root /bin/bash</div><div class="line">2 daemon /usr/sbin/nologin</div><div class="line">3 bin /usr/sbin/nologin</div><div class="line">...</div></pre></td></tr></table></figure></p>
<h2 id="2-2_模式和操作">2.2 模式和操作</h2><p>awk的行为可以是花括号包起来的多个操作：<br><code>{action1; action2; … ;}</code><br>默认的模式匹配中就已经包含了if的意思了，表明当该模式满足时候就进行操作，如果没指定默认操作就是打印出这些满足要求的整行记录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/Tom/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">➜  ~ awk <span class="string">'$3&lt;3000'</span> employees</div><div class="line">Sally Chang     1654      7/22/54     650000</div><div class="line">Billy Black     1683      9/23/44     336500</div><div class="line">➜  ~ awk <span class="string">'$0 ~ /Tom/&#123;print&#125;'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">➜  ~ awk <span class="string">'$0 ~ /Tom/&#123;print "NAMEINFO-&gt;" $1, "~"  ,$2&#125;'</span> employees</div><div class="line">NAMEINFO-&gt;Tom ~ Jones</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-3_模式匹配">2.3 模式匹配</h2><p>(a) 整行所有字段匹配<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/[TM]/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">➜  ~ awk <span class="string">'/To|Mar/'</span> employees</div><div class="line">Tom Jones       4424      5/12/66     543354</div><div class="line">Mary Adams      5346      11/4/63     28765</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) ~ 特定字段匹配操作符，而使用符号!可以表示取反的意思<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$2 ~ /Ch/ &#123;print NR,$1,$2&#125;'</span> employees  </div><div class="line">3 Sally Chang</div><div class="line">➜  ~ awk <span class="string">'$2 !~ /Ch/ &#123;print NR,$1,$2&#125;'</span> employees  </div><div class="line">1 Tom Jones</div><div class="line">2 Mary Adams</div><div class="line">4 Billy Black</div><div class="line">➜  ~ awk <span class="string">' $4 ~ /^Gr/'</span> datafile     </div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 其他的匹配例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">' $5 ~ /\.[4-6]+/'</span> datafile</div><div class="line">eastern         EA      TB Savage               4.4     .84     5       20</div><div class="line">north           NO      Margot Weber            4.5     .89     5        9</div></pre></td></tr></table></figure></p>
<p>这个起到匹配作用的是4.4和4.5代表的字段哦，英文名字中有空格，占用了两个字段位</p>
<h2 id="2-4_关系运算符和条件表达式">2.4 关系运算符和条件表达式</h2><p>(a) &lt; &lt;= &gt; &gt;= != == ~ !~ 前面是一般的比较关系运算符，后面是用于字符串或者正则表达式是否匹配<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$5 &gt;= 5.3'</span> datafile                       </div><div class="line">western         WE      Sharon Gray             5.3     .97     5       23</div><div class="line">northeast       NE      AM Main Jr.             5.1     .94     3       13</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面我们看到一条有问题的数据，就是第二条记录。其实看看前面的姓名有三个字段…<br>(b) 算书运算 + - * / % ^<br>前面是正常的四则运算，而后面分别是除法、取余和取冪运算符。awk支持浮点运算，而且会按照浮点方式执行运算(比如下面的9/2=4.5)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/centr/ &#123;print NR,$1,$2,$5+3,7+8&#125;'</span> datafile </div><div class="line">9 central CT 8.7 15</div><div class="line">➜  ~ <span class="built_in">echo</span> 9 | awk <span class="string">'&#123;print $1%2, $1/2&#125;'</span></div><div class="line">1 4.5</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 逻辑运算 &amp;&amp; || !<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'$5 &gt; 5.5 &amp;&amp; $1 ~ /cen/'</span> datafile</div><div class="line">central         CT      Ann Stephens            5.7     .94     5       13</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) 条件表达式<br>类似于C/C++的?运算符，格式为：条件表达式1 ? 表达式2 : 表达式3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'NR&lt;3 &#123; print ( NF==8 ? "valid" : "invalid" ),"NF=",NF&#125;'</span> datafile</div><div class="line">valid NF= 8</div><div class="line">valid NF= 8</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(e) 范围模式 ,<br>awk的范围模式也是封闭范围。在所有记录中他们会顺序进行多次匹配，第一次匹配完后还可以进行下面接下来的第二次、第三次可能的匹配范围。如果开头匹配到了，但是没有结尾的话，会把整个文件记录的末尾当作是这次匹配的结尾作为范围<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/,/south/ &#123;print NR, $1, $2&#125;'</span> datafile</div><div class="line">1 northwest NW</div><div class="line">2 western WE</div><div class="line">3 southwest SW</div><div class="line">7 northeast NE</div><div class="line">8 north NO</div><div class="line">9 central CT</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面例子的第二次匹配没有匹配到结尾，就默认到文件的结尾<br>(f) 赋值运算 = += -= *= /= %=<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/ &#123;$1="NORTH" ; print NR,$1,$2,$3&#125;'</span> datafile</div><div class="line">1 NORTH NW Charles</div><div class="line">7 NORTH NE AM</div><div class="line">8 NORTH NO Margot</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-5_变量">2.5 变量</h2><p>(a) awk的内置变量<br>如上面例子中使用到的NR、NF，这些是awk内置的变量，可以使用$直接取值和设置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">ARGC          命令行参数个数</div><div class="line">ARGV          命令行参数构成胡数组</div><div class="line">FILENAME  当前输入文件的文件名</div><div class="line">FNR　         当前文件的记录数</div><div class="line">FS　            输入分割符，默认是空格字符</div><div class="line">NF               当前记录的字段数</div><div class="line">NR               当前的记录编号</div><div class="line">OFS             输出字段分割符</div><div class="line">ORS            记录分割符</div><div class="line">IGNORECASE  是否忽略大小写</div></pre></td></tr></table></figure></p>
<p>上面的FS、OFS看似都是空字符。其他使用例子：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> <span class="_">-ne</span> <span class="string">"123\n346\n"</span> | awk <span class="string">'&#123; print $0,ARGC,ARGV[0],FILENAME,FNR,FS,NF,NR,OFS &#125;'</span></div><div class="line">123 1 awk - 1   1 1 </div><div class="line">346 1 awk - 2   1 2 </div><div class="line">➜  ~ awk <span class="string">' &#123;IGNORECASE=1&#125;; $1=="North" &#123;print NR,$1,$2,$3&#125; '</span> datafile</div><div class="line">8 north NO Margot</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 一般变量<br>变量类型: 数值类型(默认值0)，字符串类型(默认值””)<br>强制转化: name+0 name+””<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ <span class="built_in">echo</span> 123 | awk <span class="string">'&#123; x = $1; y = ++x; print "x="x,"y="y&#125;'</span></div><div class="line">x=124 y=124</div><div class="line">➜  ~ <span class="built_in">echo</span> 123 | awk <span class="string">'&#123; x = $1; y = x++; print "x="x,"y="y&#125;'</span></div><div class="line">x=124 y=123</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-6_BEGIN、END模式">2.6 BEGIN、END模式</h2><p>BEGIN是在对输入文件进行任何处理之前进行的操作块，而实际上不需要任何输入文件，也能执行BEGIN测试，所以后面有很多同输入无关的测试，这样就可以把这些代码写道BEGIN的语句块里面。使用过程中，通常在BEGIN中设置OFS、RS、FS等参数值，以及用户定义输入格式、变量定义初始化等操作。<br>END模式也不匹配任何输入，awk是在处理完毕所有输入行之后才处理END模式<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">' BEGIN&#123;IGNORECASE=1; count=0&#125;; $1 ~ /North/ &#123;count++&#125; ; END&#123; print "Found",count&#125;  '</span> datafile</div><div class="line">Found 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-7_重定向和管道">2.7 重定向和管道</h2><p>(a) 支持 &gt; &gt;&gt;　重定向符号<br>使用的时候作为文件名参数需要使用””括起来，getline可以用于输入重定向来获得输入信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; "date" | getline date; print "The date is",date &gt; "date.file"&#125;'</span></div><div class="line">➜  ~ cat date.file</div><div class="line">The date is Wed Dec 28 18:43:39 HKT 2016</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 管道 |<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'/north/ &#123; print $0 | "grep Charles" &#125;'</span> datafile</div><div class="line">northwest       NW      Charles Main            3.0     .98     3       34</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) system 函数。可以进行系统命令调用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; system("whoami") &#125;'</span></div><div class="line">v5kf</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) printf　格式化输出信息，跟C语言的类似<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; printf "Hello, %s, you are %d years old.\n","Nicol TAO","23"&#125;'</span></div><div class="line">Hello, Nicol TAO, you are 23 years old.</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-8_条件语句和循环">2.8 条件语句和循环</h2><p>(a) if<br>在条件模式中，if是隐含的模式了，而条件语句if也可以按照需要直接声明出来的<br>句式类似于if () {} else if () {} else {}<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123; if( $1 ~ /north/) &#123; print "north related."&#125; else if ( $1 ~ /south/ ) &#123; print "south related."&#125; else &#123; print "wield..."&#125; &#125;'</span> datafile</div><div class="line">north related.</div><div class="line">wield...</div><div class="line">south related.</div><div class="line">south related.</div><div class="line">south related.</div><div class="line">wield...</div><div class="line">north related.</div><div class="line">north related.</div><div class="line">wield...</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) while<br>句法 while () {}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk &apos;BEGIN &#123; i = 0; count = 0; &#125; &#123; while ( i &lt; NR ) &#123; i ++; if ( $1 ~ /north/ ) &#123; count++; print NR,$1 $2 &#125; &#125; &#125; END &#123; print &quot;Count:&quot;,count &#125;&apos; datafile</div><div class="line">1 northwestNW</div><div class="line">7 northeastNE</div><div class="line">8 northNO</div><div class="line">Count: 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) for<br>普通for循环，句法for( ; ; ){}<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN &#123; i = 0;&#125; &#123; for(;i&lt;NR;i++) &#123; if( $1 ~ /north/ )&#123; print NR,$1,$2,"~~" &#125; &#125;&#125;'</span> datafile</div><div class="line">1 northwest NW ~~</div><div class="line">7 northeast NE ~~</div><div class="line">8 north NO ~~</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(d) break continue<br>同C/C++语言一样，是作用于跳出循环体和跳出本次循环的关键字。</p>
<h2 id="2-9_程序控制语句">2.9 程序控制语句</h2><p>(a) next<br>从文件中读取下一行输入，然后从awk脚本顶部开始重新执行。同continue效果也有点相似，只不过这里是作用于awk工具在对每行操作的自动“循环”中的<br>(b) exit<br>中断记录的处理，但是不能够跳过END语句块。exit可以带一个范围为0~255的退出参数，约定0表示成功，这个退出参数实际就传递给了$?表示执行的结果<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;  if ( $1 ~ /north/ ) &#123; print NR,$1,$2,"skip"; next; &#125; if ( $2 ~ /SO/ ) &#123; print NR,$1,$2,"exit will"; exit 3; &#125; print NR,$1,$2,"after if..."; &#125; END &#123; print "Fininal should be called here..." &#125;'</span> datafile</div><div class="line">1 northwest NW skip</div><div class="line">2 western WE after if...</div><div class="line">3 southwest SW after if...</div><div class="line">4 southern SO <span class="built_in">exit</span> will</div><div class="line">Fininal should be called here...</div><div class="line">➜  ~ <span class="built_in">echo</span> $?</div><div class="line">3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-10_数组">2.10 数组</h2><p>(a) awk中的数组也可以称为键值对，因为数组的下标可以是字符串<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123;x=0;i=0;&#125; &#123;name[x++]=$2;&#125; END &#123; for(;i&lt;NR;i++)&#123; print "name["i"] is",name[i]&#125; &#125;'</span> employees</div><div class="line">name[0] is Jones</div><div class="line">name[1] is Adams</div><div class="line">name[2] is Chang</div><div class="line">name[3] is Black</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(b) 上面是使用的普通for循环结构，而如果数组的下标不是数字类型时候，使用新的for遍历循环就很方便<br><code>for( item in array) { …array[item]…}</code><br>item会自动依次提取array中的索引值，实际数组元素可以通过array[item]来访问。awk中的数组是通过hash来存贮的，所以这里的便利理论上来说顺序是不确定的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;name[$1]=$2;&#125; END &#123; for(item in name ) &#123; print "Family name for",item,"is",name[item];&#125; &#125;'</span> employees</div><div class="line">Family name <span class="keyword">for</span> Tom is Jones</div><div class="line">Family name <span class="keyword">for</span> Sally is Chang</div><div class="line">Family name <span class="keyword">for</span> Mary is Adams</div><div class="line">Family name <span class="keyword">for</span> Billy is Black</div><div class="line">➜  ~ awk <span class="string">'&#123; if ($1 ~ /north/)&#123; count["north"] ++;&#125; else if ( $1 ~ /east/) count["east"]++; else count["other"]++;&#125; END&#123; for(item in count) &#123; print item,"related count:",count[item]; &#125; &#125;'</span> datafile</div><div class="line">other related count: 4</div><div class="line">east related count: 2</div><div class="line">north related count: 3</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>(c) 数组的其他部分<br>splite可以分割字符串，构造形成数组<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; str="/etc/samba/smb.conf"; split(str,name,"/"); for (item in name) print name[item]":";&#125;'</span></div><div class="line">:</div><div class="line">etc:</div><div class="line">samba:</div><div class="line">smb.conf:</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>这里的开头/被分割出来产生了一个空串哈…</p>
<h1 id="2-11_内置函数">2.11 内置函数</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">sub               (/reg/,替换串[,目标串])</div><div class="line">gsub             (/reg/,替换串[,目标串])</div><div class="line">index(str,sub_str)　返回sub_str第一次在str中出现的位置(偏移量从1开始)</div><div class="line">length(str)     返回字符串的字符个数</div><div class="line">substr(str,start_pos[,length])　返回子串，如果没有length，就到串的末尾</div><div class="line">match(str,/reg/)     返回正则匹配在字符串中的位置，同时设置RSTART和RLENGTH的值</div><div class="line">split(str,arr_name[,split_sig])</div></pre></td></tr></table></figure>
<p>上面两个内置函数sub和gsub的区别是，sub只进行第一次替换，而gsub会对所有串进行替换(相当于s添加了g参数吧)。下面是操作例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'&#123;sub(/[Ee]ast/,"EAST",$1); print $1,index($1,"EAST"),"length",length($1);&#125;'</span> datafile</div><div class="line">northwest 0 length 9</div><div class="line">western 0 length 7</div><div class="line">southwest 0 length 9</div><div class="line">southern 0 length 8</div><div class="line">southEAST 6 length 9</div><div class="line">EASTern 1 length 7</div><div class="line">northEAST 6 length 9</div><div class="line">north 0 length 5</div><div class="line">central 0 length 7</div><div class="line">➜  ~ awk <span class="string">'&#123; sub(/lly/,"--&amp;**",$1); print $1 &#125;'</span> employees</div><div class="line">Tom</div><div class="line">Mary</div><div class="line">Sa--lly**</div><div class="line">Bi--lly**</div><div class="line">➜  ~ awk <span class="string">'&#123;if ( match($1,/[Ee]ast/) != 0) &#123; print RSTART,RLENGTH,$1; &#125;&#125;'</span> datafile</div><div class="line">6 4 southeast</div><div class="line">1 4 eastern</div><div class="line">6 4 northeast</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>上面可以看见&amp;的用法哈</p>
<h2 id="2-12_算数函数">2.12 算数函数</h2><p>atan2(x,y) cos(x) exp(x) log(x) sin(x) sqrt(x)<br>int(x)直接舍去小数，保留整数部分<br>rand() 产生随机数(0~1) srand(x) 初始化随机数种子<br>默认情况下每次调用rand()，结果都会产生相同的随机数，这时候需要调用srand()重新产生一个种子，后面的随机数才不同<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.215969 0.629868</div><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.556348 0.749557</div><div class="line">➜  ~ awk <span class="string">'BEGIN&#123; print rand(),rand(),srand(),rand(),rand();&#125;'</span></div><div class="line">0.237788 0.291066 1 0.0931369 0.835396</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h2 id="2-13_awk正则表达式元字符">2.13 awk正则表达式元字符</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">^      行首定位符</div><div class="line">$      行尾定位符</div><div class="line">.      匹配除换行之外的单个字符</div><div class="line">*      匹配0个或者多个前导字符(这里是前导字符0或者多个，任意一个或多个字符，使用 .* )</div><div class="line">+      匹配一个或者多个前导字符</div><div class="line">?      匹配0个或者1个前导字符</div><div class="line">[]     指定字符中的任意一个字符，比如[Ll] [a-z]</div><div class="line">[^]    上面一样，不匹配的字符</div><div class="line">AA|BB  匹配AA或者BB</div><div class="line">(AB)+  匹配一个或者多个AB组合，比如AB,ABAB,ABABAB...</div><div class="line">\*     匹配*本身</div><div class="line">&amp;      保存查找匹配到的串，可以用在后面的替换中 s/love/**&amp;**/</div></pre></td></tr></table></figure>
<p>同第一部分sed工具相比，awk不支持的正则模式有<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">\(..\)   \&lt;        \&gt;    x\&#123;m\&#125;  x\&#123;m,\&#125;　x\&#123;m,n\&#125;</div></pre></td></tr></table></figure></p>
<p>从上面看来awk比较的复杂，已经具备了算数运算、逻辑、循环等一个脚本语言需要的大多数基本元素(貌似还缺函数)了。其实觉得单独用awk写脚本的不是很多，大多都是和sed一块，夹杂到shell<br>script里面用的。比如当时我工作时候用的例子：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PRIMSAM=`cat /etc/hosts | /usr/xpg4/bin/grep <span class="string">"OAM_PRIMARY_IF_A"</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</div><div class="line">SEDSAM=`cat /etc/hosts | /usr/xpg4/bin/grep <span class="string">"OAM_SECONDARY_IF_A"</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</div><div class="line">count1=`ttsys -v 1 <span class="_">-e</span> <span class="string">"select count(*) from CONFIGPARAMS where NODENAME='CPSNodes' and SUBSYSTEMNAME='Call Processing' and MANAGERNAME='Call Manager' and PARAMNAME='LocNumMapFeature';quit"</span>|sed <span class="_">-e</span> <span class="string">'s/&lt; //g'</span> <span class="_">-e</span> <span class="string">'s/ &gt;//g'</span>|awk <span class="string">'&#123;print $1&#125;'</span>`</div></pre></td></tr></table></figure></p>
<p>还比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">SMBPRINC=`klist -k | grep <span class="string">"\&lt;root@"</span> | uniq | awk <span class="string">'&#123;print $2;&#125;'</span>`</div><div class="line">TMPDIR=<span class="string">"/"</span>`date +%N | md5sum | awk <span class="string">'&#123;print $1&#125;'</span>`</div><div class="line">TMPFILE=`date +%N | md5sum | awk <span class="string">'&#123;print $1&#125;'</span>`</div><div class="line">sed <span class="_">-e</span> <span class="string">"s/^MOUNTD_NFS_V2=.*$//g"</span> /etc/sysconfig/nfs -i 2&gt;&amp;1 &gt;/dev/null</div><div class="line">sed <span class="_">-e</span> &#123;s/REALM/$( <span class="built_in">echo</span> `hostname <span class="_">-d</span>` | tr [:lower:] [:upper:] )/&#125; <span class="variable">$TESTCONFIGFILE</span> -i</div></pre></td></tr></table></figure></p>
<p>看吧，当时做的笔记还是多认真的，那时的学习是多么单纯的一件事！<br>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MacbookPro上基于ZFS的Gentoo双系统安装]]></title>
      <url>https://taozj.org/201612/install-gentoo-root-zfs-on-macbookpro-2015-early.html</url>
      <content type="html"><![CDATA[<p>　　实在没想到，买了Macbook Pro还是避免不了折腾的命，原本很大程度买Macbook Pro就是不想折腾滴。<br>　　或许上层开发程序员无所谓，但无奈对于对做Linux底层开发者来说，涉及到macOS和Linux操作系统的差异性太大了；即使macOS命令行程序无比丰富，但是BSD风格和Linux那一套相比有时候差异还挺大的；8G内存用虚拟机太吃力了——总之，这种情况唯有双系统可解～<br>　　至于发行版，自从遇到Gentoo之后，就对其他发行版无爱了，而文件系统也一直坚持着ZFS装系统，XFS保存数据。这次是macOS+Gentoo了，原理和步骤差异不大，这里总结一下，给需要的人做个参考吧！<br><img src="/post_images/images/201612/11bbad51.jpg" alt="gentoo"></p>
<ol>
<li><strong>EFI启动引导rEFInd</strong><br>　　因为macOS系统使用GPT分区和EFI引导模式，所以要安装的Gentoo也必须使用这种引导模式。rEFInd是一个优秀的EFI引导器，支持Windows/macOS/Linux平台，所以这里需要使用rEFInd来接管，然后用来引导macOS和Gentoo。<br>　　安装rEFInd的方式十分简单，按照<a href="http://www.rodsbooks.com/refind/sip.html" target="_blank" rel="external">教程</a>几步就可以了。从EI Capitan开始，macOS启用了SIP特性，所以必须在恢复模式下安装rEFInd。<a id="more"></a></li>
<li><p><strong>Linux引导盘准备</strong><br>　　Gentoo的安装和其他系统很不一样，必须先用一个LiveCD/DVD首先启动，然后通过chroot模式安装。<br>　　之前自己都是使用带有zfs支持的<a href="http://ftp.osuosl.org/pub/funtoo/distfiles/sysresccd/" target="_blank" rel="external">system-rescue-cd</a>来安装的，但这次funtoo的示例教程用了Ubuntu。我也采用了Ubuntu LiveCD的方式，主要是考虑到Ubuntu一直对各种硬件支持良好(主要是考虑到MacbookPro没有有线网络支持)。通过dd if=ubuntu-16.04.1-desktop-amd64.iso of=/dev/sdb bs=4K写入U盘后，就可以用rEFInd来引导它了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ubuntu@ubuntu:~$ sudo -i</div><div class="line">root@ubuntu:~<span class="comment"># apt-add-repository universe</span></div><div class="line">root@ubuntu:~<span class="comment"># apt update</span></div><div class="line">root@ubuntu:~<span class="comment"># apt install --yes debootstrap zfs-initramfs</span></div><div class="line">root@ubuntu:~<span class="comment"># dmesg | grep ZFS</span></div><div class="line">[  377.595348] ZFS: Loaded module v0.6.5.6-0ubuntu10, ZFS pool version 5000, ZFS filesystem version 5</div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统分区</strong><br>　　幸亏当时买了个次乞丐版的256GB的硬盘，把160GB留给了macOS，剩下的就丢给了Gentoo。<br>　　因为采用了EFI引导方式且ESP分区已经存在，所以只需要创建root、swap和数据分区就可以了。大家都是在macOS下使用磁盘工具释放了部分的空闲空间的，而macOS默认已经把硬盘的空闲部分创建了一个分区了，所以在parted中需要首先rm 4那个分区。<br>　　至于分区的大小，首先交换分区需要大于物理内存8G的大小，因为休眠suspend to disk需要使用它；rootfs需要大一些，主要是zfs后面快照备份的时候也会占用空间；这里对于数据是创建了store不是创建home分区，主要是考虑到后面很多软件和系统的设置都会保留在用户的home分区，如果把home放到rootfs备份会方便些，而真正的数据放到store分区，软连接到home目录下面就可以。最终的分区结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># parted -a optimal /dev/sda</span></div><div class="line">GNU Parted 3.2</div><div class="line">Using /dev/sda</div><div class="line">Welcome to GNU Parted! Type <span class="string">'help'</span> to view a list of commands.</div><div class="line">(parted) <span class="built_in">print</span>                                                            </div><div class="line">Model: ATA APPLE SSD SM0256 (scsi)</div><div class="line">Disk /dev/sda: 251GB</div><div class="line">Sector size (logical/physical): 512B/4096B</div><div class="line">Partition Table: gpt</div><div class="line">Disk Flags: </div><div class="line"></div><div class="line">Number  Start   End    Size    File system     Name                  Flags</div><div class="line"> 1      20.5kB  210MB  210MB   fat32           EFI System Partition  boot, esp</div><div class="line"> 2      210MB   161GB  160GB   hfs+            Customer</div><div class="line"> 3      161GB   161GB  650MB   hfs+            Recovery HD</div><div class="line"> 4      161GB   172GB  10.7GB  linux-swap(v1)  swap</div><div class="line"> 5      172GB   220GB  48.3GB  zfs             rootfs</div><div class="line"> 6      220GB   250GB  29.6GB  xfs             store</div></pre></td></tr></table></figure>
</li>
<li><p><strong>创建zfs分区</strong><br>　　以前自己都是这么做的，主要是参考Richard Yao的<a href="https://github.com/ryao/zfs-overlay/blob/master/zfs-install" target="_blank" rel="external">zfs-install</a>操作，他是gentoo中zfs部分的开发和维护者。关注他之前有段时间沉寂了，gentoo的zfs好久没更新，但最近又再次活跃起来了。<br>　　Richard Yao的那篇文章引导和启动使用的是grub和openrc，而本文用的是EFI和systemd，所以会有一些细微的差异。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># mkdir /mnt/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool create -f -o ashift=12 -o cachefile=/tmp/zpool.cache -O normalization=formD -O atime=off -m none -R /mnt/gentoo zroot /dev/sda5</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool status</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=none -o canmount=off zroot/ROOT</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/ zroot/ROOT/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/usr/portage -o atime=off zroot/ROOT/portage</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/usr/portage/distfiles zroot/ROOT/distfiles</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs create -o mountpoint=/var/tmp/portage -o sync=disabled -o compression=lz4 zroot/ROOT/build-dir</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs list -t all</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool set bootfs=zroot/ROOT/gentoo zroot</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统安装准备</strong><br>　　上面的步骤已经为新系统创建好了rootfs，并且挂在了/mnt/gentoo的目录下面。下面就是将基系统stage解压到这个分区上面去，并做出一些配置更新后，chroot到这个新系统中去。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># wget http://mirrors.ustc.edu.cn/gentoo/releases/amd64/autobuilds/current-stage3-amd64/stage3-amd64-20161215.tar.bz2</span></div><div class="line">root@ubuntu:~<span class="comment"># tar -xvjpf stage3-amd64-*.tar.bz2 -C /mnt/gentoo</span></div><div class="line">root@ubuntu:~<span class="comment"># mkdir -p /mnt/gentoo/etc/zfs</span></div><div class="line">root@ubuntu:~<span class="comment"># cp /tmp/zpool.cache /mnt/gentoo/etc/zfs/zpool.cache</span></div><div class="line">root@ubuntu:~<span class="comment"># cp -L /etc/resolv.conf /mnt/gentoo/etc/resolv.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># mount -t proc none /mnt/gentoo/proc  </span></div><div class="line">root@ubuntu:~<span class="comment"># mount --rbind /dev /mnt/gentoo/dev &amp;&amp; mount --rbind /sys /mnt/gentoo/sys</span></div><div class="line">root@ubuntu:~<span class="comment"># mount --make-rslave /mnt/gentoo/dev &amp;&amp; mount --make-rslave /mnt/gentoo/sys</span></div><div class="line">root@ubuntu:~<span class="comment"># chroot /mnt/gentoo /bin/bash</span></div><div class="line">root@ubuntu:~<span class="comment"># env-update; source /etc/profile; export PS1="(chroot) $PS1"; cd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment">#</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>系统基础安装</strong><br>　　到了这里已经chroot到目标系统中了，所做的任何操作都会保留在新系统中。不过基本系统组件，很多都没有，包含内核。<br>　　首先需要更新portage，设置profile，更新make.conf。敝人用的<a href="/upload/make.conf">make.conf</a>已经共享了，大家可以借鉴使用，酌情修改相关USE。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge-webrsync</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --sync</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile list</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile set 12 #default/linux/amd64/13.0/systemd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --info | grep ^USE</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># nano -w /etc/portage/make.conf</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge -auDN @world</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>编译kernel和zfs模块</strong><br>　　到这里，系统关键的kernel还没有产生，一般来说gentoo-sources都是比较稳定的，可以安心开启~amd64。<br>　　虽然自4.9内核发布后，各位基佬吵扰着要升级内核尝试TCP BBR拥塞控制算法，但是看了zfs目前只支持4.8的内核分支，所以这里就只用了4.8.15版本内核。内核配置是个细心活，既要支持硬件的驱动，又要删除不必要的部分精简内核(尤其对有洁癖的人来说)，还需要根据使用情况调测相应地参数。个人的<a href="/upload/kernel_4.8.15">内核配置</a>也贴出来了，虽然还没细调，但是可以工作使用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-kernel/genkernel-next</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-kernel/gentoo-sources:4.8.15</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># genkernel kernel --no-clean --no-mountboot --makeopts=-j4 --menuconfig</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-kernel/spl ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-fs/zfs-kmod ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo "sys-fs/zfs ~amd64" &gt;&gt; /etc/portage/package.accept_keywords</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge sys-fs/zfs</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl preset zfs-import-cache zfs-import-scan zfs-mount zfs-share zfs-zed zfs.target</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># echo 1 &gt; /proc/sys/vm/drop_caches</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># genkernel all --no-clean --no-mountboot --makeopts=-j4 --zfs --callback="emerge @module-rebuild" --menuconfig</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置rEFInd引导</strong><br>　　由于使用EFI引导，这里就不需要安装grub类似的软件了。由于macOS已经有了ESP分区了，这里就只需要将内核和initramfs拷贝到ESP分区中新建的gentoo目录就可以了，不过要注意内核名字的修改，否则可能不能被识别。而且后面有其他版本的内核，也可以用相同的方式拷贝进多个内核和initramfs，rEFInd会自动识别并在引导的时候给出启动内核的选项。<br>　　此外，还需要增加refind_linux.conf文件，设置如下参数以供内核启动的生活使用。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># mkdir tmp</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># mount /dev/sda1 tmp</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cp /boot/kernel-genkernel-x86_64-4.8.15-gentoonicol tmp/EFI/gentoo/vmlinuz-genkernel-x86_64-4.8.15-gentoonicol </span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cp /boot/initramfs-genkernel-x86_64-4.8.15-gentoonicol /tmp/EFI/gentoo/initramfs-genkernel-x86_64-4.8.15-gentoonicol </span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># cat /mnt/EFI/gentoo/refind_linux.conf </span></div><div class="line"><span class="string">"Default"</span>       <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro quiet"</span></div><div class="line"><span class="string">"Console"</span>       <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro quiet nox"</span></div><div class="line"><span class="string">"Emergency"</span>     <span class="string">"dozfs root=ZFS=zroot/ROOT/gentoo init=/usr/lib/systemd/systemd ro 1"</span></div><div class="line">(chroot) ubuntu ~ <span class="comment">#</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>安装gnome桌面环境</strong><br>　　如果直接使用emerge gnome会安装上gnome全家桶，这里可以使用gnome-light安装简洁的gnome环境，然后再根据自己的需要安装其他的gnome应用程序和组件。<br>　　重启之后就可以看见gdm的登录窗口了，而且对于retina高清屏gnome本身适配的很好，这确实超过了我的预期啊。<br>　　人家在苹果本上安装Linux后，据说调测好了，电池的续航是能够和macOS不相上下的。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">(chroot) ubuntu ~ <span class="comment"># useradd -m -G users,wheel,audio -s /bin/bash taozj</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># passwd taozj</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># eselect profile set 5 #default/linux/amd64/13.0/desktop/gnome/systemd</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge -auDN @world</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --ask x11-base/xorg-drivers</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># emerge --ask gnome-light</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl enable gdm.service</span></div><div class="line">(chroot) ubuntu ~ <span class="comment"># systemctl enable NetworkManager</span></div></pre></td></tr></table></figure>
</li>
<li><p><strong>备份和优化</strong><br>　　这里主要是ZFS的一些参数调优、备份、迁移、挂载等操作，作为记录后续查找方便的目的，请<strong>不要操作之！！！</strong>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># echo "options zfs zfs_arc_max=536870912" &gt;&gt; /etc/modprobe.d/zfs.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># echo PORTAGE_NICENESS=19 &gt;&gt; /etc/make.conf</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs set compression=lz4 zroot/GENTOO/build-dir</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs snapshot -r zroot@20161223_install</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs list -t snapshot</span></div><div class="line">root@ubuntu:~<span class="comment"># zfs send -Rv zroot@20161223_install | gzip &gt; /mnt/20161223_install.snap.gz</span></div><div class="line">root@ubuntu:~<span class="comment"># gzcat /mnt/20161223_install.snap.gz | zfs receive -Fv zroot</span></div><div class="line">root@ubuntu:~<span class="comment"># zpool import -f -o cachefile= -R /mnt/gentoo zroot</span></div></pre></td></tr></table></figure>
</li>
</ol>
<p>　　MacbookPro是Retina高清屏，默认在Gentoo安装后dpi自动翻倍成96*2=192，整体的Gnome显示效果不很理想，而且还有很多的程序不兼容(比如wiznote)，字体显示的十分小。最简单的方式是放弃retina，将显示分辨率降低:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">➜  ~ cat /etc/X11/xorg.conf.d/40-monitor.conf  </div><div class="line">Section <span class="string">"Monitor"</span></div><div class="line">  Identifier  <span class="string">"eDP1"</span></div><div class="line">  Option      <span class="string">"PreferredMode"</span> <span class="string">"1680x1050"</span></div><div class="line">EndSection</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<p>　　经过上面的设定，再加上之前的<a href="/201601/gentoo-overlay-and-software-recommend.html">文章</a>中使用infinitely进行字体显示和优化设置，最终的效果还是十分的清晰可人的。安装后还有一个问题就是键盘的~键无法使用，fn键默认是功能键盘，对此的纠正方法是对hd_apple模块参数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">echo</span> 0 &gt; /sys/module/hid_apple/parameters/iso_layout</div><div class="line"><span class="built_in">echo</span> 2 &gt; /sys/module/hid_apple/parameters/fnmode</div></pre></td></tr></table></figure></p>
<p>　　为了避免每次这么操作麻烦，可以将其写成一个systemd service，每次开机自动设置就可以了。</p>
<ol>
<li><strong>其他软件安装</strong><br>　　关于其他软件、插件的推荐，请参考之前整理的文档《<a href="/201601/gentoo-overlay-and-software-recommend.html">我的Gentoo Overlay和Linux软件推荐</a>》。因为gentoo是滚动更新版，而又有ZFS保驾护航，希望这个系统能战上几年！！！<br><img src="/post_images/images/201612/2312e6e7.png" alt="系统桌面"></li>
</ol>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.funtoo.org/ZFS_Install_Guide" target="_blank" rel="external">ZFS_Install_Guide</a></li>
<li><a href="https://github.com/ryao/zfs-overlay/blob/master/zfs-install" target="_blank" rel="external">zfs-install</a></li>
<li><a href="https://wiki.gentoo.org/wiki/Apple_Macbook_Pro_Retina" target="_blank" rel="external">Apple Macbook Pro Retina</a></li>
<li><a href="http://cloud-atlas.huatai.me/os/linux/gentoo/install_gentoo_on_macbook.html" target="_blank" rel="external">install_gentoo_on_macbook</a></li>
<li><a href="http://www.rodsbooks.com/refind/sip.html" target="_blank" rel="external">The rEFInd Boot Manager: rEFInd and System Integrity Protection</a></li>
<li><a href="https://github.com/coldnew/macbookpro-2015-config" target="_blank" rel="external">macbookpro-2015-config</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（四）：Raft一致性算法]]></title>
      <url>https://taozj.org/201612/learn-note-of-distributed-system-(4)-raft-consensus.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　Paxos在分布式系统中地位是不容置疑的，现代分布式系统的实现基本都直接或者间接依赖于Paxos算法。不过Paxos算法有着固有的缺陷：原始的BasicPaxos原理还是比较容易理解的，整个算法无非被分为Prepare和Accept两个阶段，但是要把这种算法工程化实现，各个节点的角色是对等的，系统的效率(可用性)将会非常的低，所以常用的也就是MultiPaxos变体版本以提高性能，这也就隐含的包含了leader的概念了，然后MultiPaxos还允许一个提交窗口，窗口中允许发起多个提案，但是这种情况下考虑到服务器随时可能崩溃的情况，算法将会变得极端复杂。Lamport爷爷就此也是简明说了几句不清不楚的优化，没有具体的实现细节，算是挖了一个巨坑吧。所以说了解BasicPaxos只是一个皮毛，将其推送到工程化可不是件容易的事情。<br>　　Raft算法是斯坦福两位博士生提出的分布式一致性系统，从其论文的题目《<a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">In Search of an Understandable Consensus Algorithm</a>》可以看出，作者以Paxos过于复杂为出发点，力求得到一个正常智商的大学生都能看懂，且工程上也容易实现的分布式系统一致性算法为目标。Raft算法借鉴了Paxos的原理，但最大不同是显式强化了Leader这个角色(虽然很多Paxos算法的实现也会产生Leader角色，但这不是Paxos算法本身所必须的)，并添加了各种约束条件(比如日志的连续性)，让算法更加容易理解和实现。虽然吾等草根屁民尚且不能从理论上审视这个算法的正确性，不过短短时间内美国很多著名大学分布式教学都将Raft算法列入教学课程，且基于Raft协议的项目也越来越多，这些事实已经足以证明一切了。<br>　　学习Raft算法，一篇<a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">普通论文</a>和一篇<a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="external">博士学位论文</a>算是不得不读的经典，而前者网上发现了翻译好的中文版本，简单对比了一下原文，发现翻译的质量还是挺高的，很值得参考，但有些原理中文理解困难的话可以对比英文方便理解。作为正规论文，按照论文八股需求难免有些啰嗦拖沓，本文就是按照前面论文阅读摘抄一些重点要点出来，而后面那篇两百多页的博士论文，后面可以慢慢评鉴一下作为补充吧，当然最好的方式还是——一言不合就读<a href="https://github.com/logcabin/liblogcabin" target="_blank" rel="external">代码</a>，毕竟作者说就两千多行！<br>　　还有，论文对状态机的描述比较的好，算是归纳了分布式系统的本质——复制状态机的基础是通过复制日志来实现的：当每个副本的初始状态相同，只要保证各个副本得到的日志都是顺序且一致的，那么按照相同的顺序执行这些日志中的指令，所有副本必然可以进行相同的状态转移得到相同的结果。所以分布式系统解决的根本问题，就是一致性问题，具体就是日志一致性问题，在这个基础上，上层就可以方便实现分布式日志、分布式数据库(bin log)、分布式存储等具体业务了。<br><img src="/post_images/images/201612/b0c484d0.jpg" alt="raft-stat"></p>
<h1 id="二、Raft算法">二、Raft算法</h1><h2 id="2-1_Raft算法基础">2.1 Raft算法基础</h2><p>　　Raft算法保证和Paxos算法具有相同的安全性，当集群中绝大多数服务器是正常的，则集群即可以正常工作，比如5个节点的集群，允许2个节点的失效。Raft算共有三种角色、需要处理三个问题，三个角色分别是Leader、Candidate、Follower，三个问题是Leader选举、日志复制和安全性，三个问题将会在后面详细阐述。<br>　　任何服务器只能处于上述三种角色中的一种，正常工作的集群具有一个Leader，剩余的节点都是Fellower，系统保证任何时候至多只有一个Leader，也有可能在选举的过程中尚未产生Leader，而在选举新Leader的时候会产生Candidate这个角色。<br><a id="more"></a><br>　　a. <strong>Leader</strong><br>　　Raft算法强化了一个领导者(Leader)的角色。一旦被选举成为Leader，就会发送空的AppendEntries RPC作为心跳给所有其他服务器，并且这个心跳会在一定空余时间后不停的发送，这样可以阻止选取超时而阻止其他服务器重新发起选举操作；<br>　　Leader负责接收客户端的请求(如果客户端和Fellower联系，那么这个请求会被重新定向给Leader)，然后附加entry到本地日志存储中，并负责把日志<em>安全地</em>复制到其他服务器上面，entry被用于Leader本地状态机后给客户端发送响应；<br>　　对于任何一个Fellower，如果已存储的日志比较旧，还会向Leader不断减小nextIndex要求发送之前的日志条目；<br>　　如果日志被安全地复制到了大多数节点上面，则增加提交索引号commitIndex，表明日志已经被安全复制；<br>　　b. <strong>Follower</strong><br>　　通常的服务器角色状态，只响应来自Candidate和Leader的请求；<br>　　如果在选举超时到达后还没收到Leader的心跳消息，或者是候选人发起投票请求，则自己变成Candidate；<br>　　c. <strong>Candidate</strong><br>　　当转变成Candidate后就立即开始选举过程——增加当前term、给自己投票、重置选举超时定时器、发送RequestVote给所有的服务器；<br>　　如果在超时之前收到绝大多数服务器的投票，就成为Leader；当一个节点收到RequestVote RPC的时候，如果请求投票节点的term不比自己旧，其日志也不比自己少，则投票给他；<br>　　如果收到来自新Leader的AppendEntries RPC，则退变成Fellower；<br>　　如果选举过程超时，则再次发起新一轮选举；</p>
<p>　　Raft中使用term表示Leader的任期，使用连续递增的整数来标记区分，在Raft中充当了逻辑时钟的作用，很多操作和记录会打上这个“逻辑时间戳”；每个服务器存储自己的term，服务器之间通信也会交换各自当前term，通过比较term可以确定哪些信息已经过期；当Candidate或Leader发现自己的term过期之后，会立即退变成Fellower的角色；如果服务器收到包含过期term的请求，就会直接拒绝这个请求返回false。<br>　　Raft算法中节点之间的通信使用RPC的方式，主要包括RequestVote、AppendEntries以及InstallSnapshot三种，RPC可以并行的被发起，而当没有及时收到响应的时候会进行重试，同时RPC只需要在绝大多数快速的节点上完成就可以了，少部分比较慢的节点不会影响到系统的整体性能。
　　</p>
<h2 id="2-2_Leader选举">2.2 Leader选举</h2><p>　　很显然以Leader为中心可以大大简化系统的设计和实现，但是分布式系统中任何一个服务器都可能随时崩溃不可用，那么必须使用选举机制来解决Leader出错导致的单点故障。<br>　　Raft中Leader地位的维持和心跳机制密切相关。集群中所有服务器默认都是Fellower的角色，如果Fellower在一段时间中没有收到任何消息(无论是正常消息还是心跳消息)，就会触发选举超时，从而认为系统中没有可用的领导者，进而开始进行选举。选举开始的时候，Fellower会增加当前term并切换为Candidate角色，然后并行向集群中所有其他服务器节点发送RequestVote RPC来给自己投票，候选人等待直到三种情况之一发生：<br>　　a. <strong>该Candidate赢得该次选举成为新Leader</strong><br>　　当某个Candidate从集群中绝大多数服务器获得针对该term的选票，则其赢得该次选举成为Leader，因为按照先来先得的原则，每个服务器最多会对一个term投出一张选票，获得绝大多数选票确保了至多只有一个候选人赢得该次选举。<br>　　一旦Candidate成为Leader，就会向其他服务器发送心跳消息维护自己Leader的地位，并且阻止产生新的Leader。<br>　　b. <strong>其他服务器成为新Leader</strong><br>　　Candidate在收集选票的时候，很可能收到其他服务器发送的声明自己是Leader的AppendEntries RPC消息，此时如果收到的AppendEntries RPC的term不小于该Candidate当前的term，则Candidate承认发送该AppendEntries RPC的服务器的Leader合法地位，自己退化为Fellower角色。否则会拒绝这个RPC并维持自己Candidate的角色。<br>　　c. <strong>一段时间后没有任何Candidate胜出</strong><br>　　一般出现在多个Fellower变成Candidate，然后同时发出RequestVote RPC请求，导致选票被瓜分后，没有任何一个Candidate获得绝大多数选票。此时Candidate会增加term并开始新一轮的Leader选举。<br>　　通常情况下这种选票瓜分的恶性竞争会持续下去。Raft采用随机选举超时的机制来减少这种情况的发生，选举超时设置为某个固定时间区域中的随机值(比如150-300ms)，这样当现有Leader挂掉之后，通常也只有一个Fellower会首先超时，然后迅速切换为Candidate、发出RequestVote RPC并赢得选举，然后快速发送心跳包；同时在发生选票瓜分的情况下，每次在Candidate开始新一轮的选举时候，会重置一个随机的选举超时时间。通过这机制，发生选票瓜分的几率被大大降低了。</p>
<h2 id="2-3_日志复制">2.3 日志复制</h2><p>　　一旦Leader的角色被确定，就可以接受客户端的请求并提供服务了。客户端的每一个请求都包含状态机的执行指令，Leader负责刚其作为一个entry追加到自己本地日志中，然后并行的向其他服务器发送附含执行指令的AppendEntries RPC，使其他服务器都复制这个日志entry。当该条日志被安全的复制后(即通过AppendEntries RPC调用的结果得知，该日志被安全地复制到绝大多数服务器上面了)，Leader会应用这条日志到自己的状态机中，并将执行的结果返回给客户端。如果(少部分)Fellower崩溃或者运行缓慢，或者因为网络等问题，即使Leader已经回复了客户端，Leader仍然会不断的重试AppendEntries RPC直到所有的Fellower都最终存储了所有的日志条目。<br>　　在Raft算法中，日志是有序序号标记的entry组成的，每个entry包含该创建时候的term、状态机需要执行的指令、在所有日志中的位置索引组成。Raft保证当日志条目被复制到绝大多数服务器上面的时候，该日志entry就会被提交，即更新commitIndex，Raft算法同时也保证所有已提交的日志都是持久化的并且最终会被所有的可用状态机执行。<br><img src="/post_images/images/201612/978287ea.jpg" alt="raft-log"><br>　　Leader跟踪了最大将会被提交日志entry的索引，并且该索引值会被包含在未来所有的AppendEntries RPC中(包含附加日志内容为空的心跳包)，这可以方便的让其他服务器知道Leader的提交位置，一旦Fellower知道一条日志已经被提交，就会按照日志的顺序将其应用到本地的状态机中去执行。<br>　　和Paxos不同的是，Raft的日志约束为连续的、中间不允许有空洞，而且相同索引的日志在各个服务器上面指令完全相同，这样的设计可以减少很多不必要的麻烦，具体来说：<br>　　(1) 如果在不同服务器的日志中拥有相同的索引和Term，那么他们存储了相同的指令；<br>　　(2) 如果不同服务器中两个日志具有相同的索引和Term，那么他们之前所有的日志条目也都全部相同。<br>　　对于上面第二点，通过每次RPC简单一致性检查就可以确保。每当Leader发送AppendEntries RPC的时候，会包含新entry紧接之前条目的索引位置和term附加在里面，当Fellower接收到的时候会进行一致性检查，如果发现索引及term指定的日志找不到，就会拒绝接收该AppendEntries RPC请求。这种一致性通过强制Fellower复制Leader日志的方式来解决，领导者对每一个Fellower都维护了一个nextIndex，表示下一个需要发送给Fellower日志条目的索引位置，Leader通过不断减少nextIndex后退的方式尝试最终会找到和Fellower日志不一致位置开始的地方，然后从这个地方开始Leader将自己的日志同步给Fellower就可以了。不过这种大规模的日志不一致性通常在服务器接连崩溃的情况下更容易产生，当新选出了Leader之后，该Leader也会强制所有服务器的nextIndex为自己本地最后一条日志索引值+1，这样在后续正常发送AppendEntries RPC请求后，所有的Fellower就会自动进行本地日志一致性检查并在必要情况下进行同步操作了。<br>　　通过这种方式，只需Leader向Fellower单方面同步日志就可以完成，而且只需要Leader正常发送AppendEntries RPC请求，Fellower自己进行一致性检查，Leader得到失败的反馈信息后，再同Fellower进行不断交互以使得两者日志最终趋于一致，而且这种操作不会影响到其他的Fellower，因而也不会影响到系统整体的性能。</p>
<h2 id="2-4_安全性">2.4 安全性</h2><p>　　上面的内容都比较的理想化，但是在现实环境中Leader、Fellower各个服务器随时都可能崩溃不可用，如果没有额外的约束整个系统的工作是不安全的，比如当只有少量日志的Fellower被选取成了新Leader的情况。<br>　　简单来说，此处就是要实现即使发生了Leader重新选取，也要让任何新Leader对于给定的term，都必须有前任Leader所有已经被提交的日志条目，那么上面的机制就仍然可以正常工作。</p>
<h3 id="2-4-1_增加选举限制">2.4.1 增加选举限制</h3><p>　　如果任何的Fellower都可以成为新人Leader，那么这个新Leader很有可能缺失前Leader的部分提交日志，很多一致性算法确实是这样的，然后通过某些方法识别出新Leader缺失日志，并在选举阶段或者成为新Leader之后快速的将这些缺失日志补齐，这些方法实现起来比较复杂。Raft算法通过很简单的限制解决了这个问题：<strong><em>在RequestVote RPC 中包含了Candidate的日志信息，然后投票人会拒绝掉那些日志没有自己新的请求</em></strong>。<br>　　上面的这条约束肯定是有效的：对于一个被提交的日志，那么这个日志肯定是被大多数服务器所见而被存储的，而一个Candidate要想成为Leader就必须和集群中的大多数服务器所通信，这样一来新Leader肯定会遇到至少一个记录着最新提交日志的服务器。再加上上面的限制条件，那么一个新当选的Leader至少会和大多数的服务器节点一样新，其肯定持有了所有已经提交了的日志条目。</p>
<h3 id="2-4-2_提交前term内的日志条目">2.4.2 提交前term内的日志条目</h3><p>　　在Raft算法中，当一个日志被安全的复制到绝大多数的机器上面，即AppendEntries RPC在绝大多数服务器正确返回了，那么这个日志就是被提交了，然后Leader会更新commitIndex。<br>　　这里书中描述的比较复杂，其实本质就是通过上面的选举机制和提交限制，让Raft算法是安全的，即使是针对前term的日志：如果日志被复制到绝大多数服务器上面，那么含有较少日志的S5服务器就不会被选举成Leader，也就不会发生描述的entry-2日志即使被复制到绝大多数服务器上面，也最终被覆盖的情况；而当含有被复制的绝大多数日志entry-2的服务器被选为新节点的时候，提交entry-4也会让前面的entry-2被隐式提交。</p>
<h3 id="2-4-3_Candidate和Fellower崩溃">2.4.3 Candidate和Fellower崩溃</h3><p>　　Candidate和Fellower崩溃的情况处理要简单的多。如果这类角色崩溃了，那么后续发送给他们的 RequestVote和AppendEntries的所有RCP都会失败，Raft算法中处理这类失败就是简单的无限重试的方式。<br>　　如果这些服务器重新可用，那么这些RPC就会成功返回。如果一个服务器完成了一个RPC，但是在响应Leader前崩溃了，那么当他再次可用的时候还会收到相同的RPC请求，此时接收服务器负责检查，比如如果收到了已经包含该条日志的RPC请求，可以直接忽略这个请求，确保对系统是无害的。</p>
<h1 id="三、集群成员变更">三、集群成员变更</h1><p>　　集群成员的变更和成员的宕机与重启不同，因为前者会修改成员个数进而影响到Leader的选取和决议过程，因为在分布式系统这对于majority这个集群中成员大多数的概念是极为重要的。<br>　　在集群中成员变更的NEW配置不可能立即在所有成员中生效，所以必须采用两阶段的方式来保证安全性，传统方式是将集群暂停工作，让其不再接受新客户的请求，更新配置完成后在让集群继续正常运行。<br>　　Raft中集群成员的变更是全自动的，通过产生一个“共同一致状态”来过渡传播NEW配置，并且做到在集群成员变更过程中仍然支持客户端请求，依靠在临界状态下达成一致的操作(针对选取和提交)需要分别在新旧两种配置上都获得绝大多数服务器投票才可以。成员变更请求在日志中以特殊的configuration entry来存储和通信，主要通过C-old,new和C-new这两个特殊日志entry来实现。<br>　　在Leader接收到成员变更请求后，会创建C-old,new日志entry，然后Leader会首先将其添加到自己本地日志中，并通过之前描述的普通日志复制提交流程，确保在OLD、NEW两个配置下的在绝大多数服务器上复制成功并提交；接下来Leader会创建一个C-new并在NEW配置下的绝大多数机器上复制成功并提交，创建C-new之后NEW配置就可以单独做出决议了。此外，这里还有一个关键性的约定——所有的服务器一旦存储了C-old,new日志条目后(实际就是见到NEW配置后)，就总是会用NEW配置而无论这个配置日志条目是否已经被提交，通过这种方式实现NEW配置在集群成员中快速传播。一旦C-old,new被提交后，OLD和NEW配置都不能单方面的产生决议(只能在新旧两个配置下都完成绝大多数投票)以保证安全，直到NEW配置下的C-new日志条目被产生，NEW配置就可以单独决议了。<br><img src="/post_images/images/201612/d255f8d6.jpg" alt="raft-member"><br>　　至于在C-old,new提交和C-new创建之间为什么会有间隙，原文没有说清楚。其实也很容易理解：在C-old,new日志entry的创建和提交之间，Leader还可能有其他新的决议发起(比如客户端请求)，按照日志顺序一旦C-old,new被提交，那么集群中绝大多数主机都更新成NEW配置了，但是在NEW配置传播的过程中，为了保证安全在这个期间产生的所有日志都必须在新老配置中都得到绝大多数投票才允许真正被提交。至于C-new的产生，是为了表明Leader承诺从这个时候起所有的日志都不再会发给OLD配置主机，所以这个点之后NEW配置就可以独立工作了，由于Raft序列化日志的特性，一旦这个C-new日志条目被提交，集群配置中被删除的服务器就可以安全下线了。<br>　　新加入的机器日志都是空白的，起始阶段都在进行日志追赶(catch up)，Raft算法为了减少可能的性能损耗，对新加入的机器都是以旁观者的状态一直追赶旧日志而不会追加新日志参与投票，只有到了追赶日志和Leader对齐了，再参与新日志追加投票以行使正常集群成员的职能。还有NEW配置可能会把现任Leader删除掉，那么当C-new被提交后，该Leader将会卸任并退化成Fellower的角色，此时在NEW配置下会发生新Leader的选举，选举得到的新Leader一定是NEW配置下的主机，而在这之前由于一致性状态的约束，如果发生Leader选举那么选出来只可能是OLD配置中的服务器，因为一致性状态选举操作必须在新旧配置中都得到绝大多数选票才行。</p>
<h1 id="四、日志压缩">四、日志压缩</h1><p>　　日志会随着系统的不断运行会无限制的增长，这会给存储带来压力，几乎所有的分布式系统(Chubby、ZooKeeper)都采用快照的方式进行日志压缩，做完快照之后快照会在稳定持久存储中保存，而快照之前的日志和快照就可以丢弃掉。<br>　　Raft算法中快照所需保存的数据有：快照点时候状态机的状态信息；最后被快照所取代的日志条目在日志中的索引值；上面被取代条目所属的任期term，此外为了支持成员更新，快照还会将当前最新的成员配置写入上面描述的那个日志索引中。<br>　　Raft采用让服务器独立创建快照，而不是只让Leader负责创建快照，主要考虑到在所有服务器本地已经具有了创建快照所需的全部信息，而且本地创建快照代替Leader创建快照，就免除了Leader要向各个节点传输快照的额外任务、带宽和性能损耗，而且在Leader负责客户端响应、发送RPC的任务外如果还需维护快照的任务，其角色就会更加复杂。<br>　　在Raft中快照都是各个服务器独立创建的，但是有时候需要Leader向其他服务器发送快照，比如某些服务器跟随的速度缓慢，或者新加入集群的服务器，此时需要向Leader同步日志的时候，如果Leader创建了快照并将之前的日志都删除掉了，那么此时就必须通过快照的方式发送了。<br>　　Raft中采用一个额外的InstallSpanshot RPC的调用来实现日志传输，虽然名曰快照，其实也就算是一个特殊的日志entry。当接收到快照的时候，通常情况下快照会包含接受者中没有的信息，即快照代表的日志entry会比接受者当前本地含有的日志要新，此时接收者会丢弃掉自己所有的日志，并在指定位置写入该快照作为最新状态；如果因为网络或其他因素，接收者含有比快照更新的日志，那么接收者负责把快照位置之前的数据全部删除，同时比快照新的数据需要保留下来。</p>
<h1 id="五、Client交互">五、Client交互</h1><p>　　Client只向Leader发送请求，当Client开始的时候会随机向集群中的任何一个服务器发送请求，如果Client挑中的恰巧不是Leader，那么该服务器会拒绝Client的请求，并将其最近获得的Leader信息(包括通信用的IP:Port)返回给Client，接下来Client根据这个信息直接向Leader重新发送请求；如果此时Leader恰巧崩溃了，那么Client的请求就会超时出错，Client会再次重新随机挑选服务器再次发送请求。<br>　　Raft算法要求Client的请求是线性化语义的，即每次请求会被立即执行，在请求和响应中只会被执行一次(也就是RESTful中的等幂性，同一个请求发起一次或者多次，最终的效果是相同的)，而要确保这个效果的方式是客户端负责对每条指令都赋予一个唯一的序列号，然后状态机跟踪每条指令最新序列号和其响应结果，如果后面收到一条指令具有相同的序列号但是该序列号已经被执行了，那么就直接返回结果而不重新执行该指令。<br>　　对于只读操作可以直接处理而不需要记录日志，但是会有读取脏数据的风险。在Leader稳定运行的时态，Leader肯定知道当前已经提交的entry，但是在新Leader选取刚上任的时候，虽然肯定是含有最完整的日志信息的，但是还不知道提交到哪条entry了(可以参看上面提交前term日志条目的情况)，所以在新Leader上任的时候会发起一个no-op的entry来刷新得到最新commit信息。然后，Leader在响应只读请求的时候，需要向绝大多数服务器发送一个心跳信息，确保当前自己还是合法的Leader。</p>
<h1 id="总结">总结</h1><p>　　如果在工程化的水平上考虑，Raft算法的确比MultiPaxos要简单容易的多，而且对比PhxPaxos中做出的诸如Master选举与心跳、Master负责所有客户端请求(允许普通节点响应脏数据除外)、日志压缩与快照等等操作，在这里看来也是那么的熟悉，只不过Raft对于整个分布式的设计和实现要更清晰、更系统，而不会让人感觉是在MultiPaxos的基础上缝缝补补拼凑出来的一个怪物吧。<br>　　眼观这么多论文，大家对Paxos的工程化实现，感觉都是相互借鉴啊，哈哈！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://raft.github.io/raft.pdf" target="_blank" rel="external">In Search of an Understandable Consensus Algorithm</a></li>
<li><a href="https://raft.github.io/" target="_blank" rel="external">raft.github.io</a></li>
<li><a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md" target="_blank" rel="external">找一种易于理解的一致性算法（扩展版）</a></li>
<li><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="external">CONSENSUS: BRIDGING THEORY AND PRACTICE</a></li>
<li><a href="https://raft.github.io/slides/raftuserstudy2013.pdf" target="_blank" rel="external">Raft: A Consensus Algorithm for Replicated Logs</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Amazon Dynamo论文阅读笔记]]></title>
      <url>https://taozj.org/201612/read-note-of-amazon-dynamo.html</url>
      <content type="html"><![CDATA[<p>　　其实个人一直比较喜欢读Google、Amazon、Facebook这类科技公司工程化的paper，一方面是这类文章通常不会夹杂着让人看着眼花缭乱的数学公式(而且很多文章往往很简单的道理也会被装饰的神神叨叨滴)；二来这些系统用到的技术都比较的大众成熟，可以很容易的在网上搜到相关资料，让你在短短时间就知道大概是个什么意思；还有最主要的是这些论文是进行实实在在工程化并用于生产环境了，方案可行性自然不用多说，在实现的过程中遇到的各种现实、细节问题也是很值得学习揣摩和借鉴的。比如，接下来要说的<a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">《Dynamo: Amazon’s Highly Available Key-value Store》</a>这篇论文要算是分布式系统设计实现中的必读经典了，虽然该套系统没有开源，而且由于商业机密部分内容没能够详细阐述，但丝毫没有影响到它对分布式系统设计实现的重要指导作用。<br><img src="/post_images/images/201612/3a93058f.png" alt="aws"></p>
<h1 id="一、前言">一、前言</h1><p>　　Amazon Dynamo系统的设计和实现从最开始就比较的实用主义：首先Amazon作为全球最领先的电商企业，其丰富的经验让其可以洞悉到绝大多数互联网公司的需求点和关切点，其次Dynamo是作为服务出售的，所以其并没有设计实现成一个至臻完美的分布式存储模型，它只支持K-V非关系型键值存储，就像是一个巨大的dict/map结构，只支持get()、put()两种简单访问方式，优化成高可写入性要求，存储的对象尺寸大多小于1M，成本考虑上支持99.9%级别的可用性(百毫秒读写响应)，但依据Amazon在云计算领域的强大实力，该系统在性能、可靠性、效能、伸缩性等方面没有丝毫的妥协。<br>　　和绝大多数分布式系统一样，Dynamo使用最终一致性获取性能从而保证可用性的，然后通过现有各项成熟的技术手段解决项目中的各种问题：数据使用一致性hashing进行分区，同时提供数据副本保证安全；通过NWR和对象vector lock版本机制有限的解决冲突并实现最终一致性；Merkle tree数据结构可以实现节点间数据的高效同步；整个系统完全去中心化，采用Gossip协议实现成员变更的同步。</p>
<h1 id="二、背景知识">二、背景知识</h1><h2 id="2-1_系统假设和设计需求">2.1 系统假设和设计需求</h2><p>　　a. 访问模式：数据项通过key唯一确定，且只提供读、写两个操作接口，对象采用二进制方式存储。这种K-V的存储符合绝大多数互联网海量对象的存储需求，对象的读取写入只支持单个对象的操作，任何多对象、关系性的操作都不支持；<br>　　b. ACID：就是分布式系统中的原子性、一致性、隔离性和持久性，强一致性模型虽然实现简单，但是可用性的最大杀手，所以该系统只提供最终一致性保证；同时也不支持隔离性，只提供单个元素的更新操作。<br>　　c. 有效性：服务必须提供稳定可靠的延时和吞吐量，根据在性能、价格、可用性和持久化各个因素的考量和妥协中，提供99.9%的可访问性；<br>　　由于在内部使用，所以不用考虑授权、鉴权操作，整个假设在一个可信环境的内网中执行的，不考虑拜占庭通信模型。<a id="more"></a></p>
<h2 id="2-2_设计考虑的问题">2.2 设计考虑的问题</h2><p>　　在商业系统领域，传统方式都是采用强一致性的数据访问，数据会在各个节点之间进行同步，在数据不确定是否正确的情况下通常设置该数据将是不可用的状态。这种模型虽然从编程角度很容易实现，但是这种情况下一旦出现问题(比如脑裂)，整个系统的可用性就必然会受到影响甚至处于不可用状态。<br>　　对于易于出现主机和网络系统的情况，可以通过优化同步操作来提高系统的可用性，比如后台异步化、并行传输，只要实现最终一致性就可以，但是异步化之后很容易导致修改和访问冲突和失败的情况，这时就需要确定何时、何人负责解决冲突问题(背锅问题)了，针对这个问题：<br>　　a. 很多传统的系统是在写阶段解决冲突和失败，这样读的时候操作会很简单，而如果比如因为冲突而不能顺利写入，写入操作就会被驳回返回失败。而Dynamo设计就是最强的可写入性，比如文中反复出现的购物车情形，即使网络不可用的情况下也不会驳回客户的请求，否则会很影响用户体验，为了保证这样高的可写入性，就必须在读阶段承担起这个解决冲突和失败的任务。<br>　　b. 解决冲突的角色可以是数据中心也可以是用户应用程序，前者是自动化解决冲突，通常只能用简单的机制来解决，比如“使用最新写入值(last write win)”，而用户程序处理会更加的灵活，比如多个版本共同求交集结果等方式。<br>　　除此之外，Dynamo还需要考虑：系统的高伸缩性；节点的对称性，所有的节点都一视同仁；去中心化，采用P2P的发现和同步技术，这一直是分布式系统追求的目标(比如避免单点故障)。</p>
<h1 id="三、系统架构">三、系统架构</h1><p>　　系统的工程化会涉及到相当多的细节，比如：数据持久性存储、可伸缩性、负载均衡、成员管理和错误探测、错误恢复、复制备份同步、过载处理、状态迁移、并发和任务调度、请求安排、请求路由、系统监测和报警、配置管理。篇幅限制，这篇论文没有对上面所有内容都展开论述。</p>
<h2 id="3-1_系统接口">3.1 系统接口</h2><p>　　Dynamo的数据类型是K-V，只支持最简单的get()和put()读和更新接口。Dynamo的底层会将key进行MD5 hash处理得到128bit的索引值，通过其确定底层实际的存储节点。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">get(key);</div><div class="line">put(key, context, object);</div></pre></td></tr></table></figure></p>
<p>　　get(key)正常情况下会返回key锁关联的object，而如果发生冲突(且底层无法解决冲突)的话，会返回一个列表，包含各个冲突的版本和context信息，用户可以用自己的机制解决这些冲突，并将结果写回更新成最新版本；put(key, context, object)会进行存储更新操作，其context参数通常是之前get读返回的。</p>
<h2 id="3-2_分区算法">3.2 分区算法</h2><p>　　对于节点出错和删除，以及添加节点的时候，必须采用一致性hashing的方式保证对其他节点最小影响。一致性hashing的知识在<a href="/201612/consistent-hashing.html">《一致性hash原理》</a>已经详细描述过了，主要也是基于hash环分区的方式实现的，而且相似地，为了让存储节点均匀分布、实现负载均衡，采用了虚拟节点的改进方式，这样不仅在平常访问的时候，而且在增加和删除节点的时候，都会将影像平均分布到其他节点上去，而不会对少数节点造成加大影响。</p>
<h2 id="3-3_副本">3.3 副本</h2><p>　　因为Dynamo实现的是存储系统，而不是前面介绍到的缓存系统，所以为了数据的安全必须使用产生多副本(Replication)机制。Dynamo会让每个数据产生N个副本，关于这些副本的分布，是用到前面通过一致性hash根据key计算出该数据属于哪个虚节点，然后沿着顺时针的方向在接下来的N-1个节点上产生该数据的额外副本。<br>　　上面负责存储key的节点和副本节点共同组成了preference list列表。考虑到有些节点会出错不能访问的情况，这个列表的长度通常会大于N。而且在使用了虚拟节点机制后，物理节点会在hash环中出现多次，所以如果不加挑选的话，很有可能N个虚拟节点会映射到底层少于N个实际的物理存储节点上，显然这样的话单个物理节点可能会出现多个虚拟节点副本的丢失，所以系统在选择节点组成preference list的时候，都是采用跳跃的方式，确保列表中保存的都是物理节点各不相同的虚拟节点。</p>
<h2 id="3-4_数据版本机制">3.4 数据版本机制</h2><p>　　Dynamo只保证最终一致性，采用异步的机制进行读写操作。<br>　　Dynamo采用vector clocks的机制，vector clock记录了某节点对该key更改的版本记录，是一个(node, counter)的结构，那么所有节点对该对象的修改将可以组成一个vector clock的列表。系统可以根据检查两个节点上某个对象的vector clock列表，而判断该对象在各节点上的副本，是序列化的因果关系还是并行分支的关系：如果是前者(大多数正常情况)，系统就可以自动进行语法冲突合并(syntactic reconciliation)，新版本的数据覆盖旧版本的数据；后者冲突情况则需要返回包含所有冲突版本等信息的context，然后由client端负责解决这个冲突，并最后用context更新写会最新结果，称为语义冲突合并(semantic reconciliation)。<br><img src="/post_images/images/201612/e2821ae0.png" alt="aws-1"><br>　　比如上图的过程，D1[(Sx, 1)]、D2[(Sx, 2)]都是由同一个节点X做的修改，所以不可能产生版本冲突，而当因为节点出错、前端负载均衡等因素影响，后面的更新都基于D2但发生在了Y、Z两个节点上，接下来客户读取的时候会发现D3、D4之间没有因果关系，因此将所有结果都罗列返回给客户端，client负责合并后并通过X节点更新写入，且相应地增加Sx的版本号。<br>　　看到这里可能会想到，如果所有的写请求都发向某个固定的节点，难么版本冲突的概率不就会大大降低了么？如果该节点一直可用，那么这种序列化的修改肯定是可以大大降低冲突的概率的，但是论文指出这样的操作负载是不均衡的，那么不均衡的节点请求会导致可用性降低。实际上，通常的写都是紧跟在读操作之后(难道是必须的？put需要一个context啊)，通常写会发送到读响应最快的那个节点上面去，这样的优化就可以保证较好的写入性能，同时也间接实现了”READ-YOUR-WRITE”这读己之所写级别的一致性。<br>　　如果记录每个节点的更新版本的话，通常情况不会产生问题，因为更新都是在preference list的前N个节点，但是在发生脑裂或某些节点出错后，后续节点会依次代替不可用节点响应写入请求，那么这个vector clock列表长度必然会不断增加。为了防止这种情况，实践中的vector clock会加上时间戳以记录该节点最后修改的时间，当vector list列表的长度超过固定长度(比如10)的时候，将时间戳最旧的节点版本信息剔除出去。</p>
<h2 id="3-5_get()和put()操作">3.5 get()和put()操作</h2><p>　　用户的请求都是在HTTP层之上发起的，将用户请求分派到特定节点，分派的方式有两种：<br>　　a. 通用的负载均衡分配，这时分配是通用的基于后端节点的负载信息确定的；<br>　　b. 通过将客户端链接上节点发现(partition-aware)程序库，那么客户端就知道分布式节点的信息，请求会直接瞄准到对应的节点上面去。<br>　　两者各有优缺点，第一种方式应用程序不用链接额外的库，第二种方式更加的高效，会跳过一些无畏的请求转发，所以大多情况下请求会有更小的延迟。<br>　　通过客户端方式定位节点，客户端会以10s周期性的随机从一个节点下载集群的节点成员列表(这个列表是通过Gossip协议方式同步，并保证所有节点最终一致性的)，有了这些信息客户端就直接可以向目标节点发送请求，而不会产生一次可能的请求转发了。这里成员列表更新是客户端主动pull模式，而不是节点主动push模式，很显然前者模型更简单方便，但是可能得到的列表是旧的，此时客户端如果请求失败的话，会立即请求刷新成员列表。<br>　　通常的读写操作都会在preference list的前top-N节点上操作的，如果是以客户端链接节点发现库的方式，负载均衡可能会将请求随机分配到任意节点，如果分配的节点不在该key的preference list的top-N中，那么该请求会自动转发到top-N的第一个节点(任何节点本地都含有整个系统完整的成员列表)。这里所说的top-N节点都是指健康可用的节点，系统会自动跳过那些出错或者不可访问节点，使用排在后面的低rank节点替补上来。<br>　　Dynamo采用NWR的机制来维护多个节点上数据副本的一致性，R和W表示读、写请求最少完成节点数目就可以表示本次操作成功，因而读写请求的延迟由最后一个完成读写操作的节点所决定，配置上要求R+W&gt;N就形成了一个Quorum的机制，而R/W两者相对大小也代表了这个系统读/写性能之间的权衡。所以对于put()请求，当接收到请求的那个节点首先产生新版本的vector clock，本且本地写入该更新值，同时将新版本的值连同新vector clock发送给top-N的其他节点，当最后一个第(W-1)节点完成写入后，该更新操作被认为成功；对于get()请求，收到请求的节点会向top-N的所有节点发送读请求，然后等待收到R个响应后，如果节点收到的R个请求中会有多个版本的数据且无法因果合并冲突，则返回所有版本，冲突合并后的数据会更新并写回节点上去，如果超时后还没返回R个响应，则会做出错处理。</p>
<h2 id="3-6_出错处理：Hinted_Handoff">3.6 出错处理：Hinted Handoff</h2><p>　　Dynamo中的Quorum成员不是固定的。之前说道为了考虑节点会出错的情况，preference list的长度通常会大于N，而top-N通常都是在hash环中按照顺时针方向依次选取的N-1个在不同物理节点上的虚拟节点，当出现脑裂或者部分节点宕机、不可访问的时候，就会依序访问接下来preference list中的接下来的节点。<br><img src="/post_images/images/201612/e5241d11.png" alt="dynamo-2"><br>　　对于上图中，假设N=3且preference list成员依次包含A、B、C、D节点，此时节点A临时不可访问，那么发送到A的数据将会被发送给D，同时会在元数据中标明hint信息，指明这个消息本来是要发送给A节点的。当D收到带有hint消息的数据时候，会在本地单独开辟一个数据库用于存储该类信息，在代替A节点响应请求的同时，还会周期性的检查节点A是否已经恢复，如果恢复了将会把这些副本同步给A节点，然后D节点再把这些本地存储给删除掉。<br>　　现实中，可能因为供电、网络、制冷系统、自然灾害等因素导致整个数据中心挂掉，Dynamo会配置成每个key的preference list会夸数据中心存储，数据中心之间采用高速网络连接，以保证在单个数据中心无法访问的时候整个系统仍然可用。</p>
<h2 id="3-7_永久出错处理：同步恢复">3.7 永久出错处理：同步恢复</h2><p>　　上面的情况主要用于临时性、短暂性的节点不可访问的情况，对于其他永久性出错的情况，Dynamo采用副本同步(replica synchronization)的机制来处理。<br>　　Dynamo使用了Merkle trees的方式，该数据结构是个hash tree，这种数据结构的叶子节点都是单独key对应value的hash值，而父节点都是子节点的hash值，这样的好处是两个父节点的hash值一致，那么就不用逐个比较他们的子树了。当比较两个根节点的hash值的时候如果不一致，就需要不断的交换比较子节点的hash值，一直查找到不相等的叶子节点从而查找到需要同步的key，然后同步更新之。虽然这样操作麻烦一些，但是不需要在节点之间同步整个树结构或者整个数据集，减少了传输量从而增加了同步效率。<br>　　在Dynamo中，每个节点都为其所承担的hash virtual node的key范围建立一个Merkle树，那么当任意两个节点存储了相同数据(副本)的时候，这两个节点交换root节点的hash值看两者是否是已同步的状态，如果不相同采用树遍历的方式检查到未同步的部分。麻烦的是，当新加入节点的生活，需要重新建立Merkle树结构。</p>
<h2 id="3-8_成员管理和错误探测">3.8 成员管理和错误探测</h2><h3 id="3-8-1_Ring_Membership">3.8.1 Ring Membership</h3><p>　　管理员可以通过命令行或者浏览器的方式连接到某个节点上面去，然后发送添加、删除节点的指令，接受处理请求的节点会把这个成员变更事件和时间记录固化下来，然后通过Gossip协议不断地传播这个事件(就是每个节点每秒会随机地选择peer节点，然后两者通信交换自己的本地的全局节点成员信息，并合更新并两者的成员列表)，虽然没有具体时间的保证，但是Gossip协议会保证最后某个时间集群中，所有node都会就成员列表达成最终一致性。<br>　　当一个新的节点添加进来的时候，根据一致性hash和虚拟节点的原理，会产生多个虚拟节点和其hash space的对应关系(tokens)，并固化到本地磁盘上面，虽然新加入的节点起始只含有自己的token信息，然后根据前面相同Gossip协议传播机制，最终所有节点都会在本地存储这种虚拟节点的分区信息，所以这种本地存储也使得任何一个节点都可以快速的将目的key的读写请求进行精准转发。</p>
<h3 id="3-8-2_External_Discovery">3.8.2 External Discovery</h3><p>　　论文描述了逻辑分区的Dynamo环的情况，但是我想主要可能考虑新加入多个节点不能快速互相发现和传播吧。Dynamo会选择一些节点作为种子(seed)的角色，这些种子是通过配置或者其他服务方式产生的，对所有的节点都可见，那么新加入的节点就可以快速的和这些种子节点进行交互和同步，传播的效率大大提高了。</p>
<h3 id="3-8-3_Failure_Detection">3.8.3 Failure Detection</h3><p>　　错误检测主要是防止节点尝试和不能访问的节点进行交互，尽量避免通信失败的情况。其实只要B节点不响应A节点的消息，那么A节点就认为B节点出错了，此时A节点就会选择和B节点具有相同数据副本的节点发送请求，同时A节点还会周期性地探测B节点是否恢复可用了。<br>　　最初的Dynamo设计使用去中心化的方式，维护一个全局的最终一致性的节点失败状态信息，后来发现这种设计是多余的：通过前面的增加或者删除节点的操作，然后通过Gossip协议节点的存在性会达到最终一致性，而临时性的节点不可用直接根据请求是否响应就可以探测出来，候选的节点会自动接替之用于响应服务。</p>
<h2 id="3-9_存储节点(物理节点)的添加和删除">3.9 存储节点(物理节点)的添加和删除</h2><p>　　当一个节点加入到hash环中的时候，比如节点X，考虑到上面的分区问题外，还会涉及到数据副本的问题，会有至多N个节点会和这个变动的hash区间相关联。在这个分区划分出来之后，一些节点不需要再负责这部分区域的keys的时候，会把这部分keys的数据传输到这个新加入的节点上来。<br>　　比如对于上面的图，当节点X加入到节点A-节点B中间的时候且N=3的时候，节点X就需要存储(F,G]、(G,A]、(A,X]区域的数据，而对应的节点B、C、D就不需要保存对应部分的数据副本，因此他们会将这部分数据传输给节点X。</p>
<h1 id="四、后言">四、后言</h1><p>　　Dynamo的基本实现算是理解完了。说到这里，之前看到腾讯微信后台出了PaxosStore的分布式存储，用以替代之前的QuorumKV存储，而后者恰巧是基于NWR(N为3，W/R为2)协议实现的分布式存储系统。他们给出的最终测试结数据看来，QuorumKV和PaxosStore两者的性能(延迟)差距并不大，而是在请求失败率的指标上有较大的改进。<br>　　没有QuorumKV的实现细节，Dynamo和PaxosStore也没有过正面PK，所以这里也不好乱喷。只不过从原理上来说，NWR只是保证异步修改多个副本，协议本身并没有保证最终一致性，那么冲突肯定是更容易发生的；而Paxos协议在更新的时候就需要多个Acceptor进行表决，并达成最终一致性(如果此轮表决没有达成一致还会继续Propose再表决)，这种情况下冲突的概率肯定是很低的，所以得到他们的测试结果也是情理之中的事情，毫无悬念。<br>　　Paxos的论文过于的理论，工业实现确实不容易，坑点很多。感觉Raft虽然添加了一些假设，但是将整个系统实现会方便一大截，有机会要好好拜读一下那篇著名的斯坦福博士论文，你懂得！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
<li><a href="http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;mid=2650994526&amp;idx=1&amp;sn=255dd87bd8601919bda3d597c65439f3" target="_blank" rel="external">微信PaxosStore内存云揭秘：十亿Paxos/分钟的挑战</a></li>
<li><a href="http://the-paper-trail.org/blog/consistency-and-availability-in-amazons-dynamo/" target="_blank" rel="external">Consistency and availability in Amazon’s Dynamo</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[一致性hashing的原理解析]]></title>
      <url>https://taozj.org/201612/consistent-hashing.html</url>
      <content type="html"><![CDATA[<p>　　一致性hash最常见的应用情形就是缓存，其实只要涉及到hash和多台主机请求路由的情况，都可能涉及到一致性hash问题。一致性hash主要是考虑到集群中节点挂掉或新增节点的时候，要对已有节点的影响降到最小，传统hash值取余方式肯定不能满足这个要求，交换节点位置影响还有限，但是新增节点、删除节点会让绝大多数的缓存失效，除了导致性能骤降外很有可能会压垮后台服务器。对于日常使用的情况，节点挂掉算是小概率事件，但是对于像Amazon Dynamo这种规模的分布式集群来说，节点挂掉是必然事件——甚至每天都会有集群中的主机或者硬盘出问题。<br>　　一致性hash的解决思路，就是对缓存的object和Node使用同一个hash函数(实际不需要完全一致，但至少保证产生的hash空间相同)，让他们映射到同一个hash空间中去，当然这很容易实现，因为大多数的hash函数都是返回uint32类型，其空间即为1~$2^{32}$-1。然后各个Node就将整个hash空间分割成多个interval空间，然后对于每个缓存对象object，都按照顺时针方向遇到的第一个Node负责缓存它。通过这种方法，在新增加Node和删除Node的时候，只会对顺时针方向遇到的第一个Node负责的空间造成影响，其余的空间都仍然有效。<br><img src="/post_images/images/201612/58d63a48.png" alt="c-hash-add-remove"><br>　　假设有Object A、Object B、Object C、Object D四个对象，以及Node A、Node B、Node C、Node D四个节点。根据上面的一致性hash原理，如果Node C挂掉了，那么Node C掌管的区域(包括Object C)都将会由Node D所接管；而如果增加节点Node X，那么原先Node C掌管的空间将会被分割，导致Node X之前的对象Object C由Node X所接管；针对节点之间交换顺序的情况，也可以预见也只有交换的那两个节点对应的区间会被影响。<a id="more"></a><br>　　当然，上图各个节点的均匀分布是理想状态，实践中通常采用节点的IP地址或者主机名来计算hash值，在整个hash空间不太可能分布的这么均匀，而且即使当前比较均匀的话后面也会由于增加和删除节点打破这种状态。因为通常Node数目不会非常大，导致这种分布不会很均匀，所以采用虚拟节点(virtual nodes)的技术来增加节点的数目，这些虚拟节点再由底层实体Node来承载，当虚拟节点足够多的时候，他们趋向于将整个hash空间均匀成各个区间了。<br><img src="/post_images/images/201612/49f1526a.png" alt="c-hash-vip"></p>
<p>　　MySQL的文档指出一致性hash算法有Ketama和Wheel两种，但是后者Wheel算法的相关资料没有找到。因为Memcached的服务端是设计成单机模式的，如果需要达到多节点协同的效果，就必须在客户端支持负载均衡和一致性hash算法。目前开源流传的主要是last.fm实现的<a href="https://github.com/RJ/ketama" target="_blank" rel="external">libketama</a>，作者声称已经在Last.fm的生产环境稳定运行十几年，用C语言实现，而且提供了各种语言的接口，不过这个项目貌似也开始长草了，作者正在寻找maintainer。<br>　　这个库十分的小，代码没有多少。同时在作者的博客也给出了具体的实现步骤：<br>　　a. 确定主机列表，比如 1.2.3.4:11211, 5.6.7.8:11211, 9.8.7.6:11211；<br>　　b. 对上面的每个主机”ip:port-%d”字符串计算MD5散列值，因为每个MD5是128位，所以可以产生4个unsigned int散列值，每个主机循环40次，即每个主机产生160个虚拟节点，这里每个虚拟机点都保存了实体节点的地址，可以直接取出给客户端访问使用；<br>　　c. 把这些散列值进行排序，然后想象它们分布在0~$2^{32}$-1的散列空间中去；<br>　　d. 当存取一个key的时候，先计算出unsigned int的散列值，然后通过二分查找的方式，快速定位到满足条件的虚节点，并从中取出响应的物理节点的地址信息；<br>　　e. 关于节点的添加和删除，我查看到估计只有ketama_roll这个函数相关，其会判断文件修改时间戳，如果修改了就使用信号量锁住系统，然后重新读取配置重新建立虚拟节点。因为虚拟机点的建立方式是固定规则的，所以对于那些没有修改的主机，其得到的虚拟节点仍然存在，hash一致性得到维持。</p>
<p>　　从上面的描述看来，一致性hash的原理和实现其实还是挺简单明了的。此外，还需要提到无意中观察到的一个案例，就是Google在其Maglev系统中，并没有直接采用通常的一致性hash解决方案，而是改进成了一个Maglev hashing。因为对于一致性hash，通常考量的有两个方面：<br>　　a. load balancing: 对于backend group中的节点，他们所承担的负载应该是大致均匀的；<br>　　b. minimal disruption: 当backend group中的节点发生增删变化时候，没有变化的节点应当受到最小的影响。<br>　　虽然通过虚拟节点和hash盘的手段，上面的两个需求都可以得到一定的满足，但是Google的这个Maglev系统后台会有上千台的服务器集群，所以对负载均衡和最小扰动需求要高的多：要想负载均衡就需要添加更多的虚拟节点以平均单个物理节点的影响，虚拟节点数目增加后会对查找key到虚拟节点映射操作负担增加。<br>　　Maglev hashing的最主要步骤，就是以不同的方式产生每个entry(其实这个entry也有虚拟节点等价的意义)的lookup table。假设backend的节点数目为N，entry的条目数为M(通常M为大于100×N的质数)，使用两个hash函数h1、h2计算产生offset和skip，首先第一步初始化得到permutation表。<br><img src="/post_images/images/201612/775090a1.png" alt="c-hash-p"><br>　　上图是假设h1和h2计算得到的三个backend的(offset, skip)分别为(3,4)、(0,2)、(3,1)情况下所产生的结果，原文中算法伪代码写的十分详细了，可以轻易进行工程化实现。通过permutation表，就可以得到entry和backend节点的映射关系lookup table，不过生成lookup table的步骤原文没有说，看了半天是这个意思：首先产生长度为N的数组，然后把permutation表按照从左到右、从上到下的顺序遍历，如果发现该数字代表的entry还没有backend节点就将其所在的节点填进去，如果已经有了就直接跳过，直到lookup table填满了完成。<br><img src="/post_images/images/201612/0e1b7bea.png" alt="c-hash-table"><br>　　从上图中可以看出，原始生成的lookup table中三个节点的分别比较均匀，而如果将B1节点移除，新生成的lookup table中剩余的B0、B2节点分配还是比较均匀的，而且改动的条目都是原始B1节点的entry，而B0和B2的条目都没有更改。在后文的测试中也发现，当在1000台backend节点下以0%~2.5%的比例并发撤出节点模式故障的情况下，查找表的改动率相比传统一致性hash比率也是相当低的，而且在有限entry数目下各个节点的负载均衡也得到了保证。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf" target="_blank" rel="external">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
<li><a href="http://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html" target="_blank" rel="external">The Simple Magic of Consistent Hashing</a></li>
<li><a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/" target="_blank" rel="external">Programmer’s Toolbox Part 3: Consistent Hashing</a></li>
<li><a href="https://www.metabrew.com/article/libketama-consistent-hashing-algo-memcached-clients" target="_blank" rel="external">libketama: Consistent Hashing library for memcached clients</a></li>
<li><a href="https://github.com/RJ/ketama" target="_blank" rel="external">GitHub ketama</a></li>
<li><a href="http://www.tom-e-white.com/2007/11/consistent-hashing.html" target="_blank" rel="external">Consistent Hashing</a></li>
<li><a href="http://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/44824.pdf" target="_blank" rel="external">Maglev: A Fast and Reliable Software Network Load Balancer</a></li>
<li><a href="https://www.evanlin.com/maglev/" target="_blank" rel="external">Maglev : A Fast and Reliable Software Network Load Balancer</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Nginx的软件负载均衡实现解读]]></title>
      <url>https://taozj.org/201612/nginx-load-balancing.html</url>
      <content type="html"><![CDATA[<p>　　负载均衡在服务端开发中算是一个比较重要的特性。因为Nginx除了作为常规的Web服务器外，还会被大规模的用于反向代理前端，因为Nginx的异步框架可以处理很大的并发请求，把这些并发请求hold住之后就可以分发给后台服务端(backend servers，也叫做服务池， 后面简称backend)来做复杂的计算、处理和响应，这种模式的好处是相当多的：隐藏业务主机更安全，节约了公网IP地址，并且在业务量增加的时候可以方便地扩容后台服务器。<br>　　负载均衡可以分为硬件负载均衡和软件负载均衡，前者一般是专用的软件和硬件相结合的设备，设备商会提供完整成熟的解决方案，通常也会更加昂贵。软件的复杂均衡以Nginx占据绝大多数，本文也是基于其手册做相应的学习研究的。据介绍除了Nginx，常用的基于反向代理的负载均衡软件还包括：HAProxy、Apache(mod_proxy)、Squid。<br><img src="/post_images/images/201612/ac230f42.png" alt="load-balancing"></p>
<h1 id="一、基本简介">一、基本简介</h1><p>　　负载均衡涉及到以下的基础知识。<br>　　(1) <strong>负载均衡算法</strong><br>　　a. Round Robin: 对所有的backend轮训发送请求，算是最简单的方式了，也是默认的分配方式；<br>　　b. Least Connections(least_conn): 跟踪和backend当前的活跃连接数目，最少的连接数目说明这个backend负载最轻，将请求分配给他，这种方式会考虑到配置中给每个upstream分配的weight权重信息；<br>　　c. Least Time(least_time): 请求会分配给响应最快和活跃连接数最少的backend；<br>　　d. IP Hash(ip_hash): 对请求来源IP地址计算hash值，IPv4会考虑前3个octet，IPv6会考虑所有的地址位，然后根据得到的hash值通过某种映射分配到backend；<br>　　e. Generic Hash(hash): 以用户自定义资源(比如URL)的方式计算hash值完成分配，其可选consistent关键字支持一致性hash特性；<br>　　(2) <strong>会话一致性</strong><br>　　用户(浏览器)在和服务端交互的时候，通常会在本地保存一些信息，而整个过程叫做一个会话(Session)并用唯一的Session  ID进行标识。会话的概念不仅用于购物车这种常见情况，因为HTTP协议是无状态的，所以任何需要逻辑上下文的情形都必须使用会话机制，此外HTTP客户端也会额外缓存一些数据在本地，这样就可以减少请求提高性能了。如果负载均衡可能将这个会话的请求分配到不同的后台服务端上，这肯定是不合适的，必须通过多个backend共享这些数据，效率肯定会很低下，最简单的情况是保证会话一致性——相同的会话每次请求都会被分配到同一个backend上去。<br>　　(3) <strong>后台服务端的动态配置</strong><br>　　出问题的backend要能被及时探测并剔除出分配群，而当业务增长的时候可以灵活的添加backend数目。此外当前风靡的Elastic Compute云计算服务，服务商也应当根据当前负载自动添加和减少backend主机。<br>　　(4) <strong>基于DNS的负载均衡</strong><br>　　通常现代的网络服务者一个域名会关连到多个主机，在进行DNS查询的时候，默认情况下DNS服务器会以round-robin形式以不同的顺序返回IP地址列表，因此天然将客户请求分配到不同的主机上去。不过这种方式含有固有的缺陷：DNS不会检查主机和IP地址的可访问性，所以分配给客户端的IP不确保是可用的(Google 404)；DNS的解析结果会在客户端、多个中间DNS服务器不断的缓存，所以backend的分配不会那么的理想。</p>
<h1 id="二、Nginx中的负载均衡">二、Nginx中的负载均衡</h1><p>　　Nginx中的负载均衡配置在<a href="https://www.nginx.com/resources/admin-guide/load-balancer/" target="_blank" rel="external">手册</a>中描述的极为细致，此处就不流水帐了。对于常用的HTTP负载均衡，主要先定义一个upstream作为backend group，然后通过proxy_pass/fastcgi_pass等方式进行转发操作，其中fastcgi_pass几乎算是Nginx+PHP站点的标配了。</p>
<h3 id="2-1_会话一致性">2.1 会话一致性</h3><p>　　Nginx中的会话一致性是通过sticky开启的，会话一致性和之前的负载均衡算法之间并不冲突，只是需要在第一次分配之后，该会话的所有请求都分配到那个相同的backend上面。目前支持三种模式的会话一致性：<a id="more"></a><br>　　(1). <strong>Cookie Insertion</strong><br>　　在backend第一次response之后，会在其头部添加一个session cookie，即由负载均衡器向客户端植入 cookie，之后客户端接下来的请求都会带有这个cookie值，Nginx可以根据这个cookie判断需要转发给哪个backend了。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sticky cookie srv_id expires=1h domain=.example.com path=/;</div></pre></td></tr></table></figure></p>
<p>　　上面的srv_id代表了cookie的名字，而后面的参数expires、domain、path都是可选的。<br>　　(2). <strong>Sticky Routes</strong><br>　　也是在backend第一次response之后，会产生一个route信息，route信息通常会从cookie/URI信息中提取。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sticky route <span class="variable">$route_cookie</span> <span class="variable">$route_uri</span>;</div></pre></td></tr></table></figure></p>
<p>　　这样Nginx会按照顺序搜索$route_cookie、$route_uri参数并选择第一个非空的参数用作route，而如果所有的参数都是空的，就使用上面默认的负载均衡算法决定请求分发给哪个backend。<br>　　(3). <strong>Learn</strong><br>　　较为的复杂也较为的智能，Nginx会自动监测request和response中的session信息，而且通常需要回话一致性的请求、应答中都会带有session信息，这和第一种方式相比是不用增加cookie，而是动态学习已有的session。<br>　　这种方式需要使用到zone结构，在Nginx中zone都是共享内存，可以在多个worker process中共享数据用的。(不过其他的会话一致性怎么没用到共享内存区域呢？)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sticky learn </div><div class="line">   create=<span class="variable">$upstream_cookie_examplecookie</span></div><div class="line">   lookup=<span class="variable">$cookie_examplecookie</span></div><div class="line">   zone=client_sessions:1m</div><div class="line">   timeout=1h;</div></pre></td></tr></table></figure></p>
<h3 id="2-2_Session_Draining">2.2 Session Draining</h3><p>　　主要是有需要关闭某些backend以便维护或者升级，这些关键性的服务都讲求gracefully处理的：就是新的请求不会发送到这个backend上面，而之前分配到这个backend的会话的后续请求还会继续发送给他，直到这个会话最终完成。<br>　　让某个backend进入draining的状态，既可以直接修改配置文件，然后按照之前的方式通过向master process发送信号重新加载配置，也可以采用Nginx的on-the-fly配置方式。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ curl http://localhost/upstream_conf?upstream=backend</div><div class="line">$ curl http://localhost/upstream_conf?upstream=backend\&amp;id=1\&amp;drain=1</div></pre></td></tr></table></figure></p>
<p>　　通过上面的方式，先列出各个bacnkend的ID号，然后drain指定ID的backend。通过在线观测backend的所有session都完成后，该backend就可以下线了。</p>
<h3 id="2-3_backend健康监测">2.3 backend健康监测</h3><p>　　backend出错会涉及到两个参数，max_fails=1 fail_timeout=10s;意味着只要Nginx向backend发送一个请求失败或者没有收到一个响应，就认为该backend在接下来的10s是不可用的状态。<br>　　通过周期性地向backend发送特殊的请求，并期盼收到特殊的响应，可以用以确认backend是健康可用的状态。通过health_check可以做出这个配置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">match server_ok &#123;</div><div class="line">    status 200-399;</div><div class="line">    header Content-Type = text/html;</div><div class="line">    body !~ <span class="string">"maintenance mode"</span>;</div><div class="line">&#125;</div><div class="line">server &#123;</div><div class="line">    location / &#123;</div><div class="line">        proxy_pass http://backend;</div><div class="line">        health_check interval=10 fails=3 passes=2 match=server_ok;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面的health_check是必须的，后面的参数都是可选的。尤其是后面的match参数，可以自定义服务器健康的条件，包括返回状态码、头部信息、返回body等，这些条件是&amp;&amp;与关系。默认情况下Nginx会相隔interval的间隔向backend group发送一个”/“的请求，如果超时或者返回非2xx/3xx的响应码，则认为对应的backend是unhealthy的，那么Nginx会停止向其发送request直到下次改backend再次通过检查。<br>　　在使用了health_check功能的时候，一般都需要在backend group开辟一个zone，在共享backend group配置的同时，所有backend的状态就可以在所有的worker process所共享了，否则每个worker process独立保存自己的状态检查计数和结果，两种情况会有很大的差异哦。</p>
<h3 id="2-4_通过DNS设置HTTP负载均衡">2.4 通过DNS设置HTTP负载均衡</h3><p>　　Nginx的backend group中的主机可以配置成域名的形式，如果在域名的后面添加resolve参数，那么Nginx会周期性的解析这个域名，当域名解析的结果发生变化的时候会自动生效而不用重启。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">http &#123;</div><div class="line">    resolver 10.0.0.1 valid=300s ipv6=off;</div><div class="line">    resolver_timeout 10s;</div><div class="line"></div><div class="line">    server &#123;</div><div class="line">        location / &#123;</div><div class="line">            proxy_pass http://backend;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">   </div><div class="line">    upstream backend &#123;</div><div class="line">        zone backend 32k;</div><div class="line">        least_conn;</div><div class="line">        ...</div><div class="line">        server backend1.example.com resolve;</div><div class="line">        server backend2.example.com resolve;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　如果域名解析的结果含有多个IP地址，这些IP地址都会保存到配置文件中去，并且这些IP都参与到自动负载均衡。</p>
<h3 id="2-5_TCP/UDP流量的负载均衡">2.5 TCP/UDP流量的负载均衡</h3><p>　　通常，HTTP和HTTPS的负载均衡叫做七层负载均衡，而TCP和UDP协议的负载均衡叫做四层负载均衡。因为七层负载均衡通常都是HTTP和HTTPS协议，所以这种负载均衡相当于是四层负载均衡的特例化，均衡器可以根据HTTP/HTTPS协议的头部(User-Agent、Language等)、响应码甚至是响应内容做额外的规则，达到特定条件特定目的的backend转发的需求。<br>　　除了Nginx所专长的HTTP负载均衡，Nginx还支持TCP和UDP流量的负载均衡，适用于LDAP/MySQL/RTMP和DNS/syslog/RADIUS各种应用场景。这类情况的负载均衡使用stream来配置，Nginx编译的时候需要支持–with-stream选项。查看<a href="https://www.nginx.com/resources/admin-guide/tcp-load-balancing/" target="_blank" rel="external">手册</a>，其配置原理和参数和HTTP负载均衡差不多。<br>　　因为TCP、UDP的负载均衡都是针对通用程序的，所以之前HTTP协议支持的match条件(status、header、body)是没法使用的。TCP和UDP的程序可以根据特定的程序，采用send、expect的方式来进行动态健康检测。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">match http &#123;</div><div class="line">    send      <span class="string">"GET / HTTP/1.0\r\nHost: localhost\r\n\r\n"</span>;</div><div class="line">    expect ~* <span class="string">"200 OK"</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-6_其他特性">2.6 其他特性</h3><p>　　slow_start=30s：防止新添加/恢复的主机被突然增加的请求所压垮，通过这个参数可以让该主机的weight从0开始慢慢增加到设定值，让其负载有一个缓慢增加的过程。<br>　　max_conns=30：可以设置backend的最大连接数目，当超过这个数目的时候会被放到queue队列中，同时队列的大小和超时参数也可以设置，当队列中的请求数大于设定值，或者超过了timeout但是backend还不能处理请求，则客户端将会收到一个错误返回。通常来说这还是一个比较重要的参数，因为Nginx作为反向代理的时候，通常就是用于抗住并发量的，如果给backend过多的并发请求，很可能会占用后端过多的资源(比如线程、进程非事件驱动)，最终反而会影响backend的处理能力。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.nginx.com/resources/glossary/load-balancing/" target="_blank" rel="external">WHAT IS LOAD BALANCING?</a></li>
<li><a href="https://www.nginx.com/resources/admin-guide/load-balancer/" target="_blank" rel="external">NGINX LOAD BALANCING – HTTP LOAD BALANCER</a></li>
<li><a href="https://www.nginx.com/resources/admin-guide/tcp-load-balancing/" target="_blank" rel="external">NGINX LOAD BALANCING – TCP AND UDP LOAD BALANCER</a></li>
<li><a href="https://www.nginx.com/products/session-persistence/" target="_blank" rel="external">SESSION PERSISTENCE WITH NGINX PLUS</a></li>
<li><a href="https://www.nginx.com/resources/glossary/dns-load-balancing/" target="_blank" rel="external">WHAT IS DNS LOAD BALANCING?</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/understanding-nginx-http-proxying-load-balancing-buffering-and-caching" target="_blank" rel="external">Understanding Nginx HTTP Proxying, Load Balancing, Buffering, and Caching</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1_%28%E8%AE%A1%E7%AE%97%E6%9C%BA%29" target="_blank" rel="external">负载均衡</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[【置顶】个人阶段性学习和规划总结(技能树)]]></title>
      <url>https://taozj.org/201612/study-conclusion-stage.html</url>
      <content type="html"><![CDATA[<p>　　专注后台服务端开发也好久了，自我感觉经验增加了很多，接触到的东西确实不少，博文也批量更新了很多。表面看似很多很杂，但个人心中思路计划感觉还是比较明确的，此处做一阶段性整理和总结吧。<br>　　其实不仅仅是后台服务端开发，就整个软件开发的知识构成也是有所层次的。个人毕竟不是正规计算机科班出身，也就是大家所说的半路出道的野程序员，很多时候感觉自己的知识构成还是有所缺陷。长痛不如短痛，晚补不如早补，该学的终究跑不掉！<br><a id="more"></a><br>　　语言就不说了，主流将会是C/C++系，偶尔会用些Python。其实到了这个阶段，个人已经看透语言了，因为软件开发的思路，手段万变不离其宗，如果不是为了研究语言完全没必要学习那么多语言，基础夯实了接触新语言也是分分钟的事(不过，不得不说C++是个例外)。后面试着啃啃《深度探索C++对象模型 》，虽然书已经买了，不过翻开几页感觉十分吃力，不知道后面能不能够看得懂。C++的另外一个高级方向是模板元编程，不过个人估计至少近两年不打算去涉及，应为一方面感觉自己C++的还没那么深厚，同时模板元编程在实用性工程中使用较少，如果现阶段对C++了解还没那么深刻，而把太多的时间放在这上面有点舍本取末的感觉。<br>　　后台服务端开发技能树就整理如下：</p>
<p><strong>基础知识类</strong></p>
<ul>
<li>C/C++语言和Boost库<ul>
<li><a href="/201607/learn-note-of-boost-%281%29-smart-ptr-memory-pool.html">《基于Boost库的C++学习笔记（一）：智能指针和内存池》</a></li>
<li><a href="/201608/feeling-of-cpp-11-and-two-ticks.html">《关于C++11新标准的学习心得及两个小轮子分享》</a></li>
<li><a href="/201609/cpp11-atomic-and-memory-model.html">《C++11新标准中的Atomic原子操作和内存模型》</a></li>
</ul>
</li>
<li>数据结构和算法<ul>
<li><a href="/201611/data-structure-and-algorithm-%281%29-hash.html">《数据结构和算法（一）：hash散列容器》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%282%29-avl.html">《数据结构和算法（二）：AVL自平衡二叉树》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%283%29-rbtree.html">《数据结构和算法（三）：红黑二叉树》</a></li>
<li><a href="/201611/data-structure-and-algorithm-%284%29-sort.html">《数据结构和算法（四）：主流内排序算法》</a></li>
</ul>
</li>
<li>计算机网络<ul>
<li><a href="/201607/construct-running-close-of-tcp.html">《TCP链接建立和关闭过程》</a></li>
<li><a href="/201612/tcp-connection-keep-alive.html">《网络开发中客户端连接保鲜机制实现方法》</a></li>
</ul>
</li>
<li>操作系统</li>
<li>设计模式<ul>
<li><a href="/201610/talk-about-singleton.html">《说说设计模式中的单例》</a></li>
<li><a href="/201611/design-patterns-%281%29-creational.html">《设计模式整理总结（一）：创建型模式》</a></li>
<li><a href="/201612/design-patterns-%282%29-structural.html">《设计模式整理总结（二）：结构型模式》</a></li>
<li><a href="/201612/design-patterns-%283%29-behavioral.html">《设计模式整理总结（三）：行为型模式》</a></li>
</ul>
</li>
</ul>
<p><strong>后台开发基础类</strong></p>
<ul>
<li>进程，线程<ul>
<li><a href="/201609/read-%28linux-mulit-thread-server-develop%29.html">《Linux多线程服务端编程 读摘》</a></li>
<li><a href="/201609/lockless-in-multi-thread.html">《多线程中无锁队列的学习心得》</a></li>
<li><a href="/201611/about-multi-process-thread-dev-manage.html">《浅谈多进程程序的控制和管理》</a></li>
<li><a href="/201611/forkp-mulit-process-manage-framework.html">《forkp多进程程序管理库的轮子》</a></li>
</ul>
</li>
<li>异步框架<ul>
<li><a href="/201604/linux-env-program-%281%29-async-blocking-io-model.html">《Linux环境开发（一）：同异步、阻塞的IO模型相关的问题》</a></li>
<li><a href="/201604/linux-env-program-%282%29-difference-select-poll-epoll.html">《Linux环境开发（二）：Linux IO复用之select/poll/epoll的差异分析》</a></li>
<li><a href="/201605/learn-note-of-libevent-%281%29-basic-usage.html">《Libevent学习笔记（一）：基本使用》</a></li>
<li><a href="/201605/learn-note-of-libevent-%282%29-thread-pool-in-memcached.html">《Libevent学习笔记（二）：Memcached中Libevent和线程池使用初探》</a></li>
<li><a href="/201606/learn-note-of-libevent-%283%29-internel-impl-and-framework.html">《Libevent学习笔记（三）：内部实现原理初探》</a></li>
<li><a href="/201609/basics-of-boost-asio-%281%29-read-the%20docs.html">《Boost.Asio开发的相关基础知识（一）：读读文档》</a></li>
<li><a href="/201609/basics-of-boost-asio-%282%29-overview-of-the%20async-framework.html">《Boost.Asio开发的相关基础知识（二）：异步框架总览》</a></li>
<li><a href="/201609/basics-of-boost-asio-%283%29-strand.html">《Boost-Asio开发的相关基础知识（三）：Strand序列化执行用户回调》</a></li>
</ul>
</li>
<li>协程<ul>
<li><a href="/201609/usage-of-coroutine-in-boost-asio.html">《Boost.Asio中Coroutine协程库之使用》</a></li>
<li><a href="/201611/introduction-of-boost-context-and-new-coroutine-library.html">《Boost.Context库简介及协程的构建》</a></li>
<li><a href="/201611/learn-note-of-tencent-libco-coroutine.html">《腾讯libco协程库学习笔记》</a></li>
<li><a href="/201611/libto-coroutine-library-base-on-boost-context2.html">《基于Boost.Context协程库的轮子libto设计与实现》</a></li>
</ul>
</li>
<li>数据库设计管理和优化<ul>
<li><a href="/201605/data-type-and-index-of-mysql-database.html">《MySQL数据库的数据类型和索引介绍》</a></li>
</ul>
</li>
<li>日志模块</li>
<li>互联网协议<ul>
<li><a href="/201605/fastcgi-support-for-http-server-libmicrohttpd.html">《对libmicrohttpd的HTTP服务器添加FastCGI支持》</a></li>
<li><a href="/201605/principle-of-oauth2.html">《互联网流行的OAuth 2.0 开放授权原理》</a></li>
<li><a href="/201612/http2-spec.html">《HTTP/2协议规范和特性》</a></li>
<li><a href="/201701/https-principle.html">《HTTPS原理简单介绍》</a></li>
</ul>
</li>
<li>后台开发可升缩性概论<ul>
<li><a href="/201702/study-note-of-scalable-backend-%281%29-front.html">《后台开发那些常用技术再次小结（一）：前端部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%282%29-web-service.html">《后台开发那些常用技术再次小结（二）：Web服务层》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%283%29-storage.html">《后台开发那些常用技术再次小结（三）：存储部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%284%29-cache.html">《后台开发那些常用技术再次小结（四）：缓存部分》</a></li>
<li><a href="/201702/study-note-of-scalable-backend-%285%29-message-queue.html">《后台开发那些常用技术再次小结（五）：消息队列》</a></li>
</ul>
</li>
</ul>
<p><strong>后台开发高级类</strong></p>
<ul>
<li>分布式系统<ul>
<li><a href="/201611/learn-note-of-distributed-system-%281%29-abstraction-and-2PC-3PC.html">《分布式系统入门笔记（一）：分布式系统基本概念和两三阶段提交》</a></li>
<li><a href="/201611/learn-note-of-distributed-system-%282%29-paxos-algorithm.html">《分布式系统入门笔记（二）：Paxos算法》</a></li>
<li><a href="/201611/learn-note-of-distributed-system-%283%29-see-paxos-from-phxpaxos.html">《分布式系统入门笔记（三）：从PhxPaxos中再看Paxos协议》</a></li>
<li><a href="/201612/learn-note-of-distributed-system-%284%29-raft-consensus.html">《分布式系统入门笔记（四）：Raft一致性算法》</a></li>
<li><a href="/201701/learn-note-of-distributed-system-%285%29-zab-consensus.html">《分布式系统入门笔记（五）：ZooKeeper之ZAB一致性协议》</a></li>
<li><a href="/201701/learn-note-of-distributed-system-%286%29-application.html">《分布式系统入门笔记（六）：基于ZooKeeper的分布式系统的应用场景》</a></li>
<li><a href="/201612/nginx-load-balancing.html">《Nginx的负载均衡原理》</a></li>
<li><a href="/201612/consistent-hashing.html">《一致性hash原理》</a></li>
<li><a href="/201612/read-note-of-amazon-dynamo.html">《Amazon Dynamo论文学习笔记》</a></li>
</ul>
</li>
<li>RPC<ul>
<li><a href="/201612/learn-note-of-google-grpc.html">《Google gRPC学习笔记》</a></li>
<li><a href="/201701/rpc-principle-and-tips.html">《RPC设计和使用中的一些杂谈》</a></li>
</ul>
</li>
<li>消息中间件</li>
<li>缓存<ul>
<li><a href="/201607/design-and-impl-of-minicached-base-on-memcached.html">《基于memcached的单机轻量级通用缓存库minicached的实现》</a></li>
</ul>
</li>
</ul>
<p><strong>技术和实战经验类</strong></p>
<ul>
<li>json、protobuf等序列化<ul>
<li><a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a></li>
</ul>
</li>
<li>系统测试、跟踪和性能调优<ul>
<li><a href="/201701/linux-performance-basic.html">《Linux服务器的那些性能参数指标》</a></li>
<li><a href="/201701/gnu-gdb-debug.html">《GNU GDB调试手册》</a></li>
<li><a href="/201702/cmake-cheatsheet.html">《CMake工具使用手册》</a></li>
</ul>
</li>
</ul>
<p>　　从上面的整理中可以看出，在不同的业务层次和业务需求下，后台开发涉及到的知识面相当之多。“吾生也有涯，而知也无涯。以有涯随无涯，殆已！”任何一个人都不可能把所有的这些知识做足、做透、做深入的，其中任何一个方面深入下去都有足够多的东西可以去挖掘和研究的。列举后会发现自己的博客都涉及到了，给人一种不务正业、蜻蜓点水的感觉，其实个人想法是：在对后台系统认识不够深入健全的情况下，最好把这些知识都涉及了解一些，后续再选择一两个方向做深入、纵向研究，就像临床医师学习的时候都是全科医生培养，然后在工作时候再在特定专科积累经验、做精做强，我想也是相同的道理。做任何事情，如果没有全局的观念和视野，那么往往能得到的也只是局部最优解。<br>　　另外就是像之前说的，学习的时候如果能够由项目带着，自然是最幸福不过的事情了；否则的话，就多看看开源项目的代码吧。作为后台服务端开发的话，在此十分推荐Nginx项目，是一个异步多进程的经典实践。虽然是一个Web服务器，但是支持相当多的特性，后台开发中的很多问题都有涉及，比如长连接keepalive、负载均衡等，C语言也容易看的懂，可以快速借鉴用到自己的项目中去。<br>　　“源码面前，了无秘密！”这是个好习惯。</p>
<p>　　后续要做的事情，就是要把之前的博客整理一下，主要是:<br>　　(1). 格式方面: 虽然自己不是做前端的，别人也提供了现成的框架和模板，做到像<a href="https://imququ.com/" target="_blank" rel="external">《JerryQu 的小站》</a>这样的博客，文章整洁的可以当手册来用。<br>　　(2). 文字方面：以前自己的博客写完一般就直接发布了，难免有用词不当、语句不通的情况。后面自己每篇文章都要好好读一下。<br>　　(3). 知识更新方面： 这也是最重要的，因为随着自己学习的深入、见识的增加、理解的深入，之前的某些观点可能不完整，甚至是错误的，本着对自己对网友的负责，不合理的东西必须立即的修正。这些部分争取用修订的模式展示出来，个人癖好——成长的足迹也是一种快乐。<br>　　PS：之前的博客URL使用默认的中文模式，导致经过urlencode的地址看上来丑爆了，长痛不如短痛，所以前两天将所有的URL都修成了英文模式的。这导致之前共享出来的链接都是死链了，默认让跳转到首页了，很是抱歉！</p>
<blockquote>
<p>路漫漫其修远兮，吾将上下而求索！</p>
</blockquote>
<p>本文完!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[设计模式整理总结（三）：行为型模式]]></title>
      <url>https://taozj.org/201612/design-patterns-(3)-behavioral.html</url>
      <content type="html"><![CDATA[<h1 id="三、行为型模式">三、行为型模式</h1><p>　　行为型模式主要包括：职责链(Chain of Responsibility)、命令(Command)、解释器(Interpreter)、迭代器(Iterator)、中介者(Mediator)、备忘录(Memento)、观察者(Observer)、状态(State)、策略(Strategy)、模板方法(Template Method)、访问者(Visitor)，行为型模式共有11种。</p>
<h2 id="3-1_职责链(Chain_of_Responsibility)模式">3.1 职责链(Chain of Responsibility)模式</h2><p>　　定义：是多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。将这些个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。<br><img src="/post_images/images/201612/45efdf59850422593bbcfc54db35f529.png" alt="coresponse"><br>　　Handler类，引用下一个Handler，同时提供接口设置下一个Handler以实现后继链，还包括具体处理方式的抽象接口HandleRequest；ConcreteHandler处理它所负责的请求，可以访问它的后继者，即可以调用HandleRequest处理该请求，或者将请求转发给后继者。<br>　　当有多个对象可以处理同一个请求的时候，哪个对象处理该请求由运行时候自动确定。这样使得接收者和发送者都没有对方明确的信息，且链中的对象自己也不知道链的结构，职责链可以简化对象的相互链接，他们仅需保持一个指向其后继者的引用就可以了，而不需要保持其所有候选接收者的引用。</p>
<h2 id="3-2_命令(Command)模式">3.2 命令(Command)模式</h2><p>　　定义：将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。<br><img src="/post_images/images/201612/94e0c5a6540e5ec253d38c99ee1d71c1.png" alt="command"><br>　　源于行为请求者和行为实现者如果紧密耦合的话，虽然实现简单，但是极为的僵化。命令模式可以把请求一个操作的对象和知道怎么执行一个操作的对象分割开来。实践人家建议不要为代码急于实现命令模式，即使后面需要重构，也很容易实现它，只有真正需要记录、撤销、恢复等操作的功能时，才考虑实现命令模式。<br>　　Command类抽象出一个Execute()接口；ConcreteCommand将一个接收者对象绑定于一个动作，然后调用接收者响应的操作，以实现Execute()；Client创建一个具体命令对象并设定它的接收者；Invoker要求该命令执行这个请求；Receiver知道如何实现请求对应的具体操作，就是实现Action的内容。<br>　　实例：Command模式很容易实现一个菜单Menu的功能，菜单的每一个MenuItem都是一个ConcreteCommand，当用户点击一个菜单项的时候，MenuItem调用Command规定的Execute()方法执行相应的操作。MenuItem本身并不知道他用的是哪个ConcreteMenu类，但是在创建MenuItem的时候已经通过构造函数放着请求的接收者，而Execute则可以直接调用接收者的一个或者多个操作。<br><a id="more"></a></p>
<h2 id="3-3_解释器(Interpreter)模式">3.3 解释器(Interpreter)模式</h2><p>　　定义：给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。<br><img src="/post_images/images/201612/27dbb00eec448f9bc07ac58d885f7ffe.png" alt="interpreter"><br>　　如果一种特定类型的问题发生的频率足够的高，那么可能就值得将该问题的各个实例表达表述为一个简单语言中的句子，这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。解释器中的非终结符表达式定义相应子表达式的解释操作，而各终结符表达式的解释操作构成了递归的基础。<br>　　AbstractExpression抽象表达式声明一个抽象的解释操作Interpret()，这个接口为抽象语法树中所有的节点锁共享；TerminalExpression和NonterminalExpression为终结符表达式和非终结符表达式，都继承自AbstractExpression并实现Interpret接口；Context包含解释器之外的一些全局信息。</p>
<h2 id="3-4_迭代器(Iterator)模式">3.4 迭代器(Iterator)模式</h2><p>　　定义：提供一种方法顺序访问一个聚合对象中各个元素，而又不需要暴露该对象的内部表示。而且可以提供对聚集的多种方式遍历，为遍历不同的聚集结构提供如开始、下一个、是否结束、当前哪一项等统一接口。<br><img src="/post_images/images/201612/e649902f1fa7eb024f661e5b5ccb3266.png" alt="iterator"><br>　　Iterator声明访问和遍历元素的相关接口，如First()、Next()、IsDone()、CurrentItem()等接口；ConcreteIterator为具体迭代类，引用一个具体聚集对象，同时针对对象类型实现Iterator的操作接口，注意对该聚合遍历时候需要跟踪当前的位置信息；Aggregate提供Iterator对象的创建接口CreateIterator()；ConcreteAggregate具体聚合类，实现创建相应迭代器的抽象接口CreateIterator()。<br>　　总体来言，迭代器模式分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，有可以让外部代码透明的访问结合内部的数据。</p>
<h2 id="3-5_中介者(Mediator)模式">3.5 中介者(Mediator)模式</h2><p>　　定义：用一个中介对象来封装一系列的对象交互。中介者使各对象不需要显式相互引用，从而使其耦合松散，而且可以独立地改变他们之间的交互。<br><img src="/post_images/images/201612/8defe9a79b6e6c30fd28563ede2b83ad.png" alt="mediator"><br>　　尽管将一个系统分割成许多对象通常可以增加其可复用性，不过对象间的相互关联的激增又反而会降低其可复用性。<br>　　Mediator类为抽象中介者类，需要知道所有的具体同事类，定义一个借口用于与各同时对象通信，从具体的同事接收消息，向具体同时发送命令；Colleague是抽象同事类，ConcreteColleague是具体同事类，每个同事只知道自己的行为，而不了解其他同事的情况，但他们都认识中介者对象并保持一个对中介者的引用，当需要与其他同事通信的生活，与它的中介者通信。当然如果中介者需要扩展，可以扩展到具体的ConcreteMediator。<br>　　当一组对下你个以定义良好但是复杂的方式进行通信，产生的相互依赖关系结构混乱难以理解，或者一个对象引用其他很多对象并且直接与这些对象通信，导致难以复用该对象的时候，可以考虑用中介者模式。由于把对象如何协作进行了抽象，将中介作为一个独立的概念并将其封装在一个对象中，这样关注的对象就从对象各自本身的行为转移到他们之间的交互上来了，就站在一个更宏观的角度上看待系统。但是由于ConcreteMediator控制了集中化，于是把交互的复杂性变为了中介者的复杂性，使得中介者变得比任何一个Colleague都复杂。<br>　　实例比如：房东和租房者都可以作为信息的发送者和接收者，他们同时需要有设置中介的接口SetMediator，而中介需要提供接口setPerson来把信息发送者和接收者相关联，同时负责转发消息。</p>
<h2 id="3-6_备忘录(Memento)模式">3.6 备忘录(Memento)模式</h2><p>　　定义：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。这样以后就可将该对象恢复到原先保存的状态。<br><img src="/post_images/images/201612/84574927a50d0731a3ef786022a1a25a.png" alt="memento"><br>　　比如为了允许用户取消不确定的操作，或者支持从错误中恢复过来，需要实现检查点和取消机制，因此需要事先将状态信息保存在某处，这样才能支持对象的恢复操作。如果简单的提供一个接口让其它对象直接得到这些状态，将会暴露对象的细节并且破坏对象的封装性。<br>　　Originator作为发起人内部包含状态信息，其负责创建一个Memento，用以记录保存当前时刻的状态，并支持用备忘录恢复其内部状态，发起人可以根据需要决定Memento可以存储Originator内部的哪些状态；Memento负责存储Originator内部的状态，并防止Originator以外其他对象访问备忘录，备忘录实际上有两个接口，其宽接口给Originator，可以访问恢复对象所需要的所有信息，窄接口给Caretaker（内部私有引用具体的memento），只能将备忘录传递给其他对象；Caretaker负责保存好备忘录，但不能对备忘录的内容进行操作或者检查。当需要保存部分的信息而不是全部信息Clone的时候，使用该模式。<br>　　Memento模式比较适用于功能比较复杂，但需要维护或记录属性历史的类，或者需要保存的属性是众多属性中的一小部分，Originator可以根据保存在Caretaker中的Memento信息还原到以前的某个状态。<br>　　实例比如：GameRole是一个发起者，其提供Save()和Load()接口可以创建Memento对象和加载Memento对象，CareTaker负责保存Memento对象，但是却不能访问其内容，可以发起保存memento或者在GameRole需要加载的时候取出memento。</p>
<h2 id="3-7_观察者(Observer)模式">3.7 观察者(Observer)模式</h2><p>　　定义：观察者模式通常也称为发布/订阅模式(Publish-Subsrcibe)，其定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象，当这个主题对象在状态发生变化时，所有依赖于它的对象都得到通知并被自动更新。<br><img src="/post_images/images/201612/07c6d34850c572ac653b1eeb152549cf.png" alt="observer"><br>　　Subject主题或者抽象通知者，知道其观察者，通常将所有观察者对象的引用或指针保存在一个聚集observers里，每个主题可以有任意数量(多个)的观察者，同时提供可以增删观察者的接口；Observer抽象观察者，为那些在目标发生改变时需获得通知的对象定义一个更新接口Update()；ConcreteSubject将有关状态存入subjectState，当它的状态发生改变的时候，给所有登记的观察者发出Notify通知；ConcreteObserver维护一个指向ConcreteSubject对象的引用，存储有关状态到observerState，这些状态应当同目标状态保持一致，实现Observer的更新接口，使自身状态与目标状态保持一致。<br>　　将一个系统分割成一系列相互协作的类，其最大副作用就是需要维护相关对象的一致性，如果希望维护一致性而使得各个类相互紧密耦合，会对维护、扩展和重用带来不便。而观察者模式之关键对象包括Subject和Observer，一个Subject可以有任意数目的依赖他的Observer，一旦Subject的状态发生变化，所有的Observer都可以得到通知，当Subject发出通知的时候，并不需要知道它的观察者。<br>　　当一个抽象模型有两个方面，其中一个方面依赖于另外一个方面，他们封装成独立的对象中可以增加使他们各自独立的改变和复用；同时当一个对象的改变需要通知其他对象的时候，而他不知道具体有多少对象有待改变的时候，这些情况都应该考虑使用观察者模式。<br>　　实例比如：Blog作为主题，Observer作为订阅者。Blog提供Attach()、Remove()接口来添加删除订阅者并保存在list<observer*>容器中，然后Notify()接口分别调用Blog中定义的Update()方法。前端中的数据和各个表格、饼状图等展示的关系，也可以使用观察者的模式来设计。</observer*></p>
<h2 id="3-8_状态(State)模式">3.8 状态(State)模式</h2><p>　　定义：当一个对象的内在状态改变时允许改变其行为，对象看起来像是修改了它的类。<br><img src="/post_images/images/201612/a456374ff7dc662232755ed2f0c2b307.png" alt="state"><br>　　Context类定义了用户感兴趣的Request()接口，不断处理请求、更改状态，同时引用维护一个ConcreteState子类的实例state，这个实例保存了当前状态，同时实现Request()接口，不断处理请求同时更改状态；State抽象状态类，定义一个接口Handle()以封装与Context的一个特定状态相关的行为；ConcreteState作为每一个子类实现一个与Context的一个状态相关的具体行为。<br>　　状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂的时候，把状态的判断逻辑转移到表示不同状态的一系列类当中，可以把复杂的判断逻辑简单化。<br>　　考虑使用状态模式的情况：<br>　　(1) 一个对象的行为取决于它的状态, 并且它必须在运行时刻根据状态改变它的行为。<br>　　(2) 一个操作中含有庞大的多分支的条件语句，且这些分支依赖于该对象的状态。<br>　　因此状态模式就是为了消除庞大的条件分支和转移语句，将所有与状态相关的代码都存在于某个具体的ConcreteState类中，通过定义新的ConcreteState类可以轻松的增加新的状态和转移。<br>　　实例比如：TCPConnection中的状态机，连接对象根据连接的状态(TCPState-TCPEstablished,TCPListen,TCPClosed)的不同表现出不同的行为操作。</p>
<h2 id="3-9_策略(Strategy)模式">3.9 策略(Strategy)模式</h2><p>　　定义：定义了一个算法家族，把他们一个个封装起来，让它们之间可以互相替换。此模式让算法的变化，不会影响到使用算法的客户，使得算法可独立于使用它的客户而变化。<br><img src="/post_images/images/201612/df3416af0920848768346469d24cbe2f.png" alt="strategy"><br>　　Strategy定义所有支持的算法的公共接口AlgorithmInterface()，Context使用这个接口来调用某个具体的ConcreteStrategy定义的算法；ConcreteStrategy具体算法类实现这个接口产生某具体算法；Context类用一个具体的ConcreteStrategy对象来配置，维持一个对Strategy对象的引用strategy，并定义一个接口来让Strategy类访问它的数据，接口ContextInterface()通过调用具体的strategy.AlgorithmInterface()实现功能而不影响客户的使用。<br>　　策略模式是一种定义一系列算法的方法，从概念上说这些算法完成的都是相同的工作，只是实现不同而已。他们可以以相同的方式调用所有的算法，减少各种算法与使用算法类之间的耦合。<br>　　策略模式的Strategy类层次为Context定义了一系列可供重用的算法或行为，其作为父类的继承关系有助于汲取出这些算法中的公共功能。当不同的行为堆砌到一个类里面，难免会使用条件语句选择合适的行为，而将这些行为封装在独立的Strategy类里面，可以用于消除这些条件语句，源于在策略模式中，选择所需具体实现的职责，由客户端对象承担，并转嫁给Context对象了。 策略模式在使用的时候，要么创建好具体的算法对象传递进去，要不使用名字、标签等形式来指定算法类型，而在C++中，也可以使用模板参数的方式直接实例化需要的类型。</p>
<h2 id="3-10_模板方法(Template_Method)模式">3.10 模板方法(Template Method)模式</h2><p>　　定义：定义一个操作中的算法的骨架，而将一些步骤延迟到子类当中，模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。<br><img src="/post_images/images/201612/21026edf67b004a3d9e0eb313c8ab16e.png" alt="template-method"><br>　　AbstractClass抽象模板负责定义抽象的原语操作，具体的子类将重新定义它们以实现一个算法的各步骤，同时实现一个一个模板方法，还需要定义一个算法的骨架，该模板方法不仅可以调用原语操作，也调用定义在AbstractClass或其他对象中的操作(反正都会被ConcreteClass所继承)；ConcreteClass实现原语操作以完成算法中与特定子类相关的步骤。每个AbstractClass可以有任意多个ConcreteClass与之对应，而每个ConcreteClass都可以给出这个抽象方法的不同实现。<br>　　当使用了继承体系，并且肯定这个继承有意义，就应该将所有重复的代码都应该上升到父类去，而不是让每个子类都去重复。当需要完成一系列的步骤或者过程，但个别步骤(上文的原语)在更详细的实现上可能不同的话，通常应该使用模板方法的模式来处理。也就是一次性实现一个算法的不可变部分，并将可变的行为留给子类来实现。<br>　　模板的方法通过把不变的行为移到超类，去除子类中的重复代码，从而实现一个好的代码复用平台。而当不可变和可变的行为在方法的子类中混合在一起的时候，不变的行为就会在子类中重复出现，需要通过模板方法把这些行为移动到单一的地方。<br>　　实例比如：填写简历，可以抽象出Resume类并定义FillResume()进行创建过程(比如SetPersonalInfo、SetEducation等)，然后在Resume的各个派生类中实现构造过程的具体细节。</p>
<h2 id="3-11_访问者(Visitor)模式">3.11 访问者(Visitor)模式</h2><p>　　定义：表示一个作用于某对象结构中的各元素的操作，它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。<br><img src="/post_images/images/201612/4942fdb4717846ef56dffcbf5f5ef903.png" alt="visitor"><br>　　Visitor为该对象结构中ConcreteElement的每一个类声明一个Visit操作，该操作的名字和特征标识了发送Visit请求给该访问者的哪个类；ConcreteVisitor1,2为具体访问者，实现每个由Visitor声明的操作，每个操作实现算法的一部分；Element定义了一个Accept()操作，它以一个Visitor访问者作为参数；ConcreteElementA,B实现具体的Accept()操作；ObjectStructure能枚举它的元素，可以提供一个高层的接口允许访问者访问他的元素，他可以是一个Composite或是一个集合，比如一个列表或者一个无序集合。<br>　　访问者模式的目的是要把处理从数据结构中分离出来，很多系统是数据结构和算法分开，如果系统有比较稳定的数据结构，又有易于变化的算法的话，使用访问者模式比较的合适，访问者模式让算法操作的增加变得容易，因为新增加的操作就等于新增加一个访问者类。但是访问者模式d的缺点是增加新的数据结构变的困难了。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[设计模式整理总结（二）：结构型模式]]></title>
      <url>https://taozj.org/201612/design-patterns-(2)-structural.html</url>
      <content type="html"><![CDATA[<h1 id="二、结构型模式">二、结构型模式</h1><p>　　结构型模式主要包括：适配器(Adapter)、桥接(Bridge)、组合(Composite)、装饰(Decorator)、外观(Facade)、享元(Flyweight)、代理(Proxy)，总共有七种类型。</p>
<h2 id="2-1_适配器(Adapter)模式">2.1 适配器(Adapter)模式</h2><p>　　定义：将一个类的接口转换成客户希望的另外一个接口，Adaptor模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。<br>　　类适配器模式<br><img src="/post_images/images/201612/c2c1c67522d126c478b563084b413203.png" alt="adaptor"><br>　　对象适配模式<br><img src="/post_images/images/201612/984f9b6f02bd155897b4e811c5e72645.png" alt="adaptor2"><br>　　当需要的东西就在眼前，系统的数据和行为都正确，但是接口不符合，可以使用适配器模式，目的使得原有控制范围之外的一个原有对象与某个接口匹配。适配器模式主要应用于希望使用一些现存的类/工具，但是接口又与复用环境要求不一致的情况。其实现包括类适配器模式、对象适配模式两种：类适配器使用多重继承对一个接口与另一个借口进行匹配；对象匹配器依赖于对象组合的方式。<br>　　Target抽象出客户特定领域所期望的接口；Adaptee定义一个已存在的接口，是需要适配的接口；Adapter对前面的Adaptee接口与Target接口进行适配，如果是类适配ß方式则Adaptor派生Adaptee并实现其中的特定接口，如果是对象适配方式，则通过在内部封装一个私有的Adaptee对象，然后把源接口的调用转换为目标接口。<br>　　举例：一个现成的例子就是STL容器中，有标准的deque双端队列，而要实现stack/queue的数据结构就是通过适配器模式来实现的。</p>
<h2 id="2-2_桥接(Bridge)模式">2.2 桥接(Bridge)模式</h2><p>　　定义：将抽象部分与它的实现部分分离，使他们都可以独立地变化。<br><img src="/post_images/images/201612/a1baf46977e24c1e313dd8166b774850.png" alt="bridge"><br>　　当一个抽象可能有多个实现时候，通常采用继承来协调他们，但是这种方法不够灵活，类的继承关系是在编译的时候就定义好了，子类的实现和它的父类有非常紧密的依赖关系，很难让抽象部分和实现部分独立地进行修改和重用。实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多分角度分离出来让他们独立变化。<br>　　Abstraction定义接口，并且维护着对Implementor对象的指针或者引用；RefinedAbstraction扩充由Abstraction定义的接口；在Implementor中规定实现类的接口，其接口不一定要与Abstration的接口完全一致，而且通常两者的接口完全不同，一般Implementor接口仅提供基本操作，而Abstration定义了基于这些基本操作较高层次的操作；ConcreteImplementorA,B…负责实现Implementor接口并定义它的具体实现。<br>　　具体的例子：电脑制造商和操作系统，前者设计接口installOS()，后者实现接口installOS_impl()，然后两者可以分别独立的演化，在Computer中包含对OS的一个引用就可以调用具体的installOS_impl()了。再比如抽象Window和实现WindowsImpl，前者包含后者对象的一个引用imp，那么Icon/TransientWindow的任何操作都可以调用imp-&gt;XXX()来实现了。<br><a id="more"></a></p>
<h2 id="2-3_组合(Composite)模式">2.3 组合(Composite)模式</h2><p>　　定义：将对象组合成树形结构以表示“部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。处理的是整体和部分可以被一致对待的问题。<br><img src="/post_images/images/201612/5ea6a10e047a95a672107c21676af19a.png" alt="bridge"><br>　　Component为组合中的对象声明接口，在适当情况下实现所有类公有接口的默认行为，同时也提供访问和管理(Add/Remove)Component的子部件；Leaf在组合中表示叶节点对象，叶节点没有子节点；Composite定义有子部件的那些部件的行为，存储子部件，同时在Component接口中实现与子部件有关的操作。<br>　　Composite模式的关键是一个抽象类，它既可以代表元素，又可以代表元素的容器，即支持元素类型的一些操作，又有一些额外的操作访问和管理他的子部件。当需求中是体现部分与整体层次结构的时候，以及希望用户可以忽略组合对象和单个对象的不同，统一地使用组合结构中的所有对象时，就应该考虑使用组合模式了。<br>　　举个例子就是总公司和分公司以及各个部门的关系，Company列出接口，而ConcreteCompany可以进行Add/Remove操作，同时XXXDepartment不支持Add/Remove操作。</p>
<h2 id="2-4_装饰(Decorator)模式">2.4 装饰(Decorator)模式</h2><p>　　定义：动态地给一个对象添加一些额外的职责，就增加的功能来说，装饰模式比生成子类更为灵活。<br><img src="/post_images/images/201612/9c851b3346872ad685e123e983f3dc5b.png" alt="decorator"><br>　　虽然通过继承机制是添加功能的一种有效途径，但是这种方式不够灵活，因为继承关系是静态的，用户就不能控制添加功能的方式和时机，解决的方式是将组件嵌入到另一个对象中，由这个对象实现额外功能，这个嵌入的对象就叫做装饰。对Component类本身来说，是无需知道Decorator的存在的(组件无需对他的装饰有任何的了解，而Strategy模式中component组件本身知道可能进行哪些扩充，必须引用和维护相应的策略，这是两者最大的区别)，但是通过Decorator却起到给Component增加职责的功能，而且其对于使用该组件的客户是透明的，客户的请求被转发到该组件，透明性还允许嵌套多个装饰，实现任意多的功能。<br>　　Component定义一个对象的接口，可以给这些对象动态地增加一些职责；ConcreteDecorator可以通过实现Component定义的接口，给对象添加一些具体的职责；Decorator维持一个指向Component对象的指针或者引用，并定义一个与Component接口一致的接口；ConcreteDecorator用于向组件添加职责。<br>　　装饰类通过接口SetComponent()来设置需要装饰的对象(实参可以是Component或者更加具体的ConcreteComponent，指针或者引用类型)，其参数必须是Component，这样就可以把装饰后的ConcreteDecorator再进装饰形成具有顺序的多次装饰了。这里提取两个抽象层，是为了扩展的方便，如果简单的话，是不需要提取Component和/或Decorator抽象类的。<br>　　实践中当需要新功能的时候，可以向旧类直接添加代码，但是这些代码应当是原有类的核心或者主要职责功能，但想主类增加字段、方法、逻辑会增加主类的复杂度。对于某些在特定情况下才会执行的特殊行为需要，可以将装饰的功能放在单独的类当中，并让这个类包装它需要装饰的对象，客户代码可以在运行的时候根据需要有选择、按顺序地使用装饰功能包装对象了。 这样的好处就是把类的核心职能和装饰功能分开，同时能去除相关类中重复的装饰逻辑。<br>　　实例比如Phone类，在产生具体的NokiaPhone、iPhone的核心功能子对象的同时，如果需要额外的装饰，可以依据Phone派生出DecPhone1、DecPhone2等装饰子类，然后通过调用DecPhone(nokiaPhone)就可以实现装饰了。</p>
<h2 id="2-5_外观(Facade)模式">2.5 外观(Facade)模式</h2><p>　　定义：为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，每个接口使得这一子系统更加容易使用。<br>　　Facade知道哪些子系统类负责处理请求，同时将客户的请求代理给适当的子系统对象。<br>　　比如在设计和开发阶段，应当在数据访问层、业务逻辑层、表示层之间建立外观Facade，这样可以为复杂的子系统提供一个简单的接口，降低层层之间的耦合；<br>　　在维护阶段，对于一个大型系统，可以为新系统开发一个外观类，来为设计粗糙或者高度复杂的系统提供一个简单清晰的接口；<br>　　外观模式的特点是：(1)它对客户屏蔽子系统组件，因而减少了客户处理的对象的数目并使得子系统使用起来更加方便；(2)它实现了子系统与客户之间的松耦合关系，而子系统内部的功能组件往往是紧耦合的；(3)如果应用需要，它并不限制它们使用子系统类，可以自由的在易用性和通用性之前权衡。</p>
<h2 id="2-6_享元(Flyweight)模式">2.6 享元(Flyweight)模式</h2><p>　　定义：运用共享技术有效的支持大量细粒度的对象。<br><img src="/post_images/images/201612/c1ce49f3388172fc8b9de9000664bb70.png" alt="flyweight"><br>　　享元模式可以避免大量非常相似类的开销，比如文档中的每个文字用对象来表示，大量的对象会产生很大的内存开销。在程序设计中，有时候需要生成大量细粒度的类实例来表示数据，如果能发现这些实例除了几个参数外基本上都是相同的，有时就能够大幅度的减少需要实例化的类的数量。把那些参数移到类实例的外面，在方法调用的时候再将它们传递进来，在满足相同效果的同时就可以通过共享大幅度地减少单个实例的数目。<br>　　对于享元类，那些不会随环境改变而改变的共享部分，称为享元对象的内部状态，而随着环境改变而改变的，不可以共享的状态称为外部状态。如果程序使用大量的共享对象，而大量对象造成了很大的存储开销就应该考虑使用享元，还有就是对象的大多数状态可以作为外部状态，如果删除外部状态，那么可以用相对较少的共享对象取代很多种情况的组合对象，也考虑使用享元。<br>　　Flyweight类是所有具体享元类的超类或者接口Operation(var)，通过这个接口，Flyweight可以接收并作用于外部状态；ConcreteFlyweight实现Flyweight所定义的接口，并为内部状态增加容器存储空间，ConcreteFlyweight对象必须是可共享的，它所存储的状态必须是内部的；UnsharedConcreteFlyweight是那些不需要共享的Flyweight的子类；FlyweightFactory是一个享元工厂，用来创建并管理Flyweight对象，他确保合理地共享Flyweight，当用户请求一个Flyweight的时候，负责返回一个已创建的实例或者创建一个新的对象。<br>　　实例比如棋盘的棋子Piece，颜色作为内在属性可以创建Black/WhitePiece，同时棋子的位置在棋盘上是外在属性，可以存储在std::vector中，此时std::vector存储的只是位置信息而非棋子对象，所以效率会提高不少。</p>
<h2 id="2-7_代理(Proxy)模式">2.7 代理(Proxy)模式</h2><p>　　定义：为其他对象提供一种代理以控制对这个对象的访问。<br><img src="/post_images/images/201612/c36aa451ce8d4782ccacbfb2aa251898.png" alt="proxy"><br>　　Subject定义指明了RealSubject和Proxy的公用接口(比如show()方法)，RealSubject和Proxy都需要继承Subject这个类，这样在任何使用RealSubject的地方都可以使用Proxy进行代理；Proxy类保存一个RealSubject的引用，从而使得代理可以访问代理实体，提供一个与Subject的接口相同的接口，这样代理就可以用来代替实体，在用户调用接口方法的时候，通过引用对象调用其具体的同名接口方法。<br>　　远程代理：远程代理，为一个对象在不同的地址空间提供局部代表，以隐藏一个对象在不同地址空间的事实。<br>　　虚拟代理：用于根据需要创建开销很大的对象，通过它来存放实例化需要很长世间的真实对象，这些对象在需要使用的时候才会被创建。<br>　　安全代理：用来控制真实对象访问时候的权限，一般用于对象应该有不同访问权限的时候。<br>　　智能指引：当调用真实对象的时候，代理额外处理一些事情，比如引用计数，锁定等。<br>　　实例的话，就想想SmartPointer就好啦！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[HTTP/2协议规范和特性解读]]></title>
      <url>https://taozj.org/201612/http2-spec.html</url>
      <content type="html"><![CDATA[<p>　　HTTP/2也算是个比较新的东西吧，虽然很多特性是基于之前的Google SPDY，但毕竟自2015年5月正式发布到现在也就一年半的时间。虽说绝大多数的主流浏览器在2015年底就基本都支持了HTTP/2协议(估计之前的SPDY“预演”功不可没)，但是对于生产环境的服务端来说可不会这么迅速就得到普及的，Apache 2.4.12通过mod_h2模块支持HTTP/2，nginx 1.9.5支持HTTP/2，所以一般服务器除非自己编译安装，要等到发行版入稳定仓库估计估计还得要个两年吧，毕竟最新的RHEL 7上的Apache还是2.4.6呢。<br>　　Google的主页已经全部部署了HTTP/2了(但是那个sffe服务器是个什么鬼？)，通过后面查看RFC发现HTTP/2具有很多优秀的特性，并且完全可以退化至HTTP/1.1，想想也是十分诱人啊。如果想在自己服务器部署Nginx支持HTTP/2的话，推举Ubuntu 16.04 LTS或许是一个不错的选择，最主要是因为<a href="https://www.nginx.com/blog/supporting-http2-google-chrome-users/" target="_blank" rel="external">新版Google Chrome移除了NPN只支持ALPN</a>，而这依赖于openSSL 1.0.2，但是很多系统都没有更新到这个版本，而系统最重要的基础库又不能轻易升级，所以用Ubuntu 16.04 LTS是在稳定性和便捷性一个比较好的平衡点，不过如果你的服务器跑的其他非企业级发行版就另当别论了。<br>　　至于突然想到这个，是因为昨天看到gRPC/Protobuf，底层是用的HTTP/2的协议，而且一个朋友做OTT，也是使用的HTTP/2的协议传输的。虽说现实很凄惨，但是前途很光明，瞄一下RFC7540流水帐一把吧！错过了HTTP/1.x，不要再错过了HTTP/2了。<br><img src="/post_images/images/201612/1655d08c.png" alt="http2"><br>　　PS：网上流传的baidu/fex-team的中文版翻译，大家在参阅的时候需要特别注意，一方面那份文档是基于草案翻译的，和正式发布的版本还是有一些差异，二来一些翻译的质量还待商榷，只建议用来对照正式版协议辅助理解，而不可作为依赖。</p>
<h1 id="一、HTTP/1-x主要缺点和HTTP/2协议概述">一、HTTP/1.x主要缺点和HTTP/2协议概述</h1><h2 id="1-1_HTTP/1-x的主要缺陷">1.1 HTTP/1.x的主要缺陷</h2><p>　　HTTP/1.0的请求都是短连接，服务端应答之后会主动关闭掉该连接，HTTP/1.1为了减少这种频繁连接建拆支持KeepAlive长连接，但是请求和应答仍然是串行报头阻塞的，因此HTTP/1.x如果需要实现真正的并发则必须建立多个连接才可以。通常，增加HTTP/1.x的传输效率有：<br>　　(1) 通常浏览器和服务端允许建立6~8个长连接，但是这增加了服务器并发量的压力；<br>　　(2) 将资源分布到多个主机上面去，那么整体来说就可以建立更多的并发数，算是横向扩展的一种方式；<br>　　(3) 将多个图片组合成一个大的图片，然后通过CSS的方式将各个部分逻辑分割成小的图片，总体减少了请求的次数；<br>　　(4) HTTP/1.1 pipeline，允许多个请求在应答之前发送出去，不过服务端的返回必须是严格按照FIFO的顺序返回，也就是说只要其中一个请求响应时间长了也会导致后续的响应被阻塞。<br>　　HTTP/1.x是纯文本格式的协议，协议头附带很多冗余的信息，而且这种头部会被反复传输，最终会占用大量带宽，而且TCP的拥塞控制更加会恶化响应时间。</p>
<h2 id="1-2_HTTP/2概述">1.2 HTTP/2概述</h2><p>　　HTTP/2针对上面问题做出了改进，允许在单个TCP连接上面通过Stream的逻辑概念实现复用机制，在增加传输效率的同时减少了连接数(自然也降低了服务端和客户端压力)。HTTP/2通过流量控制和优先级机制，有助于只传播接受者需要使用的数据资源，并在有限的资源下建议某些资源优先被传输处理。<br>　　HTTP/2允许服务器主动推送响应给客户端，主要是基于服务端预测客户端将来会用到的资源。<br>　　传统HTTP/1.x的每个请求和应答都是Header+Body的形式传输的，HTTP/2对传输帧进行了重新设计，采用二进制进行封装和压缩，增加了传输效率和可扩展性。HTTP/2的报头(HEADERS)帧和数据(DATA)帧组成了基本的HTTP请求和响应，而设置(SETTINGS)帧、窗口更新(WINDOW_UPDATE)帧、推送承诺(PUSH_PROMISE)帧可以实现HTTP/2的其他功能。</p>
<h2 id="1-3_HTTP/2协议包的抓取">1.3 HTTP/2协议包的抓取</h2><p>　　因为HTTP/2所有流量都是加密的，虽然使用浏览器F12调试器可以查看上层的数据，尤其是一些协议相关的非数据帧是无法查看的，任何分析协议不抓包的行为都是耍流氓，但是如果直接用Wireshark得的抓包是无法查阅的。调试SSL/TLS加密数据的方法有两种：<br>　　(1). 如果针对是使用自己的网站，则可以使用你部署服务器的私钥来解密数据包；<br>　　(2). 如果是调试第三方的网站，则可以通过设置浏览器的SSLKEYLOGFILE环境变量以导出对称密钥，然后让Wireshark共享读取这个文件就可以解密浏览器回话过程中的包。<br>　　第三方的服务端和浏览器可能会有这样那样的问题，自己截取了一份Chrome访问Google的数据包，设置一下SSL中的(Pre)-Master-Secret就可以了，过滤条件使用http2，懒癌患者晚期可以直接<a href="/upload/http2_package.zip">下载</a>使用。<br><img src="/post_images/images/201612/42aa82451aaaf166f59f2fb57f1e9182.png" alt="http2-flow"></p>
<h1 id="二、HTTP/2连接的启动">二、HTTP/2连接的启动</h1><p>　　HTTP/2需要客户端感知服务端是否支持HTTP/2，而不能一开始就进行HTTP/2通信。因为HTTP通信包括http和https两种情况，虽然HTTP/2必定是加密的，但是源请求方式不同，探测HTTP/2的方式也不相同。<br>　　在http的模式下，客户端发起一个普通的HTTP/1.1请求，外加HTTP升级机制所需要的额外头部信息，即 Upgrade: h2c头。如果服务端不支持HTTP/2则忽略这个请求，按照HTTP/1.1的模式正常的返回通信，后续对话退化到HTTP/1.x协议上面；而支持HTTP/2的服务端可以返回一个101(转换协议)响应来接受升级请求，这是一个空相应，紧接着两者就可以发送HTTP/2的帧了(先前主要是SETTINGS设置帧)。<br>　　鉴于https在2017年将会大量代替http，且很多服务器都将http直接301重定向到https，所以https下的HTTP/2连接的建立比较普遍。在这种情况下需要先协商建立TLS连接，然后在TLS的应用层协议协商(ALPN)中得出支持h2协议。ALPN是TLS的一个扩展，允许客户端在TLS连接建立后协商接下来需要使用的协议类型，当客户端或者服务器端不支持ALPN时HTTP/1.1将会被使用，否则客户端会向服务器端发送自己支持的协议列表，服务器会决定接下来要选用的协议并发送响应，比如下图中选用h2代表使用HTTP/2协议。<br><img src="/post_images/images/201612/73cb3b0bac9aa53312ed78266c8bc82f.png" alt="http2-start"><br>　　当然还有比如客户端通过其他方式知道某些主机一定支持HTTP/2，或者叫做先验知识知道协议支持。<br>　　上面的任何情况下，每个端点(客户端和服务端)都需要发送一个固定的24个字节连接序言(Magic)作为HTTP/2协议的最终确认<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n</div></pre></td></tr></table></figure></p>
<p>　　紧接着序言后面是一个设置帧，详细内容可以看上面的h2截图。</p>
<h1 id="三、HTTP/2_Frame帧结构">三、HTTP/2 Frame帧结构</h1><p><img src="/post_images/images/201612/5efd484de1faf2aa803318f932000426.png" alt="http2-frame"><br>　　所有的帧都是由9个字节的固定前缀打头的。Length指定了Payload长度，默认不超过2^14 (16,384)，除非设置了SETTINGS_MAX_FRAME_SIZE为更大的参数；Type指定了是前面某种帧的一种，比如SETTINGS、DATA等；Flags是一些bit的标志位；Stream Identifier用作后面的stream标识，0被保留用于表示连接相关的整体而不是一个具体的流。<br>　　关于流的长度，前面说道默认是2^14+9，任何的协议实现都必须能至少处理这个长度，通过SETTINGS_MAX_FRAME_SIZE可以最大扩展长度为2^24-1。任何接受到的帧太小而无法处理，或者操果设置值，应当返回FRAME_SIZE_ERROR。<br>　　HTTP/2的Header包含一个或者多个键值对，然后使用报头压缩序列化到header block中，然后他们会被分割成1个或多个header block fragments，并在HEADERS/PUSH_PROMISE/CONTINUATION中作为Payload部分传输。Cookie部分会被额外单独处理。如果fragment只有一份，那么只会在一个HEADERS/PUSH_PROMISE帧中传输，而且Flag的END_HEADERS会被置位，否则后面连续的PUSH_PROMISE/CONTINUATION只会在最后一个fragment处置位END_HEADERS，而且这些fragment必须作为一个连续的帧序列传输，没有任何类型或任何其他流的交错帧在中间。<br><a id="more"></a></p>
<h1 id="四、stream(流)和多路复用">四、stream(流)和多路复用</h1><p>　　stream流应该算在一个TCP连接中分组交换的逻辑概念，在单个的TCP连接上面，客户端可以发送多个请求，服务端可以在资源就绪的时候响应任何一个请求。其特性主要包括：<br>　　(1). 一个单独的HTTP/2连接能够保持多个同时打开的流，各个端点间从多个流中交换帧；<br>　　(2). 流可以被内部建立和使用，也可以用于客户端和服务端建立和共享，而且任何一个端点都可以关闭流；<br>　　(3). 流中帧的传输顺序十分重要，接收方将按照接收到的顺序处理帧；<br>　　(4). 流通过一个整型来标识，由发起的端点分配这个标识号。</p>
<h2 id="4-1_stream的状态">4.1 stream的状态</h2><h3 id="4-1-1_stream的状态和状态切换">4.1.1 stream的状态和状态切换</h3><p><img src="/post_images/images/201612/706987b79550d63f3e197f1065ae9e11.png" alt="http2-stream"><br>　　(1) <strong>idle</strong><br>　　流都是从idle状态开始的，发送或者接受一个HEADERS会导致其变为open状态，也可能导致其变成半关闭half-closed的状态；发送一个PUSH_PROMISE将导致流变成reserved (local)；收到一个PUSH_PROMISE将导致流变成reserved (remote)。<br>　　(2) <strong>reserved (local)</strong><br>　　发送PUSH_PROMISE的流将会变成reserved (local)，此时端点可以发送HEADERS使流变成half-closed (remote)；或者任意端点都可以发送一个RST_STREAM导致流变成closed状态，导致释放stream reservation。<br>　　(3) <strong>reserved (remote)</strong><br>　　收到PUSH_PROMISE的流将会变成reserved (remote)，此时端点收到HEADERS会使流变成half-closed (local)；或者任意端点都可以发送一个RST_STREAM导致流变成closed状态，导致释放stream reservation。<br>　　(4) <strong>open</strong><br>　　处于open状态的流可以用来发送任意类型的帧。任何一个端点都可以发送带有END_STREAM标记的帧，将会导致流变成half-closed状态：发送方变成half-closed (local)，接收方变成half-closed (remote)。任何一端发送RST_STREAM将会导致流变成closed状态。<br>　　(5) <strong>half-closed (local)</strong><br>　　此状态下的流只能发送WINDOW_UPDATE/PRIORITY/RST_STREAM类型的帧，当接收到END_STREAM或者任何一端发送RST_STREAM将会使流转为close状态。该状态下的流可以接收任何的帧。<br>　　(6) <strong>half-closed (remote)</strong><br>　　该状态的流表明对端不会再用其发送帧了，所以除了受到WINDOW_UPDATE/PRIORITY/RST_STREAM之外任何类型的帧都是错误的。该状态的流可以接收任何帧，而同样的当发送END_STREAM或者任何一端发送RST_STREAM将会使流转为close状态<br>　　(7) <strong>closed</strong><br>　　流的终结状态。当流接收到RST_STREAM之后如果收到除PRIORITY类型的帧，或者收到END_STREAM后再次受到任何帧，都应当被认为是STREAM_CLOSED错误。</p>
<h3 id="4-1-2_stream的标识符">4.1.2 stream的标识符</h3><p>　　由31位的整形来标识，因为标识符是发起端分配的，所以规定client必须用奇数，server必须用偶数，0保留用于连接控制。一个新建立的流的标识符必须大于任何发起终端已经打开或者保留的流标识符，同时发起一个新的流也表示该端之前创建的所有比这个标识符小的处于idle的流转换成关闭状态。<br>　　因为标识符不能被重用，所以长时间存在的连接可能会产生标识符用尽的状况。这种情况下，客户端会重新打开一个TCP连接然后创建新的流；服务端可以发送GOAWAY强制客户端打开一个新的连接。</p>
<h3 id="4-1-3_stream的并发">4.1.3 stream的并发</h3><p>　　通过SETTINGS帧设置SETTINGS_MAX_CONCURRENT_STREAMS参数，而且这个参数连接的两端都可以设置，作用于对端可以创建流的并发数目。处于open和half-closed状态的流会被计数，而处于reserved状态的stream不会被计数。</p>
<h2 id="4-2_stream的流量控制">4.2 stream的流量控制</h2><p>　　引入stream的概念就是为了避免TCP连接中的阻塞，而HTTP/2通过WINDOW_UPDATE帧实现流量控制，主要确保同一个连接上的各个流不会造成破坏性的干扰。其流控制有以下特点：<br>　　(1) 流量控制只针对下一跳(hop)，而不是完整路径的端对端的控制；<br>　　(2) 流量控制是基于WINDOW_UPDATE帧的，接收者告知自己打算接收的数量，这是一种基于信任实现的机制；<br>　　(3) 流量控制是有方向性的，且由接收端全权控制。实现中客户端、服务端、中介者都可以设置流量控制；<br>　　(4) 初始窗口大小是65,535，针对新建的流以及整个连接；<br>　　(5) 只有DATA帧受流量控制，其它类型的帧都不会计入到流量控制中，确保控制帧不会因为流量控制而被阻塞；<br>　　(6) 流量控制不能被禁用；<br>　　(7) HTTP/2协议只规定了WINDOW_UPDATE帧的格式，而具体的算法和实现没有说明。<br>　　其实说白了，就是在内存、带宽等资源有限的条件下，通过流量控制保证资源的合理分配，不会被某些流不公平的独占。流和连接的窗口，表示了允许服务端发送的字节数，每次发送数据后这个窗口的值就会相应地减少，一旦被用完后就不允许再发送数据了，直到远端再次发送WINDOW_UPDATE帧来增加这个窗口的值。<br>　　在网络开发中，传输速率和处理速度不匹配的情况经常的发生，通常的做法就是：(1)不断的缓存数据，慢慢地下方到下游去处理，但是这显然是不安全的，因为不可能无限制的缓存下去；(2)缓存足够量的数据后，拒绝从底层socket再次接收数据，但这显然是不公平的，这会让其他的stream数据无法被接收，少数的stream占用了绝对的资源。所以流量控制机制是十分重要的。</p>
<h2 id="4-3_stream的优先级">4.3 stream的优先级</h2><p>　　stream的优先级是通过依赖关系和权重来实现的，优先级不是必须的，服务端可以选择完全忽略优先级。新建立的流，可以在HEADERS帧中指定流的优先级，而其他时刻对于已经存在的流，可以通过PRIORITY帧来改变优先级。<br>　　这也是一种在带宽、资源有限时候的一种分配机制。端点不能够保证按照特定顺序传输、处理这些并发流，这只能算是一种建议性的机制。优先级信息是可选的，没有指定将会使用默认优先级。</p>
<h2 id="4-4_错误处理">4.4 错误处理</h2><p>　　错误包括两种情况：连接错误和流错误。<br>　　(1) <strong>连接错误处理</strong><br>　　当阻止了frame layer的进一步处理，或者连接的状态被破坏了的情况。<br>　　当任何一个端点遇见这种错误的时候，应当首先发送一个包含如下信息的GOAWAY帧：自己最后一次从对端成功接收的stream标识符，解释连接错误原因的错误码。发送完GOAWAY帧后端点必须关闭连接。发送GOAWAY帧的机制只是尽量保证报告出错的原因信息，并不能保证对端一定可靠接收到该帧。<br>　　端点可以在任何时候结束连接。端点也可以选择将流错误当作连接错误来处理。端点在结束连接的时候在允许的条件下都应当发送GOAWAY帧。<br>　　(2) <strong>流错误处理</strong><br>　　特定流的错误，不会影响到其他流的处理。<br>　　端点检测到流错误的时候，应当发送一个带有错误标识码的RST_STREAM帧，端点一定不能发送RST_STREAM帧来响应一个接收到的RST_STREAM帧，避免出现死循环的情况。</p>
<h1 id="五、Frame帧定义">五、Frame帧定义</h1><p>　　帧的类型由前缀的8位Type所定义。<br>　　(1) <strong>DATA</strong> Type=0x0<br>　　用来传输任意可变长度的字节流。通常可以用一个或者多个DATA帧来传输HTTP响应或者请求。<br>　　DATA帧中如果PADDED标识被设置，则有一个8bit的Pad Length，数据后面的Padding是可选的，主要可以用来隐藏数据包的长度信息。DATA帧只允许在非0流标识流上传输。<br>　　(2) <strong>HEADERS</strong> Type=0x1<br>　　可以用来打开一个stream，携带header block fragment，当单个HEADERS帧不能传输时，使用后续的CONTINUATION帧继续传递。HEADERS帧只允许在非0流标识流上传输。<br>　　(3) <strong>PRIORITY</strong> Type=0x2<br>　　PRIORITY帧主要的参数是Stream Dependency，用于设置当前流所以来的stream的其流标识符。这个帧可以在idle或closed状态的流上设置，以间接影响具有依赖关系的其他流的优先级。这个帧的长度固定是5，PRIORITY帧只允许在非0流标识流上传输。<br>　　(4) <strong>RST_STREAM</strong> Type=0x3<br>　　RST_STREAM帧只包含一个32bit的Error Code，用于解释流被终止的原因。RST_STREAM帧会立即终止一个流使其进入closed状态，接收者收到RST_STREAM帧后则不能发送除了PRIORITY之外的任何帧。RST_STREAM帧的长度固定是4，且不能在idle状态流上发送。<br>　　(5) <strong>SETTINGS</strong> Type=0x4<br>　　设置不是一种协商，而是发送者描述了自身的特性以被对端所使用，所以即使同一个参数，在客户端和服务端其参数值很可能不一样。<br>　　设置帧必须在连接开始的时候就发送，而且在通信过程中任何时候也支持发送，接收到设置帧后端点直接用帧中的新值覆盖自己的旧值，而不用保持维护先前状态。接收端会发送特殊的带有ACK长度为0的SETTINGS帧以确认。<br>　　设置帧从来都是针对连接而非单个stream的，所以其流标识符必须是0，其长度必须是6的整数倍，因为除了ACK通常的SETTINGS帧都是Identifier(2)+Value(4)。具体的参数类型参见手册。<br>　　接收者收到SETTINGS帧必须尽快更新相关参数，然后参数按照他们出现的顺序依次处理，并且保证在处理这些参数的时候不再处理其他的帧，对于不能识别的参数作忽略处理。更新完成后进行ACK确认，发送者收到ACK信息后，就可以依赖自己之前请求的参数信息了。<br>　　(6) <strong>PUSH_PROMISE</strong> Type=0x5<br>　　PUSH_PROMISE帧是预先通知对端需要初始化的流，其包含了Promised Stream ID标识符和额外的header block fragment参数信息，主要用来预先初始化压缩状态，以及保留stream标识符成为reserved状态。<br>　　某些角度看来PUSH_PROMISE帧和HEADERS帧有些像，包含END_HEADERS标志以及CONTINUATION帧的支持，其必须在一个已经open或者half-closed (remote)的流上面传输，而且如果对端设置了SETTINGS_ENABLE_PUSH，那么如果收到这种帧的ACK就是PROTOCOL_ERROR。接收者也可以返回RST_STREAM来拒绝这个PUSH_PROMISE请求。<br>　　(7) <strong>PING</strong> Type=0x6<br>　　通过PING帧是一种从发送端测量最小RTT的机制，同样也是一种检测连接是否可用的方法，可以被任意端发送。<br>　　发送PING帧的流标识符必须是0，并且应当被给予高优先级。其负载必须是一个8字节的自定义数据，而接收端ACK的时候设置ACK标志并原样返回该负载。<br>　　(8) <strong>GOAWAY</strong> Type=0x7<br>　　GOAWAY帧主要是用于主动关闭连接或者当连接遇到严重错误的情况下。其是一种优雅的方式进行关闭：不再接受新的流，并且处理完之前已经建立的流。<br>　　当一端发送GOAWAY帧的时候，另外一端创建新的流就是一个竞争条件，于是GOAWAY帧带有一个Last-Stream-ID参数，表示承认发送GOAWAY帧的对端最大的流标识符，此后这个连接将不再接受新的更大标志符的流(对端可以尝试新建连接来继续建立新流)。当关闭一个连接的时候，总应当发送GOAWAY帧让对端知道那些流已经或者将要被处理，发送GOAWAY帧的流标识符必须是0。<br>　　发GOAWAY帧后发送端能丢弃流标识符大于Last-Stream-ID的帧，但是任何修改连接状态的帧不能被全部忽略。HEADERS帧、PUSH_PROMISE帧和CONTINUATION帧必须被处理来保证维持header compression状态的一致。<br>　　(9) <strong>WINDOW_UPDATE</strong> Type=0x8<br>　　主要用于实现流来控制的，包括两个级别的流量控制：流级别和整个连接级别，根据发送流的流标识符是否为0来区分。<br>　　流量控制只针对下一跳(hop-to-hop)，而不是客户端-服务端整条链路的设置(end-to-end)，因为WINDOW_UPDATE帧不会被转发，HTTP/2中只有DATA帧受流量控制限制，而且帧开头的固定9字节不会被计入。WINDOW_UPDATE的负载是一个保留位和31位的无符号整型，其值的范围为1~(2^31-1)，其值是用于累加(in addition)在端点当期剩余的窗口值上面的，端点的窗口值表明允许其发送的字节数目。<br>　　初始的流和连接窗口大小都默认是65,535，通过SETTINGS帧的SETTINGS_INITIAL_WINDOW_SIZE参数可以设置新流的初始窗口大小，而针对连接的窗口大小只能通过WINDOW_UPDATE来设置而不能通过SETTINGS帧来改变。<br>　　(10) <strong>CONTINUATION</strong> Type=0x9<br>　　可以是紧跟着前一个HEADERS帧/PUSH_PROMISE帧或者不带END_HEADERS标志的CONTINUATION帧，其负载必定是一个header block fragment。</p>
<h1 id="六、HTTP/2消息交换">六、HTTP/2消息交换</h1><h2 id="6-1_HTTP请求与应答交换">6.1 HTTP请求与应答交换</h2><p>　　客户端在一个新的流上发起请求，服务端在同一个流上做出应答。请求和应答的HTTP消息可以由HEADERS帧、CONTINUATION帧和DATA帧组合，原先chunked传输编码被废弃。HTTP的请求/应答交换完全占用了一个流：请求由客户端通过HEADERS帧发起并使流进入到open状态；当请求以END_STREAM标志帧结尾后请求结束，流进入到客户端half-closed (local)/服务端half-closed (remote)状态；响应通过服务端的HEADERS帧开始并通过END_STREAM标志帧结束，流进入到close状态。</p>
<h2 id="6-2_HTTP头部">6.2 HTTP头部</h2><p>　　HTTP的头部都是一些键值信息，在HTTP/1.x中都是ASCII编码且不区分大小写的，而在HTTP/2中需要全部转换成小写字母后再编码。这些头部组合后如果一个HEADERS帧不能传输，后面使用CONTINUATION帧继续传递，知道最后一个标志END_HEADERS意味着头部传输完毕。<br>　　(1) <strong>伪头字段</strong><br>　　HTTP/1.x有一个固定的请求头，比如“GET /resource HTTP/1.1”，来携带请求方法、URI、协议版本以及相应码，而HTTP/2用’:’开头表示的伪头部(而非真真HTTP协议头部)来携带这些信息，并且所有的伪头部必须在正规HTTP协议标准头部之前出现完。<br>　　(2) <strong>连接相关的字段</strong><br>　　在HTTP/2协议中，不应当包含连接相关(Connection-Specific)的头部，trailers是个例外。<br>　　(3) <strong>请求相关的伪字段</strong><br>　　:method GET、POST等标准方法<br>　　:scheme 通常是http或https<br>　　:authority 比如www.googleapis.com，类似于HTTP/1.x的Host头信息<br>　　:path 请求目的的URI，包括路径名和参数<br>　　对于一个请求，必须为:method、:scheme、:path包含一个准确合法的值，这些伪头部必须首先且在第一帧中出现。请求可以带DATA帧(比如POST请求)或者不带DATA帧，完整的请求最后一帧通过END_STREAM标示结束。<br>　　(4) <strong>响应相关的伪字段</strong><br>　　:status 所有的响应中都必须包含该字段。响应通过一个HEADERS帧和可选的CONTINUATION帧开始，然后通过DATA帧传输响应body。<br>　　(5) <strong>压缩和Cookie字段</strong><br>　　Cookie字段可能会有多个，他们既可以作为键值对多次出现，也可以单个cookie键接多个值，值与值之间用”; “连接。<br><img src="/post_images/images/201612/ffb18df8ced7cc0e5eeba0a962a8c801.png" alt="http2-example"><br>　　这里只是定义了头部字段和结构，而头部压缩是HTTP/2的另外一大特性，其使用的HPACK header compression技术的具体的细节，可以参看RFC7541。HPACK维护着一个static头表，是在HTTP协议中经常用到的头部结构，同时在通信的服务端和客户端维护着一个dynamic头部表，在通信过程中增加的头部信息都会记录到这个表中，此后如果需要再次传输这个头，就只需要传输在动态头表中的索引就可以了。头表的键和值采用了高效的Huffman编码，默认头表4k的大小，可以通过SETTINGS帧来修改。</p>
<h2 id="6-3_Server_push">6.3 Server push</h2><p>　　Server Push是HTTP/2中的一个新特性，不过在抓Google首页的包中没有该帧，所以也只能看着手册瞎说了。这个行为一定是服务端对客户端的行为，客户端可以通过SETTINGS_ENABLE_PUSH来控制是否开启这个功能。服务端可以预测接下来客户端需要请求的资源，然后发送这些可以被缓存的资源，最显式的好处就是提高了页面加载的速度。<br>　　Promised请求必须满足——cacheable、safe、no request body，cacheable可以让服务端校验后由客户端缓存，同时服务端必须支持:authority以支持认证。<br>　　(1) <strong>Push请求</strong><br>　　在语义上Server Push等同于一个响应，只不过这个相应的请求也是由服务端通过PUSH_PROMISE帧发起的。<br>　　比如，一个服务器接收到一个来自客户端的页面请求，页面中嵌入了其他图片连接，那么服务器会在发送这个DATA帧之前，先发送PUSH_PROMISE帧，这样可以确保客户端在接受到相应解析之前PUSH_PROMISE帧已经被接受生效了。请求帧中包含完整的头部信息，最重要的包含:path信息，所以客户端可以知道服务端推送的是哪个资源。<br>　　只可以在服务器观来open或者half-closed (remote)状态的流上发送PUSH_PROMISE帧，效果是创建一个新的流并将流切换到服务端看来reserved (local)的状态。<br>　　(2) <strong>Push响应</strong><br>　　发送完PUSH_PROMISE帧后，服务端就可以在这些预留的流上面发送响应了。如果客户端想要取消(比如客户端本地已经缓存了这个资源了)或者等待超时了这个响应，可以发送RST_STREAM帧附带CANCEL/REFUSED_STREAM进行取消这个响应。<br>　　响应以HEADERS帧开始，流会立即进入服务端视角half-closed (remote)状态，后面会带有DATA帧传输响应数据，并经过带有END_STREAM标记的帧结束，然后流进入closed状态。</p>
<p>　　洋洋洒洒这么多，就暂且这样吧！太长了自己看着也恶心。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/HTTP/2" target="_blank" rel="external">Wikipedia</a></li>
<li><a href="https://tools.ietf.org/rfc/rfc7540.txt" target="_blank" rel="external">Hypertext Transfer Protocol Version 2 | HTTP/2</a></li>
<li><a href="https://www.nginx.com/blog/7-tips-for-faster-http2-performance/" target="_blank" rel="external">7 Tips for Faster HTTP/2 Performance</a></li>
<li><a href="https://http2.github.io/faq/" target="_blank" rel="external">HTTP/2 Frequently Asked Questions</a></li>
<li><a href="https://blog.cloudflare.com/tools-for-debugging-testing-and-using-http-2/" target="_blank" rel="external">Tools for debugging, testing and using HTTP/2</a></li>
<li><a href="https://github.com/fex-team/http2-spec/blob/master/HTTP2%E4%B8%AD%E8%8B%B1%E5%AF%B9%E7%85%A7%E7%89%88%2806-29%29.md" target="_blank" rel="external">HTTP2中英对照版 06-29</a></li>
<li><a href="https://developers.google.com/web/fundamentals/performance/http2/" target="_blank" rel="external">Introduction to HTTP/2</a></li>
<li><a href="http://undertow.io/blog/2015/04/27/An-in-depth-overview-of-HTTP2.html" target="_blank" rel="external">An in depth overview of HTTP/2</a></li>
<li><a href="https://lwn.net/Articles/558302/" target="_blank" rel="external">What’s new in HTTP 2</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Google gRPC框架学习笔记]]></title>
      <url>https://taozj.org/201612/learn-note-of-google-grpc.html</url>
      <content type="html"><![CDATA[<p>　　其实gRPC算是比较年轻的项目，虽据说已在Google内部被大规模部署使用，但从GitHub上看是2016年8月19日打的v1.0.0的tag，而官方博客发布声明在2016年8月23日。正式发布也就意味着通信协议的确定、接口API已经稳定，而性能、压力、稳定性各项测试已经满足需求，可以部署到生产环境中，广大基佬们可以安心使用了。<br>　　与gRPC/Protobuf相对应的，莫过于当前最熟悉的传统经典HTTP/JSON模式了，传统开发的惯用手法就是：客户端发起请求、服务端接收请求、服务端解析请求、服务端进行业务逻辑处理、服务端打包响应、服务端发送响应、客户端解析响应。虽然现在的序列化库和网络开发框架漫山遍野多如牛毛，但是服务端和客户端开发还是需要不断地封装、解析数据，处理网络传输的各项细节。<br>　　RPC从本质上来说，就是通过客户端和服务器的协作，将客户端的本地调用转化成请求发送到服务端，服务端进行实际操作后，再将结果返回给客户端，所以从客户端的角度看来就和一个本地调用的效果一样，虽然实际上跨进程、跨主机的调用会遇见各种复杂的情况，但是RPC框架负责屏蔽这些细节信息，用户只需要专注于业务逻辑开发即可。从Wikipedia的资料看来，RPC的概念很早就已经被提出来，而最近风光无限的几个开源RPC框架基本都出自大厂之手，其源于在互联网环境下，大量的分布式应用或服务可以使用RPC的方式轻松解耦，增加了复用性，提高了开发效率。<br>　　此外还想罗嗦一句：gRPC/Protobuf不仅可以用于常规网络服务开发，甚至可以作为本地进程间通信方式使用，因为RPC本来就属于一种IPC手段。<br><img src="/post_images/images/201612/ba2490413b2c260f24d4a8f22e7c2cf0.jpg" alt="grpc"><br>　　gRPC和Protobuf天生有着紧密的联系，在gRPC中Protobuf不仅作为一种序列化的工具使用，而且用于定义服务端与客户端之间的RPC调用接口(IDL的效果)，然后通过protoc工具可以快速生成客户端和服务端的代码。gRPC允许通过Protobuf的插件，独立指定客户端和服务端生成的语言类型，这对于时下移动互联网时代的开发意义重大。Protobuf是一种重要的序列化工具，其编码效率和速率非常的高，而且在工程化的过程中Google考虑到前向兼容等各项事宜，简单的手册可以参见之前的<a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a>。无论以后用哪家的RPC，都建议好好学习熟练掌握它，因为当前一些新开源的框架库基本都默认用它作为数据交互格式。</p>
<p>　　下面借着gRPC官方的手册，流水帐般地过一下gRPC的相关东西。</p>
<h1 id="一、RPC生命周期">一、RPC生命周期</h1><p>　　gRPC支持四种服务类型：Unary RPCs、Server streaming RPCs、Client streaming RPCs和Bidirectional streaming RPCs，通过参数和返回类型是否有stream关键字来标识区分。最简单的是Unary RPC调用，客户端发送一个请求参数，服务端做出一个应答数据；Server stream RPC调用是服务端可以返回多个数据，客户端一般在while中一直读取结束；Client stream是客户端可以向服务端传输多个请求，告知服务端传输结束后等待服务端返回；而Bidirectional stream则是一个全双工的通信，两端可以在任意时刻发送和接收数据，互相独立互不干扰。<br>　　gRPC允许client提供额外的超时参数，在超时之后如果服务端还没有返回响应的话，则会返回DEADLINE_EXCEEDED错误。服务端可以查询请求的超时参数，以及该调用所剩余的完成时间值。<a id="more"></a><br>　　RPC调用结果，是由服务端和客户端本地独立决定的，比如服务端认为自己成功发送了response，但是客户端可能在超时后仍然没有收到服务端响应，而认为此次调用失败，毕竟跨进程、跨主机的调用涉及到的可能问题会很多。<br>　　客户端和服务端可以在任何时候取消(cancel)RPC调用，取消的请求会立即生效，之后的工作不会再执行，同时之前的工作也不会undo进行回滚。客户端如果使用同步模式调用，一般是无法取消调用的，因为其执行流已经被block阻塞住了。<br>　　当创建Client Stub的时候，会要求和服务端的指定端口创建一个Channel通道，这个通道可以控制各项参数，以细致化地影响和控制gRPC的行为。<br>　　从上面描述，可见gRPC不保证原子性、最终一致性等特性，这个锅看来是甩给了用户处理了！<br><!--more--></p>
<h1 id="二、Authentication认证">二、Authentication认证</h1><p>　　gRPC/Protobuf原生支持SSL/TLS加密方式传输(Token模式暂不讨论)，可以加密服务端和客户端的所有通信数据。<br>　　gRPC的认证都围绕着Credentials这个对象，分为ChannelCredentials和CallCredentials两种类型，也可以将两者关联成一个CompositeChannelCredentials，然后用其产生一个新的ChannelCredentials后，那么之后在这个Channel上所有的调用都会默认使用前面设置的CallCredentials。<br>　　(1). <strong>无加密通信模式</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> channel = grpc::CreateChannel(<span class="string">"localhost:50051"</span>, InsecureChannelCredentials());</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Greeter::Stub&gt; stub(Greeter::NewStub(channel));</div></pre></td></tr></table></figure></p>
<p>　　(2). <strong>SSL/TSL通信</strong><br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Create a default SSL ChannelCredentials object.</span></div><div class="line"><span class="keyword">auto</span> creds = grpc::SslCredentials(grpc::SslCredentialsOptions());</div><div class="line"><span class="comment">// Create a channel using the credentials created in the previous step.</span></div><div class="line"><span class="keyword">auto</span> channel = grpc::CreateChannel(server_name, creds);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Greeter::Stub&gt; stub(Greeter::NewStub(channel));</div><div class="line">grpc::Status s = stub-&gt;sayHello(&amp;context, *request, response);</div></pre></td></tr></table></figure></p>
<h1 id="三、gRPC/Protobuf_C++语言使用实例">三、gRPC/Protobuf C++语言使用实例</h1><p>　　(1). <strong>创建IDL描述文件route_guide.proto</strong><br>　　gRPC是需要先定义服务接口约定，才可以进行RPC调用，使用.proto可以同时定义客户端和服务端交换的数据格式以及RPC调用的接口，然后使用protoc工具加上特定语言的插件生成特定语言版本的辅助代码。其实相比之前的<a href="/201609/learn-note-of-protobuf.html">《Protobuf数据交换格式的使用方法》</a>，这里只是新增了service定义和rpc定义的语法。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">syntax = <span class="string">"proto3"</span>;</div><div class="line">package routeguide;</div><div class="line"></div><div class="line">service RouteGuide &#123;</div><div class="line">  <span class="function">rpc <span class="title">GetFeature</span><span class="params">(Point)</span> <span class="title">returns</span> <span class="params">(Feature)</span> </span>&#123;&#125; </div><div class="line">  <span class="comment">// server-to-client streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">ListFeatures</span><span class="params">(Rectangle)</span> <span class="title">returns</span> <span class="params">(stream Feature)</span> </span>&#123;&#125;</div><div class="line">  <span class="comment">// client-to-server streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">RecordRoute</span><span class="params">(stream Point)</span> <span class="title">returns</span> <span class="params">(RouteSummary)</span> </span>&#123;&#125;</div><div class="line">  <span class="comment">// Bidirectional streaming RPC.</span></div><div class="line">  <span class="function">rpc <span class="title">RouteChat</span><span class="params">(stream RouteNote)</span> <span class="title">returns</span> <span class="params">(stream RouteNote)</span> </span>&#123;&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Latitudes +/- 90 degrees and longitude +/- 180 degrees (inclusive).</span></div><div class="line">message Point &#123;</div><div class="line">  int32 latitude = <span class="number">1</span>;</div><div class="line">  int32 longitude = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A latitude-longitude rectangle</span></div><div class="line">message Rectangle &#123;</div><div class="line">  Point lo = <span class="number">1</span>;</div><div class="line">  Point hi = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A feature names something at a given point.</span></div><div class="line"><span class="comment">// If a feature could not be named, the name is empty.</span></div><div class="line">message Feature &#123;</div><div class="line">  <span class="built_in">string</span> name = <span class="number">1</span>; <span class="comment">// The name of the feature.</span></div><div class="line">  Point location = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A RouteNote is a message sent while at a given point.</span></div><div class="line">message RouteNote &#123;</div><div class="line">  Point location = <span class="number">1</span>;</div><div class="line">  <span class="built_in">string</span> message = <span class="number">2</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// A RouteSummary is received in response to a RecordRoute rpc.</span></div><div class="line">message RouteSummary &#123;</div><div class="line">  int32 point_count = <span class="number">1</span>; <span class="comment">// number of points received.</span></div><div class="line">  int32 feature_count = <span class="number">2</span>; <span class="comment">// number of known features passed while traversing</span></div><div class="line">  int32 distance = <span class="number">3</span>; <span class="comment">// distance covered in metres.</span></div><div class="line">  int32 elapsed_time = <span class="number">4</span>; <span class="comment">// duration of the traversal</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(2). <strong>使用protoc产生服务端和客户端代码</strong><br>　　通过protoc和C++ plugin，可以产生C++的服务端和客户端代码<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ protoc --grpc_out=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` ../protos/route_guide.proto</div><div class="line">$ protoc --cpp_out=. ../protos/route_guide.proto</div></pre></td></tr></table></figure></p>
<p>　　上面的操作会分别产生数据交换和服务接口的源文件：route_guide.pb.[cc|h]和route_guide.grpc.pb.[cc|h]，前者覆盖所有数据类型序访问和操作的接口，后者主要生成定义的RPC服务RouteGuide的相关代码。<br>　　grpc_out参数编译之后的源代码，主要产生了class RouteGuide，包含了和客户端Stub相关的内部类class StubInterface和class Stub GRPC_FINAL : public StubInterface，以及和服务端相关的class Service : public ::grpc::Service类。<br>　　(3). <strong>实现服务端业务接口</strong><br>　　通过上面步骤，操作数据和服务接口相关代码都已经自动生成了，接下来服务端的重点就是接口业务逻辑的实现了。手册样例的服务端代码实现在route_guide_server.cc源文件中，通过实现RouteGuide::Service中定义的虚函数接口，可以实现以同步阻塞方式的服务端实现(class RouteGuideImpl final : public RouteGuide::Service)，而异步方式则跟RouteGuide::AsyncService这个类相关。<br>　　此处服务端首先需要实现proto service中定义的四个调用接口，通过观察这些虚函数接口，发现他们都是返回::grpc::Status类型(返回值的详细信息可以参看<a href="http://www.grpc.io/docs/guides/error.html" target="_blank" rel="external">Error model</a>)，并且第一个参数都是::grpc::ServerContext*，而剩余部分的参数就跟当初proto文件中声明的参数一致了。在函数的具体实现代码中，设置和获取proto的数据项，就是Protobuf的标准数据操作方式了。通常操作成功后，返回Status::OK。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function">Status <span class="title">GetFeature</span><span class="params">(ServerContext* context, <span class="keyword">const</span> Point* point,</span></span></div><div class="line">        Feature* feature) override &#123;</div><div class="line">  feature-&gt;set_name(GetFeatureName(*point, feature_list_));</div><div class="line">  feature-&gt;mutable_location()-&gt;CopyFrom(*point);</div><div class="line">  <span class="keyword">return</span> Status::OK;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面代码是最简单的Unary调用方式，客户端发出一个请求参数，然后服务端返回一个数据响应。对于RPC的服务端，在使用stream模式的调用参数或者返回结果，需要使用到特殊的ServerWriter、ServerReader类型，服务端可以在循环中多次写入/读取以传递多个对象，最后返回Status状态以表示调用结束。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (<span class="keyword">const</span> Feature&amp; f : feature_list_) &#123;</div><div class="line">  ... writer-&gt;Write(f);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">while</span> (reader-&gt;Read(&amp;point)) &#123; ... &#125;</div></pre></td></tr></table></figure></p>
<p>　　对于请求和响应都是stream的类型，那么参数将直接变成为ServerReaderWriter<routenote, routenote="">* stream类型，此时的stream是一个两方向完全独立的全双工信道。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (stream-&gt;Read(&amp;note)) &#123;</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> RouteNote&amp; n : received_notes) &#123;</div><div class="line">      <span class="keyword">if</span> ( ... )</div><div class="line">        stream-&gt;Write(n);</div><div class="line">    &#125;</div><div class="line">    received_notes.push_back(note);</div><div class="line">&#125;</div></pre></td></tr></table></figure></routenote,></p>
<p>　　当把RouteGuide::Service中的虚函数接口全部实现后，服务端的业务开发也就完成了。下面是通用的服务端网络例程，绑定地址端口，接收客户端请求，十分的清晰明白：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">RunServer</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; db_path)</span> </span>&#123;</div><div class="line">  <span class="built_in">std</span>::<span class="function"><span class="built_in">string</span> <span class="title">server_address</span><span class="params">(<span class="string">"0.0.0.0:50051"</span>)</span></span>;</div><div class="line">  <span class="function">RouteGuideImpl <span class="title">service</span><span class="params">(db_path)</span></span>;</div><div class="line"></div><div class="line">  ServerBuilder builder;</div><div class="line">  builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());</div><div class="line">  builder.RegisterService(&amp;service);</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;Server&gt; server(builder.BuildAndStart());</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Server listening on "</span> &lt;&lt; server_address &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">  server-&gt;Wait(); <span class="comment">// until killed or server-&gt;Shutdown()</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> db = routeguide::GetDbFileContent(argc, argv);</div><div class="line">  RunServer(db);</div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(4). <strong>创建客户端</strong><br>　　客户端的业务代码定义在route_guide_client.cc源文件中。在RPC的调用体系中，业务相关的代码都已经实现在服务端，所以通常来说客户端会定义同服务端接口相同的函数名(非必需)，然后在这些函数实现中，完成对服务端的RPC调用，并获取调用返回的结果。<br>　　客户端在初始化的时候，需要首先创建grpc::Channel和RouteGuide::Stub两个对象。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Channel&gt; channel = grpc::CreateChannel(<span class="string">"localhost:50051"</span>,</div><div class="line">                          grpc::InsecureChannelCredentials();</div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;RouteGuide::Stub&gt; stub_ = RouteGuide::NewStub(channel);</div></pre></td></tr></table></figure></p>
<p>　　上面是用的简单非加密方式创建的Channel。然后，客户端通过stub_对象就可以直接进行RPC调用了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Point point = MakePoint(<span class="number">409146138</span>, <span class="number">-746188906</span>);</div><div class="line">Feature feature;</div><div class="line">GetOneFeature(point, &amp;feature);</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">GetOneFeature</span><span class="params">(<span class="keyword">const</span> Point&amp; point, Feature* feature)</span> </span>&#123;</div><div class="line">  ClientContext context;</div><div class="line">  Status status = stub_-&gt;GetFeature(&amp;context, point, feature);</div><div class="line">  ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　可见，每次调用都需要传入一个context对象的地址，上面是进行的默认构造，可以通过对这个context对象设置RPC调用相关的细节参数(比如超时等)。因为在不同的RPC调用之间不能共享这个对象，所以其一般都是以局部自动对象的方式创建的。<br>　　上面的Unary调用是最简单的情况。对于stream类型的调用，客户端同样有与服务端相似的ClientReader、ClientWriter以及ClientReaderWriter对象来完成相关操作。这些对象可以调用Finish()来获取服务端返回来的RPC调用状态，而WritesDone()可以显式通知对端写入完成，特别适合client-to-server streaming RPC类型的调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">while</span> (reader-&gt;Read(&amp;feature)) &#123; ... &#125;</div><div class="line">Status status = reader-&gt;Finish();</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;ClientWriter&lt;Point&gt; &gt; writer(</div><div class="line">    stub_-&gt;RecordRoute(&amp;context, &amp;stats));</div><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; kPoints; i++) &#123;</div><div class="line">  <span class="keyword">if</span> (!writer-&gt;Write(f.location())) &#123;</div><div class="line">    <span class="keyword">break</span>;     <span class="comment">// Broken stream.</span></div><div class="line">  &#125;</div><div class="line">  <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(</div><div class="line">      delay_distribution(generator)));</div><div class="line">&#125;</div><div class="line">writer-&gt;WritesDone();</div><div class="line">Status status = writer-&gt;Finish();</div><div class="line"><span class="keyword">if</span> (status.IsOk()) &#123; ... &#125;</div></pre></td></tr></table></figure></p>
<p>　　对于C++语言，gRPC/Protobuf还原生支持通过CompletionQueue实现异步模式(Asynchronous)工作。但因为手册不是很详细，此处先不讨论。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://en.wikipedia.org/wiki/Remote_procedure_call" target="_blank" rel="external">wiki Remote_procedure_call</a></li>
<li><a href="http://www.grpc.io/blog/gablogpost" target="_blank" rel="external">gRPC Project is now 1.0 and ready for production deployments</a></li>
<li><a href="https://github.com/grpc/grpc" target="_blank" rel="external">GitHub gRPC</a></li>
<li><a href="http://www.grpc.io/docs/guides/" target="_blank" rel="external">What is gRPC?</a></li>
<li><a href="http://purecpp.org/?p=933" target="_blank" rel="external">真正好用的RPC框架REST_RPC正式发布第一个版本</a></li>
<li><a href="http://blog.csdn.net/qicosmos/article/details/52386920" target="_blank" rel="external">什么样的RPC才是好用的RPC</a></li>
<li><a href="https://cloud.google.com/blog/big-data/2016/03/announcing-grpc-alpha-for-google-cloud-pubsub" target="_blank" rel="external">Announcing gRPC Alpha for Google Cloud Pub/Sub</a></li>
<li><a href="https://github.com/grpc/grpc/tree/v1.0.0/examples/cpp/route_guide" target="_blank" rel="external">gRPC example route_guide</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[网络开发中客户端连接保鲜机制的实现方法]]></title>
      <url>https://taozj.org/201612/tcp-connection-keep-alive.html</url>
      <content type="html"><![CDATA[<p>　　网络开发中的TCP连接分为长连接模式和短连接的模式，短连接就是在服务端接收到客户端请求，完成处理和应答后会主动关闭这个连接，而长连接顾名思义就是这个连接会一直存在着。一般来说，短链接的程序更容易编写和维护，因为一旦收到断开消息表明当前请求结束了，新的请求也会重新发起新的连接，而长连接需要处理拆包，粘包，错误累计飘移等各种复杂的问题。不过有得必有失，短链接最主要的问题是性能问题，每个请求都需要做三次握手和四次拆链操作，那么相同客户端和服务端交互的效率会因此大大的降低，尤其在网络连接慢的链路上会严重影响页面的加载速度。在后台局域网之中的主机高效通信，通常采用长连接的方式进行。<br>　　现在的网页做的是越来越复杂了，基本一个页面的渲染需要做到几十甚至上百次的请求才完成。HTTP协议中定义了Keep-Alive字段就是为此而定义的，现代的浏览器通常都会开6-8个长连接请求，而Apache和Nginx也可以打开配置选项支持这个特性。</p>
<h1 id="一、连接保活的原理和影响">一、连接保活的原理和影响</h1><h2 id="1-1_HTTP和TCP的KeepAlive">1.1 HTTP和TCP的KeepAlive</h2><p>　　除了HTTP协议中的Keep-Alive选项外，TCP中也有SO_KEEPALIVE这个选项。虽然名字类似，但是毕竟属于不同的网络层，所以他们之间是没有什么直接关系的。<br>　　HTTP协议中的Keep-Alive主要是在应用层实现对一个长连接的管理方式，其不需要周期性的检测这个连接是否可用，而是在每次服务端发送响应后重启一个time span的定时器，当定时器到点就表明这个time span没有数据交互，那么服务端就会主动关闭掉这个连接。TCP中的SO_KEEPALIVE是TCP协议支持的，其会在规定的时间内发送0负载的探测包给对端，正常情况下对端会返回ACK进行确定，以此探测TCP连接是否正常，在实际中这个选项可以用以：探测对端主机/服务是否活着；探测两者之间的网络连接是否正常。<br><img src="/post_images/images/201612/b77a07126d2c75f42a3920afe7c13cef.png" alt="keepalive"></p>
<h2 id="1-2_HTTP_KeepAlive对服务器的性能影响">1.2 HTTP KeepAlive对服务器的性能影响</h2><p>　　这段的内容在Nginx的手册中描述的十分清楚。因为HTTP KeepAlive的本质是一定时间内的长连接，所以这会大大降低服务端的并发量，而相比于Nginx基于事件驱动的服务端可以胜任大量的并发连接之外，Apache这种Prefork以及线程/线程池等传统型服务端模型会因为进程、线程的昂贵开销，并发量一般也就限制在几百的范围之内，一旦并发连接被KeepAlive占用后，服务器将不能再接受处理新的请求了。更加要命的是，不怀好心的人可以慢慢探测出KeepAlive的超时时间，从而更加高效地实现服务端的DDoS攻击。<br>　　KeepAlive对服务器的影响很难在测试环境中复现出来，而在线上环境运行后上面的矛盾才会显得比较的尖锐。因为测试环境一般是局域网环境，客户端和服务端都是高速本地网络连接，这时候短连接的建立、拆除连接对整个吞吐量的连接有限；而即使使用了KeepAlive的长连接，一般来说客户端的并发数目都会在服务端之下，而且快速的网络也会导致KeepAlive被大量的重用而不会超时。而且大多数测试工具都只报告成功的transactions，有些深入的特性很难挖掘出来。<br><a id="more"></a></p>
<h2 id="1-3_解决方案">1.3 解决方案</h2><p>　　Nginx给出的方案，除了详细考量KeepAlive开关、KeepAliveTimeout等参数调优之外，推荐使用Nginx作为前端HTTP Proxy。<br>　　因为Nginx是基于事件驱动的框架设计的，所以可以处理大量非活跃连接的情况，并发性能相对传统服务端有质的改变，而Nginx的后端可以和传统的服务端建立数目极少的长连接甚至短连接进行高效的通信。</p>
<h1 id="二、Nginx中连接保活的实现">二、Nginx中连接保活的实现</h1><p>　　从上面的背景知识可以看出，即便是事件驱动的网络模型，也需要处理KeepAliveTimeout的问题。实现这个功能不难，比如轮训遍历连接、创建N个超时定时器等，但是真正的挑战是对于巨大并发量情况来说，怎么样高效地更新、处理数据结构才是重点。<br>　　当前我所接触到的解决方案有：</p>
<h2 id="2-1_libco中的方案">2.1 libco中的方案</h2><p>　　之前在分析<a href="/201611/learn-note-of-tencent-libco-coroutine.html">《腾讯libco协程库学习笔记》</a>的时候，已经描述了他们对于超时侦测的解决方法：<br>　　创建stTimeout_t数据结构，然后分配40*1000的stTimeoutItemLink_t数组，每个元素的偏移量代表1ms，任何新加入的超时侦听事件都是按照和数组头超时时间的差值ms数添加到指定便宜位置数组元素中的双向链表中。每次epoll_wait获取活动事件之后，会顺便检测超时链表，将所有的已超时事件提取出来就可以了，因为使用的是双向链表的数据结构，所以即使在超时之前时间发生而删除单个的元素，以及在本应用中由于发送数据而删除并重新插入操作，都是极为快速的。<br>　　这种方式算是比较高效和优化的，而且一般KeepAliveTimeout也是有限的时间值，而通过设置数组元素的个数也可以进行时间精度和时间最大长度之间的平衡。</p>
<h2 id="2-2_陈硕的《Linux_多线程服务端编程》的方案">2.2 陈硕的《Linux 多线程服务端编程》的方案</h2><p>　　陈硕老师在其大作中所给出的解决方式是simple time wheeling，采用的数据结构是circle_buffer + hash_set + 智能指针(引用计数)的方式来管理的。具体来说：<br>　　a. 建立一个circle_buffer的数据结构，长度为指定的Timeout的秒数；同时建立一个1s间隔的定时器Timer，定时器回调函数的操作就是在circle_buffer的尾端添加一个空容器，这时候circle_buffer顶端容器的所有元素会被弹出析构；<br>　　b. 当建立连接的时候，创建连接的shared_ptr并丢入当前指定的circle_buffer容器中，同时在外部保存其一个weak_ptr待用；<br>　　c. 当这个连接有新数据的时候，取外部保存的weak_ptr提升为强引用share_ptr，添加到当前指定的circle_buffer容器中；<br>　　d. 根据智能指针的原理，如果整个circle_buffer都没有该连接的强引用的时候，表明是个不活跃的连接，而且已经被正确析构了；否则活跃的连接一直被添加到circle_buffer中，保证其不会被析构掉。</p>
<h2 id="2-3_Nginx的方案">2.3 Nginx的方案</h2><p>　　Nginx的解决方案也是十分简单的，和libco不同的是其使用了rbtree的数据结构，而且不像libco具有最大超时值的限制。<br>　　Nginx的超时timer是一个放在rbtree结构中的一个node，其中记录了当前连接超时的绝对时间。每当Nginx处理完HTTP Request之后，会调用操作ngx_http_set_keepalive()更新该连接的timer，且更新过程中做了一个优化，就是如果(存在)之前超时值和现在需要新设置超时值差异不超过NGX_TIMER_LAZY_DELAY(300ms)的话就直接返回，降低热连接反复修改的频次，否则就删除之前的超时timer，更新超时时间后重新插入到rbtree结构中。<br>　　在Nginx主事件循环每次调用ngx_process_events_and_timers()的时候，会先从rbtree中快速提取最接近的超时间隔ts，并将ts作为epoll_wait()的最后一个参数传递进去以保证最坏的情况下也会在这个时间返回。之后通过ngx_event_expire_timers()处理整个rbtree中的超时链接，而其ngx_http_keepalive_handler默认就是关闭掉这个连接。<br>　　感觉这种情况下，如果使用堆的数据结构也比较的合适，可以立即返回最近的超时队列，而且当初看见好像Libevent就是这样来管理超时操作的。Nginx没有使用堆结构而是使用红黑二叉树，是不是因为堆作为完全二叉树类型，调整起来代价比较大还是？</p>
<p>　　小结：上面的几种连接超时机制，没有一种实现方式是直接基于定时器实现的。一方面这类功能不需要高精度的定时需求，二来在异步框架下可以方便的嵌入轮训定时器队列的状态；队列中的连接可以是绝对超时时间或者相对时间，只要保持一种有序的状态即可。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://varvy.com/pagespeed/keep-alive.html" target="_blank" rel="external">How to enable keep alive</a></li>
<li><a href="http://www.nowamagic.net/academy/detail/23350305" target="_blank" rel="external">HTTP Keep-Alive是什么？如何工作？</a></li>
<li><a href="https://www.nginx.com/blog/http-keepalives-and-web-performance/" target="_blank" rel="external">HTTP Keepalive Connections and Web Performance</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[设计模式整理总结（一）：创建型模式]]></title>
      <url>https://taozj.org/201611/design-patterns-(1)-creational.html</url>
      <content type="html"><![CDATA[<p>　　大多抽象于特定语言的东西都比较难，设计模式便是其中之一。大家都说设计模式是前人工程实践中的经验，所以多读历史多看看前辈走过的路可以少挖点、少踩点坑，而且对设计意图熟练掌握后，对于快速阅读代码融入项目也是很有帮助的。<br>　　据说设计模式最好使用范例ACE的源代码，不过对于这个“学之者生，用之者死”(了解到的华为、腾讯例外)的著名网络库，目前还没有接触的打算。其实之前自己也总结了一份wiki，但是感觉这东西用自然语言的方式来描述反而难以讲清楚，所以这里打算用starUML工具把这些设计模式重新画一下，配上GOF的经典定义和网络上的一些典型例子，便于大家快速查阅和回忆。<br>　　UML工具觉得starUML听轻巧好用的，其v1分支版本原来是开源的，但是后来作者抱怨缺少sponsor，所以新的v2已经闭源商业版了。其实starUML可以无限期的evaluate，而且网上所谓的破解就是简单粘贴几行代码，可见作者还是很良心大度的，目的也在于防君子不防小人了，经济自由的还是适当赞助这些慷慨的码农吧！<br>　　在使用starUML的过程中，甚至不需要了解UML语言本身，图形化的操作就可以快速设计出模型。在使用starUML的时候，建议安装C++插件，可以帮助reverse分析已有代码的设计，可以将当前的设计自动生成C++代码。<br><img src="/post_images/images/201611/8e70ac935449dec9a7ff12d8d2f26fce.jpg" alt="UML"><br>　　UML中的难点，是依赖(Dependency)、继承(Generalization)、关联(Assosiciation)、聚合(Aggregation)、组合(Composition)这几种关系Relationships的理解和区分，其实粗分类来也就前三种，聚合和组合是关联关系特化一些条件的结果。<br>　　(1) <strong>Dependency</strong><br>　　体现的是一种<strong><em>using</em></strong>的类与类之间的关系，而且这种关系是单向的。这种依赖关系体现在对一个被依赖类的结构或者行为改变，会影响到依赖于它的类。<br>　　(2) <strong>Generalization</strong><br>　　体现的是一种<strong><em>is-a-kind-of</em></strong>或者<strong><em>is-a</em></strong>的关系，即常见的派生/继承关系。<br>　　(3) <strong>Assosiciation</strong><br>　　表述的是除了上面两种方式之外类与类的联系，可以是一对多、多对一、一对一、多对多的关系，而且这种关系体现没有拥有的联系。如果在设计中不能确定区分出下面的Aggregation、Composition，可以模糊地使用Assosiciation表示。<br>　　(4) <strong>Aggregation</strong><br>　　特例化的Assosiciation关系，体现的<strong><em>has-a</em></strong>的ownership关系，部分可以离开整体而单独存在。<br>　　(5) <strong>Composition</strong><br>　　特例化的Aggregation关系，部分不能离开整体而单独存在，所以是一种Strong/Dead的依赖关系。</p>
<p>　　设计模式共分为三类：创建型、结构型、设计型。一篇文章整理起来比较冗长，所以分成了三篇。<br>　　创建型模式主要包括：抽象工厂(Abstract Factory)、生成器/建造者(Builder)、工厂方法(Factory Method)、原型(Prototype)、单件(Singleton)五种类型。<br><a id="more"></a></p>
<h1 id="一、抽象工厂(AbstractFactory)模式">一、抽象工厂(AbstractFactory)模式</h1><p>　　定义：提供一个创建一系列相关或者相互依赖对象的接口，而无序指定他们具体的类。<br><img src="/post_images/images/201611/c3766ca04cc03da98d6b36d49f67a629.png" alt="AF"><br>　　抽象工厂可以算是工厂方法的更高级一层次的抽象。AbstractFactory类可以包括多个生成某种类型的工厂方法的接口，然后再由ConcreteFactory负责具体产品的创造实现。AbstractProduct为某一类的产品声明接口，然后ConcreteProduct实现这些接口后，就可以创建该类型的实际对象了。<br>　　举例：AbstractFactory定义了用户界面工具包创建的接口，然后ConcreteFactory可以指明具体Motif、PM风格包的创建方法；而AbstractProduct指明了风格包需要操作窗口的Window、Scrollbar控件，那么经过组合之后就可以得到四种不同类型的ConcreteProduct产品了。</p>
<h1 id="二、生成器/建造者(Builder)模式">二、生成器/建造者(Builder)模式</h1><p>　　定义：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。<br><img src="/post_images/images/201611/d17bb6d38ba02b63d447d1448bcc743c.png" alt="Builder"><br>　　其通过将一个产品的内部表象和产品生成过程分割开来，从而一个建造过程可以生成具有不同内部表示的产品对象，用户只需要指定需要建造的类型就可以得到他们，而具体的建造过程和细节不需知道了。<br>　　Builder为创建一个Product对象的各个部件指定抽象接口，ConcreteBuilder实现Builder定义的创建接口以构造和装配产品的各个部分，同时ConcreteBuilder需要提供一个检索产品的接口，Director构造一个使用Builder接口的对象。<br>　　构造过程可以表示为：Client首先创建目的ConcreteBuilder对象，然后用其作为参数创建Director对象，通过调用Director的Construct()方法，在这个函数中实际调用ConcreteBuilder的具体构建方法创建Product的各个部分，其GetResult()查询接口可以将构造的对象返回给Client。<br>　　构造者模式通常用于创建一些复杂的对象，这些对象的内部构建间的顺序通常是稳定的，但不同的对象内部的构造面临着复杂的变化。而且这里没有给Product做出一层的抽象，因为这种模式默认生成出的Product差异巨大，产生抽象基类没有太大意义。<br>　　举例：比如文档交互器将文档转换成各种格式，那么Client先根据需要创建需要的ConcreteBuilder(比如ASCIICov,TeXCov,TextCov)，然后用这个对象作为参数创建Director对象，调用Director对象的Construct()方法就可以返回创建结果了。<br>　　注意：咋看一下和模板方法十分的相像，只是Builder多了一个Director的角色。从分类看来Builder属于创建型模式，主要目的是创建和实例化对象，而模板方法属于行为模式，主要是对多个相似行为进行上层抽象，如果把Director去掉，那么生成模式可以退化成模板方法。</p>
<h1 id="三、工厂方法(Factory_Method)模式">三、工厂方法(Factory Method)模式</h1><h2 id="3-1_简单工厂">3.1 简单工厂</h2><p>　　定义：通过专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。通常也叫做参数化工厂方法。<br>　　简单工厂的特点是需要在工厂类中判断需要创建的类型，从而创造相应的产品，而当需要增加新的类型时，就需要修改简单工厂类本身。该模式的最大优点是工厂类中包含了必要的逻辑判断，根据客户端的选择参数动态实例化相关的类，对Client来说使用简单，免除了与具体产品的依赖。但是增加、减少、修改产品的操作都需要对简单工厂类代码进行变动，违反了开放-封闭原则。 </p>
<h2 id="3-2_工厂方法">3.2 工厂方法</h2><p>　　定义：定义一个用于创建对象的接口，让子类决定实例化哪一个类，使得一个类的实例化延迟到其子类。<br><img src="/post_images/images/201611/60fa169d90cdab8adc2e5120705f0dad.png" alt="FM"><br>　　像往常一样，Product和ConcreteProduct定义了具体产品的接口和其实现，Creator声明了工厂方法的接口FactoryMethod()，该方法返回一个Product类型的对象，ConcreteCreator实现Creator定义的FactoryMethod()，并返回一个ConcreteProduct实例。实际中Creator也可以提供一个默认的对象构造。<br>　　工厂方法模式实现的时候，客户端决定实例化哪个具体的ConcreteCreator类型，把简单工厂的内部逻辑判断转移到了客户代码中了，所以工厂方法是简单工厂模式的进一步抽象和推广。工厂方法每增加一个类型，就需要增加一个对应的工厂类，所以工厂方法中类的数目会比较多。</p>
<h1 id="四、原型(Prototype)模式">四、原型(Prototype)模式</h1><p>　　定义：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象，拷贝是原型模式的关键所在。<br><img src="/post_images/images/201611/154422a06ae2053fbc268e9e87a7c613.png" alt="Proto"><br>　　Prototype声明一个克隆自身的Clone()接口，ConcretePrototype()负责实现克隆自身的操作。其主要限制是每一个Prototype的子类都必须实现Clone()操作，才能实现对象的完整克隆。此外在克隆的时候，需要注意浅复制和深复制的区别。<br>　　Prototype模式原理实现比较简单，但是重点在于其使用场景和价值：原型模式从一个对象创建另外一个可定制的对象，而不需要知道任何创建的细节；原型模式通常会产生一个原型管理器，然后允许客户在运行时候动态的增加、删除、修改原型实例，更加的灵活；通过修改参数、修改结构等方式，可以扩充原型实例的数目，而不需要原先为产生这些类型而修改创建细节。</p>
<h1 id="五、单件(Singleton)模式">五、单件(Singleton)模式</h1><p>　　定义：保证一个类仅有一个实例，并提供一个访问它的全局访问点。<br><img src="/post_images/images/201611/aed945f4a76f0b85258be07632c7f83e.png" alt="Single"><br>　　Instance()操作允许客户访问它的唯一实例，在C++中通常是一个静态类方法和static局部变量。<br>　　关于单例的讨论问题，已经在另外一篇文章<a href="/201610/talk-about-singleton.html">说说设计模式中的单例</a>中讨论过了，此处不再细究。</p>
<p>本文的starUML文件上传到了<a href="/post_images/images/201611/DesignPatterns.mdj">这里</a>，欢迎使用！同时随着我的认识，本文件和本系列文档也会持续更正滴。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/wuzhekai1985/article/category/859763" target="_blank" rel="external">设计模式C++实现</a></li>
<li><a href="https://book.douban.com/subject/2334288/" target="_blank" rel="external">大话设计模式</a></li>
<li><a href="https://book.douban.com/subject/1052241/" target="_blank" rel="external">设计模式:可复用面向对象软件的基础</a></li>
<li><a href="https://sourcemaking.com/design_patterns" target="_blank" rel="external">Design Patterns</a></li>
<li><a href="https://dotnetfreakblog.wordpress.com/2014/01/11/concept-of-dependency-generalization-association-aggregation-composition-in-object-oriented-programming/" target="_blank" rel="external">Dependency, Generalization, Association, Aggregation, Composition in Object Oriented Programming</a></li>
<li><a href="https://github.com/kamranahmedse/design-patterns-for-humans" target="_blank" rel="external">Design Patterns for Humans</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[forkp多进程程序管理库的轮子]]></title>
      <url>https://taozj.org/201611/forkp-mulit-process-manage-framework.html</url>
      <content type="html"><![CDATA[<p>　　是前两天写的一个小工具，主要目的是实现Linux平台下master进程对worker子进程的监控和管理，并且必要情况下自动重启worker进程以实现保活的功能，这应该算是运维人员最喜欢的东西了吧。<br>　　本人在之前的文章<a href="/201611/about-multi-process-thread-dev-manage.html">《浅谈多进程程序的控制和管理》</a>中介绍了Nginx中master process和worker process的工作原理，其实这基本也可以作为多进程程序的开发范例来使用，虽然通常情况下的业务需求不用像Nginx做的那么复杂和完整，比如支持二进制程序不停服务平滑升级等，但是master进程对子进程进行监测并异常情况下自动重启服务的功能还是比较有用的。这种情况下，本人就萌生了写一个多进程程序开发的框架的想法，以后写多进程程序就不用重头做起了。<br>　　在Linux中进程管理的基本方式基本都是通过信号来实现的，因为子进程正常或者异常退出后，会由操作系统保证向其父进程发送SIGCHLD信号，所以父进程可以通过监听SIGCHLD的方式，高效异步的获取子进程退出的通知并对应做出相应地处理。如果只想让子进程保活，那么父进程只需要自定义处理SIGCHLD信号，并进行waitpid调用释放子进程的资源，然后重启子进程就可以了。不过既然想做一个通用点的库或者框架，那么还有一些细节的地方需要注意和完善，同时增加一些便利的功能还是很实际的。<br>　　forkp的子进程以两种方式工作：Process库和Exec管理服务，在同一个forkp实例中，同时对这两种方式提供了支持。<br>　　<strong>(1) Process库</strong><br>　　这种模式实际就是将Nginx的子进程管理模块抽象出来的效果，在新开发的多进程项目中，子进程的服务以可调用对象的方式注册启动。Nginx的配置文件可以设置worker process的进程数量，但这也假设了产生的所有worker process都是同构的，但是实际上多进程的子进程有可能会是异构的，因此在设计的时候，forkp会严格完全按照启动时候调用spawnWorkers的种类和次数来监测子进程。<br>　　master进程除了接收和处理SIGCHLD信号之外，还借助看门狗的模式来监测子进程，虽然实际上我不确定这有实际的意义，比如出现worker进程还没挂掉但是已经不能正常工作了的情况，因为通常程序错误或者跑飞了都会挂掉的。master进程和worker进程之间建立了匿名管道，master进程以1sec间隔向worker进程发送SIGWINCH信号，worker进程接收到该信号后通过匿名管道发回一个字节，如果master连续错过3个回应，就会发送kill杀死该子进程。这个功能是通过子进程屏蔽SIGWINCH信号来测试的。<br>　　需要额外说明的是，这里不要期待master进程做过多业务相关的内容。通常，master进程创建了侦听套接字后，所有的worker进程也继承了这个侦听套接字，而内核可以直接将侦听套接字的连接请求自动分发到worker进程中去，如果使用forkp开发类似Nginx这类程序，就可以很容易采用这种模式来满足需求。如果要期待master进程做过多的事情，由于master进程已经集成了一个epoll异步事件框架，那么程序可能要大改，还需三思。另外一点，就是master进程如果出错，所有的子进程都会退出，让master处理过多的任务，无异于增加了单点风险。<br>　　<strong>(2) Exec管理服务</strong><br>　　这种工作模式是对于已经存在的二进制程序，此时master进程fork出worker进程后，worker进程通过execv系统调用执行新的二进制程序，这个时候我把子进程调用exec后的实体叫做 <strong>子程序</strong>。由于exec系统调用重新执行一个二进制程序，所以此时master进程和worker进程除了通常的父子进程之外没有什么其他联系了，唯一的便捷就是可以同现有的所有程序方便的集成。此时像上面看门狗的形式就不能工作了，而是通过kill不发送任何具体信号的方式，来侦测指定pid的子进程是否存在。<br>　　事先说明最好还是把程序和服务写稳定一些，这只是作为一个补救措施，不可过度依赖这种机制。还有就是，比如我的ss5服务器偶尔会挂掉，此时通过forkp调用，就会在退出后自动重启服务了。<br>　　当然，工业上有现成的zabbix等更加成熟、可靠的开源方案……<br><a id="more"></a><br>　　在实现中，还有一些需要注意的地方，在此标记下来：<br>　　<strong>(1) 信号处理上下文</strong><br>　　本来说，master是一个单进程，没用什么竞争条件，但是当引入了信号处理程序之后情况就比较复杂了。信号是异步的，master任何时候都可能收到子进程和用户控制台发送的信号，所以这种情况下进程上下文和信号处理上下文对数据的访问需要互斥保护，尤其对容器的迭代访问和修改会导致冲突概率非常大，而信号处理上下文默认只对正在处理的信号是BLOCK的，如果多个信号修改同一个数据，信号处理程序之间还需要同步。所以在进程中访问互斥数据的时候，除了需要使用volatile关键字防止编译器优化外，还需要对应地BLOCK住相应信号集才可以。<br>　　如果直接用这种方式进行保护的，会发现维护工作很繁杂。其实看看Nginx的处理方式，再想想Linux信号处理下半部分，解决方式就很明朗了：在信号处理上下文中做最少的关键性工作，然后将其他任务记录并推迟，后面在进程的上下文中进行处理。所以在Nginx的信号处理中，绝大多数都是根据信号的种类设置对应的状态标识，然后master进程轮训根据状态做对应的操作，这样就可以保证处理完全串行化了。<br>　　<strong>(2) 重定向子进程的输出</strong><br>　　这个是因为当时的某个程序没有规划好日志，很多信息都是打印到标准输出和标准错误输出上的，这样默认情况下所有子进程的标准输出和错误输出都出现在了master进程的终端上，这在多个进程的情况下必然导致消息的混杂。所以这里的处理方法是，在父子进程之间创建一条匿名管道，在fork子进程之后，通过dup2将子进程的STDOUT_FILENO和STDERR_FILENO和这个管道相关联，master异步方式读取管道传输的内容后，写入进程相关的log文件中去。</p>
<p>　　正如前面提到的，Process模式和Exec模式两种情况，实际上也是该项目两个发展维度：<br>　　（1）前者讲求父进程和子进程之间进行一定的耦合，可以封装增强父子进程间的通信，比如创建socketpair进行全双工通信、共享内存、进程间文件锁进行数据共享等，这样master进程可以不断收集子进程的数据，甚至担任中介者的模式进行信息转发。不过进程之间的耦合也不应该过强，缺点前面说过了，而且还很容易将原本多线程的程序写成复杂的多进程程序。<br>　　（2）后者讲求程序的控制，希望可以在不停服务的情况，动态增加、删除、控制子程序。这种情况下只用信号的方式肯定是不能满足需求的了，后续需要添加配置文件支持，以启动时候预加载某些子程序，可能还需要写一个客户端才能向forkp服务传递更加复杂的信息。<br><img src="/post_images/images/201611/137563f4.png" alt="forkp"><br>　　PS:管理类某些二进制程序，发现定时器不能工作量。看了一下exec手册，原来exec族系列函数不会完全重新来，会继承calling process的一些属性，其中就包括signal_mask和signal_pending，这些东西还真是不用不知道啊。</p>
<p>　　Show you the code, just do it!</p>
<div class="github-widget" data-repo="taozhijiang/forkp"></div>]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（三）：从PhxPaxos中再看Paxos协议工程实现]]></title>
      <url>https://taozj.org/201611/learn-note-of-distributed-system-(3)-see-paxos-from-phxpaxos.html</url>
      <content type="html"><![CDATA[<p>　　Phxpaxos已经开源了，且他们号称开源和内部使用的是同一套代码，那么作为小厂的程序员可有福了，可以一睹研究一下生产环境下大规模分布式系统是怎样练成的。初看代码可能会比较犯晕，果真生产环境的实现跟<a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">《Paxos made code》</a>的复杂度不是一个数量级的，可是复杂归复杂，但毕竟代码中没有用到复杂的Moden C++特性、大量的模板元编程和晦涩难懂的编码技巧，所以只要功夫下到位相信还是肯定能搞明白其内部流程的。<br>　　本文就是通过Phxpaxos中所附带的简单例子，摸索了解Phxpaxos中对Paxos算法的实现，算是验证一下前面对Paxos算法的学习吧。当然之前也说过，Phxpaxos同Lamport老爷爷的原版Multi-Paxos相比已经修改了很多，毕竟老爷爷的文章比较的偏理论化，所以理论上不修改的Multi-Paxos是不可能满足线上分布式系统的可用性和可靠性需求的，具体对于遇到的修改再行另表吧。</p>
<h1 id="一、预备操作">一、预备操作</h1><p>　　默认情况下Phxpaxos的存储模块使用的是glog，但不知道怎么回事，在我MacOS下VMware Fusion虚拟机Ubuntu-1604的环境下，严格按照<a href="https://github.com/tencent-wechat/phxpaxos/wiki/%E4%B8%AD%E6%96%87%E8%AF%A6%E7%BB%86%E7%BC%96%E8%AF%91%E6%89%8B%E5%86%8C" target="_blank" rel="external">《编译安装手册》</a>还是会报无法创建log文件的错误，不知道是不是因为目录使用NFS挂载的原因，因为在实体机上面本地存储没有发现这个问题，此处也不详究了。其实Phxpaxos的实现中，很多地方都有详细的且分好等级的日志信息，查看代码发现只要设置了pLogFunc函数指针，就可以在所有log记录之前执行这个hook函数，于是乎可以在sample中设置这个option，那么整个系统的运行路径和运行状态也就一览无余了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdarg.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">custLog</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> iLogLevel, <span class="keyword">const</span> <span class="keyword">char</span> * pcFormat, va_list args)</span> </span>&#123;</div><div class="line">    <span class="keyword">char</span> sBuf[<span class="number">1024</span>] = &#123;<span class="number">0</span>&#125;;</div><div class="line">    vsnprintf(sBuf, <span class="keyword">sizeof</span>(sBuf), pcFormat, args);</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; sBuf &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line">oOptions.pLogFunc = custLog;</div></pre></td></tr></table></figure></p>
<p>　　Phxpaxos的代码虽然是多，但是当除掉存储模块、网络模块、CheckPoint模块、Benchmark和单元测试等部分代码后，核心代码其实也是十分有限的，而且和Paxos算法相关的部分都单独放在algorithm目录中了，查看这个文件夹中的文件名，赫然醒目的acceptor、proposer、learner、instance，就让我们估计道知道他们是什么角色履行的职责了。</p>
<h1 id="二、附带phxelection选主例程解析">二、附带phxelection选主例程解析</h1><p>　　Phxpaxos附带的两个sample详细构建过程都在<a href="https://github.com/tencent-wechat/phxpaxos/blob/master/README.zh_CN.md" target="_blank" rel="external">《README》</a>中描述清楚了，本来是想phxelection和phxecho两个例子都一起跟踪的，但是后面看着看着发现，phxelection流程走完基本就定型了，phxecho和前者的差异主要就是传递了自定义的StateMachine，所以在Paxos算法Chosen Value之后，会额外的执行客户提供的状态机转移函数Execute()，这其实和phxelection在原理上没有本质的差异，因为后者算是对于选主的特殊情况，预先定义了MasterStateMachine状态机而已。不过phxecho的日志量要小一些，可以两个例程结合起来看。<a id="more"></a></p>
<h3 id="2-1_Phxpaxos中的Master_Node">2.1 Phxpaxos中的Master Node</h3><p>　　在Phxpaxos的设计中弱化了Multi-Paxos中提到的Leader角色，而是使用了Master的概念，在后面PhxSQL项目的文档中也强调了：Master是唯一具有外部写权限的Node，所以可以保证这个Node的数据肯定是最新的副本，Client的所有写请求和强一致性的读请求都需要直接或者由其他Node代理转发到这个Master Node上面，而对数据一致性要求不高的普通读请求，其读请求才可以在非Master Node上面执行。<br>　　由此可见，在稳定的情况下Master Node起到了单点协调者的作用。但是当系统新启动，或者在Master Node挂掉的时候，就需要有一个选主的操作。<a href="https://zhuanlan.zhihu.com/p/21540239" target="_blank" rel="external">《Paxos理论介绍(3): Master选举》</a>已经将选主的原理详细说明了。概而言之，就是在没有Master的时候，大家都可以认为自己是Master并发出TryBeMaster请求，这就等于大家实现一个Basic-Paxos的流程，根据Paxos的算法原理可以保证，最后只有唯一一个节点的提案被Chosen，这时候被Chosen提案的Proposer就被选为Master Node。在系统运行的过程中，各个节点会事先约定一个租赁周期，在这个周期到达之前Master Node可以提起续约的请求，其他节点当发现约定的检查周期到达之后并且Master租赁有效期间之前还能够请求到Master Node，就表示Master Node续约成功，此时就不再发起TryBeMaster的请求。这样在稳定的情况下Master Node可以一直稳定的运行下去，而当Master Node异常或者普通Node和Master Node通信失常情况下的处理方式，会在后文中作进一步的解释。</p>
<h3 id="2-2_phxelection选主的实现流程">2.2 phxelection选主的实现流程</h3><p>　　Phxpaxos中的两个项目默认是使用的三个节点来实验的，根据Paxos中Majority的需求，其节点数至少是三个，而且尽可能的是奇数数目。每一个运行的进程对外被抽象成Node节点，在内部使用带序列号的Instance作为执行单元，且每个Instance内部都含有完整的Acceptor、Proposer、Leader的角色，而且同一个Instance中的三个角色是存在于同一个进程中的，相互之间的结果是立即可见的。</p>
<h3 id="2-2-1_Node初始化操作">2.2.1 Node初始化操作</h3><p>　　Phxelection历程启动很简单，当代码创建PhxElection对象oElection后，直接调用其成员函数PhxElection::RunPaxos()启动。在这个成员函数中，可以设置相关参数oOptions(注意这个选项很大，而且后续会深入透传到整个Phxpaxos内部)，这个sample中，最主要的是要打开选主开关bIsUseMaster，然后调用Node::RunNode()，也只在这个函数中才进行PNode实体的创建和初始化工作，并将得到对象的地址保存返回给poNode指针，这样用户程序也可以操作Node(而非PNode)规定的其他可用接口来访问或操作底层对象了。<br>　　PNode对象的创建采用典型的两段式构造，当然下面很多对象都是两段式构造，主要工作在PNode::Init()中实现，这个初始化涉及的内容比较的多，几乎贯穿了整个系统的启动过程：<br>　　(1). InitLogStorage: 好像底层是基于啥LevelDB搞的吧，先不管它了；<br>　　(2). InitNetWork: 默认的网络配置是根据命令行参数解析到的节点网络信息IP:Port，对于UDP协议创建接收套接字和一个发送套接字，对于TCP则是通常的bind-listen服务端初始化。TCP类型的初始化工作，还包括使用epoll_create创建异步事件侦听，同时创建封装了pipe匿名管道的Notify对象用于对接收到的消息进行传递，并设置管道NONBLOCK且将管道的读端添加EPOLLIN事件侦听；设置成员变量poNetWork；<br>　　(3). MasterList: 由于我们只用到一个Group，所以只创建一个MasterDamon对象，可见默认的Master Lease是10s，可以通过SetLeaseTime自由自定义设置这个租赁周期但是必须大于1s；同时还要创建一个MasterStateMachine对象，首先尝试从之前保存的数据加载历史信息，如果读取失败进行默认初始化，同时设置version的值为(uint64_t)-1；<br>　　(4). Group: 和上面一样也只有一个，主要把上面已经初始化的信息保存到这个容器里面；这个里面，让我们最感兴趣的是创建了一个Instance类型的m_oInstance对象，大概看了一下Instance类的声明就让人感到十分兴奋，因为大部分的消息回调OnRecieveXXX都在这个类的声明里面，同时还包含了Acceptor、Proposer、Learner成员，表明我们离Paxos已经是很接近了；<br>　　(5). ProposeBatch: 批量提交，算是Phxpaxos相比Multi-Paxos的一个新操作，待到我后面研究到这个深度的时候再深入；<br>　　(6). InitStateMachine: 参数只有一个——Options，一个超大巨形体参数，但是在这个sample中我们并没有创建StateMachine，所以这里的AddStateMachine啥也没做，当然对于另外一个Phxecho需要使用用户定义的StateMachine，此处就会进行添加；然后当我们开启了选主的功能后，各个Node都会启动运行RunMaster()，这个操作会创建一个线程运行MasterDamon::run()，这个线程就是Master Node选取和维护的主要实现部分，此处跳过，后面会单独展开详述；<br>　　(7).  Group Init: 将启动时候添加的所有Node列表信息添加到SystemVSM中，同时添加GetSystemVSM()、GetMasterSM()两个StateMachine。其实看到这里，让人感觉到StateMachine实际等价于某个带状态的函数，当所谓的StateMachine发生转移的时候，实际就是其对应的函数被执行。然后执行Instance::Init()，由于Instance的初始化有较多操作，且是跟Paxos密切相关的，下面单独展开介绍。</p>
<h3 id="2-2-2_Instance初始化操作">2.2.2 Instance初始化操作</h3><p>　　在Instance初始化的过程中，主要是对Paxos中的几个角色的初始化，其角色大多都是继承自Thread类，所以意味着各自以线程的方式独立运行。我们主要关心的角色有：<br>　　(1). Learner<br>　　最终映射成LearnerSender::run()线程，做的事情就是：等待条件变量m_bIsComfirmed被设置，然后调用SendLearnedValue(m_llBeginInstanceID, m_iSendToNodeID);从llBeginInstanceID开始一直发送到当前的m_llInstanceID。对在每一个instance发送的过程中，都需要从log中查取这个instance的相关信息(比如提案节点、提案号、Chosen Value等)后打包发送，具体的信息请参看Learner::SendLearnValue()中的打包过程，然后可以选择之前在Node初始化中网络部分的TCP还是UDP方式发送，具体任务交由网络模块负责了。<br>　　Learner会等待记录ACK信息，当前被确认的ID保存在m_llAckInstanceID变量中，确认超时后错误返回，错误时候记录当前已经发送的llSendInstanceID变量不被更新。<br>　　(2). Acceptor<br>　　初始化较为的简单，因为我们没有历史记录，所以加载数据发现为空，就将m_llInstanceID设置为0就可以了；<br>　　(3). CheckpointMgr<br>　　这个暂时也不展开说了。作为一个状态机如果要重新加载状态，最直观的就是从最开始零状态一直进行历史记录回放，但是这种方式效率低，而且随着状态机的运行记录所有的历史信息也是不现实的，所以为了增加效能实现的CheckPoint功能就是将历史记录某个时间点的状态做完整快照，加载状态可以从那个CheckPoint开始重放到当前日志记录的状态(这个过程叫做CatchUp)，具体的信息可以查看<a href="https://github.com/tencent-wechat/phxpaxos/wiki/%E7%8A%B6%E6%80%81%E6%9C%BACheckpoint%E8%AF%A6%E8%A7%A3" target="_blank" rel="external">《状态机Checkpoint详解》</a>。<br>　　本sample都是从头开始的，这些东西基本都是0状态的。<br>　　(4). IOLoop<br>　　这也是开辟一个线程，主要是在一个消息队列m_oMessageQueue中不断的完成取出消息和处理消息(主要就是通过一个带互斥锁、条件变量封装的std::deque<t>，腾讯说好的无锁队列呢？)的工作，正常情况下会取出消息，然后发配到OnReceive(*psMessage)处理，而OnReceive的处理流程会对数据包拆包检查，然后根据消息类型分别发配给Learner、Acceptor、Proposer对应角色去处理，消息的类型定义在了comm\commdef.h的enum PaxosMsgType中，看上去Proposer和Acceptor比较明确，而Learner处理的消息比较多啊。<br>　　通过把这个OnReceive的处理大概逛了一下，基本就是标准的Paxos协议的内容了，比如Proposer接收到Acceptor的表决信息后，会先调用m_oMsgCounter.AddReceive()，然后检查m_oMsgCounter.IsPassedOnThisRound()看看是不是已经满足超过半数决议了，如果是就进行接下来的例程Accept()或者向Learner广播消息ProposerSendSuccess()，而如果投票失败(否决票过多或者超时)则等待几十毫秒后重新发起Prepare请求。<br>　　上面提及的只是消费消息，消息的生产者在哪里呢？之前说道PNode在初始化网络层的时候有过TCP和UDP两种通信方式，TCP通过使用event异步事件，而UDP在一个线程中不断的接收消息，这些渠道接收到的信息，最后都会放到这个队列中去的。<br>　　此外Instance还保留了一个m_oRetryQueue重试队列，用于处理Paxos相关消息，具体什么原理暂时不详。<br>　　上面的这些线程的循环，都在m_bIsEnd=true的时候会退出来，在IOLoop::Stop()会设置这个变量，检索后在Instance对象被析构的时候会调用之。</t></p>
<h3 id="2-2-3_MasterDamon主线程工作">2.2.3 MasterDamon主线程工作</h3><p>　　唉，代码中有好多错误的单词，不知道可不可以作为一个槽点……<br>　　根据上面说到的选主原理，这个线程的工作内容也十分简单，实质的工作内容就是TryBeMaster()：首先在Master Node稳定正常的情况下自身会自动续约，那么在m_llAbsExpireTime之前就会返回m_iMasterNodeID和版本号，否则返回nullnode；当Node发现返回nullnode的时候，无论是Master Node的原因还是自己和其通信的原因，都会发起一个包含llMasterVersion信息的Proposer请求，那么：<br>　　(1). 系统刚开始的时候，所有的Node都认为自己是Master Node，然后发起Propose()请求，经过Basic-Paxos的正常流程，会最终有一个Node被Chosen，由于大家都在同一个Instance中，被Chosen Value所对应同一进程中的Learner已经知道Chosen Value了，然后就会立即发送ProposerSendSuccess()广播给所有的Learner(也可以配置该节点自身需不需要进行学习)，所有Learner接收到该消息后都通过OnProposerSendSuccess()进行学习，并设置m_bIsLearned=true状态；Learner的后续执行流程检查到这个状态后，就会执行状态机MasterStateMachine状态转移Execute()即LearnMaster()，设置所有节点的m_iMasterNodeID为被Chosen Value的节点。系统启动Master Node新选取成功时候，m_llAbsExpireTime的值为0，而后面续约的时候更新为提起Propose时刻+Master租赁时长-100ms长度，自此选主成功。<br>　　(2). 所有节点都会在Lease Timer之前发起(但不一定会实质执行)TryBeMaster()，为了减少异常情况下通过Basic-Paxos新选取Master时候可能的“活锁”冲突，大家发起Prepare的时间点会有个微小的elf差异，当发现Master Node在超时时间之前仍然有效的时候，非Master节点都直接返回而不执行BeMaster()，Master节点会发起一个续约的正常Propose请求，最终状态机转移的时候更新时间等信息，然后所有节点学习重新调整即可；<br>　　(3). 当Master Node本身挂掉的时候，大家都会发起Propose请求，那么此时就退化成初始状态多个Node采用Basic-Paxos的方法选主的情况了；<br>　　(4). 当某个非Master Node因为通信或者其他的原因，错误的发起了BeMaster()的时候，wiki也说了这里是个“乐观锁”的解决思路：这个节点将自己观测到的最大version打包到Propose参数里面去，后续通过正常的Paxos流程会被Chosen，待到最后执行状态转移LearnMaster()的时候，会解包对参数进行校验，发现请求的version版本和当前最新版本不符，那么放弃这次状态机的实质切换操作而直接返回了。我们乐观的预估，此时改节点和系统的通信正常了，在真正的MasterNode下次续约的时候，改节点将会正确学习到Master Node的信息并正常工作。</p>
<h1 id="三、小结">三、小结</h1><p>　　排除代码中很多写错的英文单词，虽然涉及到的模块、对象众多，但是整个项目的设计和实现还是挺清晰的，配合详细的wiki和文档以及详细的日志信息，初学者花时间跟踪项目流程还不是很困难，同时也算是了解到了腾讯内部C++的开发风格，而在代码的关键点添加BreakPoint()回调接口还是挺有新意的。<br>　　还有，项目作者号称需要C++11标准的支持，但是发现除了for表达式、nullptr关键字外，C++的新特性基本可以说都没用到，不过也好，这样的代码更容易跟踪理解。项目中使用了大量的定时器和延时操作，就像当初通信核心网代码一样，这也是复杂系统所不能避免的。此外成员变量十分的多，但是基本都没有提供注释，这点读起来比较的费力。<br>　　本篇文章算是走了个流水，但是核心重要的CheckPoint、成员动态变更和他们创造的BatchPropose都被略过了，有时间再研究吧。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">Paxos made code</a></li>
<li><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf" target="_blank" rel="external">Paxos Made Live - An Engineering Perspective</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos" target="_blank" rel="external">Phxpaxos</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/blob/master/README.zh_CN.md" target="_blank" rel="external">Phxpaxos README</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[腾讯libco协程库学习使用笔记]]></title>
      <url>https://taozj.org/201611/learn-note-of-tencent-libco-coroutine.html</url>
      <content type="html"><![CDATA[<p>　　在跟踪libco库时候发现一位网友提的issue，实在是看不下去了，哔了狗了。人家说程序员最喜欢的事是别人的项目有详细的wiki或文档，最讨厌的事情就是自己写文档，看来果真如此啊。不过libco自带了好几个例子，算是把libco的功能都展示了出来，过一遍也就知道怎么使用了。<br><img src="/post_images/images/201611/8064b68a1b41936d255f92f5a91eb647.png" alt="libco"><br>　　libco算是一个比较轻巧的协程库吧，看着代码不多，都是用朴实的C语言写的，而且完全不依赖于外部的ucontext或Boost.Context库，就想着读下代码彻底了解一下这个腾讯内部大规模用的协程库是怎么炼成的。从背景资料看来，一般对于新立项开发的系统，很多公司可能选择异步的方式来搞定，但是对于历史遗留的大规模同步模型的业务，异步化改造将会极具挑战性的事情，因为异步的方式需要代码分割重布，算是大换血的手术了；而如果采用协程和hook阻塞调用的方式，可以对传统同步类型业务基本无侵入的情况下享受异步带来的好处，这种手段确实很诱人。<br>　　额外想说的是，人家说隔行如隔山，其实当前在分工这么明确的环境下，隔业也同隔山啊，据说协程在游戏引擎行业早就大规模的被应用了以至于游戏开发者都不屑于提及这些，反而在互联网的后台压力越来越大的情况下，传统搞后台的兴起这个概念出来了。还有一点好奇的是，代码里面居然用了<strong>APPLE</strong>关键字和对kqueue异步的支持，腾讯不是一直是SuSE的粉丝么，难道后台也用到了很多BSD的服务器？</p>
<h1 id="一、协程的创建和调度">一、协程的创建和调度</h1><p>　　libco支持的协程原语包括：co_create、co_resume、co_yield、co_yield_ct、co_release。</p>
<h1 id="1-1_协程的创建管理">1.1 协程的创建管理</h1><p>　　(1). co_create()：创建一个协程。因为协程寄生于线程中的，所以每个线程需要有自己线程级别的资源来维护管理自己的协程。这里程序没有使用到线程局部存储TLS的方式，而是采用全局的stCoRoutineEnv_t类型的指针数组，然后采用线程tid进行索引的方式获取线程独立的存储结构。虽然定义上pid_t一般是int类型，但是系统一般不会用到这么大的范围，如果没有额外配置系统，默认最大的线程ID值定义在/proc/sys/kernel/pid_max为32768，所以这里使用上没什么问题，且空间浪费也不是很大。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> stCoRoutineEnv_t &#123;</div><div class="line">	stCoRoutine_t *pCallStack[ <span class="number">128</span> ];</div><div class="line">	<span class="keyword">int</span> iCallStackSize;</div><div class="line">	stCoEpoll_t *pEpoll;</div><div class="line">	stCoRoutine_t* pending_co; stCoRoutine_t* ocupy_co;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　在创建上述线程相关资源的时候，还会自动创建一个没有执行体的主协程，同时线程中还会创建一个stCoEpoll_t结构用于异步事件相关的操作，默认侦听fd数目最多为1024x10，同时在pTimeout-&gt;pItem上还创建了60x1000个stTimeoutItemLink_t结构(但是事件最大支持20s的超时，注释说40s，这里实际是60s!!!)，且后续在事件循环中，根据fd的事件状态会挂载到pstActiveList和pstTimeoutList链表上面去。<a id="more"></a><br>　　真正创建协程的函数是co_create_env()，每个协程有自己密切相关的结构stCoRoutine_t。对于协程可以分配的栈空间是128k~8M的范围，并且以4k对齐，传统的stackfull协程基本都是采用独立栈的方式实现的。<br>　　libco除了协程独立栈支持外，最大的创新是支持共享栈。原理就是通常stackfull实现所使用的fixed_stack分配的内存都用不了多少，内存浪费巨大导致系统整体创建的协程数目有限；而segment_stack的效率性能低下；所以共享栈采用的方式就是每次发生协程切换的时候，把实际用到的栈内容stack_bp-stack_sp通过save_stack_buffer来保存到malloc的内存中去，然后调用coctx_swap进行寄存器信息的切换，再把切换进来的新协程之前以相同方式保存的栈数据再拷贝到上面的共享栈空间的对应的内存位置上去(栈指针在coctx_swap已经更新完了，这里只是填补数据的作用，而且每个协程切换前后一直使用相同的共享栈，即使有局部指针也没有问题)，从而大大增加了内存的利用效率。<br>　　(2). co_release、co_free<br>　　只是释放了stCoRoutine_t的资源，虽然对于共享栈没有问题，但是对于独立栈貌似连栈空间内存资源都没释放啊？<br>　　(3). co_resume、co_yield、co_yield_ct<br>　　这几个函数都是跟协程切换相关的，他们底层都会调用co_swap进行在独立栈/共享栈环境下的切换，只是在操作前会进行协程管理相关资源的更新。<br>　　co_resume可以恢复协程的执行，同时创建的协程第一次启动也是使用这个接口，并且在第一次启动的时候会初始化特殊的coctx_t结构(具体啥东西就不细究了)。在协程执行结束后，会自动设置cEnd=1，同时将自己yield出去，虽然是CPP的代码但是没有用到RAII，所以相关的资源需要调用者手动释放。</p>
<h2 id="1-2_协程的切换">1.2 协程的切换</h2><p>　　libco的协程调度比较的有意思，env-&gt;pCallStack[ env-&gt;iCallStackSize-1 ]永远指向了当前执行的协程，所以co_self()最终返回的就是相同的内容。<br>　　当co_resume调用时候实际是将新协程添加到这个pCallStack并iCallStackSize++，co_yield实际将当前协程和上一个协程pCallStack[ env-&gt;iCallStackSize-2 ]进行切换并iCallStackSize–。所以从这个原理上看来，pCallStack永远包含了可以被运行的协程，并通过co_resume、co_yield将协程从这个可运行Stack中进行添加和删除操作，当然大多处时候都是使用手动或者异步事件驱动来实现。在最开始环境初始化的时候创建了一个主协程，这个主协程coctx_t是默认初始化的且没有执行体(?)，驻守在了pCallStack结构的顶部。<br>　　当创建协程时候传入的函数执行完毕后，会在CoRoutineFunc可见其设置co-&gt;cEnd=1;并自动将自己yield出去。<br>　　基于异步事件的程序开发，通常是由主线程不断的调用epoll_wait收取就绪和超时事件，然后对这些Item依次执行OnPollProcessEvent()函数，这个函数通常就是co_resume()让那个等待的协程继续执行下去，所以协程的调度完全算是由事件驱动完成并串行执行的。</p>
<h1 id="二、协程应用开发接口">二、协程应用开发接口</h1><p>　　当上面创建协程、释放协程、切换协程的原语有了，就可以进行一些高级接口和特性的封装，方便协程库用户的使用，并尽可能对现有的业务代码做最小化侵入了。这些封装和接口其实也是其他协程库在设计中可以考虑实现的。</p>
<h2 id="2-1_阻塞调用Hook">2.1 阻塞调用Hook</h2><p>　　涉及到的接口有：co_enable_hook_sys、co_disable_hook_sys、co_is_enable_sys_hook。<br>　　在libco里面，大多数的默认阻塞例程基本都打开了sys_hook的支持了。这个Hook的原理，就是通过glibc中dlfcn.h的dlsym和RTLD_NEXT结合起来，从而给标准库函数添加钩子或者产生一个wrapper的效果。比如下面的这个常见的默认阻塞的read()函数，在没有打开sys_hook或套接字是阻塞类型的情况下，通过RTLD_NEXT将直接调用后面链接库的原始标准read()版本，否则会插入一个poll的操作，当然这个poll本身也是打了Hook的，详细的内容后面会有介绍。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">read_pfn_t</span> g_sys_read_func = (<span class="keyword">read_pfn_t</span>)dlsym(RTLD_NEXT,<span class="string">"read"</span>);</div><div class="line"></div><div class="line"><span class="keyword">ssize_t</span> read( <span class="keyword">int</span> fd, <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> nbyte ) &#123;</div><div class="line">	HOOK_SYS_FUNC( read );</div><div class="line">	</div><div class="line">	<span class="keyword">if</span>( !co_is_enable_sys_hook() )</div><div class="line">		<span class="keyword">return</span> g_sys_read_func( fd,buf,nbyte );</div><div class="line">		</div><div class="line">	<span class="keyword">rpchook_t</span> *lp = get_by_fd( fd );</div><div class="line"></div><div class="line">	<span class="keyword">if</span>( !lp || ( O_NONBLOCK &amp; lp-&gt;user_flag ) ) &#123;</div><div class="line">		<span class="keyword">ssize_t</span> ret = g_sys_read_func( fd, buf, nbyte );</div><div class="line">		<span class="keyword">return</span> ret;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">int</span> timeout = ( lp-&gt;read_timeout.tv_sec * <span class="number">1000</span> ) </div><div class="line">				+ ( lp-&gt;read_timeout.tv_usec / <span class="number">1000</span> );</div><div class="line"></div><div class="line">	<span class="keyword">struct</span> pollfd pf = &#123; <span class="number">0</span> &#125;;</div><div class="line">	pf.fd = fd; </div><div class="line">	pf.events = ( POLLIN | POLLERR | POLLHUP );</div><div class="line">	<span class="keyword">int</span> pollret = poll(&amp;pf, <span class="number">1</span>, timeout );</div><div class="line"></div><div class="line">	<span class="keyword">ssize_t</span> readret = g_sys_read_func( fd, (<span class="keyword">char</span>*)buf, nbyte );</div><div class="line">	<span class="keyword">if</span>( readret &lt; <span class="number">0</span> )</div><div class="line">		co_log_err(<span class="string">"CO_ERR: read fd %d ret %ld errno %d poll ret %d timeout %d"</span>,</div><div class="line">					fd, readret, errno, pollret, timeout);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> readret;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　基本大多数的C库和系统调用函数都被打上了hook，当然原文档里面特别提到了gethostbyname()，有兴趣的可以单独深入了解一下。</p>
<h2 id="2-2_异步Event">2.2 异步Event</h2><p>　　涉及到的接口有：co_poll、co_eventloop、co_get_epoll_ct。<br>　　co_get_epoll_ct() 就是用于查找返回当初在线程级初始化中，创建stCoRoutineEnv_t的时候所创建的stCoEpoll_t类型pEpoll指针。<br>　　co_eventloop() 就是对epoll_wait调用处理的一个死循环，epoll_wait会进行一个1ms超时的短时间blocking调用，然后将可用的Item添加到pstActiveList中去，然后检查超时的事件并把超时的事件也添加到pstActiveList中去。当收集了这么多的active事件后，接下来依次调用各个Item的pfnProcess函数(这个函数通常是执行co_resume唤醒协程)。<br>　　co_poll() 该接口不仅可以在用户协程程序中直接使用，在hook_sys中也是被hook成poll()的形式而被大量使用。其操作较为复杂，分为以下几个步骤：<br>　　(1). 首先创建stPoll_t对象，设置完描述符相关的参数后，最重要的是设置pfnProcess=OnPollProcessEvent、pArg=co_self()；当事件就绪后就是通过这个函数和参数将自己切换回来；<br>　　(2). 将自己添加到ctx-&gt;pTimeout队列中去。关于这个ctx-&gt;pTimeout队列，其实是一个简单的链表数组结构，可以维持60x1000ms=60s的超时间隔，然后新的Item要插入进去的话，是就算其相对表头绝对超时时间的偏移长度来定位到指定的数组位置并进行插入的。当然这个接口设计的有点问题，就是poll的系统调用可以设置timeout=-1表示永不超时，但是这里的超时是必须设置且不能超过相对超时表头(理论是)60s，使用起来可能会有些误解。通过这样的数据结构，每次epoll_wait循环后取超时事件就十分方便快速了。<br>　　(3). epoll_ctl通过EPOLL_CTL_XXX将实际的事件侦听添加到操作系统中去。这里才发现poll和epoll的事件类型好像不兼容，所以两者常常会用函数转来转去的。<br>　　(4). co_yield_env()将自己切换出去；<br>　　(5). 后续执行表明因为事件就绪或者超时的因素又被切换回来了，此时调用epoll_ctl将事件从操作系统中删除掉(这也暗示了是ONE SHOT模式的哦)，保存返回得到的就绪事件。<br>　　(6). 释放资源，本次调用完成。</p>
<h2 id="2-3_协程局部存储">2.3 协程局部存储</h2><p>　　涉及到的接口有：co_setspecific、co_getspecific。<br>　　这个还是比较简单实现的，对于非协程执行环境或者主协程环境，直接调用pthread库的pthread_setspecific、pthread_getspecific的线程局部存储接口，而如果是在一般工作协程的环境，每个协程预留分配了1024个指针用于存储这些value的地址。</p>
<h2 id="2-4_协程同步">2.4 协程同步</h2><p>　　涉及到的接口有：co_cond_alloc、co_cond_signal、co_cond_broadcast、co_cond_timedwait。<br>　　大家都知道mutex和条件变量是多线程环境下的开发利器，由于协程是用户态主动切换的，所以感觉对mutex需求不是很大，但是条件变量很有作用，在生产者-消费者模型中可以快速唤醒等待资源的合作者，增加调度效率。<br>　　co_cond其实也是一个小Trick：<br>　　(1). 首先通过co_cond_alloc()创建一个stCoCond_t对象管理所有的条件事件，其实是一个stCoCondItem_t类型的链表头尾；<br>　　(2). 当co_cond_timedwait()等待的时候实际是创建一个stCoCondItem_t，设置pArg=co_self()、pfnProcess=OnSignalProcessEvent，然后将其添加到先前的stCoCond_t链表中去，当然如果设置了超时参数还需要添加到线程的pEpoll-&gt;pTimeout中去，然后通过co_yield_ct();把自己切换出去；<br>　　(3). 当生产者资源就绪的时候，通过co_cond_signal/co_cond_broadcast在stCoCond_t链表中取出后添加到pEpoll-&gt;pstActiveList中等待被调度，当然如果超时了还没有被生产者唤醒，如上所述线程epoll_wait循环中，会自动将其添加到就绪队列中执行回调的。<br>　　所以条件变量实际上就是除却使用poll的方式外，由协程自己控制将需要唤醒的协程添加到pEpoll-&gt;pstActiveList队列中去来实现的。</p>
<h2 id="2-5_闭包操作">2.5 闭包操作</h2><p>　　感觉怪怪的，那就先不看了，C++的std::bind、lambda用起来也是爽哒哒滴！</p>
<h1 id="三、小结">三、小结</h1><p>　　设计的亮点在于：可运行协程Stack管理结构，调度的效率更高；shared_stack共享栈设计，节约内存提高创建协程的数量；hook阻塞系统调用和标准库函数，对原有业务代码侵入性小；抽象出多种协程应用开发常用接口，使用简洁方便。<br>　　我的libto小轮子还有不少的东西可以完善哈，再次广告一下！</p>
<div class="github-widget" data-repo="taozhijiang/libto"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/tencent-wechat/libco" target="_blank" rel="external">libco</a></li>
<li><a href="http://dev.qq.com/topic/58203cfcd149ba305c5ccf85" target="_blank" rel="external">揭秘：微信是如何用libco支撑8亿用户的</a></li>
<li><a href="https://www.zhihu.com/question/52193579/answer/129597362" target="_blank" rel="external">腾讯开源的 libco 号称千万级协程支持，那个共享栈模式原理是什么?</a></li>
<li><a href="http://docs.oracle.com/cd/E19253-01/819-7050/chapter3-24/" target="_blank" rel="external">链接程序和库指南</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Boost.Context2库的协程库轮子libto的设计与实现]]></title>
      <url>https://taozj.org/201611/libto-coroutine-library-base-on-boost-context2.html</url>
      <content type="html"><![CDATA[<p>　　个人对协程开发还是比较感兴趣的，当然不仅仅是因为从最近的各大开源系统趋势中，发现基于协程的高性能服务端系统被各大厂所越来越重视，而是以前自己对操作系统有过一段时间的学习和专研，可是内核级的线程让我们能做的事情十分有限(不如说是水平太差了吧)，反而是现在协程作为用户级别的线程，用户态程序就可以对其做很多事情，比如调度、定时、io阻塞、睡眠等操作，所以说协程库的开发具有很强的可玩性啊，当然要写一个好的协程库也是十分有挑战的。同时，多个协程存在于同一个线程中，且同一时刻只有一个协程处于运行状态，所以很多的调用必须仔细小心，任何一个协程被阻塞就会导致整个线程被阻塞。<br>　　自己学习Boost.Context后，虽然对其基本原理略知一二，但是实际使用上却是无从下手，虽然也知道也有现成可用的Boost.Coroutine协程库，可惜和往常一样，Boost库的代码都想当的晦涩难懂。幸好Meizu的libgo开源来着，代码写的也是能给人看的，抛去Windows兼容和其他一些复杂的技法，模仿着写一个朴实易懂的协程库轮子看来也并非不无可能。当然在最终的实践中，也还是有一些同原库不一致的地方，虽然不一定会比原库的好，但是觉得更符合自己的思维习惯吧。此处还需要提到另外一个协程库libcopp，也据称是一个服务于生产环境的协程库了，虽然在github上面十分低调，但是从博客看来作者的C++和系统底层功力比较深厚。其实啊，有些人一直就很牛，而这位作者的博客历程看来其实前几年也很菜，但是近两年来成长迅速，真是让吾等可望不可及啊，虽然偶也在拼命奔跑着。</p>
<h1 id="一、基本结构">一、基本结构</h1><p>　　本着“开发库不应该默默地单独创建线程”的原则，libto可以以两种方式运行，如果创建Task、Timer的时候不添加额外的dispatch参数，那么协程的调度和执行、epoll事件的查询都只会在主线程中执行；如果创建Task、Timer的时候指定了dispatch参数，就会将这个协程创建在指定索引对应的线程中(如果线程不存在就创建对应的线程)，每个线程单独调度自己的协程，但是协程状态阻塞事件的检查和更新全部都在主线程中操作。<br>　　在多工作线程模式下把所有的事件轮训放到主线程中，主要的考虑的一方面是将异步的工作放在主线程中，当主线程中不添加其他复杂任务的时候可以及时的轮训各个线程的异步事件，异步信息不会受到各个工作线程的负载量而受影响；二来当工作线程没有活跃的事件时候可以将其阻塞睡眠，主线程在必要的时候可以异步唤醒对应的工作线程，借此降低活跃的线程数节约资源。由于主线程和工作线程都需要修改任务队列，这里就需要额外的同步操作以保护数据结构。<br><a id="more"></a></p>
<h1 id="二、协程开发原语">二、协程开发原语</h1><h2 id="2-1_sch_yield">2.1 sch_yield</h2><p>　　类似于yield的工作，当前工作的协程被无条件的被切换出去，然后每个线程的主协程负责调度选择下一个要执行的协程并将其切换至运行的状态。虽然不一定有主协程这个名词，我把线程运行时候默认的执行环境叫做主协程，而对应的其他使用Boost.Context创建出来的执行环境叫做工作协程，由于不像多线程中可以用内核态这个特权状态强制切换执行上下文，线程中的所有协程都是平等的，只能自己主动交出执行权。<br>　　在协程库中，每个工作协程都是从主协程切换进去的，当yield切换出来的时候也是返回到主协程中，主协程在这个时机可以选择下个要执行的协程以实现调度。</p>
<h2 id="2-2_sch_read/write/rdwr">2.2 sch_read/write/rdwr</h2><p>　　Linux中几乎所有的文件描述符的操作默认都是阻塞的，但是理论上在协程中的任何操作都不应当被阻塞，否则整个线程都被阻塞了，浪费的是“大家”(所有协程)的时间，所以正确的方法是对于所有可能阻塞的异步操作，都应该把当前协程切换出去，等到资源可用的时候再无障碍顺利执行，这也就是select/poll/epoll的本质思路。<br>　　libgo做了一个小trick(当然libco也是这么个做法，或者是谁借鉴谁，亦或者是整个协程库的通用做法)，把原先所有可能阻塞的C库和系统调用接口(accept、read、recv…)都同名重写打了一个hook，根据C++调用名字查找规则，编译器会优先调用相同命名空间中的函数，然后通过libgo_poll-&gt;add_into_reactor方式将文件描述符和事件添加到epoll中去，之后立即把自己切换出去，主协程的Run()会轮训检查调用epoll_wait检查底层的就绪事件，并调度的时候在适当时机唤醒这个等待的协程。<br>　　这样固然是好，用户甚至无需修改代码就可以充分利用协程和异步的优势，只是工作量要大一些。我就用了更直接的模式，我认为每个开发者应该有足够的素质知道哪写操作会阻塞，实现调用sch_xxxx进行异步检查，然后进行无阻塞的IO操作，当然缺陷就是要显式把所有的sch_xxxx显式侵入用户代码，好的协程库肯定不能这么干滴。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">libto::st_make_nonblock(sock);</div><div class="line"></div><div class="line">sch_read(sock);</div><div class="line"><span class="keyword">size_t</span> count = recv (sock, buf, <span class="number">512</span>, <span class="number">0</span>);</div><div class="line">sch_write(sock);</div><div class="line">write(sock, msg_200.c_str(), msg_200.size());</div></pre></td></tr></table></figure></p>
<p>　　当然非阻塞socket读取数据什么时候结束是考验网络开发基本素质了哦。</p>
<h2 id="2-3_sch_timer">2.3 sch_timer</h2><p>　　这个的实现主要得益于内核中的timerfd，把定时器也进行fd化了，这一方面是基于信号实现的定时器使用起来是极其不可靠的，同时提供fd接口就是方便统一到select/poll/epoll的框架下面。所以根据上面的思路，添加一个带回调的定时器操作，其实也就是创建一个任务，只是在回调函数前面增加一个timerfd的异步侦听操作。让人兴奋的是内核的很多东西都开始fd化了，比如eventfd、timerfd、signalfd……<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> ( (timerfd = <span class="number">_</span>timer_prep(msec, forever)) == <span class="number">-1</span>)</div><div class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line"><span class="keyword">if</span> (forever) &#123;</div><div class="line">    <span class="function">Task_Ptr <span class="title">p_task</span><span class="params">( <span class="keyword">new</span> Task([=] &#123;</span></span></div><div class="line">        <span class="keyword">for</span>(;;)&#123;</div><div class="line">            <span class="keyword">char</span> null_read[<span class="number">8</span>];</div><div class="line">            <span class="number">_</span>sch_read(timerfd);</div><div class="line">            read(timerfd, null_read, <span class="number">8</span>);</div><div class="line">            func();</div><div class="line">        &#125;</div><div class="line">    &#125;));</div><div class="line">    addTask(p_task);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面用for(;;)循环设置了一个连续间隔定时器，如果只需要one_shot类型的定时器就把循环拿掉，同时在回调结束的时候关闭事先创建的timerfd释放资源就可以了。</p>
<h2 id="2-4_sch_sleep_ms">2.4 sch_sleep_ms</h2><p>　　有了sch_timer那么sch_sleep_ms的协程睡眠实现更是不在话下了，使用相同的思路，创建一个timerfd并再次通过_sch_read等待事件就绪，然后关闭timerfd后执行流程得以继续进行，模拟了一个睡眠等待的效果，此处就不多表了。<br>　　这些fd的异步操作不能在主线程的主协程中被调用，主协程没有Task结构，所以也无法添加到阻塞队列中去。还有就是不要依靠这些定时、睡眠操作有多么高的准确度，因为它基于主线程主协程的事件检测和工作协程的工作负载情况，所以这里十分考量协程调度算法的效率。</p>
<h1 id="三、小结">三、小结</h1><p>　　项目的主页在：</p>
<p><div class="github-widget" data-repo="taozhijiang/libto"></div><br>　　当然，现在也仅仅是出了一个原型，后面还有很多工作需要做：资源的安全释放、协程的调度和空闲处理、任务和定时器的取消删除、各种异常情况的处理等等，离生产环境的要求还差的远。最近搜索发现一篇系统性的协程文章<a href="http://www.akira.ruc.dk/~keld/research/COROUTINE/COROUTINE-1.0/DOC/COROUTINE_REPORT.pdf" target="_blank" rel="external">A Portable C++ Library for Coroutine Sequencing</a>比较的好，后面仔细研究一下，希望能把这个小项目做地不断完善健壮起来。<br>　　协程的工作实际就是达到基于事件的异步开发效果，但是相比传统的异步开发，因为每个协程都要一个协程栈，所以对内存的要求会多一些；还有就是，用协程开发的程序，线下虽然可以通过不链接协程库采用阻塞的方式进行调试，但是线上遇到问题，协程库程序问题的跟踪调试估计会比较棘手。<br>　　通过main.c中的代码写了个简易的http response服务端，启动了11个线程，然后accept得到的客户端轮询分发的方式，使用-c 30的seige压了一下，发现并发量还不到20 trans/sec。发现自己写过的服务端用这种方式测试性能从来都没有过百的，而同样的方式测试Nginx也是只有几十的响应并发量，对网上那些库单机成千上万的请求量真是望洋兴叹了，是我哪里的姿势不对么？</p>
<p>更新 20161122：<br>　　根据libco的思路，添加了一些系统调用的hook，同时修复了调度BUG，再通过增加siege测试的并发请求数目，吞吐量涨了一些了哦，但是这个协程库的最大并发量还没有去探测。经过大致的测试，跟预想的一样，其性能跟异步模式下的多线程还是有一些差距的(也有可能我本身的调度和切换有问题)。<br><img src="/post_images/images/201611/504374a23605e708dc62eb5e915102bf.png" alt="libto"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/yyzybb537/libgo" target="_blank" rel="external">libgo</a></li>
<li><a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a></li>
<li><a href="https://www.owent.net/" target="_blank" rel="external">I’m OWenT</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（二）：Paxos算法介绍]]></title>
      <url>https://taozj.org/201611/learn-note-of-distributed-system-(2)-paxos-algorithm.html</url>
      <content type="html"><![CDATA[<p>　　Paxos算法是一种基于消息传递通信模型的分布式系统中，使得各节点就某个值达成一致的问题的算法，其既可以工作在单机的多个进程上面，也可以工作在网络上面的多个主机上面。Paxos协议假定各个节点之间的通信采用异步的方式，且基于非拜占庭模型，也就是允许消息的延迟、丢失或者重复，但是不会出现内容损坏、篡改的情况，在实践中通过添加额外的校验信息很容易保证收到的消息是完整的。<br>　　在Paxos算法中主要有以下几种角色：Client、Acceptor、Proposer、Learner。由于本文是直接从<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>开始学习研究的，其已经是一个被优化过的所谓Multi-Paxos算法，允许指令预取提交，算是针对原始Basic-Paxos的一种改进模型了，通常会借助选举算法在多个Proposer和Learnner中选取出Leader，后面涉及的时候再讨论。<br>　　a. <strong>Client</strong>：主要是向分布式系统发送请求，并等待分布式系统的响应，虽然实现的时候也有跟Proposer联系在一起的，但是通常不建议这么做；<br>　　b. <strong>Acceptor</strong>(Voters)：被组织成投标团体，对Proposer提出的决议Prepare/Accept进行表决；<br>　　c. <strong>Proposer</strong>：起到客户代理的作用，请求Acceptor批准客户的请求，同时当发生冲突的时候起着协调者的作用，增加提案号重新请求；<br>　　d. <strong>Learner</strong>：学习已经被Chosen通过的提案，大部分起到replication备份的作用，当客户的请求被批准后，采取相应的行为动作，如果其想要知道某提案是否被通过，比如遗漏了某个命令的决案消息，也可以主动(向Acceptor)发起查询；</p>
<h1 id="一、Paxos算法原理">一、Paxos算法原理</h1><p>　　Paxos算法中根据Client的请求，由Proposer发起提案，其中每个提案都有一个全局唯一的数字编号来进行标识，这个编号由外部组件负责生成并且不断地递增，所以在Paxos中每个提案应该是以[提案编号, Value]的组合形式来表示。在Multi-Paxos中每个instance之间是完全独立的，所以不要求这些instance提案编号是相互不同的，而且在一些实现中会同时发送[instance_id, 提案编号, value]的，下文仅考虑一个instance中的Basic-Paxos算法的过程。<br>　　下面的描述中，对于每个节点，假设[n_a, n_value]是已经被accept的提案编号及其值，n_h表示Acceptor已经遇到并处理过的最大提案编号，n_my表示Proposer当前使用的提案编号：<br>　　(1). <strong>阶段一：Prepare阶段</strong><br><img src="/post_images/images/201611/405ea0de21228fe51ad392742b75d23e.jpg" alt="Paxos-Prepare"><br>　　a. Proposer选择一个提案编号n_my&gt;n_h，然后向某个多数派Acceptor所组成的集合发送请求<prepare, n_my="">，要求该集合中的Acceptor作出回应；<br>　　b. 当Acceptor收到<prepare, n="">这个消息后，如果发现n_my<n_h小于已经看到响应过的提案编号，则直接拒绝返回<prepare-reject>，否则n_h=n，同时返回已经被accept的值<prep-ok, n_a,="" n_value="">，同时该Proposer不会再响应小于n_h(n)的提案了；<a id="more"></a><br>　　(2). <strong>阶段二：Accept阶段</strong><br><img src="/post_images/images/201611/51580dde724fea031c4627b36b71e779.jpg" alt="Paxos-Accept"><br>　　a. 如果Proposer没有接收到绝大多数的<prep-ok>回应，则延时后重试，采用更大的提案编号；否则<br>　　b. 如果Proposer接收到大部分Acceptor的<prep-ok>回应，那么查看前面<prep-ok>的返回消息，如果之前所有回复的Acceptor都还没有accept任何值(当V=null时)，Proposer可以自己选择任何的V值(当然不会乱选啦，就是原先提案值)，否则V设置为所有<prep-ok, n_a,="" n_value="">中最大n_a对应的n_value，然后返回<accept, n_my,="" v="">给所有的节点；<br>　　c. 当被发送的Acceptor节点接受到<accept, n,="" v="">的时候，如果n<n_h，则回复<accept-reject>，否则更新n_a=n, n_value=V, n_h=n，同时返回<accept-ok>；<br>　　(3). <strong>阶段三：Decide阶段</strong>(Learner获取提案)<br><img src="/post_images/images/201611/b80428b6fb42b4b06944a2f4217c97e0.jpg" alt="Paxos-Decide"><br>　　a. 如果Learner从绝大多数Acceptor节点获得<accept-ok>，则发送<decide, n_value="">给所有Learner学习；否则<br>　　b. 如果Learner没能获得绝大多数Acceptor的<accept-ok>，则放弃；<br>　　Learner获取一个已经被Chosen选定提案的前提，是这个提案被大多数的Acceptor通过发送<acceptor-ok>所批准。最简单的方式是所有的Acceptor将所有的<acceptor-ok>回复消息发送给所有的Learner，那么通信的数量将会是Acceptor和Leaner数量相乘；优化方法之一是选取一个主Learner，主Leaner得知提案被通过后，再将结果送达给其他Learner，但是这样会引入单点故障的问题；还可以选择一个小范围的Learner集合，这里面的Learner直接接收Acceptor的Chosen消息，然后将结果转达给其他的Learner。当然这里也是假定非拜占庭模型，Learner传播给其他Learner的Chosen Value是可信完整的。<br>　　实现上为了可能崩溃或者失效后处理，所有Acceptor在发送响应前必须持久化存储该响应，每一次Paxos结算至少要记录propose、promise、<br>accept、acknowledgment、commit五类消息，而且为了可靠性必须快速刷新到磁盘上面。</acceptor-ok></acceptor-ok></accept-ok></decide,></accept-ok></accept-ok></n_h，则回复<accept-reject></accept,></accept,></prep-ok,></prep-ok></prep-ok></prep-ok></prep-ok,></n_h小于已经看到响应过的提案编号，则直接拒绝返回<prepare-reject></prepare,></prepare,></p>
<h1 id="二、Multi-Paxos">二、Multi-Paxos</h1><p>　　虽然最初Lamport爷爷富具幽默感的Basic-Paxos没有拜读过，但是从网上资料以及<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>的Multi-Paxos也得知之前Basic-Paxos在工程化中会有一些固有的问题。其实<a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">《Paxos Made Simple》</a>中的各种优化，算是已经为工程实现提供了较多的预备和考量了。<br>　　Basic-Paxos中所有的Proposer都可以发布提案，用后面的话来说就是所有的Proposer都认为自己是Leader，那么可能出现的问题就是产生活锁——当多个Proposer的提案被否决后，都增加自己的提案编号再次尝试，最终导致的结果就是循环僵持下去而没有任何的提案被Chosen。Multi-Paxos的解决方式是在稳定的状态下，只有唯一的Proposer Leader，因为只有这个Leader能够发起Prepare增加提案值，所以正常情况下他的提案总能够被接受和选择，那么Phase-I的Prepare阶段就可以被省略优化了(同时也省略了prepare、promise日志写盘操作)。而且，Paxos的算法保证可以在短时间(比如选举Leader)的情况下，允许有多少个Leader同时存在，此时退化到Basic-Paxos算法了，但是算法的正确性不会被破坏。<br>　　实现中可以把Proposer、Acceptor、Learner看成整体的Server端，而且文章中也是将他们和StateMachine融合在一个进程中去，Client向Server端发送请求以组成C/S模型架构。因为单Server端是不可靠的，所以通常会部署多个Server端，只要给这些Server端以相同的序列输入，那么根据决定状态机他们的输出肯定是相同的，所以Client可以使用任意一个Server的输出作为结果，而这里需要保证的，就是这多个Server执行输入状态机命令的顺序是相同的。<br>　　上面的说法还是比较的抽象，可以使用PhxPaxos的一张图来表明：<br><img src="/post_images/images/201611/8665a65ad07bb54f5380d53ed6bb3b62.jpg" alt="Paxos-Instance"><br>　　为了保证所有的机器(以Node来称呼)都以相同的顺序执行状态机命令，多个Node定义为网络进程，可以在一台物理主机上也可以分布在多台机器上，以IP:Port标识，我们定义顺序连续编号的Instance代表一个状态机命令(同时也就是对应一个Client请求)以用来确定一个Value，每个Instance都由单个Proposer、Accetpor、Learner和StateMachine组成，当我们假定Node的组成是固定的，那么所有Node上面相同编号的Instance的角色将组合成一个集合被Paxos算法所使用。每个编号的Instance负责确定相应编号的值，顺利的情况下可能一次提案就能通过，也有可能被否决后， Proposer增加提案号多次操作才被接收选定。上图的Paxos group是按照业务逻辑进行划分的，跟实现原理没有关系，当我们关注每一个单独的Paxos group，里面都是一个完整的Multi-Paxos的实例。对于Node A/B/C通常会产生一个Leader Proposer负责代理Client的请求提出议案，然后Node A/B/C的所有Acceptor组成Quorums负责投票表决，最后Learner整理表决的结果得到Chosen Value。<br>　　同时，每个单独编号的Instance之间是完全隔离的，他们单独执行互不干涉，也正是因为如此，Multi-Paxos使得多个Instance并行执行成为了可能。实际上在Lamport爷爷文章中也提到了，Leader可以预取r个命令——也就是说，在命令1到i被选择Chosen之后，它就可以同步提出命令i+1,…, i+r，这些命令有些可能会执行失败，正常情况下该instance的Proposer会重新提启动预案再次尝试，但是此时如果Leader挂掉之后，就在命令序列中留下一些间隔(gap)，新Leader会为这些gap重新执行Phase-I操作以便去获取其Chosen Value。但是后面说到节点使用不改变状态机状态的”no-op”命令占用这些间隔，然后继续执行，那么占用这些命令号原先的指令怎么办呢？丢弃？<br>　　PS：上面这个问题，刚才跟PhyPaxos的作者沟通过，至少在他们PhxPaxos里面，Chosen Value可以是并行的，但是状态机转移是完全序列化的，也就是当出现gap的时候状态机无法转移，所以才需要填充no-op指令让状态机跳过这些Instance Number然后执行下去。按照我的理解，Chosen Value可以在预取窗口中并行执行，而且Value以任意顺序被Chosen出来，但是commit使得状态机转移必须是严格串行化的，查看Paxos Made Live中，状态转移就是过各个Node执行callback函数，而这个过程是被严格序列化的，并且通常真正的业务变更和执行操作也是体现在callback中的。或许上面no-op占用命令就是通过某种机制告知客户端该命令执行失败了吧，猜的别打我！<br>　　前面说到开始打算从PhxPaxos入手了解Paxos机制的，但是后续发现Phxteam还是对Paxos做了一些的更改，因为纯粹的Paxos太过于理论，原版的协议是不可能直接拿来工程应用就达到可用性和可靠性的需求的，往往工程化的过程中会这里改改那里改改的，最终发现已经不是原版协议了，到头来改造成的协议其正确性也难以得到证明了。对于Paxos的实现，可以查阅Marco Primi的硕士论文《Paxos made code - Implementing a high throughput Atomic Broadcast》，这篇论文对Paxos算法进行了通俗的阐述，其合作者Daniele Sciascia将其中的LibPaxos库进行了开源，采用C语言实现并配备sample，虽然距离线上使用可能还有所欠缺，但是整个代码结构思路清晰、通俗易懂，本来想写篇文章说说它的，但是实现的真是太直白了，提笔后发现也没啥好写的了。<br>　　还有，学术级别的论文《Paxos Made Live》虽不够详细，但总结的也是工程实践中的精华，如果作者能开源其实现就棒极了！</p>
<h1 id="三、后言">三、后言</h1><p>　　在工程上得到验证的分布式协议并不多，2PC在数据库中使用较多，但是现在分布式系统肯定不是2PC、3PC协议所能解决的。Paxos算法的出现就是要异步、去中心化，通过陪审团民主选取的方式来确定一个值。无论是Multi-Paxos极其改进的ZAB、Raft现在是红的发紫(还有个Viewstamped Replication是什么鬼)，但归根结底其本质还是Paxos，只是在某些情况下增加了一些限制以便于工程化实现，因为Paxos本身过于的理论，实现起来确实是“reliable implementation proves to be nontrivial”！<br>　　关于ZAB和Raft，自己还了解的不太多。据说他们是限制命令提交是严格序列化的，当某一个命令没有被提交后后续的命令都全部阻塞在内存里面，所以性能和Multi-Paxos相比是他们被诟病的槽点，不过其设计思路后续还是可以了解借鉴的，尤其是Raft作者Diego Ongaro洋洋洒洒两百多页的PhD论文和算法伪代码的表述，大大增加了工程化的便捷性。<br>　　“Paxos只是个协议，用于在分布式环境下确定一个值”，现在念起来意味深长。Paxos的实现也只是在分布式系统中作为基础服务，然后构建上层的分布式存储、分布式数据库、分布式日志等服务还需要跟具体的业务相关联，分布式日志系统好理解，而将数据库的binlong作为分布式对象就可以得到分布式数据库了，当然分布式存储还不知道什么原理，因为目前的论文看来Paxos无法进行大尺寸文件的传输，期待PaxosStore早日开源吧！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf" target="_blank" rel="external">Paxos Made Simple</a></li>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/wiki" target="_blank" rel="external">phxpaxos wiki</a></li>
<li><a href="http://www.tudou.com/programs/view/e8zM8dAL6hM/" target="_blank" rel="external">paxos和分布式系统</a></li>
<li><a href="http://coolshell.cn/articles/10910.html" target="_blank" rel="external">分布式系统的事务处理</a></li>
<li><a href="https://en.wikipedia.org/wiki/Paxos_(computer_science" target="_blank" rel="external">wikipedia Paxos</a>)</li>
<li><a href="https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95" target="_blank" rel="external">Paxos算法</a></li>
<li><a href="https://www.ece.cmu.edu/~ece845/docs/paxos-govindan-2012.pdf" target="_blank" rel="external">Paxos, Agreement, Consensus</a></li>
<li><a href="http://blog.csdn.net/sparkliang/article/details/5740882" target="_blank" rel="external">Paxos Made Simple【翻译】</a></li>
<li><a href="http://www.inf.usi.ch/faculty/pedone/MScThesis/marco.pdf" target="_blank" rel="external">Paxos made code</a></li>
<li><a href="https://www.cs.utexas.edu/users/lorenzo/corsi/cs380d/papers/paper2-1.pdf" target="_blank" rel="external">Paxos Made Live - An Engineering Perspective</a></li>
<li><a href="https://timyang.net/distributed/paxos-scenarios/" target="_blank" rel="external">Paxos在大型系统中常见的应用场景</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[分布式系统入门笔记（一）：分布式系统基本概念和两三阶段提交]]></title>
      <url>https://taozj.org/201611/learn-note-of-distributed-system-(1)-abstraction-and-2PC-3PC.html</url>
      <content type="html"><![CDATA[<p>　　现在觉得分布式系统比较的有意思，不是说这个概念流行时髦可以装逼，而是像Lamport爷爷在其论文中所描述的那样，分布式系统更像是一个场景，一个民主性团体协作的过程。在这个分布式的群体中，任何一个角色都有自己的行为，都可能出错，都可能无法跟别人通信，都有可能网络分区“脑裂”，也都有可能会死掉，分布式系统让我们的眼界从原先的单个人，扩展到一个社会团体了。<br>　　大名鼎鼎的分布式锁Google Chubby的作者Mike Burrows说过：“这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次品！”Paxos在当前的生产环境中获的了巨大的成功，或许真的学了他就不用学别的分布式协议了，不过整个分布式系统中的概念、观念和涉及到的问题还是要了解一下的。<br>　　同时，后续Paxos的学习打算从微信团队的PhxPaxos入手，主要考虑到的是：他们声称基于Paxos Made Simple进行工程化，不进行任何算法变种，所以代码学习研究会比较的原汁原味；资料比较多比较详细，偶尔还会有相关更新资料放出；通过微信的生产环境进行验证，说明比较肯定稳定、可靠和高效；其实后面看了写些Google Chubby信息，感觉PhxPaxos工程实现中遇到的问题和解决的思路跟Chubby大部分比较相似，所以这些共性的东西跟谁学都没有太大的差异。</p>
<h1 id="一、基础预备知识">一、基础预备知识</h1><h2 id="1-1_事务极其ACID特性">1.1 事务极其ACID特性</h2><p>　　分布式系统中的事务(Transaction)是对系统中数据进行访问和更新操作所组成的程序执行逻辑单元，事务的应当具有四个特征ACID：原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability)。<br>　　原子性保证事务是一个不可分割的单位，事务中的操作要么全部成功执行，要么都不执行；一致性保证数据库中只能包含成功的事务提交的结果，从一个成功状态变更到另外一个成功状态；隔离性用于控制并发环境中事务之间的干扰关联程度；持久性一般是数据落盘，在提交后其修改应该是永久的，在宕机或者重启后数据能重新被恢复到成功结束的状态。<br>　　对于隔离性，标准SQL规范中定义了四种事务隔离级别：<br>　　(1). <strong>未授权读取</strong>：也称为读未提交(Read Uncommitted)，该隔离允许脏读，可以读到别的事务执行中任何可能的未提交中间状态，事务可以读取未提交的数据，这也被称为脏读。未提交读从性能上不会比其他级别好太多，但是缺乏其他级别的很多好处，在实际应用中一般很少使用；<br>　　(2). <strong>授权读取</strong>：也称为读已提交(Read Committed)，一个事务开始时只能“看见”已经提交的事务所做的修改，授权读取允许不可重复读取，因为两次执行同样的查询，可能会得到不一样的结果。这是除MySQL之外大多数数据库(SQL Server, Oracle)的默认隔离级别；<br>　　(3). <strong>可重复读取</strong>：(Repeatable Read)保证在一个事务处理的过程中如果多次读取同一个数据时，其值都跟事务开始时候是一致的，该事务级别禁止了不可重复读和脏读，但是可能会出现幻读(Phantom Read)。不可重复读和幻读还是有一定差异的，一般前者是update修改数据体现的差异，后者是在insert、delete时候体现出来的差异，比如范围查询的记录数在别的事务插入或者删除记录的时候会变得不一致；<br>　　(4). <strong>串行化</strong>：(Serializable)最高的隔离级别，其要求所有的事务都串行化执行，可以避免幻读问题。其会极大影响数据库的并发性能。</p>
<h2 id="1-2_CAP理论和BASE理论">1.2 CAP理论和BASE理论</h2><h3 id="1-2-1_CAP理论(布鲁尔定理)">1.2.1 CAP理论(布鲁尔定理)</h3><p>　　一个分布式系统不可能同时满足一致性(Consistency)、可用性(Availability)和分区容错性(Partition tolerance)这三个基本要求，最多只能同时满足其中的两项。<br>　　(1). <strong>一致性</strong>：指的在分布式环境下数据在多个副本之间是否能够保持一致性，如果针对数据项的更改操作执行成功后，所有的用户都可以读到其最新值，那么这个系统被认为是强一致性的。<br>　　(2). <strong>可用性</strong>：对于用户的每一个操作请求，都能够在有限的时间内返回结果。<br>　　(3). <strong>分区容错性</strong>(容忍网络分区)：分布式系统在遇到任何网络分区故    障的时候，仍然能够保证对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障。<br>　　对于CAP理论的实践中，既然是分布式系统肯定要满足P，所以很多分布式系统的架构设计通常是根据业务类型是在A可用性和C一致性上面做出平衡的结果，这里的C一致性不是说放弃一致性，因为放弃一致性数据错误了整个系统就没有意义了，而是说放弃实时的强一致性，但是保证数据的最终一致性，需要到达最终一致性需要一个时间窗口，用于各个数据副本之间同步。<a id="more"></a></p>
<h3 id="1-2-2_BASE理论">1.2.2 BASE理论</h3><p>　　BASE理论是CAP中一致性和可用性互相权衡的结果，代表着：Basically Available(基本可用)、Soft State(软状态)、Eventually Consistent(最终一致性)，表明分布式系统即使无法做到强一致性，但是每个应用都可以根据业务的特点，采用适当的方式来使系统达到最终一致性。<br>　　(1). <strong>基本可用</strong>(Basically Availble)：当出现不可预知的故障的时候，允许在响应时间、或者功能上有所损失，核心功能仍然可用；<br>　　(2). <strong>弱状态</strong>(Weak State)：也称为软状态，指的允许系统中的数据存在中间状态，并认为该中间状态不会影响到系统整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时；<br>　　(3). <strong>最终一致性</strong>(Eventual Consistency)：强调系统中所有的数据副本，在经过一段时间的同步之后，最终总能够达到一个一致性的状态，其不需要实时保证系统数据的强一致性；在工程实践中最终一致性存在以下变种，他们可以按照需要自由组合搭配，以设计实现出最终一致性的分布式系统：<br>　　a. <strong>因果一致性</strong>(Causal Consistency)：如果进程A在更新完某个数据项之后通知了进程B，那么进程B之后对数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B对数据项进行更新的话，也是基于A更新后的最新值，不会发生丢失更新的状况。此外，与进程A无因果关系的进程C访问该数据没有任何限制；<br>　　b. <strong>读己之所写</strong>(Read Your Writes)：进程A更新一个数据项之后，它自己总能够访问到更新后的最新值；<br>　　c. <strong>会话一致性</strong>(Session Consistency)：会话一致性将对系统数据的访问框定在一个会话当中，系统能够保证在同一个有效的会话中实现“读己之所写”的一致性，执行更新操作之后客户端能够在同一个会话中始终读到该数据项的最新值；<br>　　d. <strong>单调读一致性</strong>(Monotonic Read Consistency)：如果进程从系统中读出一个数据项的某个值之后，那么系统对于该进程后续的任何数据操作都不应该返回更旧的值；<br>　　e. <strong>单调写一致性</strong>(Monotonic Write Consistency)：一个系统需要能够保证来自同一个进程的写操作都是被顺序执行的。</p>
<h1 id="二、两阶段提交">二、两阶段提交</h1><p>　　分布式系统中最经典的就是二阶段提交协议、三阶段提交协议和Paxos算法了。设计出这些协议的主要原因，就是在分布式系统中，每个节点可以知道自己在事务操作的过程中是成功还是失败，但是无法知道其他分布式节点的操作结果。传统上就是产生一个协调者Coordinator来统一调度各个分布式节点的执行逻辑，其负责调度参与者的行为，并决定这些参与者是否要把事务进行提交。<br>　　目前大部分的<a href="https://docs.oracle.com/cd/B28359_01/server.111/b28310/ds_txns003.htm#ADMIN12222" target="_blank" rel="external">数据库</a>都是采用二阶段提交协议来完成分布式事务处理的。</p>
<h2 id="2-1_事务执行过程">2.1 事务执行过程</h2><h3 id="2-1-1_阶段一：提交事务请求(Commit_request)">2.1.1 阶段一：提交事务请求(Commit request)</h3><p>　　(1). <strong>事务询问</strong>：协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待所有参与者的回应；<br>　　(2). <strong>执行事务</strong>：各参与者执行事务操作直到可以提交的点后暂停，并将Undo和Redo信息记入事务日志中；<br>　　(3). <strong>各参与者向协调者反馈事务询问的结果</strong>：如果参与者成功执行了事务操作，则反馈给协调者YES响应，表示事务可以执行，如果参与者没有成功执行事务，那么反馈给协调者NO响应，表示事务不可以执行；</p>
<h3 id="2-1-2_阶段二：执行事务提交(Commit_phase)">2.1.2 阶段二：执行事务提交(Commit phase)</h3><p>　　协调者会根据参与者反馈的情况来决定最终是否可以执行事务提交操作，正常情况包括如下两种情况：<br>　　(1). <strong>执行事务提交</strong>：假如协调者从所有的参与者获得的反馈都是YES响应<br>　　a. <strong>发送提交请求</strong>；协调者向所有参与者发出Commit信息；<br>　　b. <strong>事务提交</strong>：参与者收到Commit请求后，会正式执行事务提交操作，并在完成提交后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务提交结果</strong>：参与者在完成事务提交之后，向协调者发送Ack消息；<br>　　d. <strong>完成事务</strong>：协调者收到所有Ack消息后，完成事务。<br>　　(2). <strong>中断事务</strong>：任何一个参与者向协调者反馈了NO响应，或者在等待超时之后，协调者尚无接收到所有参与者的反馈响应，那么就会中断事务<br>　　a. <strong>发送回滚请求</strong>：协调者向所有参与者节点发送Rollback请求；<br>　　b. <strong>事务回滚</strong>：参与者收到Rollback请求后，会利用在阶段一种记录的Undo日志信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用锁和其他事务资源；<br>　　c. <strong>反馈事务回滚结果</strong>：参与者在完成事务回滚之后，向协调者发送Ack消息；<br>　　d. <strong>中断事务</strong>：协调者收到所有参与者反馈的Ack消息后，完成事务中断；</p>
<h2 id="2-2_2PC的优缺点">2.2 2PC的优缺点</h2><p>　　(1). <strong>优点</strong>：原理简单、实现方便，而且是强一致性算法。<br>　　(2). <strong>缺点</strong>：同步阻塞、单点问题、脑裂、太过保守。<br>　　a. <strong>同步阻塞</strong>：最严重的问题，会极大限制分布式系统的性能，当参与者向协调者发送投票信息后，必须阻塞等待直到收到commit/rollback命令；<br>　　b. <strong>单点问题</strong>：一旦协调者出现问题，整个2PC都无法运转，而且如果协调者是在阶段二中出现问题的话，那么其他参与者将会一直处于锁定事务资源的状态当中；<br>　　c. <strong>数据不一致</strong>：当协调者向所有参与者发送Commit请求后如果部分协调者因为问题没有执行Commit，那么就会使得整个分布式系统出现数据不一致的情况；<br>　　d. <strong>太过保守</strong>：没有完善的容错机制，任意一个参与者节点的问题都会导致整个事务的失败；</p>
<h1 id="三、三阶段提交">三、三阶段提交</h1><p>　　将原先的事务拆分成canCommit、preCommit 和DoCommit三个阶段组成。</p>
<h2 id="3-1_事务执行过程">3.1 事务执行过程</h2><p><img src="/post_images/images/201611/f2f443bf6560482a3a4dd3eeb002bedb.png" alt="3PC"></p>
<h3 id="3-1-1_阶段一：CanCommit">3.1.1 阶段一：CanCommit</h3><p>　　(1). <strong>事务询问</strong>：协调者向所有的参与者发送一个包含事务内容的canCommit请求，询问是否可以执行事务的提交操作，并开始等待各参与者的响应；<br>　　(2). <strong>各参与者向协调者反馈事务询问的响应</strong>：参与者收到canCommit请求后，正常情况下如果其自身认为可以顺利执行事务，则反馈给协调者YES响应，并进入预备状态，否则反馈给协调者NO响应；</p>
<h3 id="3-1-2_阶段二：PreCommit">3.1.2 阶段二：PreCommit</h3><p>　　协调者会根据各参与者的反馈情况决定是否可以执行事务的preCommit操作，正常情况下，可能包含两种情况<br>　　(1). <strong>执行事务提交</strong>：协调者从所有的参与者获得的反馈都是YES响应<br>　　a. <strong>发送预提交请求</strong>：协调向所有参与者节点发出preCommit请求，并进入Prepared阶段；<br>　　b. <strong>事务预提交</strong>：参与者收到preCommit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中；<br>　　c. <strong>各参与者向协调者反馈事务执行的响应</strong>：如果参与者成功执行了事务操纵，那么就反馈协调者ACK响应，同时等待最终指令：Commit或者Abort；<br>　　(2). <strong>中断事务</strong>：任何一个参与者反馈了NO响应，或者在等待超时之后，协调者尚不能收到所有参与者的反馈响应，就会中断事务<br>　　a. <strong>发送中断请求</strong>：协调者向所有参与者发出Abort请求；<br>　　b. <strong>中断事务</strong>：无论收到来自协调者的Abort请求，或者在等待协调者请求过程中出现超时，参与者都会中断事务；</p>
<h3 id="3-1-3_阶段三：doCommit">3.1.3 阶段三：doCommit</h3><p>　　该阶段是真正的事务提交，有两种情况<br>　　(1). <strong>执行提交</strong>：<br>　　a. <strong>发送提交请求</strong>：假设协调者处于正常状态，并且收到了来自所有参与者的ACK响应，那么它将从预提交状态切换到提交状态，并向所有的参与者发送doCommit请求；<br>　　b. <strong>事务提交</strong>：参与者收到doCommit请求之后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务提交结果</strong>：参与者完成事务提交之后，向协调者发送ACK消息；<br>　　d. <strong>完成事务</strong>：协调者收到所有参与者Ack消息后，事务结束。<br>　　(2). <strong>中断事务</strong>：假设协调者处于正常工作状态，并且有任意一个参与者向协调者发送了NO响应，或者在等待超时之后协调和尚无法收到所有参与者的反馈响应，那么就会中断事务<br>　　a. <strong>发送中断请求</strong>：协调者向所有参与者发送Abort请求；<br>　　b. <strong>事务回滚</strong>：参与者接收到Abort请求后，会利用其在阶段二中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的锁和其他事务资源；<br>　　c. <strong>反馈事务回滚结果</strong>：参与者在事务回滚之后，向协调者发送Ack信息；<br>　　d. <strong>中断事务</strong>：协调者收到所有参与者反馈的Ack消息后，中断事务。<br>　　需要注意的是，一旦进入阶段三，可能会出现两种故障：协调者故障或者协调者和参与者之间的网络通信出现故障，无论如何都会导致参与者无法及时收到来自协调者的doCommit或Abort请求，针对这种情况，只要参与者收到了preCommit命令，在参与者在等待超时之后如果还没有收到协调者的指令，会默认继续进行事务提交。</p>
<h2 id="3-2_3PC的优缺点">3.2 3PC的优缺点</h2><p>　　3PC的针对2PC的主要优化有：事先不申请资源的情况下进行preCommit演练，此处成功后续事务成功执行的可能性也会比较大；3PC是非阻塞的协议，在第三阶段如果参与者在时间窗口之内没有收到协调者的命令，会默认进行提交；<br>　　(1). <strong>优点</strong>：降低了参与者的阻塞范围，能够在出现单点故障后继续达成一致；<br>　　(2). <strong>缺点</strong>：在解决2PC的阻塞问题时候引入了新的问题，就是在参与者收到preCommit之后如果网络出现分化，此时协调者所在的节点和参与者无法进行正常的网络通信，此时参与者依然会进行事务的提交，很有可能会出现数据不一致的情况。同时3PC需要进行三次的消息传递，性能会有所影响。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26292004/" target="_blank" rel="external">从Paxos到Zookeeper:分布式一致性原理与实践</a></li>
<li><a href="https://github.com/tencent-wechat/phxpaxos/wiki" target="_blank" rel="external">phxpaxos wiki</a></li>
<li><a href="http://www.cnblogs.com/arccosxy/p/3986115.html" target="_blank" rel="external">数据库高分笔记02：隔离级别</a></li>
<li><a href="http://coolshell.cn/articles/10910.html" target="_blank" rel="external">分布式系统的事务处理</a></li>
<li><a href="https://docs.oracle.com/cd/B28359_01/server.111/b28310/ds_txns003.htm#ADMIN12222" target="_blank" rel="external">Two-Phase Commit Mechanism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol" target="_blank" rel="external">Two-phase_commit_protocol</a></li>
<li><a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol" target="_blank" rel="external">Three-phase_commit_protocol</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[浅谈多进程程序的进程控制和管理方式]]></title>
      <url>https://taozj.org/201611/about-multi-process-thread-dev-manage.html</url>
      <content type="html"><![CDATA[<p>　　多线程程序、多进程程序是当前单机应用常用并行化的手段，线程是可以直接被CPU调度的执行单元，虽然多进程程序中每个进程也可以是多线程的，但是本文主要讨论的多进程程序默认是每个进程都有一个单独线程的情况。多线程程序和多进程程序，涉及到的线程间和进程间的通信、同步原语基本都是相同的，所以两者的开发在一定程度上有着高度的相似性，但同时差异化也十分的明显，所以高性能程序使用多线程还是多进程实现常常也是争论的焦点。<br>　　虽然自己之前开发的程序基本都是基于pthreads和C++ std::thread的多线程程序，但是多进程程序还是有它相应的用武之地的，比如大名鼎鼎的Nginx中master和worker机制就是采用多进程的方式实现的，所以这里也对多进程和多线程程序的区别联系整理一下，最后顺便看看Nginx中master和worker进程的管理和实现机制，在后续开发多进程程序的时候可以直接借鉴使用。</p>
<h1 id="一、多线程和多进程程序">一、多线程和多进程程序</h1><p>　　Linux中有一句耳熟能详的话——线程被认为是轻量级的进程，在现代操作系统的概念中，进程被认为是资源管理的最小单元，而线程被认为是程序执行的最小单元，所以多线程和多进程之间的差异基本体现在执行单元之间对资源耦合度的差异。虽然对于用户空间而言，最为广为使用的pthreads线程库提供了自己一套线程创建和管理、线程间同步接口，其实在Linux下面创线程和创建进程都是使用clone()系统调用实现的，只是在调用参数(flags)上不同，导致创建的执行单元具有不一样的资源共享情况，从而造就了线程和进程实质上的差异。<br><img src="/post_images/images/201611/22fcba011a0b363f047b1d5cc28e75f9.jpg" alt="线程和进程"></p>
<h2 id="1-1_多线程的特点_multi-threaded">1.1 多线程的特点 multi-threaded</h2><p>　　从上面的图中看出，同一个进程中的多个线程，跟执行状态相关的资源都是独立的，比如：运行栈、优先级、程序计数器、信号掩码等都是独立的，而打开的文件描述符(包含套接字)、地址空间(除了函数中的自动变量属于栈管理，还有新提出来的线程局部变量，其它基本都是共享的)都是共享的。这里还设计到信号处理句柄、信号掩码等，因为在多线程中信号的问题比较的复杂，后面单独列出来解释。<br>　　共享相同的地址空间、文件描述符给程序的开发带来了极大的便利，创建多线程的开销要小的多，而且在运行中任务切换损失也很小，很多的缓存都维持有效的，还有比如负责套接字listen的线程和工作线程之间可以方便的传递网络连接创建的套接字，生产线程和消费线程可以方便的用队列进行数据交换，程序设计也可以特化出日志记录、数据落盘等工作线程各司其职。但是天下没有免费的午餐，任何的便利都是需要付出代价的，多个执行单元可以访问资源意味着共享资源必须得到保护和同步，这是多线程程序设计不可回避的问题：<br>　　(1). 多个线程可以安全的访问只读的资源，但是哪怕只有一个修改者也是不安全的，额外说一句，我们说的保护是保护的资源，而不是行为；<br>　　(2). 传统很多库函数都不是线程安全的，这些函数当初设计的时候没有考虑到多线程的问题，所以使用了大量的全局变量和静态局部变量，这些函数是不可重入的。所以在你调用库函数、链接别人库的时候，一定要看看有没有”_r”后缀的版本；<br>　　(3). 还要就是之前不断被提到的内存模型，因为同个进程中的多个线程可能会并行的执行，这时候如果在线程之间有高速度的数据同步需求的时候，必须让资源的更新能够及时地被别的线程感知到；<br>　　(4). 多线程程序正因为线程之间共享的资源太多，所以如果一个线程出现严重的问题，其余的线程也会被杀死。遥想当年在TP-LINK的时候，所有的服务功能都以线程的形式被包裹在一个用户进程中，某个模块出现问题都可能导致上不了网需要重启，所以现在看来稳定运行的TP-LINK路由器不得不说是一个奇迹~ <a id="more"></a></p>
<h2 id="1-2_多进程的特点_multi-process">1.2 多进程的特点 multi-process</h2><p>　　多进程程序之间保证了资源的高度隔离，只在创建出来的父子进程之间有少量的联系，进程组、回话等就不在此讨论了。<br>　　这个时候需要共享的资源必须显式共享，虽然操作系统优化机制可以让他们的只读数据(比如执行代码)物理上共享，进程间的资源共享或者通过关联到文件系统的某个路径或者文件，或者通过全局字符串名字方式，通过以某个进程首先创建资源，其他进程打开资源的方式共享。由于历史原因，Linux进程间通信通常包含SYS V和Posix两套接口，其种类和功能大同小异，但是个人的实际感受Posix的操作接口要更加的好用一些。<br>　　Linux进程间通信通常用到的方法有：匿名管道、命名管道、信号、消息队列、共享内存、信号量和套接字，其中匿名管道只用于有亲属关系的父子进程之间的一种单功通信方式，在fork()创建进程之前创建匿名管道。其中个人用的最多的是命名管道、共享内存和信号量：命名管道由于返回的文件描述符，可以十分方便的融合到现有的select/poll/epoll框架下面去；信号量主要用于模拟进程间互斥的行为；共享内存用于进程间大规模的数据共享。陈硕的一句名言就是“在多进程之间共享内存无异于掩耳盗铃”，其实多进程间通过共享内存的方式共享数据弊端和限制确实很多：首先共享内存中不能共享指针，而指向共享内存段本身的指针也最好用便宜的方式退化指针；如果共享内存的数据经常会被修改，那更是个灾难。当然简单只读数据是可以的，比如Nginx的缓存也使用了共享内存。<br>　　多进程程序的好处，就是消除了进程之间的耦合度后，操作系统的保护机制可以让多个进程更加的独立可靠，而且分成多个进程之后管理进程比管理线程方便灵活的多；同时，多进程程序可以实现进程的特异化管理，比如在Nginx设计中master process是特权进程，可以读取配置文件、修改数重要数据等关键操作，而worker process是普通权限进程，只负责业务方面的处理，符合系统管理中的最小化权限原则；再有就是多进程程序可以进行业务的热更新平滑升级，下面的Nginx算是将这一功能使用的淋漓尽致啊。<br>　　但是多进程的程序也有个问题，就是很多共享的资源、同步的手段都是命名全局的，很有可能进程意外退出后这些资源都得不到回收，补救的办法只能是重启操作系统，汗~</p>
<h2 id="1-3_多线程程序和信号">1.3 多线程程序和信号</h2><p>　　感觉信号一直是Linux平台下开发比较头疼的问题，尤其对于多线程情况下的程序，信号的处理将更加的复杂。</p>
<h3 id="1-3-1_单线程程序中信号的处理方式">1.3.1 单线程程序中信号的处理方式</h3><p>　　Linux中的信号的处理方式可以是SIG_IGN、SIG_DFL以及自己通过sigaction设置自定义处理函数，进程创建的时候信号都有默认的处理方式，而用户可以后续选择忽略、默认处理方式、自定义处理这些信号(SIGKILL、SIGSTOP两个信号只能默认处理方式，不能被忽略或者重定义处理)，当进程接收到信号的时候就会转向信号处理历程去执行。<br>　　信号可以在某些情况下被系统发送(比如触发段错误)，或者被别的进程使用kill发送，或者进程自己调用kill、raise系统调用触发信号。进程可以通过signal mask去block某些信号，默认情况下是没有信号被block的，此时如果被block的信号发送过来了，将会被设置为pending的，然后一旦该进程unblock了该信号，pending的信号将会立即被传递。</p>
<h3 id="1-3-2_pthreads库多线程环境对信号处理的方式">1.3.2 pthreads库多线程环境对信号处理的方式</h3><p>　　pthreads库多线程中信号处理的方式，和信号的种类、各个线程对信号的mask状态共同决定的。<br>　　Linux中多线程环境下信号的种类可以分为同步(Synchronously)信号和异步(Asynchronously)信号：同步信号是针对某个线程的，比如某个线程执行过程中除以零(SIGFPE)、访问非法地址(SIGSEGV)、使用了broken的管道(SIGPIPE)，这些信号都根某个特定的线程特定的执行上下文有关，还有就是同个进程中线程之间通过pthread_kill显式发送信号的情况；异步信号主要是其他进程向该进程通过kill向这个进程(而非其中的线程)发送信号，并不跟某个特定的线程相关联的情况。<br>　　pthreads库中多线程之间共享sigaction结构但是不共享sig_mask结构，这意味所有的线程共享相同的信号处理方式，而不论信号处理方式是谁设置的。进程在最初fork()后创建的第一个线程继承了其signal mask，而通过pthread_create创建的其他线程也继承了这个信号mask，后续可以通过pthread_sigmask接口控制本线程对某些信号的block或者unblock。<br>　　有了上面的知识，信号在多线程下的行为就可以被确定了：<br>　　(1). 所有的线程共享相同的sigaction，所以所有进程对某个信号的处理方式是完全相同的；<br>　　(2). 同步信号是针对某个特定线程的，该线程是否接收处理这个信号看其signal mask设置情况；<br>　　(3). 异步信号是针对这个进程的，当这种信号到达的时候，进程会从没有block这个信号的线程集合中随机选出一个出来处理这个信号，如果所有的线程都block该信号，那么这个信号将被pending起来，直到有线程unblock这个信号，就将其发送给那个线程处理。</p>
<h2 id="1-4_其他">1.4 其他</h2><p>　　由于在Linux下面创线程和创建进程是通过不同的参数使用clone()系统调用来实现的，Linux的线程本质上就是采用进程的方式实现的。在task_struct结构中就涉及到以下域：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">1592</span>         <span class="keyword">pid_t</span> pid;</div><div class="line"><span class="number">1593</span>         <span class="keyword">pid_t</span> tgid;</div></pre></td></tr></table></figure></p>
<p>　　pid是内核自己维护的进程号，tgid是用户空间可见的进程号，通过gettid()调用可以返回pid，而getpid()调用返回的是tgid。在clone()系统调用中，通过传递CLONE_THREAD参数，新进程的tgid会被设置成父进程的tgid，否则新进程的tgid会设为其自身的pid。<br>　　这就说明内核自己通过pid的方式，把用户看来的线程当作进程来管理；而同个进程的各个线程通过相同的tgid被逻辑上形成一个整体——线程组。</p>
<h1 id="二、master管理多个worker进程">二、master管理多个worker进程</h1><p>　　在Nginx的配置文件中有个条目worker_processes，其用于指定master进程可以产生几个worker进程，默认情况下是CPU执行单元的数目。在Linux下实验发现，当kill掉worker进程的时候，master进程会自动再次启动worker进程，但是当kill掉master进程的时候，worker进程仍然活着并向外提供服务，这种方式或许是对于常驻服务最好的处理语义：master进程存在的时候会保证设定数目的工作进程存在，而master进程挂掉的时候worker进程仍然继续服务，不会存在单点故障导致服务立即停止的情况。<br>　　其基本原理也很简单，这源于在Linux平台下，当子进程退出的时候，内核会向父进程发送SIGCHLD信号，父进程可以捕获这个信号，并通过wait系统调用搜集子进程退出的相关信息，此后子进程的资源会被相应的释放掉。因此，父进程可以通过接收信号的方式异步得到子进程退出的消息，并且适当安排创建工作者进程。<br>　　当然，这仅仅是一个小trick，探究一下，发现Nginx的设计中，尤其是多进程服务端程序的开发维护中，大有学问可以借鉴！同时还有一个跟Nginx关系十分密切，估计也是使用相同master-worker方式构建的多进程的构架的，那就是php-fpm。之所以说关系密切，就是因为Apache本身支持php的解析，而Nginx只能通过外挂的方式，而挂件最常见的恰巧就是php-fpm了，通过ps查看，其也像是master-worker的结构，不过没看代码尚且不敢断定。<br><img src="/post_images/images/201611/e1d0cda50c4a1d7c54969d6895805fa6.gif" alt="NginxExt"></p>
<h2 id="2-1_跟踪环境的配置">2.1 跟踪环境的配置</h2><p>　　不知道啥时候，自己都快成了代码控了，GitHub上面一些感兴趣的项目代码都会clone下来并不断pull跟踪，nginx就是其中之一啊。调试环境设置很简单，只是有些点需要额外注意一下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">root@srv:~/nginx<span class="comment"># apt-get install libpcre3-dev zlib1g-dev</span></div><div class="line">root@srv:~/nginx<span class="comment"># auto/configure --with-debug</span></div><div class="line">root@srv:~/nginx<span class="comment"># make</span></div></pre></td></tr></table></figure></p>
<p>　　上面configure的时候一定要添加–with-debug参数，这个时候可以让可执行程序支持生成debug的log信息，同时如果是MacOS的系统的话，还需要事先用homebrew安装gcc，然后添加–with-cc=/usr/local/bin/gcc-5指定使用gcc编译器(后面有时间说是要折腾一下Clang的，而苹果xcode默认就是用的这货)，不过MacOS底层用的是kqueue而不是epoll，你应该知道我要说什么；make编译之后会在objs目录下面生成nginx可执行程序<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@srv:~/nginx<span class="comment"># mkdir logs</span></div><div class="line">root@srv:~/nginx<span class="comment"># objs/nginx -p .</span></div></pre></td></tr></table></figure></p>
<p>　　通过-p参数，可以避免使用默认系统路径的权限问题，以及对现有环境的干扰。此时进程全部转到后台执行了，更要命的是IDE的调试环境此处被断开失连了，所以需要在nginx.c中将系统初始化过程的ngx_daemon()注释起来，就可以正常断点跟踪了。<br>　　到此，Nginx的调试跟踪环境设置完成，设置conf/nginx.conf中log级别error_log  logs/error.log  debug;然后通过tail -f logs/error.log所有运行调试日志尽收眼底。</p>
<h2 id="2-2_多进程服务端程序设计">2.2 多进程服务端程序设计</h2><p>　　通过官网Nginx文档大致了解了一下他的构架，看的真是让人拍案叫绝大快人心，请待我慢慢道来。</p>
<h3 id="2-2-1_多进程下的套接字">2.2.1 多进程下的套接字</h3><p>　　传统上Nginx在启动开始的时候就bind一个地址进行listen，后续在fork()创建worker process的时候，这些进程是共享这个侦听套接字的，这个在linux fork()的手册中明确地被表示出了(PS:这里需要注意shutdown和close的区别，前者会主动进行拆链请求，后者会降低引用计数，shutdown在拆链后如果还有其他进程使用，那么读会返回EOF，写会引发SIGPIPE)</p>
<blockquote>
<p>The  child  inherits  copies  of the parent’s set of open file descriptors.  Each file descriptor in the child refers to the same open file description (see open(2)) as the corresponding file descriptor in the parent. The child inherits copies of the parent’s set of open message queue descriptors, open directory streams.</p>
</blockquote>
<p>　　所以master process创建出来的所有worker process都是可以accept()客户端请求的，当多个进程对同一个socket调用accept()接收连接的时候，他们都会把自己放到这个套接字的等待队列上面去，然后一旦有客户发起连接请求，这个队列上面等待的进程就会被唤醒，这个过程在之前分析epoll的时候就介绍过了，但是在较早的epoll版本中，上面的唤醒过程会产生惊群(Thundering Herd)的问题：即使只有一个连接请求到来，也会唤醒在这个共享侦听套接字上所有等待的进程，而所有进程争抢这个连接只有一个能获得连接，其他所有进程都无功而返，所以新版的epoll添加了EPOLLEXCLUSIVE这么一个新的flag，通过在EPOLL_CTL_ADD的时候使用，保证在事件就绪的时候不会产生惊群的问题。<br>　　Nginx对于共享accept套接字惊群问题的处理，有三个方法：<br>　　(1). accept_mutex = on<br>　　当这个选项打开的时候，worker process在其任务循环的时候，会首先通过ngx_trylock_accept_mutex去获得一个进程间的ngx_accept_mutex互斥锁，而该锁通常是使用文件锁来实现的。在持有这个锁的时候，首先收集底层就绪的事件，同时执行accept的所有回调，然后释放该锁，处理一般的非accept事件。<br>　　(2). accept_mutex = off<br>　　这个设置在较新版本的Nginx已经是默认关闭的，主要考虑到的是：一来通过EPOLLEXCLUSIVE、下面的SO_REUSEPORT等新技术可以避免accept的时候惊群的问题；另一方面Nginx采用基于事件的处理方式，worker process只有很少的几个，而不像Apache的技术Prefork很多的子进程，所以即使发生惊群对系统造成的影响也极为有限。<br>　　(3). reuseport<br>　　在Linux内核3.9的时候，内核Socket支持了SO_REUSEPORT选项，而Nginx在1.9版本中引入了这个选项，这样每个worker process都可以同时侦听同一个IP:Port地址，内核会发现哪些listener可用，从而自动将连接请求分配给给定的worker process，消除了Nginx传统上通过用户态采用accept_mutex互斥锁而带来的性能损耗问题。<br>　　上面三种方式的性能对比在官方也给出了<a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/" target="_blank" rel="external">测试结果</a>。</p>
<h3 id="2-2-2_基于事件的异步模型">2.2.2 基于事件的异步模型</h3><p>　　异步模型是新一代http服务器Nginx和老牌Apache最大的不同之处：<br>　　Apache采用的是Prefork技术，服务启动之后预先启动一定数目的子进程，当服务器压力增大的时候不断增加子进程的数目，而当服务器空闲后自动关闭一些子进程，虽然这种弹性常驻子进程比One Child per Client的模型要进步很多，但是经过这么久的多进程、协程开发技术的熏陶可知，子进程的增加只在一定范围内可以增加服务能力，同时子进程在进程切换、内存等方面会对服务器带来很大的压力，如果当连接客户达到C10K的时候其占用的资源是不可估量的。不过Apache 2.4版本具有线程、事件等特性，试图减少进程带来的巨额开销。<br>　　但是Apache毕竟是老牌的Web服务器，其扩展模块非常的多，可以直接解析执行各种脚本，而不需要CGI/FastCGI这类额外的支持，而且性机可能更好，所以常见的情况就是Apache做后端服务器，而Nginx做前端反向代理的设计模式。<br>　　Nginx采用的是基于事件驱动的模型来解决C10K问题，所以通常Nginx只需要启动很少(通常CPU执行单元个数)的worker process就可以同时服务大量连接，以至于越来越多的http服务器迁移到Nginx平台上面。其工作流程主要是：<br>　　当master process通过fork()创建出几个worker process的时候，worker process进程主执行函数为ngx_worker_process_cycle()，这里面除了检查各种状态标识(比如接受到父进程发送的信号后，设置ngx_terminate、ngx_quit、ngx_reopen等标识)作出特定行为外，其正事主要是通过ngx_process_events_and_timers处理事件：<br>　　此时如果accept_mutex==on，而当ngx_trylock_accept_mutex抢锁失败则直接返回，否则就会设置NGX_POST_EVENTS这个标识，表示事件的回调延后执行。因为我们要把持锁的临界区降低，所以在持锁的过程中，通过ngx_process_events(实质乃是ngx_epoll_module_ctx.actions)检查底层侦听套接字就绪的事件，根据epoll特性可以快速的收集就绪事件并添加到ngx_posted_accept_events和ngx_posted_events队列上去，执行ngx_posted_accept_events队列回调后释放锁，最后执行一般的事件回调操作。<br>　　如果accept_mutex==off，那么在ngx_process_events的过程中，事件的回调将会在搜集就绪事件的过程中同步执行。</p>
<h2 id="2-3_Nginx配置文件和二进制程序平滑升级">2.3 Nginx配置文件和二进制程序平滑升级</h2><p>　　Nginx中多进程之间将信号运用的活灵活现(Windows平台下没用借用信号的方式，而是用其特有的Event事件进行的通信)，使得Nginx可以在不间断服务的情况下进行配置文件，甚至是二进制文件的平滑升级操作，信号的含义可以参见ngx_config.h，信号处理参见ngx_process.c:ngx_signal_handler，在信号处理文件中其实也只是设置一些状态变量，然后在进程的时间循环中去执行相应的操作，比如向worker process发送特定信号、启动worker process等。</p>
<h3 id="2-3-1_Nginx配置文件平滑升级">2.3.1 Nginx配置文件平滑升级</h3><p>　　通过nginx –s reload或者直接kill -SIGHUP向Nginx master process发送信号，当master process接受到SIGHUP信号的时候：<br>　　a. 检查配置文件，然后打开新的listen socket和日志文件，如果失败则让old nginx继续执行，否则<br>　　b. 创建新的worker process，同时向old worker process发送信息，让他们graceful关闭，old worker process会关闭侦听套接字，服务已经连接的客户，当所有连接客户服务完了之后退出</p>
<h3 id="2-3-2_Nginx二进制程序平滑升级">2.3.2 Nginx二进制程序平滑升级</h3><p>　　将新的二进制文件拷贝覆盖原二进制执行文件，然后向master process发送SIGUSR2信号，当master process接收到该信号的时候：<br>　　a. 将pid文件重新命名为nginx.pid.oldbin<br>　　b. 执行新的可执行文件，按照常规的路径会产生new master process和new worker process，此时新老进程全部并存，并且全部正常工作——接受客户端连接请求和服务客户端<br>　　c. 向old master process发送SIGWINCH，其将会把自己所有的old master workers关闭，注意此时old master process的侦听套接字仍然工作的，必要时候还是会自动产生自己的worker process。调试新版本升级是否正常：如果正常就向old master process发送SIGQUIT，加上之前SIGWINCH工作所有的old process清理完毕；如果不正常，向old master process发送SIGHUP产生worker process，同时向new master process发送SIGTERM信号立即清理所有的new worker process，然后使用SIGKILL杀死new master process</p>
<h2 id="2-4_其它">2.4 其它</h2><p>　　Nginx这样的设计策略，在某些情况下也可能会出问题。<br>　　在Linux系统有一个重要参数/proc/sys/vm/overcommit_memory，当其值=0的时候表示采用启发式的内存管理，进程可以申请比当前空闲内存更多的内存需求，这主要是出于进程申请的内存很多情况下不会立即被使用，甚至在进程的整个生命周期也不会被用到，通过这种overcommit机制实际上是对内存资源最大化利用的一种优化，但是当进程的内存在需要使用的时候(兑现)可能会出现Out Of Memory的情况，此时操作系统就有这么一个机制：通过杀死一些普通进程来释放内存，以维持基本系统和大多数业务的正常运转，也是在极端情况下“弃车保帅、李代桃僵”的无奈之举，这种行为被称为OOM-killer。<br>　　此时需要牺牲哪个进程呢？内核有一套评分标准，进程的得分可以通过/proc/<pid>/oom_score来访问，针对这个分数的计算有两套标准：<br>　　<strong>早期内核</strong><br>　　早期内核会把进程内存空间大小(p-&gt;mm-&gt;total_vm)作为起始分数，然后通过进程的CPU使用时间(tms_utime+tms_stime)、进程的运行时间(jiffies - p-&gt;start_time)、进程的优先级调整值(nice)、进程的权限(root)、进程是否直接访问硬件(direct hardware access)来对这个points进行修正，以实现这样的一种选择模型：对已经完成的工作损失最小、可以获得大量的空闲内存、不会杀死虽然大量使用内存但是无辜的进程、尽量最小化牺牲进程的数目(最好是1个)。<br>　　内核采用/proc/<pid>/oom_adj接口来实现对最终badness的调整，实际是对badness()计算的结果采用bitshift移位的方式进行，其取值范围是-16~+15(-17表示将当前进程完全排除在kill候选之外)，当oom_adj&gt;0时，则badness&lt;&lt;=oom_adj，否则badness&gt;&gt;=-(oom_adj)。<br>　　<strong>当前内核</strong><br>　　当前内核对point的计算进行了简化重写，以实现更简单、更可预测性的启发式功能。其初始point值就是进程对应的RSS(Resident Set Size)+pagetable+swap space，然后通过进程的权限进行调整后就可以用了。这种方式得到的值采用原来oom_adj类似指数型的调整就不合适，所以内核提供了/proc/<pid>/oom_score_adj的接口进行线型调整，其取值范围为-1000~1000。<br>　　在父进程创建子进程的时候，前面的adj会被继承下去。</pid></pid></pid></p>
<p>　　在了解到上面的背景后，<a href="http://mogu.io/159-159" target="_blank" rel="external">文章</a>提到的现象也是可以理解的，Nginx创建的worker进程是非特权进程(运行时间短、内存消耗多)，很有可能在OOM情况下被牺牲，而master进程得知工作进程退出后，会尝试重建worker进程，于是上演了上面这么一出。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://github.com/nginx/nginx" target="_blank" rel="external">GitHub Nginx</a></li>
<li><a href="http://blogs.datalogics.com/2013/09/25/threads-vs-processes-for-program-parallelization/" target="_blank" rel="external">THREADS VS. PROCESSES FOR PROGRAM PARALLELIZATION</a></li>
<li><a href="http://elinux.org/images/1/1c/Ben-Yossef-GoodBadUgly.pdf" target="_blank" rel="external">On Threads, Processes and Co-Processes</a></li>
<li><a href="http://www.yolinux.com/TUTORIALS/LinuxTutorialPosixThreads.html" target="_blank" rel="external">POSIX thread (pthread) libraries</a></li>
<li><a href="https://docs.oracle.com/cd/E19455-01/806-5257/6je9h033a/index.html" target="_blank" rel="external">Extending Traditional Signals</a></li>
<li><a href="http://maxim.int.ru/bookshelf/PthreadsProgram/htm/r_40.html" target="_blank" rel="external">Pthreads Programming Chapter 5 - Pthreads and UNIX Threads and Signals </a></li>
<li><a href="/201604/server-prog-port-from-windows-to-linux.html">Windows服务端程序向Linux平台移植事项</a></li>
<li><a href="http://blog.csdn.net/21aspnet/article/details/7420091" target="_blank" rel="external">深刻理解Linux进程间通信（IPC）</a></li>
<li><a href="https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/" target="_blank" rel="external">Inside NGINX: How We Designed for Performance &amp; Scale</a></li>
<li><a href="http://www.aosabook.org/en/nginx.html" target="_blank" rel="external">The Architecture of Open Source Applications – NGINX</a></li>
<li><a href="http://nginx.org/en/docs/control.html" target="_blank" rel="external">Controlling nginx</a></li>
<li><a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/" target="_blank" rel="external">Socket Sharding in NGINX Release 1.9.1</a></li>
<li><a href="http://linuxgazette.net/129/saha.html" target="_blank" rel="external">Issues In Concurrent Server Design on Linux Systems - Part I</a></li>
<li><a href="https://anturis.com/blog/nginx-vs-apache/" target="_blank" rel="external">Nginx vs Apache</a></li>
<li><a href="http://mogu.io/159-159" target="_blank" rel="external">Linux内核分析： OOM杀掉nginx后导致的系统hang问题</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[macOS新平台工作环境的设置和迁移]]></title>
      <url>https://taozj.org/201611/transform-work-env-to-mac-os.html</url>
      <content type="html"><![CDATA[<p>　　感谢厨神Tim Cook在10月27日短暂而又精彩的MacBook Pro发布会，让我在期待了大半年之后，终于毫不犹豫地下单购买了2015年初期版本的老款Macbook Pro。新版Macbook Pro做的更加轻薄靓丽，无不彰显了Apple强大的工业设计能力，但是抛开缺了苹果标志的信仰灯不能装逼了暂且不说，Macbook Pro不仅仅是专供美工使用的，对于广大程序员同志而言缺失实体Esc和Fn键是不能容忍的，况且这次更新后处理器、内存方面并没有什么变更，对于实用主义者来说新款版本更新动力不大。<br>　　其实对于Linux平台的程序员而来，当经历过人生最能折腾的年代玩遍各大发行版之后，绝大多数人都投皈依到了MacOS的门下，而现在我就属于其中的一位，其中最主要的原因就是MacOS系统和Linux系统具有着极大的亲缘性，MacOS的很多组件都移植自开源的BSD系统，所以Linux程序员在MacOS下用Terminal会有十分亲切的感觉，同时对于原生没有打包进MacOS的软件和工具，外挂神器homebrew更是让其如虎添翼，基本Linux下的绝大多数软件包括gcc都可以一句命令安装，方便的不得了。除此之外就是MacOS系统良好的美学设计和极为完善的软件生态系统，大多Windows下的软件都有Mac的版本，更是可以让那些长久以往而来对Linux桌面怒其不争的人彻底摆脱双系统的困扰。<br>　　MacOS系统的软件，参见文章末尾的两个推荐链接就可以了。能力充裕财务自由的还是买正版吧，毕竟自己也是做软件的，破解软件虽然能省几个钱，有些需要打开系统安装未认证软件的权限，风险得失自己平衡。我把自己用到的软件罗列如下：</p>
<blockquote>
<p>　　Alfred3、iTerm、zsh、oh-my-zsh、搜狗输入法、WizNote、ShadowsocksX、WingIDE、Chrome、QQ、WeChat、SlickEdit、DropBox、Steam、KeePassX、VLC、ThunderBird、Sublime、Microsoft Office 2016、Photoshop CC、网易云音乐、Thunder、VMware Fusion、BetterZip、SecureCRT、Navicat Premium、iStat Menus、MacVim、Snip、MacDown、Moom、Adobe Acrobat Pro、CheetSheet、PopClip、CleanMyMac 3、Fantastical 2、Bartender 2、Dash、GnuPG2、Manico、Go2Shell</p>
</blockquote>
<p>　　当然上面的软件可能不是最优的，主要是以前一些常在Windows和Linux下面使用的软件保存了一些数据，如果换成别的软件数据的迁移会比较的麻烦，因此不是特别差的也将就着用了。<br>　　关于虚拟机，可能大家会疑惑，前面刚把万能的MacOS系统吹的天花乱坠兼容类Unix系统，有着类似Windows系统良好软件生态圈，为什么还是摆脱不了虚拟机的宿命呢？其实对于大多数不涉及系统级的开发，MacOS算是够用了，但是作为服务端开发的人，时常需要使用操作系统底层的异步特性，虽然select是Posix标准以至于连Windows都支持，但是对于高性能的异步构架却不然：Windows使用的I/O completion ports，BSD、MacOS使用的kqueue，Linux使用的epoll，基本是各自为政，所以要进行Linux的服务端软件开发调试，就不得不安装个虚拟机，然后再装一个原生的Linux操作系统才行。<a id="more"></a><br>　　MacOS下面的虚拟机算Parallels Desktop、Vmware Fusion、VirtualBox三分天下，VirtualBox据说其代码写的稀烂就PASS了，Parallels Desktop在苹果上使用的最为广泛，但是发现其对最新的Ubuntu 16.04 LTS支持的不好，最后就选择了Vmware Fusion了，其向来对Linux支持的最为完善，而且现在虚拟机的催化剂VMware Tools也已经交与社区维护了，所以现在各大主流的Linux发行版的官方仓库都集成了open-vm-tools-desktop软件包，可以一键虚拟机加速了，每个发行版都会对其进行测试验证，所以显然这样对Guest OS的支持是最优的了。<br>　　安装系统就不说了，需要注意的是：把虚拟机完全备份之后要排除在TimeMachine之外，否则很快你的备份硬盘就会被撑爆掉，其次Guest OS就不要开高分Retina分辨率了，虽说Ubuntu对高分屏支持的不错，但是你的显卡会爆掉的。这里主要讲究的是在MacOS和Linux之间通过NFS的方式共享文件，为啥选择NFS而不是CIFS或者vmhgfs，主要是因为NFS是类Unix下原生的东西，对Linux文件系统的特性和语义算是支持的最好的，操作如下：<br>　　(1). 在Host MacOS上面建立/etc/exports，并且导出自己想要共享出去的目录，后面-mapall是要共享出去的user和group。注意MacOS下面nfsd服务端文件共享的配置格式和Linux平台下是不一样的<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">➜  cat /etc/exports</div><div class="line">/Users/taozj/Dropbox/ReadTheCode/ -network 172.16.20.0 -mask 255.255.255.0 -mapall=taozj:staff:ubuntu</div><div class="line">/Users/taozj/Dropbox/GitHub/ -network 172.16.20.0 -mask 255.255.255.0 -mapall=taozj:ubuntu:staff</div><div class="line">➜</div></pre></td></tr></table></figure></p>
<p>　　(2). 让nfsd开启自动启动，然后每次修改了上面的/etc/exports，都可以用nfsd update进行刷新<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">➜  sudo nfsd <span class="built_in">enable</span></div><div class="line">➜  sudo nfsd start</div><div class="line">➜  sudo nfsd update</div></pre></td></tr></table></figure></p>
<p>　　(3). 使用nfsd checkexports可以检查/etc/exports是否有配置错误，showmount -e列出本机成功共享出去的目录信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  nfsd checkexports</div><div class="line">➜  showmount <span class="_">-e</span></div><div class="line">Exports list on localhost:</div><div class="line">/Users/taozj/Dropbox/ReadTheCode    172.16.20.0</div><div class="line">/Users/taozj/Dropbox/GitHub         172.16.20.0</div></pre></td></tr></table></figure></p>
<p>　　(4). 这个时候可以在Linux平台命令行挂载是否成功，如果你是Ubuntu系统，你会看到共享过来的文件属主为(501,dialout)，那是因为在MacOS配置nfsd的时候使用的-mapall=taozj参数，我的用户taozj的uid和gid刚好是(501,20)，而Ubuntu上面默认第一个常规用户的uid是从1000开始的，而gid=20刚好代表dialout组，所以得到了这么个奇怪的用户所有者。解决的方法要么配置idmapd服务进行id映射，我就找了个简单的方法偷个懒，在Linux下面将当前用户的uid变成和MacOS一样的501<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@ubuntu:~<span class="comment"># usermod -u 501 user</span></div><div class="line">root@ubuntu:~<span class="comment"># usermod -a user -G dialout</span></div></pre></td></tr></table></figure></p>
<p>　　通过这个操作，用户user的uid将会从1000变成现在的501，同时/home/user目录下的所有文件的属主也会自动被修改，其他位置的文件可能需要手动chown操作，挂载测试是否成功，读写是否正常，没有问题的话就可以写入/etc/fstab中开机自动挂载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">172.16.20.1:/Users/taozj/Dropbox/ReadTheCode/	/home/user/MacOS/ReadTheCode	nfs	auto,rw,noatime,nolock,intr,tcp,actimeo=1800	0	0</div><div class="line">172.16.20.1:/Users/taozj/Dropbox/GitHub/	/home/user/MacOS/GitHub		nfs	auto,rw,noatime,nolock,intr,tcp,actimeo=1800	0	0</div></pre></td></tr></table></figure></p>
<p>　　然后在网络上无意中浏览到了MacOS移植了BSD的xhyve容器库，不知道怎么样，玩容器的伙伴又可以摆弄了。<br>　　电脑买回来预装的EI Caption，用着这个版本也好，因为每次苹果系统的升级都会修复旧款设备运行过于流畅的Bug，况且据说新版的macOS Sierra软件兼容性和其他稀奇古怪的问题之多多，本人也就懒得升级了。工作环境的切换真心费神费力，希望这次入驻Mac平台后，Dropbox和TimeMachine能够保平安，让我把有限的精力投入到更加有意义的事情上去。</p>
<p>　　MacOS平台软件推荐帖<br>　　<a href="http://miao.hu/2012/02/26/osx-exp-share/" target="_blank" rel="external">http://miao.hu/2012/02/26/osx-exp-share/</a><br>　　<a href="https://github.com/hzlzh/Best-App" target="_blank" rel="external">https://github.com/hzlzh/Best-App</a><br>　　[系统设计推荐<br>　　<a href="http://www.codeceo.com/article/programmer-macbook-workplace.html" target="_blank" rel="external">http://www.codeceo.com/article/programmer-macbook-workplace.html</a><br>　　<a href="http://sourabhbajaj.com/mac-setup/" target="_blank" rel="external">Mac OS X Setup Guide</a></p>
<p>　　PS:用了一段时间，发现坑点还是蛮多的。虽然说Terminal支持很多Unix的工具，但是有的工具还是跟Linux有所差别，可能是因为苹果是BSD系的吧，当初耍FreeBSD的时候就遇到过类似的问题。默认的编译器是Clang，编译最新的Boost还是会出现这样那样的问题，想把默认编译器换成homebrew安装的gcc-5.4.0，但是貌似做不到，哭。。。<br>　　此外，大多数的软件对gcc支持好，但是Clang就不一定了，比如最新upstream在Linux用gcc编译重来没出现过问题，但是Apple Clang一直都有问题，最后切换到boost-1.62.0发布版本才可以。<br>　　虽然买的256G硬盘，另外扩充了一个Jet Drive 128G，空间是够用的，但是发现开启虚拟机还是内存压力很大的说。</p>
<p>　　PS：上班的时候，需要使用Windows电脑但是又想工作内容都在网盘中，这时候最简单的方法就是把Windows当作共享服务器，然后Linux挂载共享分区到自己的路径中。因为Windows对CIFS的支持算是最好的，Windows导出共享文件夹也是极为的简单，而且Linux作为客户端挂在也毫无压力：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  ~ id taozj </div><div class="line">uid=1007(taozj) gid=1007(taozj) groups=1007(taozj)</div><div class="line">➜  ~ mkdir remote_build</div><div class="line">➜  ~ sudo mount -t cifs //192.168.1.194/Users/taozj/Dropbox/BitBucket/v5kf_dev /home/taozj/remote_build -o  username=<span class="string">"taozj"</span>,uid=<span class="string">"1007"</span>,gid=<span class="string">"1007"</span> -v</div><div class="line">Password <span class="keyword">for</span> taozj@//192.168.1.194/Users/taozj/Dropbox/BitBucket/v5kf_dev:  *************</div><div class="line">mount.cifs kernel mount options: ip=192.168.1.194,unc=\\192.168.1.194\Users,uid=1007,gid=1007,user=taozj,prefixpath=taozj/Dropbox/BitBucket/v5kf_dev,pass=********</div><div class="line">➜  ~ ls <span class="_">-l</span> remote_build </div><div class="line">total 0</div><div class="line">drwxr-xr-x 2 taozj taozj 0 Feb 10 09:43 aimlsrvd</div></pre></td></tr></table></figure></p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost.Context库简介及Boost.Coroutine协程使用方式]]></title>
      <url>https://taozj.org/201611/introduction-of-boost-context-and-new-coroutine-library.html</url>
      <content type="html"><![CDATA[<p>　　最近从各大公司的开源项目看来，基于协程的高性能服务端开发变得越来越流行了，比如我了解到的微信团队的<a href="https://github.com/tencent-wechat/libco" target="_blank" rel="external">libco</a>、魅族的<a href="https://github.com/yyzybb537/libgo" target="_blank" rel="external">libgo</a>、以及<a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a>。传统的高性能服务端的开发大多都是基于异步框架和多线程或者多进程的模型来设计的，这种架构虽然经历了长久的考验且经验丰富，但是却有着固有的缺点：<br>　　(1). 异步构架将代码逻辑强行分开，不利于人类常理的顺序思维习惯，自然也不是对开发者友好的；<br>　　(2). 线程虽然相对于进程共享了大量的数据，创建和切换效率较高，算是作为内核级别轻量级别的调度单元，在X86构架下线程的切换需要大量的CPU指令周期才能完成；同时，当业务增长的时候，如果通过增加工作线程的情况下增加处理能力，反而有可能让系统大部分的资源消耗在线程管理资源和线程调度的开销中去了，获得恰得其反的效果，所以在Nginx中工作进程的数目和CPU执行单元的数目是相同的，通过进程(线程)亲和CPU核的方式，可以最小化进程(线程)切换带来的损失(比如缓存失效等)；<br>　　(3). 虽然我们某些时候可以通过::sched_yield();主动放弃CPU请求调度，但是被切换进来的线程完全是调度算法决定的，相对于被切换进来的线程是被动的，作为常见的生产——消费者线程模型，两者只能被动苟合而很难做到高效“协作”；<br>　　(4). 也是因为上面的原因，线程之间的切换基本都属于用户程序不可控的被动状态，所以很多临界区必须通过加锁的方式进行显式保护才行。<br>　　在这种环境下，更加轻量级的协程开发便应运而生，且被各大厂家广为使用了。除了各个研发实力强的大厂开发出服务自己业务的高性能协程库之外，Boost库也发布了Boost.Coroutine2协程库，其中包含了stackless和stackful两种协程的封装，他们的简单使用方法，在我之前的《<a href="201609/usage-of-coroutine-in-boost-asio.html">Boost.Asio中Coroutine协程之使用</a>》已经做了相对比较详细的介绍说明了。这里主要了解介绍一下相对于协程高级接口之下，较为底层中涉及到协程切换过程中资源管理维护之类的基础性东西——Boost.Context库(适用于stackful协程)。<a id="more"></a><br>　　其实协程的实现方式有很多，有能力的大厂可以自己手动进行创建和维护栈空间、保存和切换CPU寄存器执行状态等信息，这些都是跟体系结构密切相关，也会涉及较多的汇编操作，而对于一般的开发者想要快速开发出协程原型，通常采用ucontext或者Boost.Context这现有工具来辅助栈空间和运行状态的管理，ucontext算是历史比较悠久的，通过ucontext_t结构体保存栈信息、CPU执行上下文、信号掩码以及resume所需要的下一个ucontext_t结构的地址，但是人家实测ucontext的性能要比Boost.Context慢的多，Boost.Context是今年来C++各大协程底层支撑库的主流，性能一直在被优化。<br>　　Boost.Context所做的工作，就是在传统的线程环境中可以保存当前执行的抽象状态信息(栈空间、栈指针、CPU寄存器和状态寄存器、IP指令指针)，然后暂停当前的执行状态，程序的执行流程跳转到其他位置继续执行，这个基础构建可以用于开辟用户态的线程，从而构建出更加高级的协程等操作接口。同时因为这个切换是在用户空间的，所以资源损耗很小，同时保存了栈空间和执行状态的所有信息，所以其中的函数可以自由被嵌套使用。<br>　　从我查阅的资料来看来，最近发布的Boost.Context新版本相对老版本更新了很多，抽象出了execution_context的类型，从其内部实现文件可以看出，其实内部的基础结构还是使用的fcontext_t来保存状态，使用make_fcontext、jump_fcontext以及新增的ontop_fcontext来操作之，对过往版本熟悉的<a href="https://www.owent.net/2016/06/boost-context-1-61%E7%89%88%E6%9C%AC%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%8F%98%E5%8C%96.html" target="_blank" rel="external">大佬们</a>当然可以直接调用这些接口。现在最新的Boost.Context依赖于C++11的一些新特性，而Boost的协程库也针对性的维护了两个版本Boost.Coroutine和Boost.Coroutine2，不知道是不是这个原因所致，毕竟他们的作者都是Oliver Kowalke。<br>　　创建execution_context会首先分配一个context stack空间，在其栈顶部保留了维持这个context信息的数据结构，设计中execution_context的环境中不能访问这个数据结构，只能在调用操作符operator()调用的时候其内部状态会自动的更新保存，用户无需关心。正如同boost::thread一样，operator()execution_context也是不支持拷贝的，只支持移动构造和移动赋值操作。<br>　　所有的execution_context都需要一个context-function，其函数签名如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">auto</span> <span class="title">execution_context</span><span class="params">(execution_context ctx, Args ... args)</span></span></div></pre></td></tr></table></figure></p>
<p>　　第一个参数ctx是固定的，表明是会在当前context被suspend的时候自动切换resume至的context，通常来说是当前context的创建和调用者，后面的可变参数会自动传递给execution_context::operator()函数作为参数。<br>　　Boost.Context的execution_context简单使用的例子<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> n = <span class="number">9</span>;</div><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>&gt; source(</div><div class="line">    [n](ctx::execution_context&lt;<span class="keyword">int</span>&gt; sink, <span class="keyword">int</span><span class="comment">/*not used*/</span> ) <span class="keyword">mutable</span> &#123;</div><div class="line">    <span class="keyword">int</span> a=<span class="number">0</span>, b=<span class="number">1</span>;</div><div class="line">    <span class="keyword">while</span>(n-- &gt;<span class="number">0</span>)&#123;</div><div class="line">        <span class="keyword">auto</span> result = sink(a);</div><div class="line">        sink = <span class="built_in">std</span>::move(<span class="built_in">std</span>::get&lt;<span class="number">0</span>&gt;(result));</div><div class="line">        <span class="keyword">auto</span> next = a + b;</div><div class="line">        a = b; b = next;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> sink;</div><div class="line">&#125;);</div><div class="line"></div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">10</span>; ++i) &#123;</div><div class="line">    <span class="keyword">if</span>(source) &#123;</div><div class="line">        <span class="keyword">auto</span> result = source(<span class="number">0</span>);</div><div class="line">        source = <span class="built_in">std</span>::move( <span class="built_in">std</span>::get&lt;<span class="number">0</span>&gt;(result) );</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="built_in">std</span>::get&lt;<span class="number">1</span>&gt;(result) &lt;&lt; <span class="string">" "</span>;   </div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">// 输出结果为：0 1 1 2 3 5 8 13 21 0 %</span></div></pre></td></tr></table></figure></p>
<p>　　函数的返回类型跟实例化execution_context的模板参数类型有关：如果suspend和resume两个context之间不需要数据传递而仅仅是控制流的切换，可以使用void实例化execution_context类型创建对象，否则对于resume者来说其接收到的返回值是std::tuple类型，第一个值是suspend的context对象，其余部分是打包好的返回值，如果仅仅返回单个值但是是不同的数据类型，可以考虑使用boost::variant，多个返回值依次封装就可以了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">string</span>&gt; ctx1(</div><div class="line">    [](ctx::execution_context&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">string</span>&gt; ctx2, <span class="keyword">int</span> num, <span class="built_in">std</span>::<span class="built_in">string</span>) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> str;</div><div class="line">    <span class="built_in">std</span>::tie(ctx2, num, str) = ctx2(num+<span class="number">9</span>, <span class="string">"桃子是大神"</span>);</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::move(ctx2);</div><div class="line">&#125;);</div><div class="line"></div><div class="line"><span class="keyword">int</span> i = <span class="number">1</span>;</div><div class="line"><span class="keyword">int</span> ret_j; <span class="built_in">std</span>::<span class="built_in">string</span> ret_str;</div><div class="line"><span class="built_in">std</span>::tie(ctx1, ret_j, ret_str) = ctx1(i, <span class="string">""</span>);</div><div class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; ret_j &lt;&lt; <span class="string">"~"</span> &lt;&lt; ret_str &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div></pre></td></tr></table></figure></p>
<p>　　如果想要在某个被resumed的context上面额外执行自己指定的其他某个函数，可以将调用的第一个参数设置为exec_ontop_arg，然后紧接需要调用的函数，再正常传递context所需要传递的函数，在调用的时候，参数传递给这个指定的函数去执行，同时要求这个函数的返回类型必须是std::tuple封装的可以传递给resume context的参数，然后发生context切换resume使用其参数继续执行。这在新版Boost.Context中引入不久，效果相当于在原来执行context上面添加了一个hook调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">ctx::execution_context&lt;<span class="keyword">int</span>&gt; func1(ctx::execution_context&lt;<span class="keyword">int</span>&gt; ctx, <span class="keyword">int</span> data) &#123;</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered first time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered second time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: entered third time(atten): "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="keyword">return</span> ctx;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="built_in">std</span>::tuple&lt;boost::context::execution_context&lt;<span class="keyword">int</span>&gt;,<span class="keyword">int</span>&gt; func2(boost::context::execution_context&lt;<span class="keyword">int</span>&gt; ctx, <span class="keyword">int</span> data) </div><div class="line">&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func2: entered: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::make_tuple(<span class="built_in">std</span>::move(ctx), <span class="number">-3</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span>&#123;</div><div class="line">	<span class="keyword">int</span> data = <span class="number">0</span>;</div><div class="line">	ctx::execution_context&lt; <span class="keyword">int</span> &gt; ctx(func1);</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: returned first time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(data+<span class="number">1</span>);</div><div class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1: returned second time: "</span> &lt;&lt; data &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">	<span class="built_in">std</span>::tie(ctx, data) = ctx(ctx::exec_ontop_arg, func2, data+<span class="number">1</span>);</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面代码输出的结果显示在下方，data+1==5被传递给func2，然后func2包装了ctx和自己的参数，ctx得到继续执行，使用了func2传递给的参数：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">func1: entered first time: 1</div><div class="line">func1: returned first time: 2</div><div class="line">func1: entered second time: 3</div><div class="line">func1: returned second time: 4</div><div class="line">func2: entered: 5</div><div class="line">func1: entered third time(atten): -3</div></pre></td></tr></table></figure></p>
<p>　　对象execution_context在创建的时候会分配一个context stack，在context-function返回的时候会被自动析构。<br>　　经过追查，发现execute_context是在Boost-1.59中引入的，在其之前的版本还是直接通过联合调用jump_fcontext()、make_fcontext()来操作fcontext_t结构来保存和切换stack和执行状态信息的，虽然现在execution_context封装的更加易用，但是老式的fcontext_t操作结构更加的容易容易理解，感兴趣的想了解更加深入的内容可以查阅老版本的文档。</p>
<p>　　之前看Boost.Coroutine的时候，什么call_type、push_type……概念看的眼花缭乱，这里看看协程底层支持的基础框架Boost.Context，有一种豁然开朗的感觉，其实当有人帮你把这些复杂的、依赖于底层架构的东西做完封装好之后，或许期待我有时间的那一天，也能做一个属于自己的协程库，等后面了解一下libgo、libcopp等协程库的原理和思路之后，要不也来造个轮子！</p>
<p>PS：其实协程把用户的思路变成同步的了，那么开发协程库的人就要把执行流的跳转任务给担当下来。上面的例子应该还不是特别难理解，Boost::Context规定说execution_context::operator()被调用的时候，程序的运行发生切换，所以上面的切换点也就明白了。就是感觉最近发布的几个版本变化实在太大了，虽然名字一样，有时候是指针有时候不是指针，还是指定一个版本——1.62.0深入好了。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://msdn.microsoft.com/en-us/magazine/jj553509.aspx" target="_blank" rel="external">Windows with C++ - Lightweight Cooperative Multitasking with C++</a></li>
<li><a href="http://www.tolon.co.uk/2012/08/boost-context/" target="_blank" rel="external">LIGHTWEIGHT COOPERATIVE MULTITASKING WITH BOOST.CONTEXT</a></li>
<li><a href="http://www.boost.org/doc/libs/1_62_0/libs/context/doc/html/index.html" target="_blank" rel="external">Boost Context</a></li>
<li><a href="https://www.owent.net/2016/06/boost-context-1-61%E7%89%88%E6%9C%AC%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E5%8F%98%E5%8C%96.html" target="_blank" rel="external">boost.context-1.61版本的设计模型变化</a></li>
<li><a href="https://github.com/owt5008137/libcopp" target="_blank" rel="external">libcopp</a></li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0099r0.pdf" target="_blank" rel="external">A low-level API for stackful context switching</a></li>
<li><a href="http://www.boost.org/doc/libs/1_58_0/libs/context/doc/html/context/context.html" target="_blank" rel="external">Boost.Context fcontext_t</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据结构和算法（四）：主流内排序算法]]></title>
      <url>https://taozj.org/201611/data-structure-and-algorithm-(4)-sort.html</url>
      <content type="html"><![CDATA[<p>　　数据结构中通用的算法主要涉及查找和排序。查找操作基本依赖于数据组织的方式(顺序存储、链表存储、树存储等)，主流的有顺序查找、折半查找、插值查找、散列查找等，其操作比较的简单明了；而排序算法算是算法中最热门的讨论话题，算法的考察要点包括对时间、空间的需求及排序的稳定性等。当然，C++标准库中已经封装了大量的容器类以及find、sort、stable_sort等通用算法，工程开发中直接传入迭代器参数就可以使用了。</p>
<h1 id="一、基础知识">一、基础知识</h1><h2 id="1-1_排序的分类">1.1 排序的分类</h2><p>　　(1). 排序的稳定性：<br>　　在排序中如果主关键字一致，对于假设ki=kj(i≠j)，在排序前序列中ri领先于rj(即i&lt;j)，如果排序后ri仍领先于rj，则称排序方法是稳定的；反之，若可能(但不一定)排序后的序列中rj领先ri，也就是关键码相同的记录，经过排序后这些记录的相对次序仍然保持不变，则称排序方法是不稳定的。<br>　　(2). 内排序(Internal Sort)和外排序(External Sort)：<br>　　内排序是在排序整个过程中，待排序的所有记录全部被放置在内存中；外排序是由于排序个数太多，不能同时放置在内存，整个排序过程需要在内外存之间多次交换数据才能进行。后面可知，归并排序可以处理外排序问题。<br>　　(3). 按照算法的原理分类<br>　　a. 插入排序：直接插入排序、二分插入排序、希尔排序<br>　　b. 交换排序：冒泡排序、鸡尾酒排序、快速排序<br>　　c. 选择排序：直接选择排序、堆排序、<br>　　d. 归并排序：归并排序<br>　　e. 分配排序：计数排序、桶排序、基数排序</p>
<h2 id="1-2_排序算法的复杂度">1.2 排序算法的复杂度</h2><h3 id="1-2-1_算法时间复杂度">1.2.1 算法时间复杂度</h3><p>　　在进行算法分析时，语句总的执行次数T(n)是关于问题规模n的函数，进而分析T(n)随n的变化情况并确定T(n)的数量级。<br>　　算法的时间复杂度，也就是算法的时间度量，记作：T(n)=O(f(n))，它表示随着问题规模的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐进时间复杂度，简称为时间复杂度，其中f(n)是问题规模n的某个函数。这种记法称作大O记法。</p>
<h3 id="1-2-2_推导大O阶方法">1.2.2 推导大O阶方法</h3><p>　　(1). 用常数1取代运行时间中的所有加法常数；<br>　　(2). 在修改后的运行次数函数中，只保留最高阶项；<br>　　(3). 如果最高阶存在且不是1，则去除与这个项相乘的常数，从而最终得到结果。</p>
<h3 id="1-2-3_常见的复杂度">1.2.3 常见的复杂度</h3><p>　　要分析算法的复杂度，关键是要分析循环结构的运行情况，常见的时间复杂度有：</p>
<ul>
<li>O(1)常数阶；</li>
<li>O(logn)对数阶；</li>
<li>O(n)线性阶；</li>
<li>n(logn)表示nlogn阶；</li>
<li>O(n^2)平方阶；</li>
<li>O(n^3)立方阶；</li>
<li>O(2^n)指数阶。<br>　　上面的顺序也是复杂度从小到大的排列顺序。</li>
</ul>
<h1 id="二、经典排序方法总结">二、经典排序方法总结</h1><h2 id="2-1_冒泡排序">2.1 冒泡排序</h2><p>　　冒泡排序是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，直到没有反序的记录为止。<br>　　(1). 最常见的版本：经过两轮循环，用当前的i和后面的每个元素比较，如果不是最小就交换到i的位置，这样可以保证每轮外部循环都能将i位置的元素确定，但对其余的记录排序没有什么帮助，效率低。(内层循环从i开始)<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i+<span class="number">1</span>; j&lt;sz; ++j)</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[j])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[j]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(2). 正宗的冒泡排序：每次内循环的时候，进行紧密相邻两个元素的比较，将较小的数向前交换，就像是冒泡一样，确保每次最小的值能到达正确的位置，同时其余元素也能够相应地向对应的方向移动。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i)</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=<span class="number">0</span>; j&lt;sz<span class="number">-1</span>; ++j)</div><div class="line">            <span class="keyword">if</span> (store[j] &gt; store[j+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[j], store[j+<span class="number">1</span>]);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(3). 优化：在上面正宗的冒泡排序中，如果经过一轮的检查，没有发生任何的swap交换活动，则表明已经有序了，此时就可以直接跳出循环表明排序完成了。<br>　　冒泡排序其总的时间复杂度为O(n^2)。<br>　　冒泡排序是一种稳定的排序方法。</p>
<h2 id="2-2_鸡尾酒排序(Shaker排序)">2.2 鸡尾酒排序(Shaker排序)</h2><p>　　该排序又叫作双向冒泡排序，算是冒泡排序的一种轻微改进版本。普通的冒泡排序只能每次从前往后进行一个次序遍历，而Shaker排序每次遍历包括两个方向，先从前往后遍历记录最后发生交换的两个元素位置，然后从这个位置开始从后往前遍历，这种双向交替比较不仅会使小的浮上水面，也会使大的沉到水底，因而效率会比较高。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> left=<span class="number">0</span>, right=sz<span class="number">-1</span>;</div><div class="line">    <span class="keyword">size_t</span> i=<span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (left&lt;right) &#123;</div><div class="line">        <span class="comment">//第一遍，从左到右</span></div><div class="line">        <span class="keyword">for</span> (i=left; i&lt;right; ++i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &gt; store[i+<span class="number">1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i+<span class="number">1</span>]);</div><div class="line">        &#125;</div><div class="line">        -- right;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (i=right; i&gt;left; --i) &#123;</div><div class="line">            <span class="keyword">if</span> (store[i] &lt; store[i<span class="number">-1</span>])</div><div class="line">                <span class="built_in">std</span>::swap(store[i], store[i<span class="number">-1</span>]);</div><div class="line">        &#125;</div><div class="line">        ++ left;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　该排序也是稳定排序算法。<br><a id="more"></a></p>
<h2 id="2-3_简单选择排序">2.3 简单选择排序</h2><p>　　简单选择排序的过程就是通过n-i次关键字间的比较，从n-i+1个记录中选出关键字最小的记录，然后直接和第i(1≤i≤n)个记录交换之，按照这种方法依次对剩余排序位进行填充。<br>　　从简单选择排序的过程看来，其比较的次数并没有减少，但最大的特点就是交换移动数据次数相当少，所以效率会高一些。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> index = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;sz; ++i) &#123;</div><div class="line">        index = i;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i+<span class="number">1</span>; j&lt;sz; ++j)</div><div class="line">            <span class="keyword">if</span> (store[j] &lt; store[index])</div><div class="line">                index = j;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (i != index)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[index]);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　因为会有元素交换，所以简单选择排序不是稳定排序算法。<br>　　简单选择排序总的时间复杂度为O(n^2)。</p>
<h2 id="2-4_插入排序">2.4 插入排序</h2><h3 id="2-4-1_直接插入排序">2.4.1 直接插入排序</h3><p>　　直接插入排序的基本操作是将一个记录插入到已经排好序的有序表中，从而得到一个新的、记录数增加1的有序表。<br>　　直接插入排序是一种插入排序的方法，实际使用的时候可以在序列的头部添加一个哨兵，将i的数据放到哨兵后就空出一个位置，便于后面数据的挪动，找到空位后将哨兵位置的原数据插入进去就可以了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="keyword">int</span>&gt; tmp;</div><div class="line">    <span class="keyword">auto</span> it = tmp.begin();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; i: store)</div><div class="line">    &#123;</div><div class="line">        <span class="keyword">for</span> (it = tmp.begin(); it!=tmp.end() &amp;&amp; *it&lt;i; ++it)</div><div class="line">            <span class="keyword">continue</span>;</div><div class="line">        tmp.insert(it, i);</div><div class="line">    &#125;</div><div class="line">    store.assign(tmp.cbegin(), tmp.cend());</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　直接插入排序法的时间复杂度为O(n^2)。<br>　　直接插入排序是一种稳定的排序算法。</p>
<h3 id="2-4-2_二分插入排序">2.4.2 二分插入排序</h3><p>　　二分插入排序又叫折半插入排序，算是前面直接插入排序的变种改进，主要是用了折半查找的思路进行了优化。上面用了容器的方式直接插入排序，下面用传统的数组方式进行插入排序的模拟。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">1</span>; i&lt;sz; ++i) &#123;</div><div class="line">        <span class="keyword">int</span> elem = store[i];</div><div class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> right = i<span class="number">-1</span>;</div><div class="line"></div><div class="line">        <span class="keyword">while</span> (left &lt;= right) <span class="comment">//当left==right，也需要判断mid前还是后</span></div><div class="line">        &#123;</div><div class="line">            <span class="keyword">ssize_t</span> mid = (left + right) / <span class="number">2</span>; <span class="comment">//向0取整</span></div><div class="line">            <span class="keyword">if</span> (elem &gt; store[mid])</div><div class="line">                left = mid + <span class="number">1</span>; <span class="comment">//必须+1 -1，否则相邻序死循环</span></div><div class="line">            <span class="keyword">else</span></div><div class="line">                right = mid - <span class="number">1</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> j=i; j&gt;left; --j)</div><div class="line">            store[j] = store[j<span class="number">-1</span>];</div><div class="line">        store[left] = elem;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-5_希尔排序">2.5 希尔排序</h2><p>　　希尔排序的思路是：将待排序列分割成若干个子序列，此时每个子序列待排序的记录个数比较少，可以在这些子序列内分别进行直接插入排序，当整个序列都基本有序时，注意只是基本有序时，再对全体记录进行一次直接插入排序。<br>　　但是这里的分组不是简单相邻的分组，而是将相隔某个“增量/increment”的记录组成一个子序列，实现跳跃式的交换移动，所以使得排序的效率提高。随着增量的不断减少，跳跃移动的步伐慢慢变小，而整个系列也变的更为的“基本有序”。还需要注意要确保最终的increment=1来实现最后一次精细的排序，然后整个序列就变的有序了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line">    <span class="keyword">size_t</span> gap = sz &gt;&gt; <span class="number">1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (gap)  &#123;</div><div class="line">        <span class="comment">//所有间隔gap的元素为一组，第一个元素不排序，所以跳过gap</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> i=gap; i&lt;sz; ++i)  &#123;</div><div class="line">            <span class="keyword">int</span> elem = store[i];</div><div class="line">            <span class="keyword">int</span> j = i;</div><div class="line"></div><div class="line">            <span class="keyword">while</span> ( j&gt;=gap &amp;&amp; elem &lt; store[j-gap] ) &#123;</div><div class="line">                store[j] = store[j-gap]; <span class="comment">//移动gap</span></div><div class="line">                j -= gap;</div><div class="line">            &#125;</div><div class="line">            store[j] = elem;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        gap &gt;&gt;= <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　目前关于增量/increment的选择还没有统一的方法。希尔排序的时间复杂度是O(n^(3/2))。<br>　　由于记录是跳跃式的移动，所以希尔排序并不是一种稳定的排序算法。</p>
<h2 id="2-6_堆排序">2.6 堆排序</h2><p>　　堆排序就是利用堆这种数据结构，实现的对简单选择排序进行的一种改进。<br>　　堆结构是具有下列性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆；或者每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。根结点一定是堆中所有结点最大（小）者，而同时较大（小）的结点也较靠近根结点。<br>　　对于一个满二叉树，根据其性质有：对于结点n，其双亲是结点[n/2]；对于节点i，其左右子树是2i和2i+i。<br>　　下面以大顶堆方法排序为例，其基本思路就是：将待排序列构造成一个大顶堆，此时整个序列的最大值就是堆顶的根结点。将它移走（其实就是将其与堆数组的末尾元素交换，此时末尾元素就是最大值），然后将剩余的n-1个序列重新构造成一个大顶堆(调整使其成为大顶堆)，这样就会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">buildHeap</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, <span class="keyword">size_t</span> curr<span class="comment">/*父*/</span>, <span class="keyword">size_t</span> last<span class="comment">/*尾，包含*/</span>)</span> </span>&#123;</div><div class="line">    <span class="keyword">size_t</span> child = <span class="number">2</span>*curr + <span class="number">1</span>; <span class="comment">//左孩</span></div><div class="line">    <span class="keyword">int</span> elem = store[curr];</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (child &lt;= last) &#123;</div><div class="line">        <span class="comment">//两个儿子中较大的</span></div><div class="line">        <span class="keyword">if</span> (child&lt;last &amp;&amp; store[child]&lt;store[child+<span class="number">1</span>]) </div><div class="line">            ++child;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (elem &gt;= store[child]) </div><div class="line">            <span class="keyword">break</span>;</div><div class="line"></div><div class="line">        <span class="comment">// 元素交换，同时递归到子节点，另外一个儿子不用管了</span></div><div class="line">        store[curr] = store[child];</div><div class="line">        curr = child;</div><div class="line">        child = <span class="number">2</span>*curr + <span class="number">1</span>;    </div><div class="line">    &#125;</div><div class="line"></div><div class="line">    store[curr] = elem;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> sz = store.size();</div><div class="line"> </div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=((sz<span class="number">-1</span>)<span class="number">-1</span>)/<span class="number">2</span>; i&gt;=<span class="number">0</span>; --i) <span class="comment">// 首先建立堆</span></div><div class="line">        buildHeap(store, i, sz<span class="number">-1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=sz<span class="number">-1</span>; i&gt;<span class="number">0</span>; --i) &#123;</div><div class="line">        <span class="built_in">std</span>::swap(store[<span class="number">0</span>], store[i]);</div><div class="line">        buildHeap(store, <span class="number">0</span>, i<span class="number">-1</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面从L-&gt;length/2开始就是因为这里需要处理的是有孩子的节点。在HeapAdjust中的关键操作，就是从底向顶，递归的将两个孩子和父节点中最大值放到父节点上面，最终堆顶就是最大值了，然后交换到数组的尾部。<br>　　构建和调整堆的时间复杂度为O(logn)，所以总体来说堆排序的时间复杂度为O(nlogn)。由于记录的比较与交换是跳跃式进行，因此堆排序也是一种不稳定的排序方法。</p>
<h2 id="2-7_归并排序">2.7 归并排序</h2><p>　　归并在数据结构中的定义是将两个或两个以上的有序表组合成一个新的有序表的过程。<br>　　归并排序的原理是假设初始序列n个记录可以看成是n个有序子序列，每个子序列长度为1，然后两两归并，得到不小于n/2的整数个长度为2或1的有序子序列；再两两归并递归下去，……，如此重复直到得到一个长度为n的有序序列为止，这种排序方法称为2路归并排序。<br>　　具体操作是先分开进行do_merge_sort，然后再进行do_merge_merge进行合并，是一个很典型的递归调用形式。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_merge_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store,</span></span></div><div class="line">                    <span class="keyword">size_t</span> beg, <span class="keyword">size_t</span> last) &#123;</div><div class="line">    <span class="keyword">if</span> (beg &lt; last) &#123;</div><div class="line">        <span class="keyword">size_t</span> mid = (beg + last) / <span class="number">2</span>;</div><div class="line">        do_merge_sort(store, beg, mid);</div><div class="line">        do_merge_sort(store, mid+<span class="number">1</span>, last);</div><div class="line">        do_merge_merge(store, beg, last, mid);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_merge_merge</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, </span></span></div><div class="line">                    <span class="keyword">size_t</span> beg, <span class="keyword">size_t</span> last, <span class="keyword">size_t</span> mid<span class="comment">/*included in first*/</span>)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">size_t</span> index_1 = beg, index_2 = mid+<span class="number">1</span>;</div><div class="line">    <span class="keyword">size_t</span> index_s = <span class="number">0</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; tmp_vec(last - beg + <span class="number">1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (index_1 &lt;= mid || index_2 &lt;= last ) &#123;</div><div class="line">        <span class="keyword">if</span> (index_1 &gt; mid) &#123;</div><div class="line">            <span class="keyword">while</span> (index_2 &lt;= last)</div><div class="line">                tmp_vec[index_s ++] = store[index_2++];</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (index_2 &gt; last) &#123;</div><div class="line">            <span class="keyword">while</span> (index_1 &lt;= mid)</div><div class="line">                tmp_vec[index_s ++] = store[index_1++];</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span>&#123;</div><div class="line">            <span class="keyword">if</span> (store[index_1] &lt; store[index_2])</div><div class="line">                tmp_vec[index_s ++] = store[index_1++];</div><div class="line">            <span class="keyword">else</span></div><div class="line">                tmp_vec[index_s ++] = store[index_2++];</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">//将最终的结果拷贝到对应的区段</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;tmp_vec.size(); ++i)</div><div class="line">        store[beg+i] = tmp_vec[i];</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　归并中需要对所有元素进行扫描合并，所以复杂度是O(n)，同时由于是二叉树类似的层次结构，所以递归遍历需要O(logn)，整体的时间复杂度是O(nlogn)。<br>　　在归并排序中只有两两比较，不存在跳跃操作，因此归并排序是一种稳定的排序算法。</p>
<h2 id="2-8_快速排序">2.8 快速排序</h2><p>　　快速排序又名分区排序，其实是冒泡排序的升级，同属于交换排序类。快速排序增大了比较和移动的距离，将较大的记录从前面直接移动到后面，较小的记录从后面直接移动到前面，从而减少了总的比较次数和移动交换次数。<br>　　快速排序基本思想：每次选择一个基准数据，通过一趟排序将待排记录分割成独立两部分，其中一部分记录均比另一部分记录小，然后分别对这两部分记录继续进行排序，最终以达到整个序列有序。<br>　　快速排序的核心思想就是数据分区、递归调用。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_quick_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store, <span class="keyword">size_t</span> left, <span class="keyword">size_t</span> right)</span> </span>&#123;</div><div class="line">    <span class="keyword">size_t</span> i=left, j=right;</div><div class="line">    <span class="keyword">int</span> pivot = store[i];</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (i&lt;j) &#123;</div><div class="line">        <span class="keyword">while</span> (i&lt;j &amp;&amp; store[j] &gt; pivot)</div><div class="line">            --j;</div><div class="line">        <span class="keyword">if</span> (i&lt;j)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[j]); <span class="comment">//pivot == store[j]</span></div><div class="line"></div><div class="line">        <span class="keyword">while</span> (i&lt;j &amp;&amp; store[i] &lt; pivot)</div><div class="line">            ++i;</div><div class="line">        <span class="keyword">if</span> (i&lt;j)</div><div class="line">            <span class="built_in">std</span>::swap(store[i], store[j]); <span class="comment">//pivot == store[i]</span></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (left != i)</div><div class="line">        do_quick_sort(store, left, i - <span class="number">1</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (right != j)</div><div class="line">        do_quick_sort(store, j + <span class="number">1</span>, right);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面的while循环是整个快速排序的核心部分，设计的比较的巧妙，在右边查找比pivot小的元素，然后将其交换到前半部[i]的位置，再在前面查找比pivot大的值，将其交换到后半部[j]的位置，整个过程中所有的数据移动都是高效有作用的。当检查的目标i、j中间交汇的时候，本轮排序结束。<br>　　在最优的情况下(pivot的值选择刚好在整个排序范围的中间)，快速排序算法的时间复杂度为O(nlogn)；在最坏的情况下，其时间复杂度为O(n^2)；平均情况下快速排序的时间复杂度是O(nlogn)。<br>　　由于关键字的比较和交换是跳跃进行的，快速排序是一种不稳定的排序方法。<br>　　pivot枢轴的选取对于整个排序算法的性能至关重要，基本算法都是选择左边第一个值来作为pivot的，其他衍生算法可以对pivot值得选取做个考究。</p>
<h2 id="2-9_线性时间排序">2.9 线性时间排序</h2><h3 id="2-9-1_计数排序">2.9.1 计数排序</h3><p>其基本算法如下：<br>　　(1). 取出待排序列中的最小值n1和最大值n2，建立一个n2-n1+1长度的数组；<br>　　(2). 依次遍历待排元素，根据待排元素的值将对应数组项计数自增；<br>　　(3). 这步比较关键，统计数组计数，每项保存前N项和count_arr[k] += count_arr[k-1];这其实是进行了值到最终排列位置的映射关系；<br>　　(4). 再依次遍历待排元素，根据元素值查找count_arr中对应的最终排序位置，计入到排序结果中。<br>缺点是空间要求比较大。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">do_sort</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; store)</span> override </span>&#123;</div><div class="line">    <span class="keyword">auto</span> it = <span class="built_in">std</span>::max_element(store.cbegin(), store.cend());</div><div class="line">    <span class="keyword">int</span> max_item = *it;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; result(store.size());</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; bucket(max_item + <span class="number">1</span>);</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; elem: store)</div><div class="line">        bucket[elem] ++;</div><div class="line"></div><div class="line">    <span class="comment">// 关键，调整计数针对索引</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i=<span class="number">1</span>; i&lt;bucket.size(); ++i)</div><div class="line">        bucket[i] += bucket[i<span class="number">-1</span>];</div><div class="line"></div><div class="line">    <span class="comment">//得到元素位置，保留结果</span></div><div class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; elem: store)</div><div class="line">        result[bucket[elem] - <span class="number">1</span>] = elem;</div><div class="line"></div><div class="line">    store = result;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="2-9-2_桶排序">2.9.2 桶排序</h3><p>　　桶排序是计数排序的升级版，通过一个映射函数将待排数据分配到各个桶里面，然后桶内部如果大于一个元素可以采用快速排序等操作方式；最后实现桶数据的合并；<br>　　(1). 设置桶的数目：bucketCount = Math.floor((maxValue - minValue) / bucketSize) + 1;<br>　　(2). 待排元素和桶的映射关系：buckets[Math.floor((arr[i] - minValue) / bucketSize)].push(arr[i]);<br>　　(3). 对桶进行从小到大的合并操作：arr.push(buckets[i][j]);<br>　　桶排序的f(k)值的计算，其作用就相当于快排中划分，已经把大量数据分割成了基本有序的数据块(桶)，然后只需要对桶中的少量数据做先进的比较排序即可。在内存足够的情况下桶的数目越多越好，确保每个桶中元素尽可能少甚至一个元素。</p>
<h3 id="2-9-3_基数排序">2.9.3 基数排序</h3><p>　　基数排序包括：从高位开始进行排序(MSD)和从低位开始进行排序(LSD)，大部分的例子都是LSD来排序的。其主要思路是从按照低位到高位，依次进行多次的桶排序，当最高位桶排序结束后，整个数据就是有序的了。</p>
<h1 id="三、排序算法小结">三、排序算法小结</h1><p>　　别人总结出来的排序算法选择的依据是：首先当数据量不大的时候选择插入或者选择排序，不要用冒泡排序；其次，当数据量大而又注重空间复杂性的生活，选择快速排序或者堆排序；再次，当数据量大有允许使用较多附加空间的时候，可以选择桶排序；最后，当在已经排序的记录上添加新的数据的时候，选择插入排序。<br>　　稳定性来看，对于非常在乎排序稳定性的应用中，归并排序是个好算法。</p>
<p>　　整理后的代码已经上传了，同样欢迎Review。</p>
<p><div class="github-widget" data-repo="taozhijiang/learncpp"></div><br>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据结构和算法（三）：红黑二叉树]]></title>
      <url>https://taozj.org/201611/data-structure-and-algorithm-(3)-rbtree.html</url>
      <content type="html"><![CDATA[<p>　　AVL自平衡二叉树在教科书上比较常见，因为是最先提出的自平衡二叉树，自然是学术价值比较的高，但是目前工业环境觉得名为红黑二叉树(Red-Black Tree)的自平衡二叉树使用的更为的广泛，比如C++标准库中的有序容器(std::set、std::map)，Linux内核中的很多数据结构等，都是用的RBTree来维护管理的。<br>　　当看完RBTree后发现，其实相对来说AVL自平衡树比RBTree更加的平衡，理论上访问效果也会更好，但是为此AVL自平衡树在插入、删除修改树结构的时候，会引入更多的旋转操作来保持平衡，所以对于经常需要添加、删除的高动态数据来说，维护这种数据结构的代价显得十分高昂，而RBTree对于树的高度限制相对要宽松的多，等于是在牺牲了部分完全性(平衡性)的条件下，以换取插入、删除操作时少量的旋转操作(但是一调整起来复杂的情况麻烦的要死~~~)。</p>
<h1 id="一、红黑二叉树简介">一、红黑二叉树简介</h1><p>　　说到红黑二叉树，不得不先请出红黑树的基本法则，虽然简单，但是维护起来还是挺复杂的：<br>　　(1). 节点都有颜色标记，且只能是红色或黑色。<br>　　(2). 根是黑色。<br>　　(3). 所有叶子都是黑色（叶子是NIL/nill_节点，不保存实际的数据）。<br>　　(4). 每个红色节点必须有两个黑色的子节点，也可以表述为从每个叶子到根的所有路径上不能有两个连续的红色节点。<br>　　(5). 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。<br>　　上述这些条件中，(1)(3)是很容易遵守的，(2)只有确实在操作到根节点的时候需要注意调整一下就行了，而(4)(5)是维持红黑树结构中常常会用到的准则。<br>　　之所以要有上面的条件和规则，就是为了这么一个保证：从根到任何一个叶子，最好的情况是整条路径全部都是黑色，假设为N，最坏的情况是黑色和红色交替的情况，那也不会超过2N，因此红黑二叉树对操作的复杂度作出了最差的保证。而维护这种数据结构，需要少量的颜色变更和不超过三次树旋转（对于插入操作最多是两次），虽然插入和删除很复杂，但操作时间复杂度仍可以保持为O(log n)而不会因为元素的数目增加而性能恶化。<br>　　之一个典型的红黑二叉树的样子。<br><img src="/post_images/images/201611/744553b4a5777c5a5e3c28140ce5ec01.jpg" alt="一个典型的红黑二叉树"><br><a id="more"></a></p>
<h1 id="二、红黑二叉树实现">二、红黑二叉树实现</h1><p>　　此处还需要事先强调一下，红黑树再复杂也是一个基本的BST，所以和AVL自平衡二叉树一样，所有的插入和删除操作，也是先按照操作BST的基本方式进行插入、删除，然后再检查是否平衡而做出相应调整，RBTree的调整操作包括着色重绘和旋转操作。</p>
<h2 id="2-1_节点数目">2.1 节点数目</h2><p>　　红黑二叉树的通用节点数据结构为<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> RBNode &#123;</div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">int</span> data_;</div><div class="line">    SmartNodePtr left_;</div><div class="line">    SmartNodePtr right_;</div><div class="line">    SmartNodePtr parent_;</div><div class="line">    <span class="keyword">enum</span> Color color_;</div><div class="line">    ...</div><div class="line">    &#125;;</div></pre></td></tr></table></figure></p>
<p>　　和之前的AVL平衡二叉树一样，节点所有指针域都使用了智能指针，这样在删除的时候只需要更改指针域，智能指针维护引用计数，并在必要的时候自动析构节点并释放内存。但和AVL Tree节点不同的是，这里多了一个parent_节点，因为在后面对RBTree做维护的时候，会有大量涉及到父亲、兄弟节点的操作，而这些亲戚节点的访问，以及当前处于左还是右子树的判断，都需要parent_域辅助完成。</p>
<h2 id="2-2_插入操作">2.2 插入操作</h2><p>　　规定，新增加的节点着色必须是红色。插入操作分以下情况：<br>　　(1). 如果此时还是空的红黑树，则该节点为根节点，将其重绘为黑色，然后返回；否则进行步骤(2)<br>　　(2). 根据BST递归查找，找到可以插入的位置时候，创建新节点后进行BST插入(更新parent_、left_、right_指针域)，然后进行步骤(3)<br>　　(3). 如果父亲节点P是黑色，此时红色节点作为孩子是允许的，红色节点的加入不会影响黑色路径的计数，原先父亲的叶子节点黑色由新插入节点的叶子节点继承，对于(4)(5)规则没有任何影响，操作完成直接返回；否则进行步骤(4)<br>　　(4). 父亲节P点是红色的，如果此时叔父节点U也是红色的，而且此刻确定祖父节点G是黑色的，进行如下操作：将祖父节点G重绘为红色，将父亲P和叔父节U点重绘为黑色，此处操作虽然子树平衡了，但是修改了祖父节点G可能导致祖父节点G和其他节点不平衡，以祖父节点G为参数重新进入步骤(3)检查递归；否则进行(5)<br><img src="/post_images/images/201611/7eed920d3313cc32b5adce8f3ae5ae9d.png" alt="插入1">  <!--more--><br>　　(5). 此时父节点P是红色、叔父节点U是黑色、祖父节点G是黑色、新增节点N是红色，根据插入节点N是父亲节点G的左孩子还是右孩子，以及父亲节点P是祖父节点G的左孩子还是右孩子分别组合，一共形成四种情况，依次处理<br>　　　　a. 如果祖父节点G、父亲节点P、插入节点N在一条直线上，即插入节点N是父亲节点P的左孩子且父节点P是祖父节点G的左孩子，或者镜像情况下插入节点N是父亲节点P的右孩子且父亲节点P是祖父节点G的右孩子，此时只需将祖父节点G改为红色，父亲节点P改为黑色，然后以祖父亲节点G为中心做一个相反方向的旋转就可以了；<br><img src="/post_images/images/201611/33b286dcf5c8b483bd3c503bd9b90d8f.png" alt="插入2"><br>　　　　b. 如果祖父节点G、父亲节点P、插入节点N不在一条直线上，此时需要以父亲节点P为中心，事先进行一次旋转使得祖父节点、父亲节点、插入节点三者在一条直线上，然后就可以按照a的情况所对应的步骤进行处理了；<br>至此，红黑树的插入操作完成。<br><img src="/post_images/images/201611/046bcb436a2b8e3b595823444f319ccc.png" alt="插入3"></p>
<h2 id="2-3_删除操作">2.3 删除操作</h2><p>　　红黑树的删除操作算是比较复杂的数据结构操作了，分出的情况比较的多，而且操作过程中涉及到的亲戚节点也比较多。<br>　　此处需要说明的是，所有BST的删除操作，都可以转换看作是单个子树的删除操作，因为删除的节点只可能有三种情况：叶子节点，这时候可以将任意一个NIL节点看做单个子树；含有一个子树的节点；含有两个子树的节点，此时按照BST的删除操作，还是会寻找一个左子树最大值或者右子树最小值替换他，并将替换节点重绘成删除节点的颜色，然后问题实质上就转化成替换节点的删除了，而替换节点不可能有两个子树的情况。<br>　　(1). 如果整个RBTree为空，直接返回；否则进入(2)<br>　　(2). 查找当前节点是否待删除节点，如果不是递归进行左树或者右树删除，如果遍历完了还未找到直接返回，否则当前就是待删除节点，进入步骤(3)<br>　　(3). 如果当前待删除节点的右子树为空，表明无法找到一个用于替换的右子树最小值节点，直接进入步骤(4)，否则查找右子数最小节点，和当前节点进行数据部分的交换(而位置关系、着色得以保留)，然后将待删除节点设置为替换节点，进入步骤(4)，至此我们找到了需要真正进行删除操作的节点N<br>　　(4). 寻找当前删除节点node的非NIL子树(如果当前节点两个孩子都是NIL那就选随便选一个假设为非NIL)作为child，然后判断当前节点是否是根节点而需要做特殊处理(此处不展开这种情况，只考虑一般的删除节点)，对于一般的删除情况，通过将node父节点指针引用到child而使用child顶替当前删除节点node，node的引用计数减少(后续会被自动析构释放)，而且此时如果删除掉的节点node是红色的，那么表明被删除节点的父亲和孩子child都是黑色的，最主要的是删除一个红色节点不影响RBTree的规则，此处就可以直接返回了；否则进入步骤(5)<br>　　(5). 此处删除掉的节点node是黑色的，而如果替换的child是红色的，那么将孩子重绘为黑色，这样原来通过黑色删除节点的路线现在都由孩子去作为黑色节点顶替了，红黑树的特性没有被破坏，直接返回；否则进入步骤(6)<br>　　(6). 进入步骤(6)就是传说中最复杂的double black情况了，在所有讨论之前这里先声明，到达这里节点的删除工作已经完成，接下来的都是调整工作了。我们将主角命名为N，其本质就是(4)操作中顶替的child节点，原先的祖父节点现在是父亲节点，原先的叔父节点现在是兄弟节点，且此时节点N是黑色的。检测兄弟节点S如果是红色，那么父亲节点P肯定是黑色，此时重绘父亲节点P成红色，重绘兄弟节点S为黑，并且如果N是父亲节点P的左儿子，则以父亲节点P为中心进行左旋操作，否则进行右旋操作，经过这一步调整，N有了一个黑色的兄弟节点和一个红色的父亲节点，但是N和现在兄弟节点S原来的儿子(现在的兄弟)挂着子树上黑色节点的数目肯定不一样，子树是不平衡的，所以还需要继续进行下面的处理，进入步骤(7)<br><img src="/post_images/images/201611/bbd92ab3423061707a0c83470fbe6aa6.png" alt="删除1"><br>　　(7). 无论是原生的还是经过步骤(6)修改得到的，此处兄弟节点S是黑色、N是黑色，然后检查兄弟节点S的两个孩子的颜色，如果兄弟节点S的两个孩子都是黑色，那么就根据父亲节点P的颜色进行讨论<br>　　　　a.如果此时父亲节点P的颜色是红色，则重绘兄弟节点S成红色、重绘父亲节点P成黑色，通过这样后原先删除掉的黑色节点就由父亲节点P补偿回来了，而兄弟节点S的整个分支没有改变，满足红黑树条件，就直接返回；<br><img src="/post_images/images/201611/c08a95731367c6d1a394aced9c7e4f23.png" alt="删除2"><br>　　　　b.如果父亲节点P的颜色是黑色，则重绘兄弟节点S成红色，此时虽然得到的整个子树是平衡的，但是原先经过兄弟节点S的子树都减少了一个黑色，此处需要以父亲节点P为参数步入步骤(4)重新调整；<br><img src="/post_images/images/201611/d608f57fc2ca75812d83e83835cd1ad1.png" alt="删除3"><br>　　如果兄弟节点S的两个孩子不都是黑色，此时步入步骤(8)<br>　　(8). 此时兄弟节点S是黑色、N是黑色，而且兄弟节点S的两个孩子至少有一个是红色的，但是父亲节点P多次递归已经不确定颜色了，然后当Parnet-Sibling-r_child不在一条线上面时(此时兄弟节点S的孩子由一个红色和一个黑色构成的时候，假设红色孩子记为r_child)，需要先旋转成一条线，同时进行颜色的修正，把兄弟节点S改成红色且r_child改成黑色，经过这个旋转后的子树是满足二叉树性质的，但是N和新的兄弟节点S不平衡(本身这个操作不会涉及到N和父亲节点P)，而且这个不平衡的情况刚好会fall through到下面步骤(9)的情况处理；而如果Parnet-Sibling-r_child在一条线上面(这其实就是前面旋转着色后的结果)，直接进入步骤(9)处理<br><img src="/post_images/images/201611/0fb332761a9fc0383ab7db9dafe01ebf.png" alt="删除4"><br>　　(9). 此时兄弟节点S是黑色，且依次挂了红色孩子、黑色孙子一条线的子树，操作是通过以父亲节点P为中心进行旋转，让原来的兄弟节点S代替父亲节点P的颜色，同时重绘原来父亲节点P成黑色，重绘原来兄弟节点S的孩子成黑色。<br>　　由于原先的父亲节点P和现在兄弟节点S的颜色是不确定的，无非做两种情况进行讨论：a. 父亲节点P原先是黑色的；b. 父亲节点P原先是红色的，看图可以直接分析出来，修改之后这条子树到其所有子叶的黑色节点数目和原先都是一样的，满足红黑树条件，删除结束。<br><img src="/post_images/images/201611/537c20030520400b68eba43c293af5ca.png" alt="删除5"></p>
<p>　　按照维基百科的<a href="https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91" target="_blank" rel="external">红黑树</a>解释的代码，自己修改整理了一下并附上注释，代码已经上传了，欢迎各位Review。</p>
<div class="github-widget" data-repo="taozhijiang/learncpp"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91" target="_blank" rel="external">红黑树</a></li>
<li><a href="http://blog.csdn.net/kartorz/article/details/8865997" target="_blank" rel="external">红黑二叉树详解及理论分析</a></li>
<li><a href="http://www.geeksforgeeks.org/red-black-tree-set-2-insert/" target="_blank" rel="external">Red-Black Tree | Set</a></li>
<li><a href="https://www.cs.usfca.edu/~galles/visualization/RedBlack.html" target="_blank" rel="external">visualization/RedBlack</a></li>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据结构和算法（二）：AVL自平衡二叉树]]></title>
      <url>https://taozj.org/201611/data-structure-and-algorithm-(2)-avl.html</url>
      <content type="html"><![CDATA[<h1 id="一、二叉树的基础知识">一、二叉树的基础知识</h1><h2 id="1-1_二叉树">1.1 二叉树</h2><p>　　二叉树(Binary Tree)是n个结点的有限集合，该集合或者为空集，或者由一个根节点和两棵互不相交的、分别称为根节点的左子树和右子树的二叉树组成，且二叉树的左右要求是有顺序的。</p>
<h3 id="1-1-1_特殊种类的二叉树">1.1.1 特殊种类的二叉树</h3><p>　　(1). 斜树：所有的结点都只有左子树的二叉树称为左斜树，所有结点都只有右子树的二叉树称为右斜树。<br>　　(2). 满二叉树：在一棵二叉树中，如果所有分支节点都存在左子树和右子树，而且所有叶子都在同一层上，称为满二叉树。<br>　　(3). 完全二叉树：对一棵具有n个节点的二叉树按层序编号，如果编号为i的结点与同样深度的满二叉树中编号为i的结点在二叉树中位置完全相同，称为完全二叉树。在实际操作上，就是按照从上到下、从左到右这种层次顺序遍历各个元素，如果该出现元素的位置出现了空档，则不是完全二叉树。<br>　　根据定义我们可知，满二叉树是完全二叉树的一种特殊情况。</p>
<h3 id="1-1-2_二叉树的性质">1.1.2 二叉树的性质</h3><p>　　这里主要总结了二叉树结构中，数据元素、高度、父子节点位置的信息：<br>　　(1). 在二叉树的第i层上至多有2^(i-1)个结点。<br>　　(2). 深度为k的二叉树最多有2^k-1个结点。<br>　　(3). 对任何一棵二叉树T，如果其终端结点数为n0，度为2的结点数为n2，则n0=n2+1。<br>　　(4). 具有n个结点的完全二叉树的深度为[log2(n)]+1，其中[x]表示不大于x的最大整数。满二叉树的度数k=log2(n+1)。<br>　　(5). 对一棵有n个结点的完全二叉树按照层序编号(从1层到[log2(n)]+1层，每层从左到右)，对任意一节点i，则有：<br>　　　　a. 如果i=1，则i是二叉树的根，无双亲；<br>　　　　b. 如果i&gt;1，则其双亲是结点[i/2]；<br>　　　　c. 如果2i&gt;n，则结点i无左孩子(结点i为叶子节点)，否则其左孩子是节点2i；<br>　　　　d. 如果2i+1&gt;n，则节点i无右孩子，否则其右孩子为结点2i+1。<br>　　通常顺序方式(数组)存储二叉树结构也是十分的常见的，如果按照完全二叉树从顶部分层遍历的，所以上面列出的二叉树的孩子和父亲之间的位置关系，也就对应了在数组中元素的索引值，这在堆排序中会被应用的最为典型。</p>
<h3 id="1-1-3_遍历二叉树">1.1.3 遍历二叉树</h3><p>　　二叉树的遍历是指从根结点出发，按照某种次序依次访问二叉树中的所有结点，使得每个结点都被访问到一次且仅被访问一次。<br>　　(1). 前序遍历：先访问根节点，然后前序遍历左子树，再前序遍历右子树；<br>　　(2). 中序遍历：从根节点开始，中序遍历根节点的左子树，然后访问根节点，最后中序遍历右子树；<br>　　(3). 后序遍历：从左到右先叶子后结点的方式遍历访问左右子树，最后访问根节点；<br>　　(4). 层序遍历：从树的第一层开始，从上而下逐层遍历，在同一层次中，按照从左到右的顺序对结点逐个访问。<br>　　二叉树的遍历虽然在语言上描述起来较为的复杂，其实代码实现上极为的简单，就是左树递归、右树递归、根元素访问三种操作顺序的排列组合的结果而已；而且，对于前序递归，其输出则是得到的元素从小到大排列的：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">pre_order</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node) <span class="keyword">return</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span>&lt;&lt;node-&gt;data_&lt;&lt;<span class="string">", "</span>;</div><div class="line">    pre_order(node-&gt;left_);</div><div class="line">    pre_order(node-&gt;right_);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　当给定条件需要重建二叉树的时候，已知前序遍历序列和中序遍历序列，就可以唯一确定一棵二叉树；已知后序遍历序列和中序遍历序列，业可以唯一确定一棵二叉树；但是已知前序遍历序列和后序遍历序列，不能确定一棵二叉树。<br><a id="more"></a></p>
<h2 id="1-2_二叉排序树(Binary_Sort_Tree,_BST)">1.2 二叉排序树(Binary Sort Tree, BST)</h2><h3 id="1-2-1_二叉排序树的性质">1.2.1 二叉排序树的性质</h3><p>　　二叉排序树又称为二叉查找树，其如果不是空树，BST其具有以下性质(很显然，这是一个二叉树组织的递归定义)：<br>　　(1). 如果左子树不为空，则左子树上所有的节点都小于它的根结构的值；<br>　　(2). 若右子树不为空，则右子树上所有的节点都大于它的根结构的值；<br>　　(3). 其左右子树也分别是二叉排序树。</p>
<h3 id="1-2-2_二叉排序树的操作">1.2.2 二叉排序树的操作</h3><p>　　二叉排序树的操作包括查找、插入和删除，其中查找就是根据当前给定的键值和每个节点比较是否相等，如果不相等根据大小关系递归在左右子树上面去查找，这里我想到C++的很多标准库中表明，当查找某个值如果没有找到的话，其返回就是该值可以被插入的位置，此时想来不无道理。<br>　　插入操作和查找比较类似，也比较的简单，而删除的时候需要根据删除节点的情况分类来对待：<br>　　(1). 如果要删除的节点是叶子节点，其没有任何子树，那么就直接删除之；<br>　　(2). 如果要删除的节点仅有左子树或者仅有右子树，那么就将其对应的左子树或者右子树这个非空子树整个移动到删除节点的位置，以完成独子承父业；<br>　　(3). 如果要删除的节点其左右子树都有节点，具体的做法可以选择：<br>　　　　a. 要么沿着要删除节点的左子树，一直向右走，找出最右的节点，取出来替换该删除节点；<br>　　　　b. 或者沿着删除节点的右子树，一直向左走，找出最左的节点，然后替换之。<br>　　上面最后一种情况的删除原理，其实就是寻找待删除节点大小最相临的前驱或后驱来直接替代它，替代后整个二叉树还是保持有序的状态，同时替换的节点由于是选择的最左或者最右节点，其最多也就只有一个子数，所以替换节点的删除本身也是十分方便的，采用上面(2)的情况处理就可以了。<br>　　二叉树的性能取决于二叉树的层数，最好的情况是O(logn)，存在于完全二叉树情况下，其访问性能近似于折半查找；最差时候会是O(n)，比如在斜树的情况下，需要逐个遍历二叉树的元素才行。</p>
<h2 id="1-3_自平衡二叉树(AVL)">1.3 自平衡二叉树(AVL)</h2><p>　　前面说到，二叉树的查找、插入、删除操作的性能十分依赖于树的高度，所以如果能把树维持在一个完全二叉树的情况下，当然是最理想最高效的情况，所以在增加和删除这种会修改二叉树结构的操作中，能检测修改后的二叉树状态并修正之，限制二叉树的高度，即为平衡二叉树。<br>　　现实中绝对完全二叉树结构是很难维持的，而AVL作为最先发明的自平衡二叉树，通过对每个节点的左、右子树之间的高度差作出限定，同时在插入、删除的时候对不满足限定的子树进行一定的操作，以达到限制树的高度，从而保证其最优的查找性能。<br>　　AVL自平衡二规定每一个节点的左子树和右子树的高度差至多等于1，同时将二叉树上节点左子树高度减去右子树高度的值称为平衡因子BF，所以平衡的二叉树所有节点的平衡因子取值只可能是-1、0、1。<br>　　其它关于AVL自平衡二叉树的相关详细信息，将在下面实现部分再予以描述。</p>
<h1 id="二、实现平衡二叉树">二、实现平衡二叉树</h1><p>　　首先说道，AVL自平衡二叉树其本质上还是一个BST，所以AVL树的查找、添加和删除的基础操作都是上面描述到的BST的操作，只是在这些操作之后，需要修正节点的高度信息，在必要的情况下进行适当的操作来保证AVL树的约束。<br>　　本文借助于<a href="http://kukuruku.co/hub/cpp/avl-trees" target="_blank" rel="external">AVL Trees</a>的实现，探究AVL树的插入、删除的维护过程。</p>
<h2 id="2-1_旋转操作">2.1 旋转操作</h2><h3 id="2-1-1_基本旋转">2.1.1 基本旋转</h3><p>　　不仅仅是AVL，几乎所有的平衡二叉树都是通过旋转调整来实现的。在树的旋转中有左旋和右旋两个最基本的操作，而实际中针对左右左、右左右等结构采用的双旋转，其实也是这种原子操作的组合而已。<br><img src="/post_images/images/201611/71ad5dc7e6cd6c10b5fc683333257b73.jpg" alt="avl旋转"><br>　　看上面的图可知，左旋和右旋虽然结构表示不一，但是都保持了A&lt;x&lt;B&lt;y&lt;C的大小结构，两者可以互相旋转得到。比如在右图到左图的左旋操作中，则得到：y将成为新的根节点、原先的根节点x将成为y的左子树、y的右子树C不变，同时根据大小关系可知A&lt;q&lt;B，所以A和B分别成为q的左右子树；右旋情况也是类似的。<br>　　此时，A、B、C的子树都没有修改，而p、q的子树发生了变化，所以需要基于他们的子树修正p、q的高度。在传统学术上，AVL节点用一个字段保留记录平衡因子，但是这篇参考文章的作者建议保留树的高度信息height，因为一方面通过两个子树的height可以在需要的时候方便的计算出平衡因子，二来树的高度信息更新起来比较的方便明了，看看<a href="http://oopweb.com/Algorithms/Documents/AvlTrees/Volume/AvlTrees.htm" target="_blank" rel="external">AvlTrees</a>中维护平衡因子的分析就知道直接更新平衡因子是有多么麻烦了。不过这里的高度是一个绝对值，每次有修改的时候都必须让直接或者间接涉及到的节点全部更新调整，不过Nikolai Ershov的操作主要都是用递归方式来实现的，代码中绝大多数的操作都是返回修改或者平衡后的子树根节点，在递归函数中调用fix-height/rebalance会从最底层的修改节点一直检查处理到根节点去。</p>
<h3 id="2-1-2_双旋转">2.1.2 双旋转</h3><p>　　双旋转通常在我们所称为的“左右左”或者“右左右”的情形下会发生，而这里也有专业的结论表示出来：当高度h(s)&lt;=h(D)的时候，只需要一次旋转就可以了，否则就需要两次旋转才能达到平衡(原文章作者的配图容易被误导，一定要仔细思考+想象！！！！)<br>　　(1). h(s)&lt;=h(D)，单次旋转<br><img src="/post_images/images/201611/baac94cdf73a6b6b2530c267f3ff3653.jpg" alt="一次旋转"><br>　　(2). h(s)&gt;h(D)，两次旋转<br><img src="/post_images/images/201611/71ad5dc7e6cd6c10b5fc683333257b73.jpg" alt="两次旋转"></p>
<p>　　比如下面左旋操作的代码，这里一定要注意操作的顺序，同时在修复高度的时候父节点的高度是根据子节点直接计算出来的，所以修复的时候一定要先修复子节点，再修复当前节点。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">rotate_left</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    SmartAvlNodePtr tmp_root = node-&gt;right_;</div><div class="line">    node-&gt;right_ = tmp_root-&gt;left_;</div><div class="line">    tmp_root-&gt;left_ = node;</div><div class="line">    </div><div class="line">    fix_height(node);</div><div class="line">    fix_height(tmp_root);</div><div class="line">    <span class="keyword">return</span> tmp_root; </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-2_插入操作">2.2 插入操作</h2><p>　　插入操作先是进行常规的BST插入，通过递归的方式查找插入点，然后创建新的节点，修改指针完成插入。<br>　　插入完成后，要沿着插入链沿着修改节点向树根的方向，递归调用rebalance调整树高度、计算平衡因子，并在必要的时候进行旋转修复操作。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">insert</span><span class="params">(SmartAvlNodePtr node, <span class="keyword">int</span> data)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node) &#123;</div><div class="line">        node = <span class="built_in">std</span>::make_shared&lt;AvlNode&gt;(data);</div><div class="line">        <span class="keyword">return</span> node;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    assert(data != node-&gt;data_);</div><div class="line">    <span class="keyword">if</span> (data &lt; node-&gt;data_) &#123;</div><div class="line">        node-&gt;left_ = insert(node-&gt;left_, data);</div><div class="line">        node = rebalance(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &gt; node-&gt;data_)&#123;</div><div class="line">        node-&gt;right_ = insert(node-&gt;right_, data);</div><div class="line">        node = rebalance(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> node;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function">SmartAvlNodePtr <span class="title">rebalance</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    </div><div class="line">    fix_height(node);</div><div class="line">    <span class="keyword">int</span> bal_factor = get_bal_factor(node);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (bal_factor &gt; <span class="number">1</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (get_bal_factor(node-&gt;right_) &lt; <span class="number">0</span>) <span class="comment">//rotate right first</span></div><div class="line">            node-&gt;right_ = rotate_right(node-&gt;right_);</div><div class="line">        <span class="keyword">return</span> rotate_left(node);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (bal_factor &lt; <span class="number">-1</span>) &#123;</div><div class="line">        <span class="keyword">if</span> (get_bal_factor(node-&gt;left_) &gt; <span class="number">0</span>) <span class="comment">//rotate right first</span></div><div class="line">            node-&gt;left_ = rotate_left(node-&gt;left_);</div><div class="line">        <span class="keyword">return</span> rotate_right(node);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> node;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-3_删除操作">2.3 删除操作</h2><p>　　平衡二叉树最复杂的就是删除操作了(包括后面的红黑树，其删除更加的复杂)，首先根据BST的基本删除方法，进行左右子树递归查找要删除的节点，当找到待删除的节点的时候：<br>　　(1). 如果要删除的当前节点没有右子树，那么用其左孩子代替它的方式来直接删除之；否则<br>　　(2). 查找右子树中最小节点，用这个最小节点替代当前节点的方式来删除该节点，同时从替代节点原位置开始，递归修复树的高度和平衡关系。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function">SmartAvlNodePtr <span class="title">remove_right_min</span><span class="params">(SmartAvlNodePtr node)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (!node-&gt;left_)</div><div class="line">        <span class="keyword">return</span> node-&gt;right_;</div><div class="line">    node-&gt;left_ = remove_right_min(node-&gt;left_);</div><div class="line">    <span class="keyword">return</span> rebalance(node);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function">SmartAvlNodePtr <span class="title">remove</span><span class="params">(SmartAvlNodePtr node, <span class="keyword">int</span> data)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (data &lt; node-&gt;data_)</div><div class="line">        node-&gt;left_ = remove(node-&gt;left_, data); </div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (data &gt; node-&gt;data_)</div><div class="line">        node-&gt;right_ = remove(node-&gt;right_, data);</div><div class="line">    <span class="keyword">else</span></div><div class="line">    &#123;</div><div class="line">        <span class="keyword">if</span> (!node-&gt;right_)</div><div class="line">            <span class="keyword">return</span> node-&gt;left_;</div><div class="line"></div><div class="line">        SmartAvlNodePtr repl = find_right_min(node-&gt;right_);</div><div class="line">        repl-&gt;right_ = remove_right_min(node-&gt;right_);</div><div class="line">        repl-&gt;left_  = node-&gt;left_;</div><div class="line">        <span class="keyword">return</span> rebalance(repl);</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> rebalance(node);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面remove操作实际进行的步骤为:<br>　　a. find_right_min采用遍历的方式，实现在待删除节点的右子树种寻求最小的节点，作为选定的替换种子节点；<br>　　b. 调用一个remove_right_min的函数，注意这个函数也是一个递归函数，递归找到最小节点后用其右子树(无论是否为空)来替换这个节点以删除之，同时调用rebalance不断平衡直到待删除节点的右子树根部位置；<br>　　c. 修改repl的指针，接管待删除节点的左右子树资源；<br>　　d. 这个函数一旦返回(repl)，就用于顶替待删除节点在其父节点对齐引用，此时待删除节点智能指针引用递减(并被析构释放)；<br>　　e. 从删除节点的父节点开始，递归调用rebalance()到整个树的根，完成删除操作。</p>
<h2 id="2-4_小结">2.4 小结</h2><p>　　自认为讲清楚了，其实AVL还算是比较简单的自平衡二叉树了。<br>　　这里所有的节点都是使用智能指针管理的，所以看不到传统实现中那么多的new delete了，通过析构函数打印调试信息，发现删除的时候对象是被析构了，智能指针大法好！</p>
<p>整理后的代码已经上传了，欢迎各位大佬Review和拍砖!</p>
<div class="github-widget" data-repo="taozhijiang/learncpp"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://kukuruku.co/hub/cpp/avl-trees" target="_blank" rel="external">AVL Trees</a></li>
<li><a href="https://zh.wikipedia.org/wiki/AVL%E6%A0%91" target="_blank" rel="external">AVL树</a></li>
<li><a href="http://www.sanfoundry.com/cpp-program-implement-avl-trees/" target="_blank" rel="external">C++ Program to Implement AVL Trees</a></li>
<li><a href="http://oopweb.com/Algorithms/Documents/AvlTrees/Volume/AvlTrees.htm" target="_blank" rel="external">AVL Trees: Tutorial and C++ Implementation</a></li>
<li><a href="http://www.geeksforgeeks.org/avl-tree-set-1-insertion/" target="_blank" rel="external">AVL Tree | Set 1</a></li>
<li><a href="https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%85%83%E6%90%9C%E5%B0%8B%E6%A8%B9" target="_blank" rel="external">二叉搜索树</a></li>
<li><a href="https://www.cs.usfca.edu/~galles/visualization/AVLtree.html" target="_blank" rel="external">visualization/AVLtree</a></li>
<li><a href="https://book.douban.com/subject/26713270/" target="_blank" rel="external">算法之美——隐匿在数据结构背后的原理（C++版）</a></li>
<li><a href="https://book.douban.com/subject/6424904/" target="_blank" rel="external">大话数据结构</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[数据结构和算法（一）：hash散列容器]]></title>
      <url>https://taozj.org/201611/data-structure-and-algorithm-(1)-hash.html</url>
      <content type="html"><![CDATA[<h1 id="一、散列表基础知识">一、散列表基础知识</h1><p>　　散列技术常常用于键－值关系的数据结构中，比如数据库索引、map、缓存等地方，其是通过在记录(值)的存储位置和其关键字之间建立一个确定的对应关系f，使得每个关键字key对应一个存储位置f(key)。散列技术的实现方式决定了其最适合的求解问题是查找与给值相等的记录(是否存在及其位置)，而对于其他查找不适合：比如某个关键字对应很多记录的情况、范围查找、查找最值等。<br><img src="/post_images/images/201611/ae697cc26bdbc100874e3ed41611619e.jpg" alt="hash散列表"></p>
<h2 id="1-1_散列函数">1.1 散列函数</h2><p>　　散列函数可以说是散列数据结构的核心，最直接的感受就是好的散列函数能够让记录能够在hash表中分布均匀(uniform distribution)，当然用于相似性查找的特殊hash类别不考虑在内。此外，在我们平常习惯性的思维中，认为只要满足X != Y，则f(X)!=f(Y)就是好的满足条件的hash函数，比如常用的CRC函数，其实如果将这类函数用在hash中，大多数情况下要比精心设计的hash函数冲突的可能性更大，会影响到hash的效率和性能。</p>
<h3 id="1-1-1_散列函数通常具备条件">1.1.1 散列函数通常具备条件</h3><p>(1). 散列均匀分布：<br>　　由于空间的限制散列表不可能无限的大，而散列冲突的几率会因为空间的限制而增大，这个时候就需要一个perfect的散列函数来作为弥补，通常设计一个好的均匀分布的散列函数是比较困难的，这也是很多散列函数专家努力的方向。<br>　　在绝大多数场合下，散列表的容量都设计成2的指数长度大小，而算出来的散列值通常采用掩码的方式快速得到散列表的索引值，所以此时的散列函数可以设计优化成在二进制的各个bit位为随机分布就可以了。不过murmur的作者也说了，好的hash函数不应当假定其用户采用’hash % tablesize’的方式来hash-to-table-index，只是作为一种常用的习惯性方法而已。<br>(2). 计算简单高效：<br>　　hash值不应当过于的复杂，hash计算的吞吐量也是hash函数的一个重要衡量标准，除了在设计中不要用过于复杂的计算操作外，实用新式CPU的高效运算指令也是提升性能的一个方面。</p>
<h3 id="1-1-2_简单常用构造散列函数的方法">1.1.2 简单常用构造散列函数的方法</h3><p>　　(1). 直接定值法：就是利用元素的关键码设计成某个线性函数的形式，比如<br>　　　　f = a × key + b;<br>　　其计算简单而且不会冲突，但是需要事先知道关键码的在小范围连续分布比较适用；<br>　　(2). 数字分析法：抽取部分数字进行诸如：反转、左环位移、右环位移、前两数与后两数相加等各种操作，其也主要用于事先知道关键字分布且关键字位数较多且若干位分布比较均匀的情况；<br>　　(3). 平方取中法：关键字位数不多的情况，先对关键字平方计算，然后取其中的某些固定位组合；这其实在实际中常用的方法，采用先放大再抽取的方式，是一种伪随机数的生成方法；<br>　　(4). 折叠法：将数字串平均分几个部分后重叠(移位法)对齐或者折叠(分界法)对齐后求和，通常用在关键字位数较多的情况下；<br>　　(5). 除留余数法：也是最常用的，mod取模缩减散列空间，这个操作可以直接针对关键字，或者是其他操作后的中间结果；若散列表表长为m，通常p为小于或等于表长的最小质数或包含不小于20的质因子的合数，因为这样产生hash冲突的可能性要少的多；<br>　　(6). 乘余取整法：<br>    f(key) = { Z × (a × key % 1) }<br>a通常取黄金分割数0.6180339，%1表示取结果的小数部分，Z为散列表的容量；<br>　　(7). 随机数法：f(key) = random(key)，适合于关键字长度不等的情况。<br><a id="more"></a>  </p>
<h2 id="1-2_散列表的冲突处理">1.2 散列表的冲突处理</h2><p>　　散列表的冲突处理主要分为闭散列法和开散列法，闭散列法也称为开放定址法。</p>
<h3 id="1-2-1_闭散列法（开放定址法）">1.2.1 闭散列法（开放定址法）</h3><p>　　当插入元素的时候，一旦发生了散列冲突，就去寻找下一个空的散列地址供插入，而查找的时候逐个查找，直到碰到开放的地址查找失败。闭散列法是通过将冲突的元素以一定的模式存储在原散列的空间中。<br>　　之所以叫做闭散列法，就是因为冲突的元素没有开辟额外的存储空间，还是在原先hash表的空间范围之内。<br>　　(1). 线性探测法：将散列表看作是一个循环向量，若初始地址是f(key)=d，则依照顺序d、d+1、d+2…的顺序取查找，即f(key)=(f(key)+1)mod N;<br>　　(2). 二次探测法：基本思路和线性探测法一致，只是搜索的步长和方向更加的多样，会交替以两个方向，步长为搜索次数的平方来查找；<br>　　(3). 双重散列法：通常双重散列法是开放地址中最好的方法，其通过提供hash()和rehash()两个函数，前者产生冲突的时候，定制化后者rehash()重新寻址，其机制比前面两种固定格式的要灵活的多；<br>　　开放定址法一般用于冲突极少的情况，同时因为没有用到指针，所以对于数据的传输是友好的。</p>
<h3 id="1-2-1_开散列法">1.2.1 开散列法</h3><p>　　与前面闭散列法对应的开散列法，一般也叫作拉链法或者链地址法，通过将冲突的元素组织在链表中，采用链表遍历的方式查找。链地址法和上面的开放定址法最大的优势是解决方法直观，实现起来简单，尤其在删除元素的时候此处只是简单的链表操作，但是前面需要考虑后面可能有元素，处理会比较复杂。同事开散列法可以存储超过散列表容量个数的元素。<br>　　(1). 链地址法：相同散列值的记录放到同一个链表中，他们在同一个Bucket中；<br>　　(2). 公共溢出法：将所有的冲突都放到一个公共的溢出表中去，适用于冲突情况很小的时候。<br>　　除了使用传统的链表，还可以使用dynamic array的方式存储，分配的时候也可以预分配多个，以保证对CPU的缓存优化友好。</p>
<h2 id="1-3_散列表的装填因子">1.3 散列表的装填因子</h2><p>　　装填因子=填入表中的记录个数/散列表的长度，实践中无论设计多好的散列函数，当装填因子超过0.7后散列表的性能就会因为散列冲突开始下降，当填入表的记录越多，装填因子就越大，产生冲突的可能性也就越大。此时可以考虑增加hash表的容量，以维持查找的性能，而且更重要的是常常在实践中，是事先不知道需要管理元素的个数的，所以动态增加散列表的容量是必须的。<br>　　修改散列表容量会导致之前元素寻址失效，这个过程也成为resize(rehash)的过程，Java的HashMap在loadfactor&gt;3/4，以及Python的dict在loadfactor&gt;2/3的时候就会自动触发resize。实践中常常使用的方法有：</p>
<h2 id="1-3-1_整体拷贝所有元素">1.3.1 整体拷贝所有元素</h2><p>　　最直观明了简单粗暴的方式，通常会double散列表的容量，然后将所有元素全部散列拷贝到新的表中，然后释放旧的表，没有什么特别的技术含量。<br>还有，有的散列库提供shrink的功能，这样就可以当loadfactor小到某个程度的时候缩减散列表的容量，释放节约内存。不过如果散列表元素动态变化较大的情况，这种反复的申请和释放对性能、缓存等有极大的破坏作用，所以很多时候shrink只是个请求，并不保证会真正实施。</p>
<h2 id="1-3-2_增量修改">1.3.2 增量修改</h2><p>　　对于元素数量多，实时性要求高的应用，通常是增量递进式的resize的，这种方式resize的步骤一般是：<br>　　(1). resize的时候分配新的hash表，同时保留旧的hash表；<br>　　(2). 当每次查找和删除的时候，同时对这两张表做操作；每次插入的时候，只对新hash表操作；<br>　　(3). 每次插入的时候，同时移动 r 个元素从旧hash表到新hash表；<br>　　(4). 当所有元素从旧hash表被移走后，resize结束，释放旧的hash表；<br>　　如果想看具体的实现，建议去读读memcached的代码，里面有这种增量resize的操作。</p>
<h2 id="1-3-3_其他方法">1.3.3 其他方法</h2><p>　　还有就是设计的hash-to-table-index的操作和是和散列表的容量是无关的等情况，在分布式缓存中一致性hash等会涉及到，有时间再展开吧。</p>
<h2 id="1-4_散列表和二叉树的对比">1.4 散列表和二叉树的对比</h2><p>　　散列表和二叉树两者原理完全不同，使用情况也各有千秋，为此C++标准对于基本的数据类型(multi_)set、(multi_)map也建立了有序和无序两个版本。还有就是在比如MySQL/Mariadb数据库建立索引的时候，就有BTree索引和Hash索引的类型：前者算是有序索引，索引记录都是按照顺序排列(数据库由于通常记录会比较多，BTree是为这种类型优化的数据结构，减少对磁盘IO的访问次数，其不是通过二叉树实现的)。<br>　　两者的选型和区别主要考虑到以下情况：<br>　　(1). 二叉树是有序容器类，散列表是无须容器类，前者可以用于比较、范围查找类的检索，后者属于只能用于检索是否存在的情况；<br>　　(2). 虽然自平衡二叉树访问效率平均为O(logn)，但是随着元素数目n的增加性能也会下降，所以对于数据量大的情况还是倾向于效率更高的O(1)代表的散列表；<br>　　(3). 在多线程的环境下，二叉树的操作往往要锁住整个数据结构，而散列表可以对每个bucket建立一个互斥锁，所以在并发率高的情况下，散列表的性能更加；<br>　　(4). 超大数据集下，分布式缓存hash有成熟的案例，二叉树？嘿嘿，从来没听过。</p>
<h1 id="二、工业上常用的散列函数">二、工业上常用的散列函数</h1><p>　　C++和Boost有unordered的散列库，而针对C就需要自己寻找散列实现。在memcached中有Jenkins和Murmur两种散列函数可选，Nginx使用的是Murmur散列函数，而最近几年原Jenkins的作者推出了SpookyHash，而Google也发布了Murmur的改进型CityHash。如果有空余时间的人可以把这些新型的hash func封装好给memcached和Nginx提PR，哈哈。</p>
<h2 id="2-1_Jenkins">2.1 Jenkins</h2><p>在整个Hash中占据重要的地位，其作者Bob Jenkins几十年钻研Hash，发表了无数相关论文，不容小觑吧。</p>
<h2 id="2-2_Murmur">2.2 Murmur</h2><p>当前使用的比较广泛，而且速度也比较快，尤其它提供32bit和64bit的输出版本，能够提供原生的高性能。</p>
<h2 id="2-3_CityHash和SpookyHash">2.3 CityHash和SpookyHash</h2><p>SpookyHash是Jenkins的作者Bob Jenkins发布的最新散列函数，而CityHash乃是大厂Google所出，且由Murmur作者Austin Appleby进行Review的。SpookyHash只提供128bit的结果，而CityHash提供64bit、128bit、256bit的输出。<br>所以新版的Hash输出的位数增多了，如果你需要32bit的散列值，那么Murmur由于是原生支持，性能会是最好的；而据Austin Appleby透露(其就职于Google)现在Google的所有产品都是基于64bit架构的，其将来也必定是大势所趋啊。</p>
<h1 id="三、C++标准库中散列的使用">三、C++标准库中散列的使用</h1><p>再次重申，如果想了解Hash的实现、使用和维护，就去读memcached的源码。我暂且还不知道C是否有现成的hash库可供使用，不过C++的用户就幸福许多了，标准库的unordered_模板容器开箱既用，而且对resize、loadfactor也提供了访问和调整的接口，十分方便。<br>不过，标准库下面C++只提供了对内置数据类型、std::string、智能指针类型定义了hash操作，而如果自己使用的key_type不是这些类型，就需要手动定义这些操作。</p>
<h2 id="3-1_在容器中指明容器模板的Hash和KeyEqual模板参数">3.1 在容器中指明容器模板的Hash和KeyEqual模板参数</h2><p>如果自定义类型需要放在unordered_(multi)set/map容器中时候，这些无须容器都是用hash的方法存放的，可以在定义声明容器对象的时候指定模板参数中的Hash和KeyEqual参数模板就可以了，前者用以从将要保存到容器Key的类型中提取计算出一个size_t的散列值，当然通常的方法是用自定义类型中某些标准std::hash支持的成员类型求得一个散列值，也可以尝试前面介绍得到的那么多散列函数计算出自己规则的size_t尺寸的散列值；而对于KeyEqual操作，如果该类型支持operator==运算符就可以不提供这个参数，我想可能是在hash冲突的时候被调用到。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">size_t</span> hasher(<span class="keyword">const</span> Sales_data&amp; sd) &#123;</div><div class="line">    <span class="keyword">return</span> <span class="built_in">std</span>::hash&lt;<span class="built_in">string</span>&gt;()(sd.isbn()); </div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">eqOp</span><span class="params">(<span class="keyword">const</span> Sales_data &amp;lhs, <span class="keyword">const</span> Sales_data &amp;rhs)</span> </span>&#123;</div><div class="line">  <span class="keyword">return</span> lhs.isbn() == rhs.isbn(); </div><div class="line">&#125;</div><div class="line"> </div><div class="line"><span class="keyword">using</span> SD_multiset = <span class="built_in">unordered_multiset</span>&lt;Sales_data, <span class="keyword">decltype</span>(hasher)*, <span class="keyword">decltype</span>(eqOp)*&gt;;</div><div class="line"><span class="function">SD_multiset <span class="title">bookstore</span><span class="params">(<span class="number">42</span>, hasher, eqOp)</span></span>;</div></pre></td></tr></table></figure></p>
<h2 id="3-2_模板特例化得方法">3.2 模板特例化得方法</h2><p>这个是治本的方法，让后面的std::hash真正认得我们的自定义类型。根据C++的规则，模板特例化必须在模板的原名字空间中，所以这里需要打开std名字空间，进行类型的模板特例化声明，然后进行定义实现操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">namespace std &#123;</div><div class="line">template &lt;&gt;</div><div class="line">struct hash&lt;Sales_data&gt; &#123; </div><div class="line">  typedef size_t result_type;</div><div class="line">  typedef Sales_data argument_type;</div><div class="line">  size_t operator()(const Sales_data&amp; s) const;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">size_t hash&lt;Sales_data&gt;::operator() (const Sales_data&amp; s) const&#123;</div><div class="line">  return hash&lt;string&gt;()(s.book) ^ hash&lt;double&gt;()(s.revenue); </div><div class="line">&#125;</div><div class="line"></div><div class="line">&#125; //关闭std名字空间</div></pre></td></tr></table></figure></p>
<p>在C++类实现中，成员变量通常都是private的，所以上面的特例化成员通常要声明为类型的友元friend才能正常工作</p>
<pre><code class="cpp">emplate &lt;<span class="keyword">typename</span> T&gt; <span class="keyword">class</span> <span class="built_in">std</span>::hash; <span class="comment">//前置声明</span>
<span class="keyword">class</span> Sales_data {
<span class="keyword">friend</span> <span class="keyword">class</span> <span class="built_in">std</span>::hash&lt;Sales_data&gt;;
 ... };
</code></pre>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.reddit.com/r/programming/comments/ozodk/cityhash_new_hash_function_by_google_faster_than/" target="_blank" rel="external">CityHash: new hash function by Google (faster than Murmur)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hash_table" target="_blank" rel="external">Hash table</a></li>
<li><a href="http://blog.reverberate.org/2012/01/state-of-hash-functions-2012.html" target="_blank" rel="external">State of the hash functions, 2012</a></li>
<li><a href="http://en.cppreference.com/w/cpp/utility/hash" target="_blank" rel="external">CPP reference</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[说说设计模式中的单例模式]]></title>
      <url>https://taozj.org/201610/talk-about-singleton.html</url>
      <content type="html"><![CDATA[<p>　　单例(Singleton)差不多算是设计模式种最简单的一种了，属于创建型模式，但是突然码起来感觉还有些不知所措。当然网上关于设计模式的范例比比皆是，但大多是限于简单说明设计模式本身，但是考究在生产环境中使用的话还是有不少其他讲究的。刚好网上搜到《Modern C++ Design: Generic Programming and Design Patterns Applied》这本书中，有一节是详细讲单例的，看了觉得不错。<br>　　单例模式的定义是指：单例模式，是保证一个类仅有一个实例，并提供一个访问它的全局访问点。通过把构造函数设置成private的，防止外部创建对象，同时提供一个公共的GetInstance方法，决定是否已经实例化过，如果没有就调用私有的构造方法创建一个实例。</p>
<p>　　文章主要是按照单例模式下三个最重要的方面：创建生成、寿命、多线程模型来考量的。当然C++讲求的是面向对象和代码重用，单例模式不能简单的通过继承来实现重用，因为构造函数是private的，所以通常单例模式可以写成模板的方式来重用，泛化比较简单，这里就不阐述了。</p>
<h1 id="一、创建生成">一、创建生成</h1><p>　　最容易迷惑初学者(包括我自己)的是单例模式很容易和“静态类(成员函数和成员变量都是静态的类)”相混淆，乍一看确实极为相似。其实他们最大的区别是单例模式是一个实实在在正常的类，所以有对象(只有一个)，也就有this指针和虚函数；而在“静态类”中没有对象，就没有引用、this指针，也没有虚函数，所以如果在你的类中有继承的话，首先遇到的就是析构函数就没法是虚函数，那么你用基类的指针或者引用析构的话，派生类的对象都没法被释放！其他成员函数的多态也就更无从谈起了。还有一点就是，“静态类”的成员初始化顺序是不确定的，这在静态成员具有复杂依赖关系的情况下更为的致命，而单例具有正常的构造函数，根据C++标准，成员初始化的顺序就是在类中声明的顺序，是可以得到保证的。<br>　　要实现单例模式的对象唯一性，那么这些成员必须是private的：构造函数、拷贝构造函数、赋值运算符，同时给予封装的需要，析构函数最好也是private的，防止用户意外删除对象。而且，GetInstance()公共方法最好返回引用的方式，原因跟上面一样的。<a id="more"></a><br>　　创建对象的方式，主流的有两种：Gamma和Meyers：<br>a. Gamma方式：是最常见的通过new T的方式在堆空间动态创建对象，但是这种方式创建的对象需要使用delete显式销毁，程序结束时虽然操作系统会回收所有的内存资源，但是析构函数并不会被自动调用，意味着所有的资源回收都依赖于操作系统默认行为。<br>b. Meyers方式：通过在函数中创建静态对象的方式在静态内存区创建对象，这里C++规定如果函数中的局部静态变量是内置类型且用常量初始化的，那么这个初始化发生在程序开始运行加载期间，而如果初始化值是非常量类型或者变量类型是具有构造函数的类型，那么初始化发生在运行期间第一次调用该函数的时候，所以：(1)new出来的对象不能自动析构，但是程序中的静态对象，在程序退出的时候可以自动析构，所以可以在析构函数中做额外的事情；(2)这个对象不是程序启动的时候创建，而是只在调用函数需要对象的时候进行创建，这在多个编译单元有依赖关系的时候更为的有效，因为编译器没法保证编译单元的处理顺序，而这种方法总是能保证在需要对象的时候能够被创建，同时懒汉创建也节省资源。</p>
<h1 id="二、寿命">二、寿命</h1><p>　　设计模式中对单例对象的生命周期没有过多的阐述，所以也容易被忽略，通常单例对象的生命周期是很明确的：产生的时候是需要访问这个对象的时候，结束的时候通常是程序(正常或者异常)退出的时候。<br>　　在程序退出的时候，C++规定，对象的析构以LIFO后创建者先析构的顺序进行(new/delete管理的对象不受此规则)，但是根据上面的方式，单例是在首次访问的时候创建对象的，所以我们无法预估和安排程序退出的时候各个单例对象的析构顺序，而尤其当这些析构对象互相调用的时候，情况将变得更加复杂。<br>　　比如我们希望一个日志单例能够在最后一刻被析构，但是某种顺序可能先就被析构了，这时候别的对象通过Instance访问的对象就是析构后无效的对象，这就是”dead-reference”问题。解决这个问题的方法，就是通过增加一个静态的成员变量destroyed_，默认为false，而在对象的析构函数中将其设置为true。这样在请求这个单例对象的时候，如果destroyed_为true，就表示对象已经被析构掉了，这个时候就需要使用placement new操作在原地再次重建这个对象，从而实现只要有用户，即使死掉也能复生的单例。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> Singleton::OnDeadReference() &#123;</div><div class="line">	Create();</div><div class="line">	<span class="keyword">new</span>(pInstance_) Singleton;</div><div class="line">	atexit(KillPhoenixSingleton);</div><div class="line">	destoryed_ = <span class="literal">false</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> Singleton::KillPhoenixSingleton() &#123;</div><div class="line">	pInstance_-&gt;~Singleton();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　作者后面还提到可以建立一种设置和追踪对象生命周期长度的机制，让某些对象“活的更长一些”，问题搞的更加复杂了，此处就不深究了。</p>
<h1 id="三、多线程模型">三、多线程模型</h1><p>　　多线程环境下，单例的创建涉及到一个竞争问题。如果直接把判断和创建的代码用一个互斥单元保护，那么每次调用对象的时候都要请求互斥量，造成了不必要的性能浪费。最经典的方式是”Double-Checked Locking”(DCL)。<br>　　但是就像在<a href="/201609/cpp11-atomic-and-memory-model.html">C++11新标准中的Atomic原子操作和内存模型</a>中所描述的，在C++11发布确定内存模型之前，对这个静态变量访问和修改在各个线程之间的可见是没有保证的，只能显式使用内存屏障保证。同时，作者还给出的方法是把这个变量设置为volatile的，查阅发现：某些编译器会保证volatile变量是一种内存屏障，阻止编译器和CPU重新安排读入和写出语义，比如Visual C++ 2005之后就做出了此类保证。<br>　　我是简单在变量的读写加了acquire和release的thread_fench，如果你想深入了解这个机制，或者想写出你认为的最高效的代码，可以参照附录中的文献。不过我觉得这里过于的纠结没什么意义，因为这个竞争条件只在创建的过程中会发生，创建之后都不会存在竞争条件了，这里过于的纠结优化这个问题真是钻牛角尖了。</p>
<p>考虑到简单实用，然后自用的一个Singleton像<a href="https://github.com/taozhijiang/ailawd/blob/c%2B%2B0x/include/redis.hpp" target="_blank" rel="external">这个样子</a>。<br>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/1755195/" target="_blank" rel="external">Modern C++ Design: Generic Programming and Design Patterns Applied</a></li>
<li><a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="external">Double-Checked Locking is Fixed In C++11</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/C-plus-plus-In-Theory-The-Singleton-Pattern-Part-I/" target="_blank" rel="external">C++ In Theory: The Singleton Pattern, Part I</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/C-plus-plus-In-Theory-The-Singleton-Pattern-Part-2/" target="_blank" rel="external">C++ In Theory: The Singleton Pattern, Part 2</a></li>
<li><a href="http://www.devarticles.com/c/a/Cplusplus/The-Singleton-Pattern-Revisited/" target="_blank" rel="external">The Singleton Pattern Revisited</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost-Asio网络开发基础知识（三）：Strand序列化执行用户回调]]></title>
      <url>https://taozj.org/201609/basics-of-boost-asio-(3)-strand.html</url>
      <content type="html"><![CDATA[<p>请参看Boost.Asio的官方文档，上面清楚的描述道：<br>　　strand可以保证严格序列化地(而不会并行地)执行event handlers，通过使用strand可以保证安全的在多线程环境下执行程序，而不需要使用者显式的使用类似mutex等方式来进行保护和同步操作。strand的可以以隐式(implicit)或者显式(explicit)的方式存在：<br>(1). 如果只在一个线程中调用io_service::run()，那么所有的event handlers都是在一个隐式strand中序列化执行的；<br>(2). 对于一个连接如果只有一个单链异步操作的时候，其不可能并发的执行event handlers，这也是隐式strand的。(文中提到了比如HTTP的单双工协议，我的理解是HTTP只会进行客户端请求、服务端返回数据这种形式，没有并行执行event handler的可能性)；<br>(3). 可以显式实例化一个strand对象，然后所有的event handlers必须使用io_service::strand::wrap()进行包裹，或者使用该strand对象显式调用post()/dispatch()发布异步操作请求；<br>(4). 对于composed asynchronous operations的操作，比如async_read()或者async_read_until()，其中间会多次调用async_read_some()，为了保证对象的安全，所有的intermediate handlers都必须在同一个strand中被串行化执行。</p>
<p>基本上strand对象创建之后，就从另外一个层次替换了io_service的行为，因为strand提供了和io_service_极其类似的成员函数：<br>(1). dispatch(CompletionHandler handler); 请求strand去执行handler，strand对象保证通过该strand添加的handlers不会被并行的执行，如果这个函数是在相同strand对象对应的handler中被调用的，那么该handler将会在函数中被立即执行(s.running_in_this_thread() == true)；<br>(2). post(CompletionHandler handler); 请求strand去执行handler并立即返回；<br>(3). get_io_service()<br>(4). running_in_this_thread(); 如果当前线程正在执行由该strand提交的handler，则返回true；<br>(5). wrap(Handler handler); 创建一个函数对象，当被invoke的时候会自动传递到strand的dispatch函数；<br><a id="more"></a><br>strand串行化执行的顺序问题：<br>在strand的文档中，对提交进取的多个handler需要串行化执行，执行的顺序有部分的保证。在以下情况下会保证asio_handler_invoke(a1, &amp;a1)会先于执行asio_handler_invoke(b1, &amp;b1)：<br>(1). s.post(a)先于执行s.post(b)；<br>(2). s.post(a)先于执行s.dispatch(b)，同时后者在strand外执行的；<br>(3). s.dispatch(a)先于执行s.post(b)，并且前者是在strand外执行的；<br>(4). s.dispatch(a)先于执行s.dispatch(b)，同时他们都是在strand外执行的；<br>(5). async_op_1(…, s.wrap(a)); async_op_2(…, s.wrap(b));这两者的执行顺序没有任何的保证，而strand所能给予的保证是a1和b1不会并行执行，如果s.wrap(x1)先被执行，那么x1也会先被执行；<br>其实，其要诀就是：如果在strand中，那么dispatch会直接在调用函数中执行，否则按照添加到队列中的顺序来排队执行。举个例子，比如假设<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">auto</span> wrapped_handler1 = strand.wrap(handler1);</div><div class="line"><span class="keyword">auto</span> wrapped_handler2 = strand.wrap(handler2);</div><div class="line">socket.async_read_some(buffer1, wrapped_handler1); <span class="comment">// op1</span></div><div class="line">socket.async_read_some(buffer2, wrapped_handler2); <span class="comment">// op2</span></div></pre></td></tr></table></figure></p>
<p>由于op1先于op2启动，所以保证buffer1在stream中接收到的数据是先于buffer2的，但是wrapped_handler1和wrapped_handler2的调用顺序是没有保证的，strand做出的保证是：<br>(1). handler1和handler2不会并发的执行；<br>(2). 如果wrapped_handler1先于wrapped_handler2被执行，那么handler1先于handler2被执行，反之亦然。</p>
<p>strand类定义在[strand.hpp]boost::asio::io_service::strand，这个类只是个空壳，主要包括两个数据成员detail::strand_service&amp; service_和detail::strand_service::implementation_type impl_两个成员，具体实现需要查看strand_service类的实现细节，该类有几个重要的成员变量：<br>(1). io_service_impl&amp; io_service_; 构造strand的时候传递进来的io_service对象；<br>(2). detail::mutex mutex_; 主要用来保护下面的locked_等内部变量；<br>(3). bool locked_; 如果当前有其他的handler正在被执行或正在被调度执行，那么这个变量是true，如果此时有新的handler需要被加入就需要等待；<br>(4). op_queue<operation> waiting_queue_; 正在等待strand但是除非等到下次strand调度，否则不应当被运行，修改时候需要mutex_保护；<br>(5). op_queue<operation> ready_queue_; 已经拥有了lock_，即将被运行的队列；</operation></operation></p>
<p>想必看到上面的成员之后，对strand的串行化原理会猜个八九分了，但是如我们之前所跟的，一个async_read_some()调用的话，descriptor_state和reactor_op会多次加入到io_service上面，对于这个二段式的操作，其序列化需求还是跟之前的io_service直接调度有些区别的吧。strand其提供最常用的接口包括dispatch、post、wrap，我们可以从这些函数中了解strand串行化的机制：<br>(1). dispatch<br>如果当前的线程正在执行strand，那么就直接调用这个handler:<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (call_stack&lt;strand_impl&gt;::contains(impl)) &#123;</div><div class="line">	<span class="function">fenced_block <span class="title">b</span><span class="params">(fenced_block::full)</span></span>;</div><div class="line">	boost_asio_handler_invoke_helpers::invoke(handler, handler);</div><div class="line">	<span class="keyword">return</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其中的invoke调用代码为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">using</span> boost::asio::asio_handler_invoke;</div><div class="line">asio_handler_invoke(function, boost::asio::detail::addressof(context));</div></pre></td></tr></table></figure></p>
<p>可见这个asio_handler_invoke就是在<a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/reference/io_service__strand.html" target="_blank" rel="external">strand介绍文档</a>中看到的，其默认操作就是直接调用用户提供的handler。关于这个asio_handler_invoke，如果要深究下去东西也很多，可以参见参考中的<a href="https://stackoverflow.com/questions/32857101/when-to-use-asio-handler-invoke" target="_blank" rel="external">When to use asio_handler_invoke?</a>，其主要思想是提供了一个可供记录的上下文环境context，因为比如composed operation中， intermediate handler可能会被创建零或者多次，这个状态必须在外层的wrap中保留下来才可以。不过在上面的例子中，貌似没有做什么额外的事情。</p>
<p>否则上面的dispatch()会调用strand_service::do_dispatch()，这里的判断就更明显了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (can_dispatch &amp;&amp; !impl-&gt;locked_)&#123;</div><div class="line">  impl-&gt;locked_ = <span class="literal">true</span>;</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">if</span> (impl-&gt;locked_)&#123;</div><div class="line">  impl-&gt;waiting_queue_.push(op);</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">&#125;</div><div class="line"><span class="keyword">else</span> &#123;</div><div class="line">  impl-&gt;locked_ = <span class="literal">true</span>;</div><div class="line">  impl-&gt;mutex_.unlock();</div><div class="line">  impl-&gt;ready_queue_.push(op);</div><div class="line">  io_service_.post_immediate_completion(impl, <span class="literal">false</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果当前是执行strand的线程并且没有lock_，那么就返回true，效果是直接执行handler；否则如果lock_了就添加到waiting_queue_上面；再则没有lock_就添加到ready_queue_队列上面，此时通过post_immediate_completion添加到io_service_.op_queue_上面被调度执行；<br>如果上面返回是true，此处就是在do_dispatch()函数内部执行了，通过设置on_dispatch_exit的RAII，在此次调用完后会把waiting_queue_的handler全部移动到ready_queue_，如果ready_queue_中真的有元素，就设置lock_为ture，并将队列中的handler添加到io_service_.op_queue_上面去。<br>上面介绍了都是善后工作，真正的函数内调用代码为：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">completion_handler&lt;Handler&gt;::do_complete(</div><div class="line">        &amp;io_service_, o, boost::system::error_code(), 0);</div><div class="line">        </div><div class="line">static void do_complete(io_service_impl* owner, operation* base,</div><div class="line">      const boost::system::error_code&amp; /*ec*/, std::size_t /*bytes_transferred*/)</div><div class="line">  &#123;</div><div class="line">    // Take ownership of the handler object.</div><div class="line">    completion_handler* h(static_cast&lt;completion_handler*&gt;(base));</div><div class="line">    ptr p = &#123; boost::asio::detail::addressof(h-&gt;handler_), h, h &#125;;</div><div class="line">...</div><div class="line">    Handler handler(BOOST_ASIO_MOVE_CAST(Handler)(h-&gt;handler_));</div><div class="line">    p.h = boost::asio::detail::addressof(handler);</div><div class="line">    p.reset();</div><div class="line"></div><div class="line">    // Make the upcall if required.</div><div class="line">    if (owner) &#123;</div><div class="line">      fenced_block b(fenced_block::half);</div><div class="line">      BOOST_ASIO_HANDLER_INVOCATION_BEGIN(());</div><div class="line">      boost_asio_handler_invoke_helpers::invoke(handler, handler);</div><div class="line">      BOOST_ASIO_HANDLER_INVOCATION_END;</div><div class="line">    &#125;</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p>这里调用的时候owner不是空的，所以会调用用户提供的handler。</p>
<p>(2). post<br>post的逻辑就比上面要简单很多了，如果locked_==true，那么就直接添加到waiting_queue_，否则的话说明当前strand没有运行，就设置lock_=true并添加到ready_queue_队列上，同时添加到io_service_.op_queue_上面等待调度执行；</p>
<p>(3). wrap<br>wrap函数算是最常用的函数了，当原来所有的async_xxxx所传入的handler，都可以直接使用strand_.wrap进行包装，就可以保证在多线程环境下序列化调用安全了。其wrap成员函数使用了detail::wrapped_handler进行包装，类成员也就dispatcher_和handler_两个成员变量。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">wrap(Handler handler) &#123;</div><div class="line">	<span class="keyword">return</span> detail::wrapped_handler&lt;io_service::strand, Handler,</div><div class="line">      detail::is_continuation_if_running&gt;(*<span class="keyword">this</span>, handler);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>由于strand在我们操作接口中的角色就是添加了一个wrap，基本的业务流程还是在io_service中进行的，所以这里预测，有无strand.wrap的差异也就是在需要调用的handler的期间：<br>当socket的IO操作完成之后，会继续调用o-&gt;complete(*this, ec, task_result);，此时会按照如下的调用链：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">task_io_service_operation::complete() -&gt; boost_asio_handler_invoke_helpers::invoke(handler, handler.handler_);</div><div class="line">-&gt; asio_handler_invoke(function, boost::asio::detail::addressof(context));</div><div class="line"></div><div class="line">asio_handler_invoke(Function&amp; function,</div><div class="line">    wrapped_handler&lt;Dispatcher, Handler, IsContinuation&gt;* this_handler)</div><div class="line">&#123;</div><div class="line">  this_handler-&gt;dispatcher_.dispatch(</div><div class="line">      rewrapped_handler&lt;Function, Handler&gt;(</div><div class="line">        function, this_handler-&gt;handler_));</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这里看出了dispatcher_.dispatch()，就跟上面分析的dispatch联系起来了，也就是上面的成员函数添加真正的handler。由之前的分析知道，用户提供的handler是在实际的IO执行完成之后才会回掉的，所以可以看出这里的strand不会保护底层的IO操作，只会保护用户提供的回调handler的串行化执行。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_asio/overview/core/strands.html" target="_blank" rel="external">Strands: Use Threads Without Explicit Locking</a></li>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/boost_asio/reference/io_service__strand.html" target="_blank" rel="external">io_service::strand</a></li>
<li><a href="http://stackoverflow.com/questions/39097644/how-strands-guarantee-correct-execution-of-pending-events-in-boost-asio" target="_blank" rel="external">How strands guarantee correct execution of pending events in boost.asio</a></li>
<li><a href="https://stackoverflow.com/questions/32857101/when-to-use-asio-handler-invoke" target="_blank" rel="external">hen to use asio_handler_invoke ?</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost.Asio网络开发基础知识（二）：异步框架总览]]></title>
      <url>https://taozj.org/201609/basics-of-boost-asio-(2)-overview-of-the%20async-framework.html</url>
      <content type="html"><![CDATA[<p>　　虽然知道异步库实现基本都是对操作系统底层支持的select/poll/epoll/kqueue机制的封装，可是热爱学习的偶，还是想像之前对Libevent一样，如果能了解Boost.Asio的内部异步机制会让人感觉是一件很爽的事情，于是就厚着脸皮把Boost.Asio的核心——io_service代码跟踪读了一下。话说阅读C++的代码确实比C麻烦不少，尤其当其中夹杂着复杂的继承关系、大量泛型参数的时候，同时Boost库的一大风格是为了代码的整洁和编译速度的优化，进行了类声明和实现的分离，形成了大量重复文件名的代码以及一般编辑器不支持的ipp后缀，阅读跳转起来十分不便，想想也真是累啊。但是还是希望自己能早日适应下来！既然选择了这条路，就迟早得迈得过这条坎才行。<br>　　之前也分析过，Windows系统得益于其重叠IO(Overlapped I/O)和完成端口(I/O completion port)机制，算是在操作系统级别支持异步IO操作的，而Linux类系统虽然也有aio_xxx的异步接口，但是用之者寥寥，现在高性能服务端基本都是清一色的select/epoll+普通IO操作实现的。以前看文章据说Linux的aio_xxx不太给力，不知道是用户的选择导致了Linux内核对aio_xxx的发展缺乏动力，还是aio_xxx不完美导致开发者不愿意使用呢？<br>　　要实现跨平台的异步库，由Reactor来实现Proactor容易，因为只要额外添加一步IO操作就可以了，但是反过来要Proactor剥离出Reactor几乎是不可能的，所以当时研究Libevent在Windows平台下好像就只支持select机制，所以预估Libevent在Windows平台下的并发量性能有限。Boost.Asio则是选择了Proactor模式，完全利用了Windows的异步特性，同时在Linux平台下通过增强Reactor来实现Proactor模式，我想这也是Boost.Asio作为一个跨平台的网络库所了不起的地方，同时也是其立志进入C++标准最有力的一票。</p>
<h1 id="一、前期准备">一、前期准备</h1><p>对于了解一个项目，最佳实践当然是Read The Fuck Code!<br>可是在阅读项目代码的时候，虽然也可以像读文章一样人工判断出执行流程，但是如果能够以边调试边运行的方式来跟踪，那么结果将会更加的确信可靠。在Linux下面，虽然编辑神器Vim/Emacs可以各种外挂配置形成超级IDE神器，但是自己这个年纪还是怕折腾了——直接用的SlickEdit，这家伙号称是最贵的IDE，但是确实挺好用的，而且是跨平台的(但是真正Windows下大多人还是会用微软自家的Visual Studio吧，真幸福)，等在下能够经济自由的那一天，定要好支持一下。SlickEdit对于一般的代码是做的很好的，但是对于大量模板情况下的跟踪，还是有所缺陷，比如没法显示实例化的模板参数类型，希望能不断更新改进。<br>我在学习调试的时候，是直接使用upstream的boost版本，但是很多发行版会打包甚至安装一些旧的发布版本，为了使用自己控制的upstream版本，需要额外的配置一下环境：<br>(a). 在GitHub上面clone最新的boost源代码，然后编译安装到本地的目录，参考的编译命令可以是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">➜  boost git:(master) ✗ ./bootstrap.sh</div><div class="line">➜  boost git:(master) ✗ ./b2 headers</div><div class="line">➜  boost git:(master) ✗ mkdir builddir installdir</div><div class="line">➜  boost git:(master) ✗ ./b2 --build-dir=builddir --prefix=installdir <span class="_">-a</span> -q toolset=gcc variant=debug </div><div class="line">➜  boost git:(master) ✗ <span class="comment">#./b2 -j4 --build-dir=builddir --prefix=/home/taozj/root/ --without-python -a -q toolset=gcc cxxflags="-std=c++0x" variant=debug threading=multi install</span></div></pre></td></tr></table></figure></p>
<p>(b). 随便新建一个项目，Boost.Asio的example中有一大把，比如找一个包含包含async_read/write_some调用的简单例程的(比如async_udp_echo_server.cpp)，然后修改项目的Makefile，将自己指定的boost安装目录中的include和lib添加到编译环境中去。Makefile的例子可以参考我<a href="https://github.com/taozhijiang/airobot_msgd/blob/master/Makefile" target="_blank" rel="external">项目</a>中使用的<br>此外，还要修改系统的LD_LIBRARY_PATH，可以通过在/etc/ld.conf.d目录中添加一个上面的安装目录，然后运行ldconfig刷新一下系统即可，否则最终链接的时候还是会报错找不到符号的。<br>(c). 这个时候，就可以使用ldd命令查看编译出来的可执行文件依赖哪些链接库，看看是不是最终依赖到了指定的本地版本boost，同时也可以运行一下可执行程序看是否正常。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  asio_learn ldd Debug/asio_learn </div><div class="line">	linux-vdso.so.1 =&gt;  (0x00007ffd33dc9000)</div><div class="line">	libboost_system.so.1.62.0 =&gt; /home/user/Dropbox/ReadTheCode/boost/installdir/lib/libboost_system.so.1.62.0 (0x00007f277ad55000)</div><div class="line">	libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f277ab38000)</div><div class="line">	libstdc++.so.6 =&gt; /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f277a7b5000)</div><div class="line">	libgcc_s.so.1 =&gt; /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f277a59f000)</div><div class="line">	libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f277a1d6000)</div><div class="line">	/lib64/ld-linux-x86-64.so.2 (0x0000556214f39000)</div><div class="line">	libm.so.6 =&gt; /lib/x86_64-linux-gnu/libm.so.6 (0x00007f2779ecc000)</div></pre></td></tr></table></figure></p>
<p>(d). 修改SlickEdit编辑器，在Project Properties-&gt;Directories-&gt;Include中，把本地的installdir/include加到最前面去，刷新Retag一下Slickedit，查看里面的变量定义跳转文件是不是正确。<br>至此，这个学习跟踪环境就完成了。</p>
<h1 id="二、io_service中三个成员变量">二、io_service中三个成员变量</h1><p>io_service核心类主要成员变量只有三个：init_、service_registry_和impl_。<br>(a). [detail/signal_init.hpp] detail::signal_init&lt;&gt; init_：在默认构造signal_init的时候，会将SIGPIPE的信号给忽略掉，这算基本是所有网络开发程序的默认行为；<br>(b). [io_service.hpp] impl_type&amp; impl_：通过宏的控制，impl_type在Linux平台等价于task_io_service类型，Linux和Windows两种平台的操作在这里会进行分流；<br>(c). [detail/service_registry.hpp] detail::service_registry* service_registry_：其实现类型是一个单例对象的侵入链表，其中每一个服务都有对应的ID号，Linux平台在后面经常遇到的服务有detail::task_io_service、detail::reactive_socket_service、detail::epoll_reactor，这些个类一方面是跟平台相关密切，同时他们之间的联系也是错综复杂，暂且不表吧！</p>
<p>[detail/impl/epoll_reactor.ipp]task_io_service中有几个重要的成员变量：<br>(a). atomic_count outstanding_work_; 表示未完成的work数目，在work_start()的时候会增加，在work_finished()的时候会递减；<br>(b). [detail/reactor_fwd.hpp] reactor* task_; 这个reactor在reactor_fwd.hpp中通过宏BOOST_ASIO_HAS_XXX来进行控制的，这也就是说没有Libevent那种可以通过调用代码的方式灵活的选择选择select/poll/epoll各种模型了，通常在Linux中会被定义成epoll_reactor；<br>(c). [detail/op_queue.hpp] op_queue<operation> op_queue_; 这里实现了一个operation_queue的队列容器，同时定义了op_queue_access这个访问者类对这个op队列进行操作管理。这个队列是多个线程共享的，存储的元素可以是descriptor_state、reactor_op类型，后面会经常涉及到这两种类型。<br><a id="more"></a></operation></p>
<h1 id="三、Initiator发起异步请求">三、Initiator发起异步请求</h1><p>从最常见的async_read_some这个socket读取请求，看看Initiator发起的这条路径是怎么处理的。<br>当开始创建和连接一个套接字的时候，其名字作用空间是[ip/tcp.hpp]ip::tcp::socket，从代码中可以看到所谓的socket(basic_stream_socket<tcp>)、accept(basic_socket_acceptor<tcp>)、resolver(basic_resolver<tcp>)都是一个个typedef的别名而已，而[basic_stream_socket.hpp]basic_stream_socket经过模板实例化，其类声明就变成了<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> basic_stream_socket</div><div class="line">  : <span class="keyword">public</span> basic_socket&lt;tcp, stream_socket_service&lt;tcp&gt;&gt;</div></pre></td></tr></table></figure></tcp></tcp></tcp></p>
<p>看到这个basic_stream_socket中的成员函数，让人宽心了一点点，因为我们开发时候常见的IO操作接口(async_)send、(async_)receive、(async_)write_some、(async_)read_some都显露出来了，因为这些函数本来就是socket调用的嘛，定睛一看其基本都是调用this-&gt;get_service()中的同名成员函数，而既然basic_stream_socket中没有get_service()的定义，那么这个函数一定是在其基类中被继承而来的(原谅我后面的这些模板参数我直接替换掉了)：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">explicit basic_socket(boost::asio::io_service&amp; io_service)</div><div class="line">  : basic_io_object&lt;stream_socket_service&gt;(io_service);</div></pre></td></tr></table></figure></p>
<p>basic_socket的构造函数需要传递一个io_service的参数，这个参数后面喂给了basic_io_object，就是这个类消化了这个参数：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">explicit basic_io_object(boost::asio::io_service&amp; io_service)</div><div class="line">  : service(boost::asio::use_service&lt;stream_socket_service&gt;(io_service))&#123;</div><div class="line">  service.construct(implementation);</div><div class="line">&#125;</div><div class="line"></div><div class="line">service_type&amp; get_service()</div><div class="line">&#123;  return service;  &#125;</div></pre></td></tr></table></figure></p>
<p>下面就需要看看这个[stream_socket_service.hpp]stream_socket_service东西是个什么鬼了，原来在Linux平台下，它的实现就是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The platform-specific implementation.</span></div><div class="line">service_impl_type service_impl_;</div><div class="line"></div><div class="line"><span class="keyword">typedef</span> detail::reactive_socket_service&lt;tcp&gt; service_impl_type;</div></pre></td></tr></table></figure></p>
<p>[detail/reactive_socket_service.hpp]reactive_socket_service可是个好类啊，其继承自reactive_socket_service_base，两个类中几乎囊括了所有对于socket的设置、IO等操作，当然为了整洁起见，所有对于socket的控制操作和底层收发操作都被实现成了自由函数，并封装在[detail/impl/socket_ops.ipp]socket_ops名字空间中。<br>例如上面，对于socket.async_read_some()这个调用，那么它的调用链就是(其中的&lt;-&gt;表示继承关系)：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">basic_stream_socket::get_service().async_receive(<span class="keyword">this</span>-&gt;get_implementation(),</div><div class="line">        buffers, <span class="number">0</span>, BOOST_ASIO_MOVE_CAST(ReadHandler)(handler));</div><div class="line"> </div><div class="line">basic_stream_socket &lt;-&gt; basic_socket &lt;-&gt; basic_io_object::service</div><div class="line">reactive_socket_service &lt;-&gt; reactive_socket_service_base::async_receive</div></pre></td></tr></table></figure></p>
<p>然后整个async_receive的实现代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// buffer must be valid for the lifetime of the asynchronous operation.</span></div><div class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> MutableBufferSequence, <span class="keyword">typename</span> Handler&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">async_receive</span><span class="params">(base_implementation_type&amp; impl,</span></span></div><div class="line">  <span class="keyword">const</span> MutableBufferSequence&amp; buffers,</div><div class="line">  socket_base::message_flags flags, Handler&amp; handler)</div><div class="line">&#123;</div><div class="line"><span class="keyword">bool</span> is_continuation =</div><div class="line">  boost_asio_handler_cont_helpers::is_continuation(handler);</div><div class="line"> </div><div class="line"><span class="comment">// Allocate and construct an operation to wrap the handler.</span></div><div class="line"><span class="keyword">typedef</span> reactive_socket_recv_op&lt;MutableBufferSequence, Handler&gt; op;</div><div class="line"><span class="keyword">typename</span> op::ptr p = &#123; boost::asio::detail::addressof(handler),</div><div class="line">  boost_asio_handler_alloc_helpers::allocate(</div><div class="line">    <span class="keyword">sizeof</span>(op), handler), <span class="number">0</span> &#125;; <span class="comment">// h v p</span></div><div class="line">p.p = <span class="keyword">new</span> (p.v) op(impl.socket_, impl.state_, buffers, flags, handler);</div><div class="line"> </div><div class="line">BOOST_ASIO_HANDLER_CREATION((p.p, <span class="string">"socket"</span>, &amp;impl, <span class="string">"async_receive"</span>));</div><div class="line"> </div><div class="line">start_op(impl,</div><div class="line">  (flags &amp; socket_base::message_out_of_band)</div><div class="line">    ? reactor::except_op : reactor::read_op,</div><div class="line">  p.p, is_continuation,</div><div class="line">  (flags &amp; socket_base::message_out_of_band) == <span class="number">0</span>,</div><div class="line">  ((impl.state_ &amp; socket_ops::stream_oriented)</div><div class="line">    &amp;&amp; buffer_sequence_adapter&lt;boost::asio::mutable_buffer,</div><div class="line">      MutableBufferSequence&gt;::all_empty(buffers)));</div><div class="line">  p.v = p.p = <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>这么一大段我先拷贝在这里，说句实话写的现在我确实看不懂，只知道有buffers和handler，后面发信给原作者问是什么回事，这才有些明白。对于reactive_socket_recv_op<mutablebuffersequence, handler="">::ptr的类型来源，可以发现在reactive_socket_recv_op类定义中有BOOST_ASIO_DEFINE_HANDLER_PTR这么一个宏，而这个宏定义在头文件[detail/handler_alloc_helpers.hpp]当中，在其中辅助生成了一个ptr类型的内部类，其实也是做了一个RAII的作用，并且可以可选择性的释放成员p.p、p.v的内容，p.h一般用来存储handler。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">BOOST_ASIO_DEFINE_HANDLER_PTR(reactive_socket_recv_op);</div><div class="line"></div><div class="line">p.p = <span class="keyword">new</span> (p.v) op(impl.socket_, impl.state_, buffers, flags, handler);</div></pre></td></tr></table></figure></mutablebuffersequence,></p>
<p>那么构造出来的p.p就是reactive_socket_recv_op类型了，其中包含了我们传递进去的buffers和handler，同时在调用start_op的时候，这个p.p也就是大名鼎鼎的descriptor_data。<br>然后就要关注通过调用start_op函数，这个函数映射到reactor_(epoll_reactor)的start_op操作，其这里完成的的工作主要有：<br>(a). 通过epoll_ctl的方式将套接字的EPOLLOUT事件侦听添加进去，同时把descriptor_data作为event的私有数据存储在ev.data.ptr；<br>(b). 将当前的操作的reactor_op添加到descriptor_data-&gt;op_queue_[op_type].push(op);这个依据操作类型相关(read_op = 0, write_op = 1, connect_op = 1, except_op = 2)的队列里面去；<br>(c). 调用work_start()来增加outstanding_work_的计数。<br>自此客户端发送的async_read_some已经被分派到操作系统epoll中去侦听相应注册的事件了，同时其buffers、handler等重要数据也被添加到了op队列中——完事具备，只欠东风了！</p>
<h1 id="四、io_service中收集就绪事件">四、io_service中收集就绪事件</h1><p>在开发中，我们都是先期做一系列的准备工作(比如增加accept的连接handler、信号处理回调等)，最后调用io_service.run()方法，从此主线程在此阻塞起来进行事件循环。当然，在io_service中与run同类的函数还要包括好几种，只是没有run()这么常用而已。这些函数都是映射到实现部分impl_(task_io_service)来调用的：<br>(a). std::size_t run();  一直阻塞直到所有的任务都完成，或者没有其他handler可以被dispatch、io_service被stop掉；多个线程可以调用同一个io_service的run()，他们共同组成没有差异的线程池模式；本函数的正常退出是调用stop或者run out of work。<br>(b). std::size_t run_one(); 最多执行一个handler，它会阻塞等待直到一个handler被dispatched、或者io_service被stop。<br>(c). std::size_t poll(); 该函数不会阻塞，它会立即运行可以运行的handlers，直到没有剩余的ready handler、或者io_service被stop。<br>(d). std::size_t poll_one(); 非阻塞的运行至多一个handler。<br>另外还有两个常用到的成员函数dispatch()和post()，只是我们在调用async_xxxx的时候隐含的实现了他们相同的功能：<br>(e). dispatch(CompletionHandler handler) 将会请求io_service立即执行给定的handler，如果当前线程是调用run(), run_one(), poll(), poll_one()的线程，那么这个handler将会被立即执行，否则会插入到task_io_service::op_queue_队列中；出现这种判断也不奇怪，因为任何的线程如果拿到io_service对象都可以用它发起异步操作请求，或者直接dispatch()/post()添加异步请求；<br>(f). post(CompletionHandler handler) 请求io_service立即执行给定的handler然后立即返回，实际就是插入到task_io_service::op_queue_当中然后就返回了。</p>
<p>就捡最常见的run来说事吧，其调用链为<br>io_service::run() -&gt; task_io_service::run()，核心代码如下<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="keyword">size_t</span> n = <span class="number">0</span>;</div><div class="line">  <span class="keyword">for</span> (; do_run_one(lock, this_thread, ec); lock.lock())</div><div class="line">    <span class="keyword">if</span> (n != (<span class="built_in">std</span>::numeric_limits&lt;<span class="built_in">std</span>::<span class="keyword">size_t</span>&gt;::max)()) <span class="comment">//计数操作</span></div><div class="line">      ++n;</div></pre></td></tr></table></figure></p>
<p>这个n就是run()返回的数目，代表了已经执行handler的计数，最大值不会超过size_t的类型最大值，关键点就落在了这个do_run_one上面了(暂时把多线程方面的东西拿掉了)：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">  <span class="keyword">while</span> (!stopped_) &#123;</div><div class="line">    <span class="keyword">if</span> (!op_queue_.empty()) &#123;</div><div class="line">      operation* o = op_queue_.front();</div><div class="line">      op_queue_.pop();</div><div class="line">      <span class="keyword">bool</span> more_handlers = (!op_queue_.empty());</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (o == &amp;task_operation_) &#123;</div><div class="line">        task_interrupted_ = more_handlers;</div><div class="line">        task_cleanup on_exit = &#123; <span class="keyword">this</span>, &amp;lock, &amp;this_thread &#125;;</div><div class="line">        (<span class="keyword">void</span>)on_exit;</div><div class="line">        task_-&gt;run(!more_handlers, this_thread.private_op_queue);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">else</span> &#123;</div><div class="line">        <span class="built_in">std</span>::<span class="keyword">size_t</span> task_result = o-&gt;task_result_; <span class="comment">//events</span></div><div class="line">        work_cleanup on_exit = &#123; <span class="keyword">this</span>, &amp;lock, &amp;this_thread &#125;;</div><div class="line">        (<span class="keyword">void</span>)on_exit;</div><div class="line">        o-&gt;complete(*<span class="keyword">this</span>, ec, task_result);</div><div class="line">        <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">      wakeup_event_.clear(lock);</div><div class="line">      wakeup_event_.wait(lock);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"><span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>成员变量task_operation_是一个task_io_service_operation类型，这里涉及到一个分流操作。跟踪代码发现在task_init以及这里RAII的task_io_service::task_cleanup的行为看来，task_operation_的效果都像是扮演者一个队列的尾端标记的作用，当队列中取出这个op就意味表示就绪的事件处理完了，需要重新收集就绪事件了，所以<br>(a). 当弹出的队列元素是task_operation_表示没有任务可以处理了，此时会调用task_-&gt;run(!more_handlers, this_thread.private_op_queue);，这个操作会通过epoll_reactor::run调用底层的epoll_wait收集更多的就绪事件，其本质就对应着下面的调用：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[detail/impl/epoll_reactor.ipp] <span class="keyword">void</span> epoll_reactor::run(<span class="keyword">bool</span> block, op_queue&lt;operation&gt;&amp; private_op_queue);</div><div class="line"><span class="comment">// Block on the epoll descriptor.</span></div><div class="line">epoll_event events[<span class="number">128</span>];</div><div class="line"><span class="keyword">int</span> num_events = epoll_wait(epoll_fd_, events, <span class="number">128</span>, timeout);</div><div class="line"></div><div class="line"><span class="comment">// Dispatch the waiting events.</span></div><div class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num_events; ++i)&#123;</div><div class="line">  <span class="keyword">void</span>* ptr = events[i].data.ptr; <span class="comment">//私有数据descriptor_state</span></div><div class="line">  &#123;</div><div class="line">    descriptor_state* descriptor_data = <span class="keyword">static_cast</span>&lt;descriptor_state*&gt;(ptr);</div><div class="line">    descriptor_data-&gt;set_ready_events(events[i].events);</div><div class="line">    private_op_queue.push(descriptor_data);</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上面的代码会根据epoll_wait的结果，将就绪事件所关联的descriptor_state数据添加到调用线程的this_thread.private_op_queue这个私有队列上面去。<br>(b). 添加到this_thread.private_op_queue就不管了么？当然不是，这里添加了一个RAII类型的task_io_service::task_cleanup，会自动把this_thread_-&gt;private_op_queue的任务添加到task_io_service_-&gt;op_queue_这个全局队列当中去，同时添加一个垫底的task_operation_，再次等待io_service调度这个任务。下个循环时候，队列弹出来的元素就不是task_operation_，而是descriptor_state类型，此后就有文章可做了，task_result_表示就绪的事件集合。这里需要注意descriptor_state是在派生了operation(task_io_service_operation)的同时，也添加了一些自己的操作，当调用descriptor_state::complete()函数的时候，其调用了自身的func_函数，要想知道这个func_究竟是哪个函数实体，还得看它在构造的时候怎么初始化的，构造函数表明：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[detail/impl/epoll_reactor.ipp]</div><div class="line">epoll_reactor::descriptor_state::descriptor_state()</div><div class="line">  : operation(&amp;epoll_reactor::descriptor_state::do_complete)</div></pre></td></tr></table></figure></p>
<p>这个func_是被初始化成了descriptor_state::do_complete成员函数，所以这里等价调用了descriptor_state::do_complete，其所做的操作为根据events调用descriptor_data-&gt;perform_io(events)函数，而perform_io函数再根据传递进来的就绪事件类型，依次调用对应具体事件的perform()函数，至于这里为啥complete会绕圈而不直接调用perform_io()，其实是因为这个complete()-&gt;func_会被复用，类似于设计模式下的状态模式，等你看到下面就自然明白了。因此其调用链为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">descriptor_state::complete() -&gt; func_ -&gt; do_complete() -&gt; perform_io() -&gt; reactor_op::perform()</div><div class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">bool</span> <span class="params">(*perform_func_type)</span><span class="params">(reactor_op*)</span></span>;</div></pre></td></tr></table></figure></p>
<p>perform调用的是perform_func_函数。在之添加异步操作请求调用start_op的时候，创建了reactive_socket_recv_op对象，在其构造函数中可以清晰地看到：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reactor_op(&amp;reactive_socket_recv_op_base::do_perform, complete_func)</div></pre></td></tr></table></figure></p>
<p>所以这个perform_func_就是reactive_socket_recv_op_base::do_perform成员函数，打开这个函数的定义，实际的IO操作就自然显现出来了，这里的接收函数，以及很多同类的IO操纵函数，都是被定义在socket_ops名字空间中的自由函数，上面已经说到了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">return</span> socket_ops::non_blocking_recv(o-&gt;socket_, bufs.buffers(), bufs.count(), </div><div class="line">  o-&gt;flags_, (o-&gt;state_ &amp; socket_ops::stream_oriented) != <span class="number">0</span>,</div><div class="line">  o-&gt;ec_, o-&gt;bytes_transferred_);</div></pre></td></tr></table></figure></p>
<p>在perform_io的函数中，还定义了一个十分重要的RAII对象io_cleanup，原理和上面的task_cleanup一样都是RAII的典型用例，可以学习过来。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">operation* epoll_reactor::descriptor_state::perform_io(<span class="keyword">uint32_t</span> events)</div><div class="line">&#123;</div><div class="line">  <span class="function">perform_io_cleanup_on_block_exit <span class="title">io_cleanup</span><span class="params">(reactor_)</span></span>;</div><div class="line">  ...</div><div class="line">  io_cleanup.first_op_ = io_cleanup.ops_.front();</div><div class="line">  io_cleanup.ops_.pop();</div><div class="line">  <span class="keyword">return</span> io_cleanup.first_op_;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>在io_cleanup的析构函数中，首先会返回第一个reactor_op对象io_cleanup.first_op_，然后后面如果还有处理过的op(比如event中堆积了多个就绪的事件)，就会调用reactor_-&gt;io_service_.post_deferred_completions(ops_)把剩余的处理完的opn依次添加到task_io_service::op_queue_上面去。<br>所以，第一个完成的op会被直接调用，其余的op会被添加全局的task_io_service::op_queue_队列上面去。至此，该descriptor_state的底层的IO已经全部完成了。</p>
<p>在上面的perform_io返回了io_cleanup.first_op_之后，会调用它的complete函数：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">void</span> epoll_reactor::descriptor_state::do_complete(</div><div class="line">    io_service_impl* owner, operation* base,</div><div class="line">    <span class="keyword">const</span> boost::system::error_code&amp; ec, <span class="built_in">std</span>::<span class="keyword">size_t</span> bytes_transferred)</div><div class="line">&#123;</div><div class="line">  ...</div><div class="line">    <span class="keyword">if</span> (operation* op = descriptor_data-&gt;perform_io(events)) &#123;</div><div class="line">      op-&gt;complete(*owner, ec, <span class="number">0</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>可能会觉得，这些对象被反复添加到task_io_service::op_queue_中，而且都是调用complete，那么IO之前的complete和IO之后的complete是怎么区分的呢？其技巧在于：<br>(a). 第一次IO之前传递进去的是descriptor_state对象，在构造的时候将基类的operation::complete()的调用函数通过func_媒介，指向了自己的成员函数do_complete()，在这个函数中定义执行了perform_io()操作；<br>(b). 在IO结束之后，其返回的类型是reactor_op，该对象的complete()，实际是调用最初我们启动async_read()提供的回调函数。<br>因为这两个类都是继承自operation的，所以都可以放到全局op_queue_当中，公用同一套处理流程，而实际的操作会根据对象的不同而不同，算不算是一个状态模式呢。同时，这里也需要弄清楚：descriptor_state是以描述符为对象的，而reactor_op是以事件为对象的，一个描述符可以侦听多个事件，多个事件的op信息使用op_queue<reactor_op> op_queue_[max_ops];数组来保存。<br>通过最终调用reactive_socket_recv_op::do_complete，函数会将调用结果的ec和bytes_transferred传递进去，然后用户提供的回调函数被正式调用，整个异步操作流程到此结束。</reactor_op></p>
<p>自此，Initiator发起异步请求操作和Proactor发起套接字socket的事件侦听和处理就连接起来了，整个工作流程表述为：<br>(a). Intiator通过async_read_some发起请求，同时提供buffer和callback信息；<br>(b). 然后reactive_socket_service一方面将socket关注的事件添加到epoll侦听中去，同时将reactor_op相关的信息添加到与事件对应的op_queue_的队列中；<br>(c). 另外通过io_service::run()，线程会通过do_run_one()-&gt;task_-&gt;run()-&gt;epoll_wait()的方式等待socket就绪的事件，一旦发现就会取出来并将descriptor_state添加到io_service队列上，io_service调度到这个descriptor_state后会调用perform_io进行底层的IO操作；<br>(d). IO完成后，会随即调用第一个reactor_op的complete；此时如果还有其它的reactor_op，会将剩余的添加到io_service::op_queue_队列，让io_service稍后调度执行对应的complete。这些complete会最终会调用用户异步操作时候提供的回调函数，同时更新传递进来的引用参数做为调用结果。</p>
<h1 id="五、composed_operation">五、composed operation</h1><p>之前提到，async_read/write，async_read_until函数是composed operatio，比如一次调用async_read可能会调用零到多次的async_read_some直到某些条件被满足。这里的composed operation是自由函数，在[read.hpp,write.hpp]中声明和定义的，同时根据提供的buffer类型具有MutableBufferSequence和basic_streambuf两大类的重载版本。这里我们先只考虑MutableBufferSequence这种类型。<br>如果只考虑一种buffer类型(比如MutableBufferSequence)，那么其async_read其实还有两种重载类型：一个是用户指定完成条件的，一个是没有指定的。从底层实现看来，两者的实现是极为相似的，只是后者提供了默认的结束条件，差异就在于当用户没有提供CompletionCondition的时候，默认是填满buffer的容量、或者发送错误的情况下async_read结束。为了使用方面，其实对于CompletionCondition条件谓语，Boost.Asio也为我们提供了很多预先定义好的类型，比如boost::asio::transfer_all()等。<br>贴出async_read的函数体：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">template &lt;typename AsyncReadStream, typename MutableBufferSequence,</div><div class="line">    typename ReadHandler&gt;</div><div class="line">inline BOOST_ASIO_INITFN_RESULT_TYPE(ReadHandler,</div><div class="line">    void (boost::system::error_code, std::size_t))</div><div class="line">async_read(AsyncReadStream&amp; s, const MutableBufferSequence&amp; buffers,</div><div class="line">    BOOST_ASIO_MOVE_ARG(ReadHandler) handler)</div><div class="line">&#123;</div><div class="line">  detail::async_result_init&lt;</div><div class="line">    ReadHandler, void (boost::system::error_code, std::size_t)&gt; init(</div><div class="line">      BOOST_ASIO_MOVE_CAST(ReadHandler)(handler));</div><div class="line"></div><div class="line">  detail::read_op&lt;AsyncReadStream, MutableBufferSequence,</div><div class="line">    detail::transfer_all_t, BOOST_ASIO_HANDLER_TYPE(</div><div class="line">      ReadHandler, void (boost::system::error_code, std::size_t))&gt;(</div><div class="line">        s, buffers, transfer_all(), init.handler)(</div><div class="line">          boost::system::error_code(), 0, 1);</div><div class="line"></div><div class="line">  return init.result.get();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>我靠，又是一个极其复杂的函数头，函数体主要执行了两个模板函数detail::async_result_init和detail::read_op，<br>在detail::read_op的operator()调用中，可以看到在一个for(;;)有关于async_read_some()的调用，不过这个for(;;)写的也非常诡异，只有在break的时候才表示执行结束的条件满足了，接下来调用handler_，否则会return掉，表示接下来还会再次跳入for(;;)循环中。</p>
<p>花了两天的功夫，总算看完了，也只能算是了解了个大概，很多的东西还是没懂。这个Boost.Asio中充斥着大量的闭包、模板元等特性，需要及其严密的逻辑和对整体的把控才能开发出来并稳定运行，由此真心膜拜一下大神<a href="https://github.com/chriskohlhoff" target="_blank" rel="external">Christopher M. Kohlhoff</a>，感谢你对C++ Network的工作，希望你的代码能让我看懂！</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="http://blog.csdn.net/luansxx/article/details/7854316" target="_blank" rel="external">boost asio 应用方法学（一）——序言</a></li>
<li><a href="http://blog.csdn.net/ithiker/article/details/24348047" target="_blank" rel="external">Linux下Boost.Asio Proactor模式实现分析</a></li>
<li><a href="http://stackoverflow.com/questions/14089412/whats-the-name-of-this-property-of-asynchronous-actions-boost-asio-related" target="_blank" rel="external">What’s the name of this property of asynchronous actions. (boost asio related)</a></li>
<li><a href="http://spiritsaway.info/cpp/asio-implementation.html" target="_blank" rel="external">Asio Implementation</a></li>
<li><a href="http://think-async.com/Asio" target="_blank" rel="external">Asio C++ Library</a></li>
<li><a href="http://vicendominguez.blogspot.com/2014/04/boost-c-library-rpm-packages-for-centos.html" target="_blank" rel="external">Boost C++ library RPM packages for CentOS 6</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost.Asio网络开发基础知识（一）：读读文档]]></title>
      <url>https://taozj.org/201609/basics-of-boost-asio-(1)-read-the-docs.html</url>
      <content type="html"><![CDATA[<p>　　虽然C++可以用Libevent等纯C实现框架进行异步操作，但是总感觉Boost.Asio才算是相对正统纯正的C++网络开发，而且据说已经起草的C++ Network Library就是基于Boost.Asio的，这不禁让我这个初入Boost的菜鸟暗中激动了一把。<br>　　在我所了解的Libevent和Boost.Asio当中，最大的差别是前者是Reactor模式，后者是Proactor模式了，不过Linux平台底层操作系统级别的select/poll/epoll只能适合Reactor模式的开发，所以Linux类平台下的Boost.Asio也是通过synchronous event demultiplexors的方式模拟实现的Proactor模式。除此之外，Libevent提供了一个Evbuffer的IO缓冲数据结构，而Boost.Asio同样也提供了boost::asio::buffer和boost::asio::streambuf两种缓冲类型，不过这也算是个壳吧，至少boost::asio:buffer构造的时候还是需要传输底层数组或者容器类实例作为实际数据的载体的。再则，Boost.Asio提供了自带线程池的功能，包括单个io_service运行在多个线程上和每个线程自己单独的io_service两种模式，这在网络库中并不多见吧。这个机制确实提高了多线程开发的效率，同时也免去了很多初学者自己制造垃圾线程池的烦恼。<br>　　可惜的是，据我Google关于Boost.Asio网上的资料确实好少，其中找到的大多都是那种教你怎么使用的简单例子，很少有深入剖析的资料，作为实际工业实现标准级别C++网络库Boost.Asio不觉得免有些奇怪，希望C++网络库标准敲定之后，这类部分能得到更多的关注吧。不过Boost.Asio确实还蛮好用的，看看附加的例子基本就能模仿出个不错的服务端了，今天把Boost.Asio的文档过了一遍，在此做个记录。</p>
<p><strong>1. 概述</strong><br>　　说到Boost.Asio，就不得不祭出这张Proactor设计模式的大图：<br><img src="/post_images/images/201609/7a27c440c2d2ebfee1afc8c1c860e7c6.png" alt="Boost.Asio Proactor"><br>　　关于图中的术语描述如下(其中当末尾明确指出了Reactor的，是在Windows和Linux类实现有所不同的地方，Linux类使用基于Reactor来模拟Proactor的模式)：<br>　　a. Initiator：应用程序相关的代码，主要是发起异步操作的请求，在启动异步操作的时候负责创建一个异步回调对象；<br>　　b. Asynchronous Operation Processor：执行异步操纵，并且将执行结束后，将时间排列到时间完成队列上去。在Reactor模式下的实现是，当select/epoll等指示出等待的资源就绪可以进行操作的时候，processor会执行实际的异步操作，完成之后会将与其关联的completion handler添加完成事件队列上去；<br>　　c. Asynchronous Operation：定义了异步执行的操作；<br>　　d. Completion Event Queue：缓存了已经完成事件直到被asynchronous event demultiplexer取出队列。在Reactor模式下通常是链接的函数对象；<br>　　e. Asynchronous Event Demultiplexer：阻塞形式地等待在完成事件队列上，直到有事件发生，然后返回一个完成事件给调用者。在Reactor模式下，是通过等待在某个事件或者某个条件变量上面，直到完成时间队列上completion handler就绪；<br>　　f. Completion Handler：用以处理异步操作完成的结果，其是个函数对象(function objects)，通常使用boost:bind()创建的；<br>　　g. Proactor：调用asynchronous event demultiplexer去从完成队列中取出完成的事件，并且调用处理(dispatch)事件对应的completion handler。<br><a id="more"></a><br><strong>2. Strand</strong><br>　　strand可以保证严格序列化地执行event handlers，使用strand可以安全的在多线程环境下执行程序，而不需要使用者显式的使用mutex等方式来同步。strand的可以以隐式或者显式的方式存在：<br>　　a. 如果只在一个线程中调用io_service::run()，那么所有的event handlers都是在一个隐式strand中序列化执行的；<br>　　b. 对于一个链接只有一个单链异步操作的时候，其不可能并发的执行event handlers，这也是隐式strand的。(文中提到了比如HTTP的单双工协议，我的理解是HTTP只会客户端请求、服务端返回数据这种形式，而不会服务端主动请求，没有并行的可能性，所以所有的请求应当必然是串行化的)；<br>　　c. 可以显式实例化一个strand对象，然后所有的event handlers必须使用io_service::strand::wrap()进行包裹，或者使用该strand对象显式post/dispatch；<br>　　关于Strand，Boost.Asio的手册说的不是很清楚，在此明确一下表示：<br>　　Boost.Asio对线程安全的保证描述是，concurrent使用不同的object是安全的，但是concurrent使用相同的object是不安全的，这就比如一个socket可以在一个线程中随便使用，或者在两个线程中不同时使用，但是绝对不允许在两个线程中重叠使用(即使通常意义上的socket也不要同时在多线程中使用)。Boost.Asio这里复杂了是因为async_write、async_read包括async_read_until这类函数被称为composed operation，他会在底层零次或者多次调用async_write_some这类函数来实现的，所以对这一类函数的调用，必须显式使用strand进行串行化其内部的操作，同时用户端程序还必须保证在执行这个操作的过程中不会有其他的async_write、async_write_some等函数的调用。这样HTTP Example3的strand也就不难解释了。</p>
<p><strong>3. 缓冲类型</strong><br>　　Boost.Asio是支持聚合读写(scatter-gather operations)的，当需要的时候将各个buffer装入容器中传递给聚合操作。对于单独的buffer，<br>　　a. boost::asio::buffer<br>　　主要有mutable_buffer、const_buffer两种类型，从一般的概念上讲是如下的含义<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">void</span>*, <span class="built_in">std</span>::<span class="keyword">size_t</span>&gt; mutable_buffer;</div><div class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">const</span> <span class="keyword">void</span>*, <span class="built_in">std</span>::<span class="keyword">size_t</span>&gt; const_buffer;</div></pre></td></tr></table></figure></p>
<p>　　但是实际Boost.Asio是定义了这两个类，主要基于以下考虑：(1)如果是上面类型，那么mutable可以转换成const的，但是反向的转换是不允许的；(2)可以保护防止缓冲区溢出，类可以通过传递的array、std::vector、std::string、std::arry、POD等各种类型自动推断出buffer的长度；(3)可以定义buffer_cast等成员函数做更丰富的操作需求，而不是底层数据的野蛮转换。<br>　　b. boost::asio::streambuf<br>　　派生自std::basic_streambuf类而关联了input和output两个序列，序列底层用一个或者多个字符数组存储数据的，当然这些数据是streambuf内部使用的，而streambuf提供一系列的接口来操作这些数据：<br>　　(1) data()成员函数访问input，返回的类型满足ConstBufferSequence类型；<br>　　(2) prepare()成员函数用于访问output，返回的类型满足MutableBufferSequence类型；<br>　　(3) commit()成员函数用于将output头部的数据移动到input的尾部；<br>　　(4) consume()成员函数用于移除input头部的数据；<br>　　streambuf的构造函数可以传递一个size_t的参数来指明input和output总共的最大尺寸，当使用的总空间超过这个限制的时候，会抛出std::length_error的异常。<br>　　此外，streambuf提供了迭代器的接口，可以连续访问内部存储的字节序列，其操作的模板是：<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">std::size_t n = boost::asio::read_until(sock, sb, '\n');</div><div class="line">boost::asio::streambuf::const_buffers_type bufs = sb.data();</div><div class="line">std::string line(</div><div class="line">    boost::asio::buffers_begin(bufs),</div><div class="line">    boost::asio::buffers_begin(bufs) + n);</div></pre></td></tr></table></figure></p>
<p><strong>4. 流数据操作</strong><br>　　Boost.Asio中的大多数操作都是基于流(stream)的，所以：对消息没有边界的概念，真正传输的数据都是一些列连续的字节序列；读和写操作实际传输的字节数目可能会比请求的数目要少。常用的同步和异步操作有：read_some()、async_read_some()、write_some()、async_write_some()。<br>　　当开发过程中有需要传输指定长度的消息的时候，可以使用Boost.Asio的read()、async_read()、write()、async_write()来实现，他们会自动重复执行传输操作，直到请求的操作数完成。不嫌麻烦的话用户程序不断尝试直到完成也是可以的。<br>　　当流请求操作结束后会涉及到EOF，成功读返回读取长度为0表示该流已经结束了。</p>
<p><strong>5. Reactor模式风格的操作</strong><br>　　有时候有的程序可能自己进行I/O操作，Boost.Asio也支持这种机制。当在IO读写函数需要传递buffer对象的地方传递null_buffers对象既可，这时候null_buffers的操作会在底层的数据准备好(可以成功读写)之后返回。<br>　　然后，客户程序就可以使用同步读写函数来进行IO操作了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">socket.async_read_some(null_buffers(), read_handler);</div><div class="line">...</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">read_handler</span><span class="params">(boost::system::error_code ec)</span> </span>&#123;</div><div class="line">  <span class="keyword">if</span> (!ec) &#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; buf(socket.available());</div><div class="line">    socket.read_some(buffer(buf));</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>6. 基于行模式的操作</strong><br>　　很多网络引用层的协议(HTTP、SMTP、FTP)都是基于行(line-based)的，所以这些协议的元素都是用”\r\n”来分隔的，此时Boost.Asio的read_until和async_read_until就可以方便的来处理基于行或者基于特定分隔符的应用层协议了，简单用法其支持的分隔符包括char、std::string、boost::regex类型的表达式。<br>　　更高端的用法是(async_)read_until支持接收一个用户定义的函数或者函数对象，其函数或者函数对象具有以下的形式：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> boost::asio::buffers_iterator&lt;</div><div class="line">    boost::asio::streambuf::const_buffers_type&gt; iterator;</div><div class="line"> </div><div class="line"><span class="built_in">std</span>::pair&lt;iterator, <span class="keyword">bool</span>&gt;</div><div class="line">match_whitespace(iterator begin, iterator end)&#123;</div><div class="line">...</div><div class="line"><span class="keyword">return</span> <span class="built_in">std</span>::make_pair(i, <span class="literal">true</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　所以我在开发HTTP简单应用的时候，都是先用streambuf的async_read_until读取”\r\n\r\n”表示HTTP头部结束的位置，分析头部的Length字段得到数据体的具体大小，然后调用async_read添加transfer_exactly参数来进行精确传输的。这里使用需要格外注意的是，HTTP的头和体不是分开传输的，绝大多数async_read_until会读一部分的BODY，这时候需要手动将这部分的数据转移到async_read的缓冲区里面去。</p>
<p><strong>7. 其它</strong><br>　　C++11提供了右值引用和移动语义，所以在Boost.Asio中可以使用这些语义来移动IO object和Handler。在移动IO Object的时候需要特别的注意，当其上面还有pending的异步操作时候，移动它是很危险的，常常诸如async_read()会保存这些对象的引用，意味着很可能后面会用到move-from的对象。一般在开始构造connection的时候可以利用移动语句，后面使用还需谨慎。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">tcp::socket socket_;</div><div class="line">connection(tcp::socket&amp;&amp; s) : socket_(<span class="built_in">std</span>::move(s)) &#123;&#125;</div><div class="line">...</div><div class="line"><span class="built_in">std</span>::make_shared&lt;connection&gt;(<span class="built_in">std</span>::move(socket_))-&gt;go();</div><div class="line">acceptor_.async_accept(socket_, ...);</div></pre></td></tr></table></figure></p>
<p><strong>8. 小结</strong><br>　　哈哈，基本没什么干货或者新东西，Boost.Asio的开发还是建议多看看官方提供的那些<a href="http://www.boost.org/doc/libs/1_51_0/doc/html/boost_asio/examples.html" target="_blank" rel="external">例子</a>，另外我的<a href="https://github.com/taozhijiang/airobot_msgd" target="_blank" rel="external">airobot_msgd</a>也囊括了大多数的操作，尽请指正。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4478.html" target="_blank" rel="external">Networking Library Proposal (Revision 5)</a></li>
<li><a href="http://blog.csdn.net/luansxx/article/details/7854316" target="_blank" rel="external">boost asio 应用方法学（一）——序言</a></li>
<li><a href="http://blog.csdn.net/ithiker/article/details/24348047" target="_blank" rel="external">Linux下Boost.Asio Proactor模式实现分析</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/overview.html" target="_blank" rel="external">Boost.Asio Overview</a></li>
<li><a href="http://www.crazygaze.com/blog/2016/03/17/how-strands-work-and-why-you-should-use-them/" target="_blank" rel="external">How strands work and why you should use them</a></li>
<li><a href="https://stackoverflow.com/questions/12794107/why-do-i-need-strand-per-connection-when-using-boostasio" target="_blank" rel="external">Why do I need strand per connection when using boost::asio?</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[C++11标准中的Atomic原子操作和内存模型]]></title>
      <url>https://taozj.org/201609/cpp11-atomic-and-memory-model.html</url>
      <content type="html"><![CDATA[<p>　　原子操作在多线程开发中经常用到，比如在计数器，序列产生器等地方，这类情况下数据有并发的危险，但是用锁去保护又显得有些浪费，所以原子类型操作十分的方便。<br>　　原子操作虽然用起来简单，但是其背景远比我们想象的要复杂。其主要在于现代计算系统过于的复杂：多处理器、多核处理器、处理器又有核心独有以及核心共享的多级缓存，在这种情况下，一个核心修改了某个变量，其他核心什么时候可见是一个十分严肃的问题。同时在极致最求性能的时代，处理器和编译器往往表现的很智能，进行极度的优化，比如什么乱序执行、指令重排等，虽然可以在当前上下文中做到很好的优化，但是放在多核环境下常常会引出新的问题来，这时候就必须提示编译器和处理器某种提示，告诉某些代码的执行顺序不能被优化。<br>　　所以这里说到的原子操作，基本都包含我们三个方面所关心的语义：操作本身是不可分割的(Atomicity)，一个线程对某个数据的操作何时对另外一个线程可见(Visibility)，执行的顺序是否可以被重排(Ordering)。<br><img src="/post_images/images/201609/1a568a5bae9b5dba290855689577f81f.png" alt="lockfree"></p>
<h1 id="一、legacy_GCC___sync">一、legacy GCC __sync</h1><p>　　据说在C++11标准出来之前，大家都诟病C++标准没有一个明确的内存模型，随着多线程开发的普及这个问题显得越来越迫切。当然各个C++编译器实现者也是各自为政，GCC自然是实用主义当道，于是根据Intel的开发手册老早就搞出了一系列的__sync原子操作函数集合，这也是被广大程序员最为熟悉常用的操作了吧，罗列如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>sync_fetch_and_OP (type *ptr, type value, ...)</div><div class="line">type <span class="number">__</span>sync_OP_and_fetch (type *ptr, type value, ...)</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>sync_bool_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line">type <span class="number">__</span>sync_val_compare_and_swap (type *ptr, type oldval, type newval, ...)</div><div class="line"><span class="number">__</span>sync_synchronize (...)</div><div class="line"></div><div class="line">type <span class="number">__</span>sync_lock_test_and_set (type *ptr, type value, ...)</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>sync_lock_release (type *ptr, ...)</div></pre></td></tr></table></figure></p>
<p>　　上面的OP操作包括add、sub、or、and、xor、nand这些常见的数学操作，而type表示的数据类型Intel官方允许的是int、long、long long的带符号和无符号类型，但是GCC扩展后允许任意1/2/4/8的标量类型；CAS的操作有两个版本分别返回bool表示是否成功，而另外一个在操作之前会先返回ptr地址处存储的值；__sync_synchronize直接插入一个full memory barrier，当然你也可能经常见到像asm volatile(“” ::: “memory”);这样的操作。前面的这些原子操作都是full barrier类型的，这意味着：任何内存操作的指令不允许跨越这些操作重新排序。<br>　　__sync_lock_test_and_set用于将value的值写入ptr的位置，同时返回ptr之前存储的值，其内存模型是acquire barrier，意味着该操作之后的memory store指令不允许重排到该操作之前去，不过该操作之前的memory store可以排到该操作之后去，而__sync_lock_release则更像是对前面一个操作锁的释放，通常意味着将0写入ptr的位置，该操作是release barrier，意味着之前的memory store是全局可见的，所有的memory load也都完成了，但是接下来的内存读取可能会被排序到该操作之前执行。可以这里比较绕，翻译起来也比较的拗口，不过据我所见，这里很多是用在自旋锁类似的操作上，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> <span class="number">_</span>sync;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">lock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">while</span>(<span class="number">__</span>sync_lock_test_and_set(&amp;<span class="number">_</span>sync, <span class="number">1</span>));</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">unlock_sync</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="number">__</span>sync_lock_release(&amp;<span class="number">_</span>sync);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其实这里的1可以是任何non-zero的值，主要是用作bool的效果。<br><a id="more"></a></p>
<h1 id="二、C++11_新标准中的内存模型">二、C++11 新标准中的内存模型</h1><p>　　上面GCC那种full barrier的操作确实有效，但是就像当初系统内核从单核切换到多核用大颗粒锁一样的简单粗暴，先不说这种形势下编译器和处理器无法进行优化，光要变量使其对他处理器可见，就需要在处理间进行硬件级别的同步，显然是十分耗费资源的。在C++11新标准中规定的内存模型(memory model)颗粒要细化的多，如果熟悉这些内存模型，在保证业务正确的同时可以将对性能的影响减弱到最低。<br>　　原子变量的通用接口使用store()和load()方式进行存取，可以额外接受一个额外的memory order参数，而不传递的话默认是最强模式Sequentially Consistent。<br>　　根据执行线程之间对变量的同步需求强度，新标准下的内存模型可以分成如下几类：</p>
<h2 id="2-1_Sequentially_Consistent">2.1 Sequentially Consistent</h2><p>　　该模型是最强的同步模式，参数表示为std::memory_order_seq_cst，同时也是默认的模型。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">-Thread <span class="number">1</span>-       -Thread <span class="number">2</span>-</div><div class="line">y = <span class="number">1</span>            <span class="keyword">if</span> (x.load() == <span class="number">2</span>)</div><div class="line">x.store (<span class="number">2</span>);        assert (y == <span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>　　对于上面的例子，即使x和y是不相关的，通常情况下处理器或者编译器可能会对其访问进行重排，但是在seq_cst模式下，x.store(2)之前的所有memory accesses都会happens-before在这次store操作。<br>另外一个角度来说：对于seq_cst模式下的操作，所有memory accesses操作的重排不允许跨域这个操作，同时这个限制是双向的。</p>
<h2 id="2-2_Acquire/Release">2.2 Acquire/Release</h2><p>　　GCC的wiki可能讲的不太清楚，查看下面的典型Acquire/Release的使用例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; a&#123;<span class="number">0</span>&#125;;</div><div class="line"><span class="keyword">int</span> b = <span class="number">0</span>;</div><div class="line"></div><div class="line">-Thread <span class="number">1</span>-</div><div class="line">b = <span class="number">1</span>;</div><div class="line">a.store(<span class="number">1</span>, memory_order_release);</div><div class="line"></div><div class="line">-Thread <span class="number">2</span>-</div><div class="line"><span class="keyword">while</span> (a.load(memory_order_acquire) != <span class="number">1</span>)  <span class="comment">/*waiting*/</span>;</div><div class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; b &lt;&lt; <span class="string">'\n'</span>;</div></pre></td></tr></table></figure></p>
<p>　　毫无疑问，如果是seq_cst，那么上面的操作一定是成功的(打印变量b显示为1)。<br>　　a. memory_order_release保证在这个操作之前的memory accesses不会重排到这个操作之后去，但是这个操作之后的memory accesses可能会重排到这个操作之前去。通常这个主要是用于之前准备某些资源后，通过store+memory_order_release的方式”Release”给别的线程；<br>　　b. memory_order_acquire保证在这个操作之后的memory accesses不会重排到这个操作之前去，但是这个操作之前的memory accesses可能会重排到这个操作之后去。通常通过load+memory_order_acquire判断或者等待某个资源，一旦满足某个条件后就可以安全的“Acquire”消费这些资源了。</p>
<h2 id="2-3_Consume">2.3 Consume</h2><p>　　这是一个相比Acquire/Release更加宽松的内存模型，对非依赖的变量也去除了happens-before的限制，减少了所需同步的数据量，可以加快执行的速度。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">-Thread <span class="number">1</span>-</div><div class="line">n = <span class="number">1</span></div><div class="line">m = <span class="number">1</span></div><div class="line">p.store (&amp;n, memory_order_release)</div><div class="line"></div><div class="line">-Thread <span class="number">2</span>-</div><div class="line">t = p.load (memory_order_acquire);</div><div class="line">assert( *t == <span class="number">1</span> &amp;&amp; m == <span class="number">1</span> );</div><div class="line"></div><div class="line">-Thread <span class="number">3</span>-</div><div class="line">t = p.load (memory_order_consume);</div><div class="line">assert( *t == <span class="number">1</span> &amp;&amp; m == <span class="number">1</span> );</div></pre></td></tr></table></figure></p>
<p>　　线程2的assert会pass，而线程3的assert可能会fail，因为n出现在了store表达式中，算是一个依赖变量，会确保对该变量的memory access会happends-before在这个store之前，但是m没有依赖关系，所以不会同步该变量，对其值不作保证。<br>　　Comsume模式因为降低了需要在硬件之间同步的数量，所以理论上其执行的速度会比之上面的内存模型块一些，尤其在共享内存大规模数据量情况下，应该会有较明显的差异表现出来。<br>　　在这里，Acquire/Consume~Release这种线程间同步协作的机制就被完全暴露了，通常会形成Acquired/Consume来等待Release的某个状态更新。需要注意的是这样的通信需要两个线程间成对的使用才有意义，同时对于没有使用这个内存模型的第三方线程没有任何作用效果。</p>
<h2 id="2-4_Relaxed">2.4 Relaxed</h2><p>　　最宽松的模式，memory_order_relaxed没有happens-before的约束，编译器和处理器可以对memory access做任何的re-order，因此另外的线程不能对其做任何的假设，这种模式下能做的唯一保证，就是一旦线程读到了变量var的最新值，那么这个线程将再也见不到var修改之前的值了。<br>　　这种情况通常是在需要原子变量，但是不在线程间同步共享数据的时候会用，同时当relaxed存一个数据的时候，另外的线程将需要一个时间才能relaxed读到该值，在非缓存一致性的构架上需要刷新缓存。在开发的时候，如果你的上下文没有共享的变量需要在线程间同步，选用Relaxed就可以了。</p>
<h2 id="2-5_小结">2.5 小结</h2><p>　　看到这里，你对Atomic原子操作，应当不仅仅停留在indivisable的层次了，因为所有的内存模型都能保证对变量的修改是原子的，C++11新标准的原子应该上升到了线程间数据同步和协作的问题了，跟前面的LockFree关系也比较密切。<br>　　手册上也这样告诫菜鸟程序员：除非你知道这是什么，需要减弱线程间原子上下文同步的耦合性增加执行效率，才考虑这里的内存模型来优化你的程序，否则还是老老实实的使用默认的memory_order_seq_cst，虽然速度可能会慢点，但是稳妥些，万一由于你不成熟的优化带来问题，是很难去调试的。</p>
<h1 id="三、C++11_GCC___atomic">三、C++11 GCC __atomic</h1><p>　　GCC实现了C++11之后，上面的__sync系列操作就变成了Legacy而不被推荐使用了，而基于C++11的新原子操作接口使用__atomic作为前缀。<br>　　对于普通的数学操作函数，其函数接口形式为：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>atomic_OP_fetch (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line">type <span class="number">__</span>atomic_fetch_OP (type *ptr, type val, <span class="keyword">int</span> memorder);</div></pre></td></tr></table></figure></p>
<p>　　除此之外，还根据新标准提供了一些新的接口：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">type <span class="number">__</span>atomic_load_n (type *ptr, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_store_n (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line">type <span class="number">__</span>atomic_exchange_n (type *ptr, type val, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_compare_exchange_n (type *ptr, type *expected, type desired, <span class="keyword">bool</span> weak, <span class="keyword">int</span> success_memorder, <span class="keyword">int</span> failure_memorder);</div><div class="line"> </div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_test_and_set (<span class="keyword">void</span> *ptr, <span class="keyword">int</span> memorder);</div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_clear (<span class="keyword">bool</span> *ptr, <span class="keyword">int</span> memorder);</div><div class="line"> </div><div class="line"><span class="keyword">void</span> <span class="number">__</span>atomic_thread_fence (<span class="keyword">int</span> memorder);</div><div class="line"> </div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_always_lock_free (<span class="keyword">size_t</span> size, <span class="keyword">void</span> *ptr);</div><div class="line"><span class="keyword">bool</span> <span class="number">__</span>atomic_is_lock_free (<span class="keyword">size_t</span> size, <span class="keyword">void</span> *ptr);</div></pre></td></tr></table></figure></p>
<p>　　从函数名，看起来意思也很明了吧，上面的带_n的后缀版本如果去掉_n就是不用提供memorder的seq_cst版本。最后的两个函数，是判断系统上对于某个长度的对象是否会产生lock-free的原子操作，一般long long这种8个字节是没有问题的，对于支持128位整形的构架就可以达到16字节无锁结构了。</p>
<p>　　Boost.Asio这里就不在罗列了，不过其中有一些例子比较好，基于内存模型的Wait-free的ring buffer、producer-customer的例子，可以去看看。</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="http://theboostcpplibraries.com/boost.atomic" target="_blank" rel="external">Chapter 45. Boost.Atomic</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/atomic.html" target="_blank" rel="external">Chapter 5. Boost.Atomic</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html" target="_blank" rel="external">6.52 Built-in Functions for Memory Model Aware Atomic Operations</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/_005f_005fsync-Builtins.html" target="_blank" rel="external">6.51 Legacy __sync Built-in Functions for Atomic Memory Access</a></li>
<li><a href="https://fotisl.com/blog/2009/11/concurrent-programming-the-fast-and-dirty-way/" target="_blank" rel="external">Concurrent programming the fast and dirty way!</a></li>
<li><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3337.pdf" target="_blank" rel="external">n3337.pdf</a></li>
<li><a href="https://gcc.gnu.org/wiki/Atomic/GCCMM/AtomicSync" target="_blank" rel="external">GCC wiki on atomic synchronization</a></li>
<li><a href="http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/" target="_blank" rel="external">Double-Checked Locking is Fixed In C++11</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[多线程开发中无锁队列的设计和实现]]></title>
      <url>https://taozj.org/201609/lockless-in-multi-thread.html</url>
      <content type="html"><![CDATA[<p>　　首先，本人对多核编程的了解还不深入，也不知道等待无关(Wait-Free)、锁无关(Lock-Free)、基于锁(Lock-Based)这些高端的东西，其实原本我只是想接触一个不用锁的数据结构这么个意思，没想到lockfree还有这么大的一个坑。</p>
<p>　　现在熟悉多线程开发的人，都知道多线程开发环境下的利器就是：互斥锁、条件变量、任务队列。<br>　　条件变量主要是用于异步唤醒的，当资源不满足的时候线程挂起睡眠，当别的线程修改条件后通知唤醒该进程；任务队列是实现生产者消费者数据交互和缓冲的主要通道，通常使用固定长度的数组做round-robin Ring数组或者采用链表的方式进行管理。当然，在实践中，除了使用经典的条件变量唤醒的方式，还有就是通过管道：生产者向管道写命令，消费者在管道阻塞的读命令，这种方式可以天然的使用read/write阻塞和非阻塞行为，同时也很方便融入现在大量的异步框架中，这是在memcached中发现的，也算是一个编程的小技巧吧。<br>　　对于单个生产者和单个消费者的情况比较的简单，每一端自身不存在竞争条件，使用round-robin Ring数组本身就可以实现无锁队列了，而链表因为元素和其前后驱有耦合性，所以问题要复杂一些。其他的数据结构还需要看底层的容器类型，比如std::queue就是个适配器类，底层的容器类型可以是std::deque或者std::list。反正这种情况下锁的竞争不会十分的激烈，在此就不再讨论了。</p>
<p>　　对于成百上千的同构生产者和消费者，锁的竞争就会比较的激烈。提出这个问题的原因，是看到附录总的文章，mutex作为多线程最常用的同步手段，底层是用futex系统调用实现的，作者测试发现通过这种方式同步，大部分的时间都被浪费到了futex系统调用的开销上面了，其原理是通过系统调用陷入内核态，将当前线程放入到mutex的等待队列上面去，然后调度其它线程执行。不过我对作者第一篇测试99%的时间用于futex系统调用甚是怀疑，因为系统调用还涉及到信号处理、内核抢占等东西，把这笔账全部算在mutex很不公平。不过，系统调用陷入内核态，以及线程切换的过程中会有上下文的保存和加载，同时伴随着大量的缓存失效等，这算是连锁带来的实实在在巨大开销。同时，这也让我感觉到当前很多系统架构，动辄开很多的线程池是否真的值得有效：虽然线程池的创建的开销少了，但是线程间频繁切换以及带来的缓存失效，也会对性能造成巨大的负面影响。<br><img src="/post_images/images/201609/638cbc55ae6b218c9f18fdcd278be833.png" alt="lockfree"></p>
<p>　　所以，锁不是多线程开发的金钥匙，大量使用锁总是有害的(死锁、活锁、持锁线程挂起)，同时也是程序的性能杀手，在所以在实践中除了小心使用、缩小锁保护的临界区之外，能使用无所的数据结构当然是最有效的提高性能的方法了。<br><a id="more"></a><br>　　通过附录中的文章，基本对无锁队列的原理有一个大概的了解了，同时也意识到这类高性能的开发需要CPU架构、CPU缓存、编译器的特性、语言的特定模型等诸多知识，是同平台、编译器紧密相关的知识，但是抛却极致方面的最求，基本的思路都比较一致：<br>　　a. 使用round-robin Ring数组而非链表作为存储结构，一方面如我所说元素之间耦合性低，涉及到的修改很少；二来数组这种顺序存储类型对CPU和缓存机制是十分友好的，同时不会频繁的申请和释放节点，不会有内存碎片的问题。<br>　　b. 同步需求包括生产者之间、消费者之间以及队列饥饿和队列饱和的情况。同质者之间的竞争基本是采用“先占坑再埋坑”的思路，确保一个线程占用一个slot，做出修改之后再发布这个slot使其它线程可见，而具体实现有附录中用CAS的，也有用其他复杂检测的机制来实现的。关于队列饥饿和队列饱和，这种情况在实践中会经常的出现，因为生产者和消费者阻抗匹配是十分理想的情况，现实情况或多或少会有生产快于消费以及生产慢于消费的情况，而且这种差异会慢慢累积下去，所以对于round-robin Ring这种空队列和满队列需要格外考虑。</p>
<p>　　参考文件中关于<a href="http://ifeve.com/disruptor/" target="_blank" rel="external">并发框架Disruptor译文</a>我觉得还是很值的一读的，先不讨论Disruptor的实现原理，单单就高性能开发方面，就看着让人觉得大开眼界的感觉：<br>　　a. 新名词，锁分为悲观锁和乐观锁，悲观锁是独占锁也就是常常遇到的独占锁，当一个线程获得该锁会阻止所有其他线程得到锁；乐观锁是当线程需要写入的时候会请求锁，检查上次读完后目标数据是否已经修改了，如果修改了会重新读取并比较，其行为很像CAS，但是让我感兴趣的是还没接触过CAS形式的锁。<br>　　b. 处理器的缓存都是按照缓存行的形式组织的，一般一个缓存行64字节(或32-256字节)，所以如果数组元素不大，那么缓存行对数组是十分友好的(后续元素预加载的效果)，可以将数组接下来的元素都加载到缓存行中，而链表就没有这个优势了，相邻的元素很可能都无法命中缓存。但是结构中的数据，head和tail通常都是连续定义的，这导致的一个问题是head、tail常常会在同一个缓存行中，这时候修改了一个端会使缓存行失效，另外一段也就被“失效”了，称之为“伪缓存”，这里等于加剧了生产者和消费者的竞争，解决的方法是在两者之间添加一个cache line padding，迫使两者在不同的缓存行中。<br>　　c. Disruptor的设计感觉对读描述的较少，用了ConsumerBarrier等于起到一个代理的作用，这个代理顺序分配当前的对象，同时也知道Producer当前已经发布的cursor位置，但是消费者消费完空出slot的信息不知道是怎么通知ProducerBarrier的，文中没有提到；同时消费者的速度有差异，慢的消费者处理完后可以跳过前面已经被消费的元素。这里看来，怎么维持一个全局最小的消费者cursor是个关键。<br>　　d. 生产者采用了“先占坑再埋坑”的思路，先申请一个空闲的位置，然后填充对应的书，完成后提交这个数据称为消费者可见。生产者维持了一个全局的cursor，而提交更新这个cursor必须是顺序提交的，也就是即使前面的生产者已经完成了生产，也必须等待后面的生产者提交之后才能提交。</p>
<p>　　附录文章<a href="http://www.linuxjournal.com/content/lock-free-multi-producer-multi-consumer-queue-ring-buffer?page=0,0" target="_blank" rel="external">Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer</a>则是实现的一个生产者消费者对称设计的无锁任务队列，基本数据结构是round-robin Ring数组，同时也是“先占坑再埋坑”的思路，不过“埋坑”的时候没有采用顺序提交的情况，而是每个生产者和消费者维持了自己的生产或者消费位置，最后程序可以协调让cursor快进，这在很大程度上减少的多个生产者、消费者空等待的情况。</p>
<p>　　说了这么多的基础知识，然后就是的进行了一个简单的实现，借鉴了前面两者采用了最简单的实现方式：生产者和消费者对称设计、顺序提交的模式，使用CAS进行无锁同步。然后呢，我也像模像样地测试了一下，结果让我大跌眼镜：在16对生产者、消费者进行一千万次请求下，使用mutex和条件变量耗时3s，而我的无锁队列为18s，慢了整整6倍！！！</p>
<p>　　后面看了下别人评论，现在CAS有被滥用的趋势，很多成熟的Lockfree方案在并发量大的时候会遇到瓶颈，甚至性能会急剧恶化下去。然后告诫就是：只有确定需要无锁结构，并且知道你在干什么的时候，才使用无锁结构！！！<br>　　代码在<a href="https://github.com/taozhijiang/learncpp/tree/master/lockless" target="_blank" rel="external">lockless</a>，忘大拿帮我看看有啥问题没？还是本身就应该是这么慢！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.linuxjournal.com/content/lock-free-multi-producer-multi-consumer-queue-ring-buffer?page=0,0" target="_blank" rel="external">Lock-Free Multi-Producer Multi-Consumer Queue on Ring Buffer</a></li>
<li><a href="http://www.searchtb.com/2012/10/introduction_to_disruptor.html" target="_blank" rel="external">一种高效无锁内存队列的实现</a></li>
<li><a href="http://ifeve.com/disruptor/" target="_blank" rel="external">并发框架Disruptor译文</a></li>
<li><a href="http://www.boost.org/doc/libs/1_59_0/doc/html/lockfree.html" target="_blank" rel="external">Chapter 18. Boost.Lockfree</a></li>
<li><a href="http://coolshell.cn/articles/8239.html" target="_blank" rel="external">无锁队列的实现</a></li>
<li><a href="http://www.intel.cn/content/www/cn/zh/processors/architectures-software-developer-manuals.html" target="_blank" rel="external">英特尔® 64 和 IA-32 架构软件开发人员手册合并版</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[开发中IO分离设计的重构杂谈]]></title>
      <url>https://taozj.org/201609/talk-about-io-seperation-design.html</url>
      <content type="html"><![CDATA[<p>　　需求的变更和增加是程序员永远挥之不去的阴影，不过这也是保证程序员饭碗之所在，否则一个系统设计开发后就一直运行下去，那估计程序员都会成为项目制聘用了，公司才不会一直花钱把你养着供着呢。<br>　　这不，之前开发的人工座席<a href="/201605/auto-answer-recommend-conclusion.html">答案自动推荐模块项目小结</a>，经过接近两个月的线上调试修BUG，算是挺稳定的了，现在出的新需求是：将数据暴露到后台，可以网页修改数据。这一下折腾的有点大法了，听我慢慢道来。</p>
<p>　　之前没有考虑到会有这种需求，而且整体设计和实现都是我一人操办，所以项目架构、数据库设计都是自己任着性质来的：<br>　　a. 主系统因为数据量比较大，所以是站点按区域分库、每个库中按时间后缀分表存储的；<br>　　b. 我这里因为查询需要检索连续的时间、且总体数据量还不是很大，还有权限等乱七八糟的原因，所以我用的方案是：只在一个库中分表，用站点编号与16取余映射到这十六个分表中，这样可以隔时间把一部分旧数据导出到别的表，保证工作的数据表在一定时间段中连续，数据表也不过于膨胀下去。同时，还因为我的客户端设计用的数据库连接池，对同库使用十分方便，而跨库异构连接处理就有些麻烦。</p>
<p>　　如果要让我解决这个问题，那从我的角度最省事的方式，就是在当前库中额外添加一个表，每次处理坐席请求有新数据的时候，额外增加一次他们要求的入库操作，这样他们要的信息一次查表就可以，不用做跨表和连表的复杂查询了。</p>
<p>　　这样我是爽了，不过前端可能不哈皮了。因为之前相似的业务，都是基于主库那种分库和时间后缀表写的，即使我这种单表最简单的操作，前端也需要修改部分的代码和逻辑。结果就是前端设计跟主业务一样的分库和时间后缀表，让我这里填充这个表供他们访问。<br><a id="more"></a><br>　　这样，我操作起来就会有些麻烦：我需要在处理自己业务逻辑，写自己的单库分表的同时，还需要处理其它几个分库时间后缀表，如果在当前线程位置直接插入，那同步保护将会复杂很多。当时看陈硕的《Linux 多线程服务器端编程》的时候，告诉我们如果有较多的IO任务，可以将IO任务单独开辟一个线程，把工作线程的任务都通过队列发送到单独的线程去负责IO操作，不要让IO操作降低工作线程的效率。借助这个思路，我可以做的思路是：工作线程把数据库执行语句格式化好，然后插入到队列当中，然后IO线程不断从队列中取出语句逐个执行就可以了，而IO线程是顺序执行的，可以无锁使用每个分库的连接。</p>
<p>　　上面的思路已经算是可以了，不过还可以把思路更扩宽一些。其实很多公司的系统增长模式就是：开始在系统中慢慢增加功能，导致一个很大很复杂的系统出现，后续发现越来越难维护，也越来越难扩展的时候，再进行解耦分割成一个个单独的模块工作，模块之间通过某种方式去通信，这样不仅可以拆解成简单模块易于维护，还可以单机多进程、多级多进程随意扩展。</p>
<p>　　于是，我也按捺不住想要尝试一下这种模式，当然还有一个原因是原先的系统是用C写的，最近对C++比较的钟爱，即使当前生产机GCC-4.4.7并不完全支持C++11(-std=c++0x)，但是结合Boost库发现C++写起来还是比C要轻松很多。系统中总共有已有前端增加的网络工作线程、新开发的后端包括数据接收主线程和分库数据相等的SQL执行线程三个角色，整体的设计思路是这样的：<br>　　a. 前面还是像上面描述的一样，libmicrohttpd工作线程在有满足条件的数据出现时候，组合需要执行的SQL语句，然后将SQL语句压入到一个任务队列中就立即返回；<br>　　b. 开辟一个网络工作线程，负责将队列中的SQL语句不断发配给后端处理进程；<br>　　c. 处理进程包括数据接收主线程和SQL执行线程，SQL执行线程跟分库的数量一致，同时维持一个对目标分库的数据库长连接；<br>　　d. 数据接收主线程负责IO接收数据，得到完成数据包后，解析规定的包头得到站点号，依据规则发配到SQL执行线程的执行队列中去。</p>
<p>　　这种非开放的后台服务端编写，还有些额外的事项需要注意和处理：<br>　　a. 由于非开放业务，数据通信在内网自己使用，这种情况下各个模块之间的通信肯定是长连接更高效，同时也不必考虑网络安全等问题；<br>　　b. 网络工作线程发现传输错误之后，会自动断开当前连接，并按照之前的地址不断重新尝试连接后端的处理进程，未能发送的数据在最大容量范围内还是会堆积在队列当中；<br>　　c. 由于连接有限，所以后端的处理进程没有异步化处理，是one connection per thread且采用阻塞方式读取处理；当错误之后服务端断开当前连接，销毁错误线程，此时同上面所描述的机制，网络工作线程会自动重新连接；此处也不必过于关心性能问题，因为这个线程只负责进行IO，人家说很多情况下单线程也能把网络带宽跑满，只负责数据转发应该是比较高效的；<br>　　d. 长连接的通信要能处理数据拆包和粘包问题，增加了复杂度。我在每个包的头部封装了两个uint32_t类型网络字节序的整数，分别是当前包的长度和对应的站点号，然后解析字段知道当前包的结束位置，同时后面分派线程的处理也容易了。其实，如果是本地回环和网络传输还是有差异的，比如之前用async_read_some，回环可以接收很长的数据，但是一旦上线，这个函数基本就只能接收一个MTU的长度。粘包测试也很简单：可以在网络工作线程堆积两个包，然后包分块慢慢发送(比如每次发64个字节等),然后查看后端主线程接收和解析包是否正常。<br>　　e. 不怕一万就怕万一，万一由于某些因素导致连续的解析失败了(不仅仅是程序的原因)，错误累积漂移会导致后面的所有业务失常。所以还需要额外增加一个检测机制作为看门狗的作用：一旦有错误发生就断开这个链接，比如解析开头的MAGIC_NUMBER、累积收到的数据大于某个值、累积接收了多少次数据包，但是这些数据包没法被消耗，就说明缓存区的包头有问题了，这个时候就应当主动断开这个链接了。<br>　　f. 最后还有一点可以优化的是，让后端开一个网络端口后门(陈硕说过少用信号)，当检测到这个后门连接并发送约定的命令时候，后端关闭侦听套接字和所有和前面网络线程的连接，等待一段时间当SQL处理线程消耗完队列中的数据后，就可以安全kill掉服务了。而前端网络线程会不断尝试连接，前面SQL处理线程可在限制的缓存数量中将请求堆积，不会造成严重的数据丢失，两者耦合性大大降低了。</p>
<p>　　慢慢优化吧，程序员的事情是永远都做不完滴。其实项目中构架、设计还是要随大流，自我创造就是跟自己挖坑啊。。。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Google Protobuf数据交换格式的使用方法]]></title>
      <url>https://taozj.org/201609/learn-note-of-protobuf.html</url>
      <content type="html"><![CDATA[<p>　　现今，如果问什么格式的数据交互最红火，非Google家的protobuf莫属了。相比XML、Json，其有点就是使用接口简单、序列化和解析速度快、数据小传输效率高，同时其还具有向后兼容、跨平台、以及丰富的语言支持接口(居然js都支持，看来直逼Json了啊)的优势。当然，其缺点是不像XML、Json那种可读性和自解释性强，特别是在网络通信时候调试起来比较麻烦。<br>　　翻墙照着Google的文档，把protobuf走了一遍，总体感觉不愧是大厂的作品，考虑到的是效率、多语言支持、兼容性以及分布式系统中多版本的兼容和演进，同时其内部是使用C++实现的，在proto“语法”设计上也会让C++用户感觉十分亲切。<br>　　老习惯还是顺便做个笔记吧。<br><img src="/post_images/images/201609/0ea1b617424d9f2e8cd77b6dbc5dadfd.png" alt="protobuf"></p>
<h1 id="一、从例子说起">一、从例子说起</h1><p>　　protobuf的使用，需要事先写好.proto文件，这个文件规定了数据传输和接受方交换数据的字段、类型等信息。然后使用编译器protobuf-compiler编译这个文件，就可以产生指定语言类型所需的辅助性文件(比如C++的.h和.cc，然后对每一个message都会产生一个类进行描述)了，然后方便的集成到项目代码中使用，当然除了命令行模式的编译，也可以在源代码中读取.proto文件进行动态编译。</p>
<h2 id="1-1_-proto文件的格式">1.1 .proto文件的格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">message Person &#123;</div><div class="line">  required string name = 1; // Your name</div><div class="line">  required int32 id = 2;      // Your ID</div><div class="line">  optional string email = 3;</div><div class="line"></div><div class="line">  enum PhoneType &#123;</div><div class="line">    option allow_alias = true;</div><div class="line">    MOBILE = 0;</div><div class="line">    CELLPHONE = 0;</div><div class="line">    HOME = 1;</div><div class="line">    WORK = 2;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  message PhoneNumber &#123;</div><div class="line">    required string number = 1;</div><div class="line">    optional PhoneType type = 2 [default = HOME];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  repeated PhoneNumber phone = 4;</div><div class="line"></div><div class="line">  reserved 2, 15, 9 to 11; // reserved保留</div><div class="line">  reserved &quot;foo&quot;, &quot;bar&quot;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>　　(1) 每个字段前面都必须有required、optional、repeated，分别表示后面的字段出现1次、0或1次、0或多次，对于repeated字段，其相同类型字段多个值出现的顺序会被保留。<br>　　(2) 数据类型可以是整形、string类型(支持的类型主要有float、double、[s|u| ]int[32|64]、bool、string)，同时还支持自定义类型的嵌套。每一个字段后面都有一个唯一的数字标号(number tag)，为了提高效率，1-15是用一个字节编码，16-2047是用的两个字节编码，所以根据霍夫曼编码的愿意应该把常用的字段用小于15的数字标号。<br>　　(3) 同一个.proto文件中可以定义多个message，尤其当他们在业务上逻辑相关时候更应该这样。.proto文件的注释支持用C/C++的//风格注释。<br>　　(4) 后续更新的时候，可能某些字段不想要了。为了兼容性起见，不应当仅仅注释或者删除掉，而应该用reserved字段尤其对数字标号进行保留，防止被别人再次使用，然后让老的程序错误解析这些字段。<br>　　(5) 对于optional的字段，可以使用default提供对应的默认值，这样当message解析发现没有这个字段时候，那么就会：如果设定有默认值，就使用这个默认值；否则其值是类型相关的——0、false、空string、枚举的第一个元素。<br>　　(6) enum枚举类型有一个选项allow_alias，打开它的时候，允许同一个枚举值有多个枚举的名字(比如上文的MOBILE和CELLPHONE)。<br><a id="more"></a></p>
<h2 id="1-2_-proto文件其它相关">1.2 .proto文件其它相关</h2><p>　　(1) 导入定义<br>　　import可以将别的文件的定义导入到当前文件，默认的import行为是只能使用导入文件中的直接定义，如果需要嵌套使用导入文件的内容，达到类似递归的应用效果，可以使用import public语句。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// old.proto</span></div><div class="line">import <span class="keyword">public</span> <span class="string">"new.proto"</span>;</div><div class="line">import <span class="string">"other.proto"</span>;</div><div class="line"></div><div class="line"><span class="comment">// client.proto</span></div><div class="line">import <span class="string">"old.proto"</span>; </div><div class="line"> <span class="comment">//此时可以使用old.proto和new.proto中的内容，但是看不到other.proto内容</span></div></pre></td></tr></table></figure></p>
<p>　　protobuf-compiler编译器对.proto文件搜索路径默认是执行protoc的当前路径，当然命令行可以使用-I/–proto_path来添加搜索路径。</p>
<p>　　(2) 嵌套类型<br>　　可以使用Parent.Type这种语法来实现嵌message的使用，而且不限制嵌套的层次深度<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">message SearchResponse &#123;</div><div class="line">    message Result &#123;</div><div class="line">        required <span class="built_in">string</span> url = <span class="number">1</span>;</div><div class="line">        optional <span class="built_in">string</span> title = <span class="number">2</span>;</div><div class="line">    &#125;</div><div class="line">    repeated Result result = <span class="number">1</span>;</div><div class="line">&#125;</div><div class="line"> </div><div class="line">message SomeOtherMessage &#123;</div><div class="line">    optional SearchResponse.Result result = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　(3) 更新消息类型<br>　　从整个文档看来，Google对于这种向后兼容性看的很重要，这也是一个大型系统逐渐演进所必需的。如果要修改一个.proto文件，那么需要遵守以下的一些守则和约定：<br>　　a. 对于一个已经存在的字段不要修改其数字标号；<br>　　b. 新增加的字段应该是optional或者repeated的；<br>　　c. 不再使用的字段，可以用OBSOLETE_等前缀命名表示废弃，但是绝对不要重用其数字标号，记得使用上面的reserved对这些数字标号保护起来；<br>　　d. 非required可以转为extension(保留给第三方在他们自己的.proto文件中使用)；<br>　　e. int32、uint32、int64、uint64、bool是兼容的，客户端可以进行结果的强制转换；<br>　　f. 修改default默认值是允许的，因为默认值不会真正的传输，只跟程序使用的.proto文件有关；</p>
<p>　　(4) extension<br>　　上面的方式可以把特定的数字标号区域保留给扩展，扩展在自己的.proto文件中，先import原有的.proto，然后再次打开message，添加扩充自己的字段，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// foo.proto</span></div><div class="line">message Foo &#123;</div><div class="line">    <span class="comment">// ...</span></div><div class="line">    extensions <span class="number">100</span> to <span class="number">199</span>; &#125;</div><div class="line"></div><div class="line"><span class="comment">// your.proto</span></div><div class="line">import foo.proto;</div><div class="line">extend Foo &#123;  optional int32 bar = <span class="number">126</span>; &#125;</div></pre></td></tr></table></figure></p>
<p>但是跟前面基本字段不同，extension的访问需要使用特殊的接口来操作，比如设置值，需要调用<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">foo.SetExtension(bar, <span class="number">15</span>);</div><div class="line">其它这类操作接口包括：HasExtension()、ClearExtension()、GetExtension()、MutableExtension()、AddExtension()。</div><div class="line"></div><div class="line">　　(<span class="number">5</span>) oneof</div><div class="line">　　类似于C/C++中的<span class="keyword">union</span>类型，当oneof包围多个可选字段的时候，至多只能给一个字段赋值，当给某个字段设置的时候，会自动清除已存其它字段的值，因为这些字段都是共享同一内存的，为的就是节省内存。</div><div class="line">```cpp</div><div class="line">message SampleMessage &#123;</div><div class="line">    oneof test_oneof &#123;</div><div class="line">        <span class="built_in">string</span> name = <span class="number">4</span>;</div><div class="line">        SubMessage sub_message = <span class="number">9</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">SampleMessage message;</div><div class="line">message.set_name(<span class="string">"name"</span>);</div><div class="line">CHECK(message.has_name());</div></pre></td></tr></table></figure></p>
<p>　　oneof中的字段定义不能有require、optional、repeated，然后具体使用的时候可以当作optional一样来使用了。<br>还有，如果一个message中有多个同名的oneof，只有最后一个可见的会被实际使用；extensions不支持oneof；oneof不能被repeated；C++中支持swap两个oneof，交换后可访问字段变成互为对方的那个。</p>
<p>　　(6) maps<br>　　proto支持相关性容器map，其定义的格式是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">map</span>&lt;key_type, value_type&gt; map_field = N;</div></pre></td></tr></table></figure></p>
<p>　　其中的key_type除了不能是浮点和bytes，其它类型(整形、string)都可以作为key；针对map其wire format的排序和迭代顺序是未定义的，用户不应当依赖其顺序；当将其转成文本类型的时候，是按照整形从小到大或者字符串的升序来排序的；当解析或者合并map的时候，如果有重复的key，那么只有最后看见的那个key被使用，而当从文本中解析的时候，如果有重复的key会做报错处理。</p>
<p>　　(7) Packages<br>　　proto的名字查找类似于C++，从最内层的类依次向外查找。有时候为了防止名字冲突，可以在.proto文件的开头声明package，起到类似名字空间的效果(实际上产生C++辅助代码的时候就是放到对应的namespace中的，比如foo.bar生成了foo::bar)。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">package foo.bar; <span class="comment">//namespace foo::bar</span></div><div class="line">message Open &#123; ... &#125;</div><div class="line"></div><div class="line"><span class="comment">// 另外一个proto中使用</span></div><div class="line">message Foo &#123;</div><div class="line">    required foo.bar.Open open = <span class="number">1</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-3_将上面的例子用起来">1.3 将上面的例子用起来</h2><p>　　针对上面的.proto文件，使用protoc编译，可以根据语言产生对应的源代码文件(比如C++的.h和.cc)。实测发现，当前很多发行版还是默认打包的protobuf-compiler-2.6甚至更旧的版本，所以建议在GitHub上面下载源代码自己编译安装最新的3.0版本。<br>　　然后，3.0的版本今年才正式发布的，语法跟之前稳定版2.6差异还是挺大的，总体的感觉是让protobuf使用更简洁了。具体的修改日志可以看参考列表中的Release Note，包括：不再区分optional、required，默认都是optional；需要指定syntax版本，默认是proto2；不支持default默认值等。编译的格式，和上面实际用到的编译命令是：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR path/to/file.proto</div><div class="line"></div><div class="line">➜  ~ protoc --cpp_out=./ msg.proto</div></pre></td></tr></table></figure></p>
<p>　　如果DST_DIR使用.zip结尾，那么产生的文件会自动用.zip打包，同时输入的.proto文件可以一次指定一个或者多个。<br>　　编译结束后会生成msg.pb.cc和msg.pb.h两个文件，然后就可以轻松应用了！</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"msg.pb.h"</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>* argv[])</span></span></div><div class="line">&#123;</div><div class="line">    Person person;</div><div class="line">    person.set_name(<span class="string">"Nicol TAO"</span>);</div><div class="line">    person.set_id(<span class="number">1234</span>);</div><div class="line">    person.set_email(<span class="string">"taozhijiang@126.com"</span>);</div><div class="line">    <span class="function">fstream <span class="title">output</span><span class="params">(<span class="string">"myfile"</span>, ios::out | ios::binary)</span></span>;</div><div class="line">    person.SerializeToOstream(&amp;output);</div><div class="line">    output.close();</div><div class="line"></div><div class="line">    <span class="function">fstream <span class="title">input</span><span class="params">(<span class="string">"myfile"</span>, ios::in | ios::binary)</span></span>;</div><div class="line">    Person person2;</div><div class="line">    person2.ParseFromIstream(&amp;input);</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Name: "</span> &lt;&lt; person2.name() &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"E-mail: "</span> &lt;&lt; person2.email() &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Test Finished!"</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>　　然后，在命令行编译执行，就该得到你想要的结果了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">➜  ~ g++ -c msg.pb.cc &amp;&amp; g++ -c main.cc                                         </div><div class="line">➜  ~ g++ msg.pb.o main.o -lprotobuf -o msg                                      </div><div class="line">➜  ~ ./msg</div><div class="line">Name: Nicol TAO</div><div class="line">E-mail: taozhijiang@126.com</div><div class="line">Test Finished!</div><div class="line">➜  ~</div></pre></td></tr></table></figure></p>
<h1 id="二、CPP使用接口">二、CPP使用接口</h1><p>　　protobuf的手册中有一章是说Encoding的，主要是从原理说protobuf的编码效率为什么会这么高。因为这对用户来说是无所谓的，所以就跳过了，感兴趣的可以去瞄。其中128-Variant变长编码的思路还是不错的。</p>
<h2 id="2-1_Messages">2.1 Messages</h2><p>　　上面使用message Foo生成的消息，最终都会产生一个public继承自google::protobuf::Message的类Foo，默认protobuf会以生成最快速度的版本，如果在.proto中设置了option optimize_for = CODE_SIZE;，就会实现最少必须函数，然后用反射的机制生成其它的；option optimize_for = LITE_RUNTIME;选项将会派生出google::protobuf::MessageLite的类型，只提供比原Message较少的一个操作子集，同时链接的库也是libprotobuf-lite.so。<br>对于嵌套类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">message Foo &#123; message Bar &#123; &#125; &#125;</div></pre></td></tr></table></figure></p>
<p>　　在生成的代码中会有Foo和Foo_Bar两个类，同时还会自动生成typedef Foo_Bar Bar;的别名。可以使用Foo::Bar访问，但是C++不允许带作用域的前向声明，所以如果要前向声明，记得有Foo_Bar这个类。</p>
<h2 id="2-2_Fields">2.2 Fields</h2><p>　　由于protobuf在传输的时候是使用数字的，所以在protobuf解码的时候，自动为这些数子生成了camel-case驼峰模式的常量，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">optional int32 foo_bar = <span class="number">5</span>;</div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">int</span> kFooBarFieldNumber = <span class="number">5</span>;</div></pre></td></tr></table></figure></p>
<p>　　对于Field的访问器accessor，如果得到的是const reference类型的，在下次modify access作用于这个message的时候，访问器可能会失效，尤其是调用了non-const的访问器类型；当accessor返回的是指针，记住：任何两次不同的accessor调用，返回的指针值都可能是不同的。<br>　　(1) Singular单个数字类型(枚举类型也跟此类似)<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int32 foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line">int32 foo() <span class="keyword">const</span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(int32 value)</span></span>;</div><div class="line"><span class="function">oid <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//清除，下次调用foo()会返回0</span></div></pre></td></tr></table></figure></p>
<p>　　(2) Singular单个字符串类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">string</span> foo = <span class="number">1</span>;</div><div class="line">bytes foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="built_in">string</span>&amp; foo() <span class="keyword">const</span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* value, <span class="keyword">int</span> size)</span></span>;</div><div class="line"><span class="function"><span class="built_in">string</span>* <span class="title">mutable_foo</span><span class="params">()</span></span>; <span class="comment">//返回一个可以修改string值的指针</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_allocated_foo</span><span class="params">(<span class="built_in">string</span>* value)</span></span>; <span class="comment">//吧value设置到foo，如果foo之前有string，则释放掉之前的string</span></div><div class="line">                       <span class="comment">//如果value==NULL，则等同于clear_foo()</span></div><div class="line"><span class="function"><span class="built_in">string</span>* <span class="title">release_foo</span><span class="params">()</span></span>; <span class="comment">//调用后foo释放string的控制权</span></div></pre></td></tr></table></figure></p>
<p>　　(3) Singular嵌入message类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">message Bar &#123;&#125;</div><div class="line">Bar foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">bool</span> has_foo(); <span class="comment">//检查foo是否已经set</span></div><div class="line"><span class="function"><span class="keyword">const</span> Bar&amp; <span class="title">foo</span><span class="params">()</span></span>; <span class="comment">//返回值，如果没有set，就返回一个没有设置的Bar，Bar::default_instance()</span></div><div class="line"><span class="function">Bar* <span class="title">mutable_foo</span><span class="params">()</span></span>; <span class="comment">//返回mutable指针，如果没有set，内部就会newly-allocated Bar并返回</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_allocated_foo</span><span class="params">(Bar* bar)</span></span>; <span class="comment">//如果bar==NULL，等同于clear_foo()</span></div><div class="line"><span class="function">Bar* <span class="title">release_foo</span><span class="params">()</span></span>;</div></pre></td></tr></table></figure></p>
<p>　　(4) Repeated数字类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">repeated int32 foo = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">int</span> foo_size() <span class="keyword">const</span>; <span class="comment">//元素的个数</span></div><div class="line"><span class="function">int32 <span class="title">foo</span><span class="params">(<span class="keyword">int</span> index)</span> <span class="keyword">const</span></span>; <span class="comment">//0-based索引对应的值</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(<span class="keyword">int</span> index, int32 value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_foo</span><span class="params">(int32 value)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//清除所有的元素</span></div></pre></td></tr></table></figure></p>
<p>　　对于枚举、字符串、嵌入message，也有对应的repeated版本，可以参阅其手册，很容易理解和想到。</p>
<p>　　(5) Oneof数字类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">oneof oneof_name &#123;</div><div class="line">    int32 foo = <span class="number">1</span>;</div><div class="line">    ... &#125;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">bool</span> has_foo() <span class="keyword">const</span>; <span class="comment">//检查当前oneof类型是kFoo</span></div><div class="line"><span class="function">int32 <span class="title">foo</span><span class="params">()</span> <span class="keyword">const</span></span>; <span class="comment">//如果当前是kFoo，返回其值，否则返回0</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">set_foo</span><span class="params">(int32 value)</span></span>; <span class="comment">//如果当前不是kFoo，调用clear_oneof_name()，然后设置其值，并且oneof_name_case()会返回kFoo</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear_foo</span><span class="params">()</span></span>; <span class="comment">//如果当前不是kFoo，则什么也不做；否则，清除其值，然后has_foo()==false，foo()==0，同时oneof_name_case()返回ONEOF_NAME_NOT_SET。</span></div></pre></td></tr></table></figure></p>
<p>　　对于枚举、字符串、嵌入message，也有对应的Oneof版本，可以参阅其手册，很容易理解和想到。</p>
<p>　　(6) Map类型<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">map</span>&lt;int32, int32&gt; weight = <span class="number">1</span>;</div><div class="line">===&gt;</div><div class="line"></div><div class="line"><span class="keyword">const</span> google::protobuf::Map&lt;int32, int32&gt;&amp; weight();</div><div class="line">google::protobuf::Map&lt;int32, int32&gt;* mutable_weight();</div></pre></td></tr></table></figure></p>
<p>　　上面的weight()和mutable_weight()会得到可修改和不可修改两个map，其可以支持std::map和std::unorderd_map中常用的函数接口，包括：迭代器、元素访问、查找、修改(添加和删除)、拷贝等。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//这种插入会被insert要好，免除可能的元素深度拷贝</span></div><div class="line">(*my_enclosing_proto-&gt;mutable_weight())[my_key] = my_value;</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">map</span>&lt;int32, int32&gt; standard_map(message.weight().begin(),</div><div class="line">                                    message.weight().end());</div></pre></td></tr></table></figure></p>
<p>　　同时如上面所示，如果不想用protobuf::Map的接口，可以像上面一样创建标准的std::map，不过构造这个map会产生所有元素的深度拷贝。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="external">protocol-buffers</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/overview" target="_blank" rel="external">protocol-buffers/docs/overview</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/reference/cpp-generated" target="_blank" rel="external">C++ Generated Code</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/encoding" target="_blank" rel="external">Encoding</a></li>
<li><a href="https://developers.google.com/protocol-buffers/docs/reference/arenas" target="_blank" rel="external">C++ Arena Allocation Guide</a></li>
<li><a href="https://github.com/google/protobuf/releases" target="_blank" rel="external">protobuf-3-releases</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[《Linux多线程服务端编程》读摘]]></title>
      <url>https://taozj.org/201609/read-(linux-mulit-thread-server-develop).html</url>
      <content type="html"><![CDATA[<p>　　花了几天的时间，把陈硕老师的《Linux多线程服务端编程》给看完了。<br>　　其实就是当初冲着网上的评价很高，号称为国人难得的C++开发之佳作，这本书很早之前就已经买了。当时一开卷就是C++中各种构造析构安全，复杂隐晦的多线程间的竞争条件，尤其当时对C++忘光了，而Boost、C++11、异步原理又不太熟悉，再加上工作上没有相关的任务做驱动，所以被唬住后也就将其搁在一边了。刚好最近在做C++的服务端开发，虽然用的是Boost.asio现成的异步框架，但是拿来看看，收获还是不少的。这本书总体内容显得还是比较“杂”的，包括了作者muduo异步库的设计思路、使用方法、实现过程和细节，还有其它跟muduo无关的，比如一些工程实践和开发经验，对C/C++语言的原理的解析，Ｃ++面向对象设计方式的评判等，相比起来显得更加的宝贵。<br>　　书中关键点都用红笔标记下了，为了后面温习查阅方便，本篇用以记录相关摘要。可能略显零碎，但也会是字字珠玑。</p>
<h1 id="第一部分_多线程编程系统">第一部分 多线程编程系统</h1><h2 id="1-1_对象构造线程安全">1.1 对象构造线程安全</h2><p>　　在对象构造期间不要泄露this指针，也不要在构造函数中注册回调函数，不要把this传递给跨进程对象，主要是确保在对象构造完成之前没有别的途径可以调用产生不确定行为。通常采用的是构造函数+initialize()的两段式构造，将复杂的工作放到构造完对象之后再初始化一次，这样缩短构造函数的时间，同时也不必在构造函数中做复杂的异常处理。</p>
<h2 id="1-2_析构对象线程安全">1.2 析构对象线程安全</h2><p>　　对象的成员mutex可以保护对象的运行，但是析构却不行，因为mutex的生命周期最多和类的生命周期一样长，根本无法保护。根本方法还是智能指针，确保对象最后引用结束的时候，对象资源被自动释放掉。</p>
<h2 id="1-3_智能指针">1.3 智能指针</h2><p>　　shared_ptr对象的引用计数本身是安全且无锁的，但是智能指针对象本身的读写(包括析构操作)却不是，如果要多个线程同时读写同一个shared_ptr对象，需要加锁。<br>　　这里的技巧是：可以在临界加锁区中将全局的shared_ptr复制成一个局部变量，后面操作局部变量，减少临界区；函数传参采用reference to const的方式传递，减少拷贝操作，也能提高性能；析构的时候不要在临界区reset()，而是在临界区中用局部变量swap，然后在临界区外部进行对象析构，减少临界区的范围。<br>　　对于析构任务重的情况，可以再开一个单独的线程，通过BlockingQueue<shared_ptr<void>&gt;把析构任务都提交到那个线程，减少对关键线程的影响。<br>　　shared_ptr还需要注意避免循环引用，对于对象周期和程序生命周期一样长的无所谓，否则交叉share_ptr在析构时候会发生问题。这时候应该owner持有指向child的shared_ptr，而child拥有指向owner的weak_ptr。</shared_ptr<void></p>
<h2 id="1-4_线程同步的原则">1.4 线程同步的原则</h2><p>　　a. 尽量最低限度的共享对象，尽量共享immutable对象，减少需要同步的情况；一旦产生了写，其他所有的读操作也都变成不是线程安全的了。<br>　　b. 使用高级的并发编程构建，比如TaskQueue、Producer-CustomerQueue、CountDownLatch等；<br>　　c. 只使用非递归的互斥器和条件锁，不用读写锁；<br>　　d. 使用atomic；<br>　　e. C的很多库函数都不是线程安全的，因为用到了静态空间，需要使用_r的版本，C++的容器是不安全的，C++的算法库大多是安全的，因为他们大多是没有状态的虚函数。<br>　　f. 多个锁操作很容易导致死锁，有些时候可以考虑比较锁地址，让地址小的先锁，以保证锁的顺序。<br><a id="more"></a></p>
<h2 id="1-5_互斥器Mutex">1.5 互斥器Mutex</h2><p>　　使用非递归的mutex，不手动lock()/free()，采用RAII机制的Guard对象自动加锁和解锁；不要使用跨进程的mutex，跨进程通信采用sockets；加锁和解锁必须在同一个线程中。</p>
<h2 id="1-6_条件变量和CountDownLatch">1.6 条件变量和CountDownLatch</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>;</div><div class="line"><span class="keyword">while</span>(<span class="built_in">queue</span>.empty()) &#123; <span class="comment">//防止spurious wakeup</span></div><div class="line">    cond.wait();&#125;</div><div class="line">    </div><div class="line">&#123; <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>; </div><div class="line"> <span class="built_in">queue</span>.push_back(x);&#125;   </div><div class="line"> cond.notify();</div></pre></td></tr></table></figure>
<p>CountDownLatch比如可以用于主线程等待多个子线程初始化完毕<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>;</div><div class="line"><span class="keyword">while</span>(count_ &gt; <span class="number">0</span>) &#123; cond.wait();&#125;</div><div class="line">    </div><div class="line">&#123; <span class="function">MutexLockGuard <span class="title">lock</span><span class="params">(mutex)</span></span>; </div><div class="line">    count_ --;</div><div class="line">    <span class="keyword">if</span>( count_ == <span class="number">0</span>) cond.notifyAll();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-7_多进程和fork">1.7 多进程和fork</h2><p>　　只有单线程的程序才可以fork()，如果多线程执行了fork()，那么只会fork()当前运行的线程，其它线程都会消失掉。一般可以在程序的开始，先fork出一个看门狗进程，看门狗进程需要是单进程的。<br>　　多进程的程序如果大量共享数据，就需要大规模的共享内存，而且进程间的通信同步都比较麻烦，而且一旦一个进程在临界区内阻塞或者crash，其他进程也会被锁死，这种情况还不如使用多线程，多进程并不会增加多少程序的稳定性。</p>
<h2 id="1-8_将IO操作剥离给单独的线程">1.8 将IO操作剥离给单独的线程</h2><p>　　无论SSD和RAID怎么样，还是在传统的思路上考虑文件IO和数据库操作会比较慢，比如日志的写或者简单逻辑的数据库的更新，可以考虑到放到一个BlockingQueue队列上，那么请求线程就可以立即返回，而这些工作由单独的后台线程去处理（不过需要考虑后台线程的处理能力，否则BlockingQueue会越来越大）。</p>
<h2 id="1-9___thread线程局部变量">1.9 __thread线程局部变量</h2><p>　　<strong>thread关键字是GCC支持的局部存储措施，其可以修饰全局变量或者函数中的静态变量(对于类类型只支持POD类)，其在初始化只能使用编译期间的常量值。</strong>thread变量是针对每个线程一份独立实体，各个线程的变量值互不干扰。<br>　　C++11标准中引入了新的关键字thread_local，而Boost的thread库提供了thread_specific_ptr，采用类似智能指针的方式实现了线程本地存储机制。</p>
<h2 id="1-10_多线程与signal">1.10 多线程与signal</h2><p>　　signal本身就比较复杂，在信号处理函数中只能调用异步信号安全的函数，即可重入函数；同时如果修改全局变量也是比较危险的，因为编译器可能将其认为不会改变而优化掉信号处理的修改。<br>　　不要在多线程中使用信号，不用SIGUSR1触发服务端行为，采用增加监听端口的方式进行通信；不要使用基于信号的定时函数，其是不可靠的；不主动处理信号的行为，使用其默认语义，除了PIPE信号；如果要处理，使用signalfd的方式，把信号转化成文件描述的方式，杜绝直接使用signal handler。<br>　　现在看来内核很多操作都fd化，比如signalfd，timerfd，eventfd等，好处就是可以用相同的接口，同时也更容易整合到各种异步框架下面去。</p>
<h1 id="第二部分_moduo网络库">第二部分 moduo网络库</h1><h2 id="2-1_TCP连接不主动关闭">2.1 TCP连接不主动关闭</h2><p>　　TCP本身是一个全双工协议，同一个描述符可以读也可以写。通常在服务端，需要的时候对socket关闭写方向的连接，保留读方向的连接，称为TCP half-close，这样的好处是如果关闭的同时对端还在传输数据过来，就不会漏收这些数据。同时习惯上，对端程序在read()返回0之后，会主动关闭自己的写端，此时服务端的读端就会被被动关闭了。当然对于恶意不关闭的，通过time_wheel回收不活跃的连接，也不会有太大的问题。</p>
<h2 id="2-2_TCP分包">2.2 TCP分包</h2><p>　　对于短链接的TCP服务，一般发送方会主动关闭连接，表示一条消息传送完毕了，自然就意味着消息的结尾，就没有分包的问题。对于长连接服务，分包的形式有：<br>　　a. 约定固定长度的消息；<br>　　b. 使用特殊字符或者字符串作为消息的边界，比如HTTP中的\r\n；<br>　　c. 每条消息的头部约定一个字段，表示消息体的长度(hton_32)；<br>　　d. 利用消息本身来进行分包，比如json的{}配对。</p>
<h2 id="2-3_限制并发连接数目">2.3 限制并发连接数目</h2><p>　　默认情况下Linux一个进程最大打开的文件数目是1024，受到/etc/security/limits.conf中的nofile设置的限制，如果需要突破这个限制可以修改这个文件。<br>　　当然如果程序达到这个限制，行为会变的很被动，一般都是自己设置一个soft limit，一旦接受的到的连接数到达这个限制，就在accept后立即关闭新拿到的socket连接，让程序进入拒绝服务状态。</p>
<h2 id="2-4_time_wheel踢掉空闲连接">2.4 time wheel踢掉空闲连接</h2><p>　　对于一个连接如果若干秒没有数据，就被认为是空闲连接，应该被处理掉。书中用到的circlur_buffer无锁结构，将时间分片轮寻，书中的方式每次收到数据都会向队列尾部添加活动链接的弱引用，然后事件切换的时候检查头部的连接。当然这样做是没什么问题的，但是操作的代码比较的高。<br>　　我用的方式比较粗，每次建立新连接的时候，会把连接的weak_ptr保存在当前的时间片上，同时每个连接带有一个touch_time事件戳，当有数据交换时候更新这个时间戳。后面在时间片切换的时候，检查每个连接是否存在(提升为shared_ptr)，如果存在检查时间戳是否超时，然后决定是否删除连接。因为不每次添加和修改连接到时间片，所以处理速度比较快，但是缺陷是超时的时间不一定，根据socket的行为为[n, 2n-1]。</p>
<h2 id="2-5_小杂项">2.5 小杂项</h2><p>　　SIGPIPE信号处理是需要忽略的，因为这个信号的默认行为是终止进程，但是网络中对方断开连接而本地继续写入的话，会触发这个信号，所以必须要忽略掉。<br>　　TCP No Delay和TCP keepalive是两个比较重要的TCP选项，前者是禁用Nagle算法，避免连续发报出现延时，对编写低延时以及特殊的程序比较重要(当时开发socket代理的时候不知道这个选项，然后被折磨惨了，估计我会终生记住这个家伙)；TCP keepalive是定期探测TCP连接是否还存在，保持一个心跳的作用。</p>
<h2 id="2-6_处理自连接">2.6 处理自连接</h2><p>　　一般程序如果先bind，就会占用端口和套接字，是没有问题的。但是当程序没有显式bind的时候，如果连接的客户端和服务端都在同一个IP主机上，而且服务端端口在local_port_range的范围内，连接的过程中客户端端口有很小几率的可能和服务端端口是一致的，此时用netstat -an会发现源端口和目的端口都是一样的，对于TCP三次握手是符合协议的，但是这样的连接无法正常通信，需要重启。</p>
<h1 id="第三部分_工程实践部分">第三部分 工程实践部分</h1><h2 id="3-1_编译选项">3.1 编译选项</h2><p>　　C++的机制比较的复杂，所以推荐代码中使用严格的编译选项，排除可能的隐式规则和实际期望行为之间的差异。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-Wall -Wextra -Werror -Wconversion -Wno-unused-parameter -Wold-style-cast -Woverloaded-virtual -Wpointer-arith -Wshadow -Wwrite-strings -march=native</div></pre></td></tr></table></figure></p>
<p>而对于有些代码中如果需要临时忽略一些错误，可以采用下面语句：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__GNUC__)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">pragma</span> GCC diagnostic <span class="meta-keyword">warning</span> <span class="meta-string">"-Wunused-function"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">...</div><div class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__GNUC__)</span></div><div class="line"><span class="meta">#<span class="meta-keyword">pragma</span> GCC diagnostic <span class="meta-keyword">error</span> <span class="meta-string">"-Wunused-function"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div></pre></td></tr></table></figure></p>
<h2 id="3-2_前向声明">3.2 前向声明</h2><p>　　前向声明可以减少头文件的包含，自然也降低了编译期间的循环依赖，加快编译速度。<br>　　对于class Foo，以下的几种使用不需要看到其完整的定义：<br>　　a. 定义或者声明Foo *和Foo &amp;，包括用于函数参数、返回类型、局部变量、类成员变量等。这是因为C++的内存模型是flat的，Foo的定义无法改变Foo的指针和引用的含义；<br>　　b. 声明一个以Foo为参数或者返回类型的函数，如果代码里面调用了这个函数，就需要提供这个类型的完整定义了，因为编译器需要使用Foo的拷贝构造函数和析构函数，需要看到类的完整声明。</p>
<h2 id="3-3_模版实例化膨胀">3.3 模版实例化膨胀</h2><p>　　虽然传统上说模板的定义需要放到头文件中，其实实际上是发生链接错误。工程上，可以把模板的实现放到库或者源代码中，二头文件中只放声明，这就是事先进行显式实例化。<br>　　还有对于private类型的成员模板，其实现也不需要放到头文件中，可以只在代码文件中实现，因为private类型只有类实现的本身会用到它。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://segmentfault.com/a/1190000002396411" target="_blank" rel="external">tcp自连接问题</a></li>
<li><a href="http://blog.csdn.net/justlinux2010/article/details/20947609" target="_blank" rel="external">源目的IP和端口都相同的连接出现的原因</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost.Coroutine协程库的简单使用]]></title>
      <url>https://taozj.org/201609/usage-of-boost-coroutine.html</url>
      <content type="html"><![CDATA[<p>　　绕了很久，看了很多的资料，总算对协程(coroutine)是有点眉目了。</p>
<p>　　由于C++原生支持多进程多线程，可以被操作系统直接调度，所以感觉对协程的支持没有那么的急迫，不过现在网上搜到很多资料，说是建议要把协程推到标准库中，可见协程还是蛮有用的。从原理上看，协程保存了执行当前位置，后续可以切换回来，像是一个用户态的线程，但是和一般的线程不同的是不是抢占式的(pre-emptive)切换，而是一种协作式的(cooperative)推拉；而对于用户来说，可以类似用符合思维习惯的同步手法，写出具有异步功能的高效代码，而不用像传统异步开发设置各种回调函数把代码割离弄的支离破碎的；最后还是得意于协程比线程更加的轻量级，切换过程也不会陷入内核态，增加系统的运行效率。<br><img src="/post_images/images/201609/5c2a3f22e3c744f8f3f7f67b39bfcc97.png" alt="coroutine"><br>　　同时最近发现了Tecent Phxteam开源出来的<a href="https://github.com/tencent-wechat/phxsql" target="_blank" rel="external">phxsql</a>项目，里面就有协程相关的使用，可见协程是可以用在高性能需求的生产环境上的。</p>
<p>　　Boost库中的协程支持两种方式：一种是封装了Boost.Coroutine的spawn，是一个stackful类型的协程；一种是asio作者写出的stackless协程。下面就两类分别罗列出相关特性。<br><a id="more"></a></p>
<h1 id="一、stackless协程">一、stackless协程</h1><p>　　在C++中有函数对象的概念后，只要类提供operator()的接口，那么类对象就可以当作函数调用，同时类的其他成员可以保存相关的状态信息。其实stackless就是通过class coroutine这个类本身来实现当前协程的状态保护的，其实其内部就是用的一个int来保留下次resume的行号的，同时提供is_child()、is_parent()、is_complete()三个函数来辅助控制协程的行为。<br>　　要支持协程的函数类必须是可拷贝构造和赋值构造的，其既可以作为实现类的基类派生，也可以作为实现类的一个成员变量，甚至是lambda、bind的参数。其定义了几个C++标准之外的伪关键字方便使用，通过包含<boost asio="" yield.hpp="">就可以使用。<br>(1) reenter<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">reenter(<span class="keyword">this</span>) &#123;&#125; <span class="comment">//继承形式</span></div><div class="line">reenter(coro_) &#123;&#125; <span class="comment">//成员变量形式</span></div></pre></td></tr></table></figure></boost></p>
<p>　　当reenter被执行的时候，控制流会跳转到最后yield或者fork的位置。<br>　　需要注意的是reenter宏是通过switch实现的，意味着当在协程体中使用局部变量的时候，当重入协程体时候不能忽略局部变量的定义。如果当前需要局部变量，那么用下面的方式使用符合的语句块。<br>(2) yield statement<br>　　常常用在异步操作的时候，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yield socket_-&gt;async_read_some(buffer(*buffer_), *<span class="keyword">this</span>);</div></pre></td></tr></table></figure></p>
<p>　　其执行的逻辑为：yield保存了当前协程的状态；其表达式初始化了异步操作；定义恢复点为statement后的一条语句；控制流被转移到了协程体的结尾。<br>　　当异步操作结束的时候，函数对象重新被唤醒，然后reenter使得执行流转移到了恢复点。当然statement表达式也可以是复合表达式，比如：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">yield&#123; </div><div class="line">    mutable_buffers_1 b = buffer(*buffer_);</div><div class="line">    socket_-&gt;async_read_some(b, *<span class="keyword">this</span>); </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>(3) yield return expression ;<br>　　通常用于生成器的环境下使用，其return后面的值作为函数的返回值传递出来，比如<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> interleave : coroutine</div><div class="line">&#123;</div><div class="line">  istream&amp; is1; istream&amp; is2;</div><div class="line">  <span class="function"><span class="keyword">char</span> <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</div><div class="line">    reenter (<span class="keyword">this</span>) <span class="keyword">for</span> (;;) &#123;</div><div class="line">      yield <span class="keyword">return</span> is1.get();</div><div class="line">      yield <span class="keyword">return</span> is2.get();</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　上面的例子会交替的从is1和is2中产生字符，其会使得return后面表达式的值被返回。<br>(4) yield ;<br>　　用于显式的控制执行的流程，通常在多个协程交替的运行完成协作工作。<br>(5) yield break ;<br>　　主要用来终止协程的，yield首先设置协程的终止状体，然后流程被转移到了协程体的结尾。<br>　　一旦终止，使用is_complete()就会返回true，同时协程不能够被再次reenter了。当然不一定要yield break，当流程执行到了协程体结尾，这些协程也会自动terminate了。<br>　　突然意识到为啥要break了，因为reenter本来就是用switch实现的嘛。<br>(6) fork statement<br>　　可以创建多个协程的拷贝，常用的情况是在服务端，协程被fork出来用于处理客户端的请求。父协程和子协程通过is_parent()、is_child()进行界定。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">reenter (<span class="keyword">this</span>) &#123;</div><div class="line">    <span class="keyword">do</span>&#123;</div><div class="line">        socket_.reset(<span class="keyword">new</span> tcp::socket(io_service_));</div><div class="line">        yield acceptor-&gt;async_accept(*socket_, *<span class="keyword">this</span>);</div><div class="line">        <span class="function">fork <span class="title">server</span><span class="params">(*<span class="keyword">this</span>)</span><span class="params">()</span></span>;</div><div class="line">  &#125; <span class="keyword">while</span> (is_parent());</div><div class="line">  ... client-specific handling follows ...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其fork语句会创建当前协程的一个拷贝，然后可能会立即执行或者被后面再调度执行，或者使用io_service::post()调度执行。<br>　　关于stackless协程的设计和实现思路，可以查看参考文献的第一篇文章的介绍，其内部真的是用一个switch实现，使用一个变量记录代码行号的哦！</p>
<h1 id="二、stackful协程">二、stackful协程</h1><p>　　其实现使用的Boost.Context来进行上下文的切换。使用需要包含头文件<boost coroutine="" all.hpp="">，位于名字空间boost::coroutines。<br>　　其实现原理是每个协程都有自己的stack和control-block(boost::contexts::fcontext_t)，在协程需要暂停的时候，当前协程的所有非易失的寄存器(包括ESP、EIP)都会被保存在control-block当中，而新激活的协程会从其相关的control-block中加载回复相关的寄存器信息，称之为上下文切换，相关的上下文切换不需要系统特权。<br>　　Boost.Context提供的协程包括两类：非对称型协程asymmetric_coroutine的和对称型协程symmetric_coroutine，前者协程知道唤醒自己的协程，当需要暂停的时候控制流转换给那个特定的协程；对称协程中所有的协程都是相等的，协程可以把控制流给任何一个其它的协程。所以对称协程主要是表达并发编程中的多个独立的执行单元，而非对称协程常常用于对数据进行顺序处理的过程。<br>　　stackful协程可以从嵌套的stackframe中暂停执行，在恢复的时候可以在其暂停的地方继续执行，而stackless协程只有顶层的函数(top-level routine)可以被暂停，所有顶层函数调用的函数都不允许被暂停，也就是不允许嵌套使用携程。<br>　　stackful的协程可以被嵌套使用，但是要求协程是可移动(move)但不可拷贝(copy)的，因为其为RAII实现的，结束的时候资源会被自动清理释放，但是拷贝会导致内部的状态不可控。同时使用时候在context_switch切换到正在执行的相同协程的行为是未定义的。</boost></p>
<h2 id="2-1_Asymmetric_coroutine">2.1 Asymmetric coroutine</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">asymmetric_coroutine&lt;&gt;::pull_type</div><div class="line">asymmetric_coroutine&lt;&gt;::push_type</div></pre></td></tr></table></figure>
<p>　　其提供了单向的数据传输操作，在数据传输的过程中伴随着Context的切换。模板参数的类型决定了数据传输的类型，如果不需要传递数据只进行Context切换，可以使用void。<br>(1) pull_type<br>　　从另外的一个context获取数据，其构造函数的参数是一个cor-function函数对象，cor-function的参数是一个push_type的引用。初始化pull_type的时候，执行流被切换到了cor-function，并且synthesize一个push_type并将引用传递给协程函数。其同时还提供operator()，只进行context切换，不传输数据(即构造函数参数为空而不是模板类型指定的实参)。<br>　　pull_type提供迭代器和std::begin()、std::end()重载，从而可以增量的切换context并进行数据的传输。pull_type的提供的成员函数get()可以从别的context中拉取数据，但是不会造成context切换，如需切换需要手动调用operator()。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">pull_type <span class="title">source</span><span class="params">(</span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::push_type&amp; sink)&#123;</div><div class="line">        <span class="keyword">int</span> first=<span class="number">1</span>, second=<span class="number">1</span>;</div><div class="line">        sink(first); sink(second);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">8</span>;++i)&#123;</div><div class="line">            <span class="keyword">int</span> third=first+second;</div><div class="line">            first=second; second=third;</div><div class="line">            sink(third);</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"> </div><div class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> i:source)</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt;  <span class="string">" "</span>;</div></pre></td></tr></table></figure></p>
<p>(2) push_type<br>　　用于将数据传输到别的执行context，其构造函数接收的cor-function参数类型是pull_type类型的引用。在初始化push_type的时候，不同的是执行流没有转移到cor-function，而是先执行push_type::operator()去synthesize一个pull_type并将其引用传递给协程函数。其push_type::operator(T)成员函数用于推送数据给对应的context。<br>(3) coroutine-function<br>　　通过pull_type::operator bool可以判断协程是否还有效(即协程函数是否已经terminated)，除非第一个模板参数是void，否则返回true的同时也意味着其还可以提供数据的。<br>　　从pull-coroutine向main-context传递数据的例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">pull_type <span class="title">source</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::push_type&amp; sink)&#123;</div><div class="line">        sink(<span class="number">1</span>); <span class="comment">// push &#123;1&#125; back to main-context</span></div><div class="line">        sink(<span class="number">2</span>); <span class="comment">// push &#123;2&#125; back to main-context</span></div><div class="line">    &#125;);</div><div class="line"></div><div class="line"><span class="keyword">while</span>(source)&#123;            <span class="comment">// test if pull-coroutine is valid</span></div><div class="line">    <span class="keyword">int</span> ret=source.get(); <span class="comment">// access data value</span></div><div class="line">    source();             <span class="comment">// context-switch to coroutine-function</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　从main-context向push-coroutine传递数据的例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// constructor does NOT enter cor-function</span></div><div class="line">boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">push_type <span class="title">sink</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::asymmetric_coroutine&lt;<span class="keyword">int</span>&gt;::pull_type&amp; source)&#123;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i:source) &#123;</div><div class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; i &lt;&lt;  <span class="string">" "</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">13</span>,<span class="number">21</span>,<span class="number">34</span>,<span class="number">55</span>&#125;;</div><div class="line"><span class="keyword">for</span>( <span class="keyword">int</span> i:v) &#123;</div><div class="line">    sink(i); <span class="comment">// push &#123;i&#125; to coroutine-function</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="2-2_Symmetric_coroutine">2.2 Symmetric coroutine</h2><p>　　其caller和callee的关系是不固定的，symmetric的协程可以把执行控制转移给任意的symmetric协程，而不一定是自己的caller。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">symmetric_coroutine&lt;&gt;::call_type</div><div class="line">symmetric_coroutine&lt;&gt;::yield_type</div></pre></td></tr></table></figure></p>
<p>(1) call_type<br>　　call_type其构造函数是一个coroutine-function函数对象，协程函数接受一个yield_type的引用作为参数。实例化call_type不会将执行流传递到协程函数，其会先调用operator()去强制合成一个yield_type并将其引用传递给协程函数。<br>　　call_type不提供get()成员函数，即不可以从其他的执行context中获取数据。<br>(2) yield_type<br>　　通过调用yield_type::operator()并使用其它call_type对象作为参数，可以把数据和执行流传递给其他的context。<br>　　其模板参数规定了传输的数据类型，通过yield_type::get()可以访问该数据。如果实例化模板使用void类型，那么可以只用作控制流传递，而不进行数据的传递。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">boost::coroutines::symmetric_coroutine&lt;<span class="keyword">int</span>&gt;::<span class="function">call_type <span class="title">coro</span><span class="params">( </span></span></div><div class="line">    [&amp;](boost::coroutines::symmetric_coroutine&lt;<span class="keyword">int</span>&gt;::yield_type&amp; yield)&#123;</div><div class="line">        <span class="keyword">for</span> (;;) &#123;</div><div class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; yield.get() &lt;&lt;  <span class="string">" "</span>;</div><div class="line">            yield(); <span class="comment">// jump back to starting context</span></div><div class="line">         &#125;</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">coro(<span class="number">1</span>); <span class="comment">// transfer &#123;1&#125; to coroutine-function</span></div><div class="line">coro(<span class="number">2</span>); <span class="comment">// transfer &#123;2&#125; to coroutine-function</span></div></pre></td></tr></table></figure></p>
<h2 id="2-3_spawn">2.3 spawn</h2><p>　　如果是这么写程序，不是蛋疼，而是要蛋碎了。幸好Boost.Coroutine库给了一个高度的封装，其使用yield_context来保存协程的运行环境，然后允许程序以同步的方式执行各种异步函数操作，而这个yield_context对象是spawn函数自动产生的。当然要想知道其内部封装的实现，还是需要另外花一份功夫的。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Function&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawn</span><span class="params">(boost::asio::io_service::strand strand, Function function)</span></span>;</div><div class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Function&gt;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">spawn</span><span class="params">(boost::asio::io_service &amp; io_service, Function function)</span></span>;</div><div class="line"></div><div class="line"><span class="comment">// Function需要的签名</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">coroutine</span><span class="params">(boost::asio::yield_context yield)</span></span>;</div></pre></td></tr></table></figure></p>
<p>　　要求spawn的第二个参数Function的签名必须是上面的类型，如果不符合，需要使用bind/lambda方式来包装。<br>　　此后，对于所有的异步操作，只需要把yield作为参数传递在原来需要callback的位置就可以了，当异步操作完成的时候，此处的程序会resume继续执行。<br>对于异步操作的函数，其前面可能是<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">handler</span><span class="params">(boost::system::error_code ec)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">handler</span><span class="params">(boost::system::error_code ec, result_type result)</span></span>;</div><div class="line"><span class="comment">//  std::size_t length =  my_socket.async_read_some( boost::asio::buffer(data), yield);</span></div><div class="line"><span class="comment">//  boost::system::error_code ec;</span></div><div class="line"><span class="comment">//  std::size_t length =  my_socket.async_read_some( boost::asio::buffer(data), yield[ec]);</span></div></pre></td></tr></table></figure></p>
<p>　　对于有result_type的类型，其result的值已经作为参数返回了（比如上面的std::size_t），而如果出错，下面的调用方法会直接抛出异常，如果想使用原先返回错误的方式而不是抛出system_error异常的方式，可以使用yield[ec]的方式调用，operator[]用于外部获取发生的错误码。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">do_echo</span><span class="params">(boost::asio::yield_context yield)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">char</span> data[<span class="number">128</span>];</div><div class="line">    <span class="keyword">for</span> (;;)</div><div class="line">    &#123;</div><div class="line">      <span class="built_in">std</span>::<span class="keyword">size_t</span> length = my_socket.async_read_some(</div><div class="line">          boost::asio::buffer(data), yield);</div><div class="line"></div><div class="line">      boost::asio::async_write(my_socket,</div><div class="line">          boost::asio::buffer(data, length), yield);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">boost::asio::spawn(my_strand, do_echo);</div></pre></td></tr></table></figure>
<h2 id="2-4_再举个栗子">2.4 再举个栗子</h2><p>　　下面写一个小例子，看看封装后的协程写异步程序是多么爽的一件事，至于为什么爽是因为同步编程才是符合人类的思维习惯的。以前设置异步读取操作后，数据的处理都必须在回调函数中处理，现在可以直接在异步操作后接着处理啦！<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line">#include &lt;boost/asio.hpp&gt;</div><div class="line">#include &lt;boost/asio/spawn.hpp&gt;</div><div class="line">#include &lt;boost/bind.hpp&gt;</div><div class="line">#include &lt;boost/shared_ptr.hpp&gt;</div><div class="line">#include &lt;boost/make_shared.hpp&gt; </div><div class="line">#include &lt;string&gt;</div><div class="line">#include &lt;ctime&gt;</div><div class="line">#include &lt;iostream&gt;</div><div class="line">#include &lt;boost/enable_shared_from_this.hpp&gt;</div><div class="line"></div><div class="line">using namespace boost::asio;</div><div class="line">using std::cerr; using std::endl;</div><div class="line"></div><div class="line">io_service io_service_;</div><div class="line"></div><div class="line">class session: public boost::enable_shared_from_this&lt;session&gt;</div><div class="line">&#123;</div><div class="line">public:</div><div class="line">    explicit session(ip::tcp::socket socket):</div><div class="line">    sock_(std::move(socket)),</div><div class="line">    strand_(io_service_),</div><div class="line">    uuid_(std::rand())</div><div class="line">    &#123;&#125;</div><div class="line">    </div><div class="line">    ~session() &#123; cerr &lt;&lt; "~sessoin -&gt;" &lt;&lt; uuid_ &lt;&lt; endl; &#125;</div><div class="line">    </div><div class="line">    void go()</div><div class="line">    &#123;</div><div class="line">        auto self(shared_from_this());</div><div class="line">        boost::asio::spawn(strand_, </div><div class="line">                boost::bind(&amp;session::do_echo, self, _1));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    void do_echo(yield_context yield)</div><div class="line">    &#123;</div><div class="line">        char data[128];  </div><div class="line">        std::size_t n = sock_.async_read_some(boost::asio::buffer(data), yield);</div><div class="line">        cerr &lt;&lt; "RECVED:【" &lt;&lt; data &lt;&lt; "】-&gt;" &lt;&lt; uuid_ &lt;&lt;endl;</div><div class="line">        std::time_t now = std::time(nullptr);</div><div class="line">        std::string time_str = std::ctime(&amp;now);</div><div class="line">        async_write(sock_, buffer(time_str), yield);</div><div class="line">        sock_.shutdown(ip::tcp::socket::shutdown_send);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">private:</div><div class="line">    ip::tcp::socket sock_;</div><div class="line">    io_service::strand strand_;</div><div class="line">    std::size_t  uuid_;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"></div><div class="line">void start_accept(yield_context yield)</div><div class="line">&#123;</div><div class="line">    ip::tcp::acceptor acceptor(io_service_, ip::tcp::endpoint(ip::tcp::v4(), 2016));</div><div class="line">    </div><div class="line">    for (;;) &#123;</div><div class="line">        boost::system::error_code ec;</div><div class="line">        ip::tcp::socket socket(io_service_);</div><div class="line">        </div><div class="line">        acceptor.async_accept(socket, yield[ec]);</div><div class="line">        if(!ec)</div><div class="line">            boost::make_shared&lt;session&gt;(std::move(socket))-&gt;go();</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc, char* argv[])</div><div class="line">&#123;</div><div class="line">    boost::asio::spawn(io_service_, start_accept);</div><div class="line">    io_service_.run();</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>编译后就可以看出运行效果了：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  ~ g++ -std=c++11 test.cpp -lboost_system -lboost_coroutine -lboost_context -o <span class="built_in">test</span></div></pre></td></tr></table></figure></p>
<p>　　其实，感觉现实中协程更多的是对编程方式的改变，对控制流的操控可以用同步的结构写出异步的效果，但是协程是用户态的而不是原生的多线程，所以并不能并行执行提高并发率。但是协程能够在各个协程间进行高效的切换，这一点可以做到比传统依赖于异步调度的效率更高，这才体现出协作的本质吧！</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="https://msdn.microsoft.com/en-us/magazine/jj553509.aspx" target="_blank" rel="external">Windows with C++ - Lightweight Cooperative Multitasking with C++</a></li>
<li><a href="http://blog.csdn.net/cchd0001/article/details/50717525" target="_blank" rel="external">boost::asio::coroutine 文档翻译 + 源码解析</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/libs/coroutine/doc/html/index.html" target="_blank" rel="external">Coroutine</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/doc/html/boost_asio/reference/coroutine.html" target="_blank" rel="external">coroutine</a></li>
<li><a href="http://www.boost.org/doc/libs/1_54_0/doc/html/boost_asio/overview/core/spawn.html" target="_blank" rel="external">Stackful Coroutines - spawn</a></li>
<li><a href="http://theboostcpplibraries.com/boost.asio-coroutines" target="_blank" rel="external">Coroutines</a></li>
<li><a href="https://avlog.avplayer.org/3597082/%E5%8D%8F%E7%A8%8B.html" target="_blank" rel="external">协程</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[C++11新标准阶段性学习心得及两个小轮子分享]]></title>
      <url>https://taozj.org/201608/feeling-of-cpp-11-and-two-ticks.html</url>
      <content type="html"><![CDATA[<p>　　突然发现，自己的博客好久都没更新了。<br>　　主要缘由是这段时间忙于学习C++11和Boost的开发，同时公司也有一个小项目正在设计开发之中，所以工作成果都转换成笔记和代码了。<br>　　说来自己学习C++11已经一月有余了，之所以称之为学习而非温习，是感觉C++11和C++98的差异实在是太大了，体现的不仅是小特性的改进，而感觉是一个质的飞跃。V2ex上人家调侃说十几年前自己学了一门语言叫做C++，现在那个语言还是叫C++，只是我已经不认识他了。当初也有个朋友说，如果C++11早一点出来，那么Google也不会推Go语言了，而现在的开发语言的格局也会大有不同，至少说不准如当下Java大行其道作为绝大多数公司服务端开发的主力语言了。无可厚非，服务端的高性能开发的极致非C/C++莫属，所以C++是一门低碳环保的语言，而C++11的右值引用、移动操作等无不在最求性能的极致。<br>　　下面就着这段时间的学习心得体会和耳濡目染，介绍一些关于C++11的新认识。同时，在工作和学习之余，自己也模仿着造了两个小轮子，已经托管到GitHub上面了——虽然简单，也很不专业，但是对C++11的新特性都覆盖了不少，算是在学习中动手、在实践中改进吧。</p>
<h1 id="一、C++11新语言">一、C++11新语言</h1><h2 id="1-1_C++11">1.1 C++11</h2><h3 id="1-1-1_RAII和标准库">1.1.1 RAII和标准库</h3><p>　　以前学C和C++，在C/C++中的堆内存的动态分配，以往都是教条式的强调malloc/free、new/delete、new[]/delete[]一定要匹配使用！千万不要忘记！而且不能free/delete多次！者虽然不是什么技术问题，但是人毕竟是人，难免不出错。而RAII的技巧，就是利用stack上的临时对象生命期的性质，当临时对象超过作用域的时候析构函数会被自动调用，于是利用程序自动管理的这一特点，可以将资源的释放操作封装在一个临时对象中自动销毁，改变以往的手动申请和释放的模式。在C++11中，几乎绝大多数类型，通过一些技巧或者包装，都可以保证其到达作用域结束的时候被正确的析构掉，而且是异常安全的。所以理论上，通过C++11标准的程序，理想状态下不需要new/delete方式来管理对象了，使用智能指针、智能锁等工具重新组织你的工程，从资源管理的泥淖中解脱出来。<br>　　其次，据说C++新标准中有2/3的篇幅是关于容器和算法库。当然有人一直争论这些容器和算法库不应当作为一个语言的标准这种形式存在，否则语言的标准将会不断的膨胀。但是作为实用主义来说，这些标准容器和标准库的存在可以大大增加开发进度，同时别人调试好的数据结构和算法也更容易开发出稳定的程序来。</p>
<h3 id="1-1-2_Boost库">1.1.2 Boost库</h3><p>　　前面说过，Boost库算是C++标准的试验田，诸位C++大牛都会把特性想法在这里开发，然后好的东西会被C++标准委员会吸纳进正式标准，比如C++11中智能指针就是从Boost中引入的。但是如陈硕老师所言，Boost库规模庞大，但也不能盲目尽信之，好的东西譬如如智能指针、noncopyable等可以直接用，免去自己制造垃圾轮子，而且可以借鉴取其实现思路和方法，以增长功力。但是也有些库用到的技术晦涩难懂，和实际使用有所脱节，而且可能效率很低。当然这些甄别取舍也是门技术，惭愧自己到达那份功力还路途遥远。<br>　　还有需要注意的是，很多的东西在Boost和C++11标准中都有一份，虽然大体功能相似，但是还是有些差异，比如：std::unique_ptr可以传递deleter函数，但是boost::scoped_ptr却不支持。看个人感觉吧，但是建议不要混用，因为即使std::shared_ptr和boost::shared_ptr等价，但是函数调用参数却不这么认为。</p>
<h3 id="1-1-3_编译速度非常慢">1.1.3 编译速度非常慢</h3><p>　　C++的运行速度不慢，但是由于现在的库中引入了大量的模板类，而模板的解析、实例化、编译等很很需要计算量。一个十来个文件的小项目在笔记本上要干一分多钟，实在忍受不了。网上搜罗的解决方式有：<br>　　(1). PCH预编译头部<br>　　照网上的说法是建立一个头文件xxx.hpp，包含在项目中常用稳定的头文件，然后编译这个头文件生成同名xxx.gch的预编译头结果，后续在项目中包含xxx.hpp就会直接使用xxx.gch预编译结果，从而减少编译时间。我照着做了，没效果，在stackoverflow上面问了好久<a href="http://stackoverflow.com/questions/39049853/about-g-not-working-with-pre-compiled-headers-pch" target="_blank" rel="external">About g++ not working with pre-compiled headers pch</a>，也没人鸟我。<br>　　不知道是GCC的BUG还是我的姿势不对，后面试试Clang吧。我觉得这种预编译头还是挺有用的，如果有预编译结果会得到优化，如果没有也能正常编译，可惜这里暂时不能用。<br>　　(2). ccache缓冲<br>　　问了罗剑锋，他说ccache应该可以优化编译效率，不过我还没试。<br><a id="more"></a></p>
<h2 id="1-2_C++编译器">1.2 C++编译器</h2><p>　　C++的编译器，基本是Windows的Visual C++和Linux平台下的g++成了默认编译器的了，但是近年来Clang+LLVM的编译套件在Mac和Linux平台声势很猛。网上搜了一下，主要声音是：<br>　　(1). GCC虽然是GNU社区开源旗舰产品，但是总体对大商业(闭源)公司不见得多友好，据说苹果提了很多Objective-C的特性，结果GNU就是不鸟他们。没办法，信仰不同嘛，再加上程序员总是有些偏执和骨子里面的犟。所以苹果招了个奇才搞出了个Clang，然后以更加宽松的BSD协议分发，这时候谷歌等大公司也乐呵进来了，众人拾材火焰高啊，看样子这是要把GCC扔进垃圾箱的节奏么。<br>　　(2). Clang和LLVM是整个编译器的前段和后端，而GCC是一体的，所以Clang可以更加专注于做好词法和语法分析。怎么感觉老一代的软件都是又大又全，新一代的软件都是段小精悍的形式出现，就像Apache和Nginx一样的案例，Apache集成了大量模块，而Nginx强于异步事件来实现高并发，很多任务反向代理给后端就好。<br>　　(3). 据说Clang编译出错提示比GCC好，尤其是对C++这种复杂的语言。后面我想切换到Clang体验一下，不过很多库默认都是GCC编译打包的，可能会有些不方便。还有人爆料最近阶段，GCC的代码质量大不如前了，这我倒没感受啥，但GCC现在疯狂的刷版本号是搞的哪一壶？<br>　　(4). 用久了总归会审美疲劳的，就像乔帮主当年的拟物图标设计的多么完美生动，后来换成扁平后还是大受欢迎，也不能说谁绝对的好与不好。</p>
<h1 id="二、服务端的信息分发">二、服务端的信息分发</h1><p><div class="github-widget" data-repo="taozhijiang/airobot_msgd"></div></p>
<h2 id="2-1_工作原理">2.1 工作原理</h2><p>　　C++下的异步开发库最有名的就数boost.asio了，其设计跟epoll以及最常见的libevent不同，为Proactor模式的，意味着在回调函数被调用的时候，IO操作已经完成了，这最典型的Windows完成端口模式。其好处就是，当IO任务特别多的时候，传统的Reactor可能会将任务队列排的很长，整个系统的响应速度变得恶化。<br>　　自己用boost.asio做了一个<a href="https://github.com/taozhijiang/airobot_msgd" target="_blank" rel="external">airobot_msgd</a>的程序。这个程序本来是给自己另外一个程序做的，目的就是将之前的一个程序开启多个运行实例，然后这个前端程序可以把所有的请求分发到后端处理，并将后端的处理结果再返回过来转发给请求客户端。其实这种算是很常见的应用需求，一方面可以增加整个系统的性能，同时也增加了容错性：后台程序只要不全挂完，总能得到响应。<br>　　或许你会问，这个不就是Nginx反向代理可以做的么，而且可以设置负载均衡参数。但是我想说airobot_msgd收到数据后会进行一个初步解析，将相同一个会话转发到后台的同一个实例上处理，并不是HTTP那种完全无状态的请求，后端要求连续的会话信息哦！<br>　　不过，如果重新设计开发这个项目的话，我可能会用MessageQueue来做了。</p>
<h2 id="2-2_实现细节">2.2 实现细节</h2><p>　　这个软件的异步操作是使用的boost.asio。高吞吐量并发的异步IO模型在boost.asio中主要有<a href="http://www.boost.org/doc/libs/1_55_0/doc/html/boost_asio/examples/cpp03_examples.html" target="_blank" rel="external">三种实现</a>方式：an io_service-per-CPU、a single io_service and a thread pool以及stackless coroutines模式。<br>　　(1). an io_service-per-CPU: 算是最简单的吧，每个io_service都在一个CPU上面串行执行，各个io_service没有影响，而每个socket是绑定在一个io_service上面的，基本不需要什么额外的保护了；<br>　　(2). a single io_service and a thread pool: 这种方式在异步读写的时候需要strand来保护，确保其被包装的相同socket回调函数串行化不会被多个线程同时执行(还有待深入考证)；<br>　　(3). stackless coroutines: 这种方式在Python等语言中用的很多，称为协程开发，但是感觉C++中用的不是很主流啊。因为C++本来就有高性能的native线程啊。<br>　　由于要根据前端的会话信息进行后端服务分配，所以需要json解析POST的消息体。GitHub上面Json的库之多如牛毛，我选的是<a href="https://github.com/dropbox/json11" target="_blank" rel="external">json11</a>这个库，就.hpp和.cpp两个文件，很容易代码方式集成到项目中，功能也都够用，而且用最新C++11实现的，RAII所有对象自动析构，可以像普通变量一样使用(同时在这个库中没有发现一个new/delete)。但是这个库有个缺点，就是整形在底层是用double存储的，精度只能支持+/-2^53范围，他们在头文件中说明地很清楚，因为javascript这类语言就支持不了大整形的。但是我觉得uint64_t这种类型还是很有用的，于是自己<a href="https://github.com/taozhijiang/json11" target="_blank" rel="external">fork了一份</a>，修改支持64位整形，并用在了项目中。<br>　　后面透过《Linux多线程服务端编程》这本书，代码也修改了一些，比如：使用time_wheel定时清理非活跃连接；服务端可以主动关闭写端，被动关闭整个连接等，随着后面的学习代码可能会持续更新。</p>
<h2 id="2-3_TODO">2.3 TODO</h2><p>　　(1). 当前对每个链接请求都是先创建connnection，结束后销毁connection，但是反复创建和销毁对象对性能还是有很大的影响的，后续优化会建立一个connection的对象池，新链接到来的时候在对象池中取出然后进行关键参数的初始化，使用完毕后进行敏感数据的处理后，再丢回对象池中；（目前已经实现）<br>　　(2). 当前只是简单的解析了HTTP的请求头部，以及固定的回复头部，后面对HTTP协议有深入了解的话，可以增加对这些头部特性实质性的支持。</p>
<h1 id="三、方便使用的数据库连接池">三、方便使用的数据库连接池</h1><p>　　之前在进行C开发的时候，就已经写了一个数据库连接池，感觉是很有用的，于是在C++的时候也没能把持住，造了另外一个轮子，项目在<a href="https://github.com/taozhijiang/aisqlpp" target="_blank" rel="external">aisqlpp</a>。</p>
<p><div class="github-widget" data-repo="taozhijiang/aisqlpp"></div></p>
<h2 id="3-1_工作原理">3.1 工作原理</h2><p>　　其实说起来很简单，就是用一个std::map存储链接和对应的占用、空闲、错误信息。在此，MySQL的官方也是有基于C++11和Boost的客户端连接库<a href="https://github.com/mysql/mysql-connector-cpp" target="_blank" rel="external">mysql-connector-cpp</a>，个人算是在这个连接库中对其封装了一下，让其看起来更好用更安全吧。</p>
<h2 id="3-2_实现细节">3.2 实现细节</h2><p>　　(1). 在每个连接中，将stmt、prep_stmt、ResultSet等信息都封装到类中，当每次需要进行新的查询或者操作的时候，都更新这些类变量，所以也不用繁琐的申请和释放这些变量了。显然，这些变量都不是线程安全的，不过任何操作过程中都需要申请这个链接，使用完毕后释放这个链接，这个过程中连接不会分配给别的线程，所以算是线程安全的。在前面的应用模型中，最好是线程池中每个线程固定分配一个链接，可以避免每次申请和释放的繁琐过程了，不过这得我深入确切的了解io_service线程池模型和strand做了什么才部署。<br>　　(2). 其次就是在查询结果的解析中，采用C++11的模板技术，便利的封装了一些查询结果的获取方式，支持单个列多条记录的查询返回和一条记录的多个列返回，让整个查询就像调用一个函数一样那么轻松。如果能用动态模板类将多条记录的多个列结果封装返回就好了，后面尝试看看。<br>　　(3). 然后，还根据RAII的原理，提供了一个request_scoped_conn接口，这个获取的的connection在离开其作用域的时候会自动释放该连接，使用起来更加方便了。</p>
<h1 id="后言">后言</h1><p>　　最后，昨天在看陈硕的《Linux 多线程服务器端编程》的时候，遇到一段摘抄，是孟岩老师(不认识，不过陈硕引用了很多他的东西)的<a href="http://blog.csdn.net/myan/article/details/3144661/" target="_blank" rel="external">《快速掌握一个语言最常用的50%》</a>，大家可以看看原文吧。<br>　　我的个人感觉呢，对于核心业务，确实不能让半瓢水的程序员匆忙上阵，否则埋的坑多了，对后续系统的维护都是灾难性的。而对于初学者，应该一定程度上多看多造轮子。如果一说到什么项目，总是想到这个库那个库的，直接拿来不勤于探究的话，那么你就充当个系统集成工程师了，技术得不到锻炼和成长。同时也不建议只看书不动手， 以为把书翻烂了知识点烂熟于胸，写起代码来能信手拈来。其实我的建议是一边写程序一边看书，当遇到新的知识点时候，看看自己的程序能否有改进，能否更优雅的实现，让程序和你的知识一样慢慢玩备起来。当然你的程序如果最终有条件线上测试，就更好了。</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[关于近来本站点的一些修改和设置]]></title>
      <url>https://taozj.org/201608/some-refined-and-modification-this-site.html</url>
      <content type="html"><![CDATA[<p>　　经过这么半年多的运营，博客积累了50多篇博文了。虽然其内容不如<a href="http://coolshell.cn" target="_blank" rel="external">CoolShell</a>那么有深度，数量也不如<a href="http://www.williamlong.info" target="_blank" rel="external">月光博客</a>那么高产，但是自我感觉收获还是比较多的：<br>　　(1)首先，感觉自己记性是比较差的，同时也没有写日记的习惯，所以这篇博客算是自己在技术路线上的日记了，当然偶尔有心情情趣了还会写点杂感体验啥的，若干年后自己回首看看，感受下自己怎么滴从幼稚无知走向成熟(希望是这么个路线)，想必也会别有一番风味；<br>　　(2)其次，还是自己记性差，所以很多的学习折腾经验还是记下来比较靠谱，平常也可以翻开来既可以做到温故而知新，还可以避免以前的坑点和弯路——以史为鉴，可以知兴替嘛；<br>　　(3)再则，程序员的交际能力普遍比较差，所以自己写点东西，算是对自己表达能力和组织能力的一种锻炼吧，还有就是比如看书看文档，看起来你不会发觉，但当笔记记录下来时候，很多细节的问题就会被发现，可以帮助你加深对事物的认识。<br>　　(4)提高自己的毅力。万事贵不在难，在于坚持。大家都说个人博客是程序员的标配，但是很多人都是开头兴致勃勃的买服务器打环境，写了几篇之后博客就长草了，所以我觉得这也是最能锻炼我的地方。还有就是，把自己所学所感记下来，会让自己觉得是真正积累(即使在脑袋中可能会忘记)，激发后学学习的动力和勇气。</p>
<p>　　个人读书的时候就写过不少博客，这次重启博客项目之后，觉得之前的东西都比较幼稚，所以就没有再导入近来，包括这个博客的折腾经历啥的，在博文<a href="/201603/blog-site-under-https.html">我的博客用上HTTPS啦</a>也有介绍。</p>
<p>　　然后，这篇博文其实我想说的是：<br>　　国外搭建博客的平台很多，静态的有GitHub、Bitbucket以及国内的codeing.net，动态的有OpenShift等，而且是都是免费的。OpenShift依托Red Hat强大的研发实例和Amazon强大的基础数据中心，算是国外最理想、最稳定可靠的动态建站环境，但是国内的访问速度不忍直视，用360测速几乎都是红的，访问速度严重影响了网站的用户体验，而且最大的隐患就是突然有一天根据某些法律让你的网站从地球上“消失”。GitHub以及稍微小众的Bitbucket短期内应该不会被封掉(感觉GitHub在某些事情上向某些政府妥协了)，但是访问速度也是慢的很，然后常常挂代理访问GitHub反而比直接访问GitHub还要快，想必其中的原因大家都心知肚明吧。还有就是coding.net，算是GitHub本土化产品，也可以搭建博客，出于规避法律的因素把服务器设置到了香港，不过速度还是不错的，但是一样的不支持HTTPS，算是没有办法中比较好的备选吧。<br>　　当然，如果你的域名是备案的，是可以用国内免费或者付费的CDN，而且即使付费的话博客访问的流量估计一个月也就几块钱，访问速度应该会有很大的改善。如果域名没有备案，就不用找了，国内没有任何一家公司敢帮你挂站或者缓存的。<br>　　同时。我本人现在博客、相册、Wiki的选型都倾向于不用数据库的。虽然LNMP是经典的架站模型，性能不错，但是挂着个数据库备份、维护都很不方便。所以如果免数据库都是文件的话，可以在GitHub托管开源版或者在Bitbucket托管闭源版本，然后本地备份再加上Dropbox同步备份，你的数据就是相当安全的，即使有一天你的网站因为某些告人或者不可告人的原因被“消失”掉了，你还可以零成本、零丢失地重新部署，很诱人吧！<br>　　上面提到WiKi，是我觉得之前很多技术类的读书笔记放在博客中，查阅不是很方便，于是想到放到WiKi中查找和更新都会比较直接，此外还有的原因是WiKi的字体比较小，界面比较简洁所以界面甚是喜欢。一搜大家都是推荐MediaWiki，但是又是一个PHP+MySQL的，然后又发现<a href="https://www.dokuwiki.org/dokuwiki#" target="_blank" rel="external">dokuwiki</a>还不错，跟我的相册一样也是PHP加文件系统的形式，备份很方便。虽然还需要学一下wiki syntax，但好在比较简单，推荐大家使用。同时也希望大家多多收藏和关注<a href="https://wiki.taozj.org/doku.php" target="_blank" rel="external">Nicol’s Wiki Page</a>。<br>　　我现在的网站是挂在阿里云的，是我的一个朋友的服务器，我帮他做运维，他借给我托管个人网站。由于我的域名没有备案，所以80端口不让访问，广大童鞋访问的时候要记得添加https哦，如果懒的输的话，这里是<a href="https://www.taozj.org" target="_blank" rel="external">我的主页</a>，点击就可以了，欢迎收藏。</p>
<p>　　OK，八月的第一篇水文就此完工！</p>
<p>　　PS: 2017-01-04已经将域名taozj.org提交到<a href="https://hstspreload.org" target="_blank" rel="external">Google HSTS preload list</a>中，以后该域名和所有子域名都会被硬编码到Google Chrome浏览器中以强制https方式访问！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Boost库学习笔记(一)：智能指针和内存池]]></title>
      <url>https://taozj.org/201607/learn-note-of-boost-(1)-smart-ptr-memory-pool.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　这篇是这个系列的开篇第一作，所以还是想简单说点题外话。<br>　　以前上学的时候学过C++，所谓经典的《 C++ Premier Plus》、《 C++ Premier》、《C++ Templates》三本书也都看过，那些诡异的语法、隐晦的潜规则也曾啃过，但是到现在基本都忘了。我想，究其原因：一方面是C++实在是过于的复杂，复杂到据说，当时一个公司的团队，打算用C++新开发一个项目，到后来整个团队跑题去研究C++语言本身了；另一方面如同自己之前所说的，缺少C++的项目经验，教科书基本就是一个点一个例子零散的教你，没有像样的大型项目训练很难深刻理解和掌握之。刚好前段时间对异步研究的比较多，然后沿着boost::asio，了解到boost C++开发库，比较出名而且在正式项目中用的比较多，觉得以此为切入点还是不错的。<br>　　还有，至于为啥要干C++。虽然现在Python、go这些语言火的如日中天，但觉得后台底层开发基本还是C，C++，Java三分天下的局面：Java在中间件中用的比较多，而且Apache旗下一大堆的分布式组件和算法库也都是Java实现的，可谓前途广阔；C作为现代编程语言的鼻祖，Linux内核项目证明了C完全是可以开发大型项目的，但是之前自己写的几个小程序，感觉C的确也是年世已高了，语法简洁但是缺乏上层抽象，很多东西需要自己造轮子，或者不断的选库集成；C++做后台是很多的，比如自己以前实习的移动通信核心网，就是C++写的，C++的模板特性，再加上C++标准不断的吸纳新的数据结构、算法等内容，让C++不断地被丰富完善，以适应现代大型项目快速开发的需求。从个人感觉上来说，Java开发最省心，这也是GC(垃圾回收)类语言的最大优势，但是不是说Java性能慢么？C语言简洁优雅而又直白，给定一个代码，可以很明确的分析其预测结果，但是正因为简洁优雅，很多高级编程的抽象需要底层去实现，开发效率算是最低吧。而C++估计是最复杂的语言了，隐含的规则很多，常常代码需要推理一下才知道可能的结果，而且如果对C++了解不深入的话，感觉更容易照成内存泄漏，其远没有C的malloc/free这么简单！<br>　　关于boost的历史缘由，以及跟C++标准的关系，这里就不再整理了，网上一搜全部都是。可以说boost库是C++新特性的实验基地吧，在boost中比较好的库，很有可能会成为后续C++的标准，所以boost也会被冠以“C++准标准”的美誉。<br><img src="/post_images/images/201607/60d27a9097df68f72fdad62133efbfe4.png" alt="Boost"><br>　　刚买了一本新的《C++ Premier》第五版，书中着重强调是一本依据C++11标准更新改写的，初步瞭阅一下，感觉不错，希望C++11和boost能给我带来新的成长。<br><a id="more"></a></p>
<h1 id="二、Boost库的代码">二、Boost库的代码</h1><h2 id="2-1_下载代码">2.1 下载代码</h2><p>　　现在C++库的趋势，就是库以头文件形式直接包含使用的，而boost中大部分库都是这种德行，除非少有的几个库需要额外的编译操作。如果想深入学习研究，不如拷贝一份源码下来，没事的时候拉拉上游的更新，有心情的时候看看源码，看看大神级别的代码是怎么练成的。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@gentoo ~ % git <span class="built_in">clone</span> --recursive https://github.com/boostorg/boost.git</div></pre></td></tr></table></figure></p>
<p>　　这个库比较的大，即使用tar.bz2打包之后，都有500多兆，毕竟有一百多个库，还有这么久的提交历史。不能忍受国内龟速的我，是在墙外的VPS上clone下来，然后打包下载下来的。然后就可以用SlickEdit建立项目tag代码了。后面可以随时更新代码：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">user@gentoo boost % git pull</div><div class="line">user@gentoo boost % git submodule update --recursive</div></pre></td></tr></table></figure></p>
<h2 id="2-2_编译一下">2.2 编译一下</h2><p>　　编译的好处，一方面确保最上游的代码是可用的，否则可以提交一些issue或者pull request，也可以为社区奉献自己的一份力；再则就是后续开发应用程序，链接到自己编译的库，调试的时候可以跟踪到库内部调试，可以在调试程序的同时，增加你对boost库的深入理解和认识。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">user@gentoo boost % ./bootstrap.sh</div><div class="line">user@gentoo boost % ./b2 --ignore-site-config --build-dir=builddir/ --prefix=installdir/ <span class="_">-a</span> toolset=gcc variant=debug threading=multi install</div></pre></td></tr></table></figure></p>
<p>　　上面的第一步，就是生成boost的编译工具b2，而第二步才是boost库的真正编译。完工之后，会在./installdir目录生成include和libs结果，怎么用就不用说了吧。</p>
<h1 id="三、智能指针">三、智能指针</h1><p>　　前面废话了这么多，本文的主题来了。智能指针(smart_ptr)定义在boost/smart_ptr当中，主要是用于解决heap堆内存动态对象生命周期（传统的C++的堆对象需要使用new/delete来创建和释放，这就需要在离开作用域以及catch捕获异常的时候，正确的调用delete释放对象），以及对象被多个所有者共享之问题，属于C++内存管理之范畴。boost包含的智能指针有如下类型（在C++11已经引入了shared_ptr和weak_ptr以及unique_ptr智能指针了）</p>
<table>
<thead>
<tr>
<th style="text-align:left">指针</th>
<th style="text-align:center">特性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">scoped_ptr</td>
<td style="text-align:center">Simple sole ownership of single objects. Noncopyable.</td>
</tr>
<tr>
<td style="text-align:left">scoped_array</td>
<td style="text-align:center">Simple sole ownership of arrays. Noncopyable.</td>
</tr>
<tr>
<td style="text-align:left">shared_ptr</td>
<td style="text-align:center">Object ownership shared among multiple pointers.</td>
</tr>
<tr>
<td style="text-align:left">shared_array</td>
<td style="text-align:center">Array ownership shared among multiple pointers.</td>
</tr>
<tr>
<td style="text-align:left">weak_ptr</td>
<td style="text-align:center">Non-owning observers of an object owned by shared_ptr.</td>
</tr>
<tr>
<td style="text-align:left">intrusive_ptr</td>
<td style="text-align:center">请不要用它！</td>
</tr>
</tbody>
</table>
<h2 id="3-1_std::auto_ptr">3.1 std::auto_ptr</h2><p>　　std::auto_ptr是C98标准中的，其目的就是代理原始对象的指针，当该变量离开作用域（以及发生异常）的时候，就会调用delete删除原始对象，保证原始对象得到正确的析构和释放。但是这个std::auto_ptr定义的比较宽泛，使用的时候需要注意一下的缺陷：</p>
<ul>
<li>多个std::auto_ptr不能同时管理同一个对象，否则在离开作用域的时候会发生多次析构，行为是不确定的；</li>
<li>其析构的时候调用的是delete而非delete[]，所以不能处理数组类型的指针；</li>
<li>std::auto_ptr设计的初忠就是可被转移的，但是在任何一个时刻，只能有一个智能指针获得对象的控制权，意味着当别的智能指针获得std::auto_ptr所管理对象的控制权的时候，这个std::auto_ptr同时就失去了控制权(==0)了；</li>
<li>不能放入容器中，因为任何的赋值将会导致控制权的转移；</li>
<li>可作为函数的返回值；</li>
</ul>
<h2 id="3-2_boost::scoped_ptr">3.2 boost::scoped_ptr</h2><p>　　能够保证被包装的任何对象都能够在离开作用域的时候被正确的析构，但是对所有权也更为的严格——一旦boost::scoped_ptr获得了对象的所有权，将不能再取回来，通过将拷贝构造函数和赋值操作符private私有，保证其管理的指针不会被复制或者转让，不容易被误用。</p>
<ul>
<li>重载了-&gt;和*操作符，可以像普通指针一样使用；</li>
<li>不能重载==和!=操作符，可以在bool上下文中检查其管理的指针是空指针还是有效指针；</li>
<li>reset(T* p)会删除原来保存的指针，然后赋值为p；</li>
<li>get()会返回原始指针，但是不能手动delete这个指针，因为在脱离作用域的时候，boost::scoped_ptr还是会再次发生析构操作的；</li>
<li>无法在标准容器中存放boost::scoped_ptr，因为这种类型的指针不支持拷贝和赋值；</li>
</ul>
<h2 id="3-3_boost::scoped_array">3.3 boost::scoped_array</h2><p>　　同boost::scoped_ptr类似，只不过是用来管理new[]数组类型的对象的，没有-&gt;和*操作符，而是重载了operator []操作符，可以索引数组元素。<br>　　由于不提供指针运算，所以也无法使用(数组首地址+元素偏移)这样的访问方法；同时不会检查索引的合法性，不能动态增加长度，不能迭代，所以没别的理由，推荐使用vector<t>。</t></p>
<h2 id="3-4_boost::shared_ptr">3.4 boost::shared_ptr</h2><p>　　基于引用计数型的智能指针，可以被自由地拷贝和赋值，也可以被放入到容器中。只有当引用计数为0的时候，才会安全的析构对象。</p>
<ul>
<li>提供*、-&gt;、bool类型的操作，get()可以获得原始指针；</li>
<li>提供reset()函数，调用时候计数值-1同时不再持有对资源的管理(内部指针为0)，但计数值不为0的时候，是不会产生析构操作的；当reset()带参数的时候，-1后会修改内部指针管理其它资源了；</li>
<li>unique()，检测use_count==1；</li>
<li>提供==和&lt;比较，等同于a.get()和b.get()的比较；提供&lt;&lt;操作符可以输出内部的指针值；</li>
<li>不能使用a.get()获得指针后再用标准C++的类型转换，而应该使用static_pointer_cast<t>、const_pointer_cast<t>、dynamic_pointer_cast<t>这类的转换接口；</t></t></t></li>
<li>【工厂模式】理想情况下智能指针管理下完全不必要使用delete了，而在堆上创建对象除了使用new，还可以使用工厂模式——boost::make_shared<t>，其参数将被传递给给模板类的构造函数，返回shared_ptr对象。</t></li>
</ul>
<h2 id="3-5_boost::shared_array">3.5 boost::shared_array</h2><p>　　基本同上。<br>　　同样的，推荐使用boost::shared_ptr<std::vector>或者std::vector<boost::shared_ptr>。对于后一种方式，虽然容器也可以直接存储原始指针，但是不能保证原始对象的析构操作，而用boost::shared_ptr则可以通过引用计数的原理正确的管理对象。</boost::shared_ptr></std::vector></p>
<h2 id="3-6_boost::weak_ptr">3.6 boost::weak_ptr</h2><p>　　本身不会被单独拿来用，通常是和boost::shared_ptr协同作为静态观测者使用的，其不会改变对象的引用计数，本身不具备指针的任何基本功能（比如*和-&gt;）。</p>
<ul>
<li>boost::weak_ptr在构造和析构的时候，不会引起boost::shared_ptr引用计数的变化；</li>
<li>use_count()成员函数返回观测资源的引用计数，而expired()等同于检测use_count()==0，表示观测资源已经不复存在；</li>
<li>boost::weak_ptr构造的时候，使用boost::shared_ptr或者其它的boost::weak_ptr进行初始化，然后调用lock()方法，如果对象存在，那么会返回一个boost::shared_ptr（同时原始资源的计数会+1），否则就返回0；</li>
<li>C++中this和boost::shared_ptr一个惯用，就是让自己的类继承enable_shared_from_this，然后就可以使用make_shared<t>工厂模式产生对象，而当需要boost::shared_ptr指针的时候，使用shared_from_this()就可以返回。关于这点，还想说的是，在使用boost::shared_ptr的时候，为了保证对象正确被析构，需要遵循以下法则：(1)在一个对象的内部，不要去利用boost::shared_ptr持有对象自身；(2)当两个对象互为对方成员变量的情况，必须使用弱引用；(3)当boost:;shared_ptr和boost::asio互用的时候，还有其它“槽点”，到时候再讨论吧。</t></li>
</ul>
<h2 id="3-7_std::unique_ptr">3.7 std::unique_ptr</h2><p>　　这个是C++11中的，跟boost::scoped_ptr比较类似，也是不能拷贝和赋值的，任何时候只能有一个std::unique_ptr控制对象。但是其提供了一个转移语义：</p>
<ul>
<li>release()会释放资源的控制权，同时返回指针。因此std::unique_ptr p2(p1.release())就实现了控制权的转移。大多数情况下，人们推荐const std::unique_ptr代替boost::scoped_ptr。</li>
</ul>
<h1 id="四、内存池pool类">四、内存池pool类</h1><p>　　定义在boost/pool当中，主要包括pool、object_pool、singleton_pool和pool_alloc四个类型。</p>
<h2 id="4-1_boost::pool">4.1 boost::pool</h2><p>　　最简单的类型，但也只能申请int/double等这些简单的数据类型，构造器接收的参数是申请单个内存块的尺寸大小。该类不会抛出异常。</p>
<ul>
<li>malloc()、ordered_malloc()用于申请内存，free()可以手动释放内存，而内存池对象离开作用域的时候会自动释放所有的内存；</li>
<li>is_from()用于判断内存块是否是从这个pool内存池对象分配出去的；</li>
<li>release_memory()让内存池释放所有没有分配的内存，而已经分配的内存不受影响；purge_memory()强制释放所有的内存（等同于内存池析构时候操作）；</li>
</ul>
<h2 id="4-2_boost::object_pool">4.2 boost::object_pool</h2><p>　　基本同boost::pool，只是在析构的时候会自动对所有分配的内存块调用析构函数。该类不会抛出异常。</p>
<ul>
<li>仍然提供malloc()和free()接口，但是这只是裸分配和释放内存，不推荐使用；</li>
<li>is_from()用于判断内存块是否是从这个pool内存池对象分配出去的；</li>
<li>construct()和destroy()接口，会首先调用malloc()/free()申请/释放内存，然后将调用参数传递给对应的构造函数/析构函数；</li>
</ul>
<h2 id="4-3_boost::singleton_pool">4.3 boost::singleton_pool</h2><p>　　接口类似boost::pool，但是是一个单件（设计模式中，单件确保只产生一个实例，但本身不是静态类），使用域操作符来调用静态成员函数，并且是线程安全的！<br>该内存池的内存会在整个程序运行的整个生命周期中一直存在，所以如果想在程序运行过程中回收内存，只能手动进行释放。</p>
<h2 id="4-4_boost::pool_alloc">4.4 boost::pool_alloc</h2><p>　　不推荐使用，就不必多言了。</p>
<p>　　附录是推荐的C++的学习教材。慢慢啃吧，会有好处的！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.boost.org/doc/libs/1_61_0/" target="_blank" rel="external">Boost Doc</a></li>
<li><a href="https://book.douban.com/subject/5276434/" target="_blank" rel="external">Boost程序库完全开发指南</a></li>
<li><a href="https://book.douban.com/subject/20471211/" target="_blank" rel="external">Linux多线程服务端编程</a></li>
<li><a href="https://book.douban.com/subject/25708312/" target="_blank" rel="external">C++ Primer 中文版（第 5 版）</a></li>
<li><a href="https://book.douban.com/subject/1110941/" target="_blank" rel="external">C++标准程序库</a></li>
<li><a href="https://book.douban.com/subject/1842426/" target="_blank" rel="external">Effective C++</a></li>
<li><a href="http://www.boost.org/doc/libs/1_61_0/libs/smart_ptr/smart_ptr.htm" target="_blank" rel="external">Smart Pointers</a></li>
<li><a href="http://theboostcpplibraries.com/" target="_blank" rel="external">The Boost C++ Libraries</a></li>
<li><a href="https://www.avboost.com/" target="_blank" rel="external">avboost, avplayer社区</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Tesseract的数字识别程序]]></title>
      <url>https://taozj.org/201607/simple-digit-recong-base-on-tesseract.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　这算是一个临时空降的任务，项目背景就懒描述了，先期目的就是从电表的照片中，自动识别出电表的读数出来。如果透过现象看本质，这显然就是一个OCR的任务，而OCR无非就是先期的图片预处理，以及后期的实际OCR识别任务两个阶段。<br>　　说到OCR，就不得不提到大名鼎鼎的Google Tesseract了(虽然这个项目最初是由惠普开发，后面交由Google维护)，几乎绝大多数的开源OCR项目，都是用它作为识别引擎的。Tesseract是开源的，而且本身就包含了很多种语言模型的训练结果，如果不是有特别的需求（比如手写的不规则字体），几乎就是开箱就用的效果。我们这里电表的读数都是8段LCD的字体，作为一类最常见的标准字体，我想自己训练也不见得模型有所提升，把精力花在第一步图像的处理方面，会得到更加显著的效果。<br>　　当然，这暂时也不是我的兴趣所在，也没有什么深入研究和体会，只是借助上面的项目搭建了个可以工作的模型，所以干货是没有的干活~</p>
<h1 id="二、EasyPR开源车牌">二、EasyPR开源车牌</h1><p>　　对于OCR，经过Google之后，我不得不推荐一个项目<a href="https://github.com/liuruoze/EasyPR" target="_blank" rel="external">EasyPR</a>，其原因不仅仅在于它是开源的，而是作者十分的用心，将整个<a href="http://www.cnblogs.com/subconscious/p/3979988.html" target="_blank" rel="external">项目流程</a>的原理、思路和实现细节介绍的十分详细，可以说是手把手教你做车牌识别的，而这无论对于准备入坑的工程师，还是在校学生灌水发论文或者毕业设计，都具有很好的指导入门作用。现在这个项目已经更新到v1.5版本了，引入了MSER等算法用于目标定位等操作，如果想跟着上面作者教程的思路，建议切换到v1.3分支查看。<br>　　参阅作者的教程，总结下来实现流程是这样的：</p>
<h2 id="2-1_图像预处理过程">2.1 图像预处理过程</h2><p>　　这个过程可以总结为抠图过程——就是在一副图像中，提取出车牌号的那一块出来，这纯粹就是个图像处理的过程；对于抠出来的图片，还通过SVM判断器分析是否是车牌图像，可以在减少后续OCR操作的同时，也增加了识别的准确率。<br>(1) 高斯模糊化，可以平滑滤除小的变化细节，保留车牌边沿这些大的细节；<br>(2) 图片灰度化；<br>(3) 对图像X轴方向做Sobel计算（等于是个求导操作），求取图像变化特征，至于为何只求水平方向而不求垂直方向，作者用实验的方法表明，水平方向Sobel足以获得足够的特征用于后续求取轮廓，而垂直Sobel计算往往对最终结果有害无益；<br>(4) OTSU法自适应对图像进行二值化（一看就是日本名字，经典啊）；<br>(5) 进行形态学的膨胀腐蚀操作，滤除小的噪声点，同时获取相应的连通区域；<br>(6) 求取Contours轮廓，同时对轮廓进行粗筛选（比如角度、大小、长宽比等）；<br>(7) SVM判别器分析图像块是否为含车牌图像；</p>
<h2 id="2-2_OCR过程">2.2 OCR过程</h2><p>　　OCR作者是使用的MLP神经网络实现的，而神经网络/深度学习对于手写数字的识别率达到98%以上，这个领域可谓神经网络的应用之典范，所以作者选此也不足为奇。<br>　　此外，OpenCV本身集成了MLP库，所以这边集成使用起来也更为的方便。<br><a id="more"></a></p>
<h1 id="三、电表和身份证识别过程">三、电表和身份证识别过程</h1><p>　　整个工程是用Python实现的，主要是得益于OpenCV和Tesseract都有Python接口的封装，借助numpy做一些简单的科学变换，可以快速的搭建模型适配参数，至于后面工程实现可以直接用目标语言予以改写，这也是之前做NLP时候的思路。实现的思路和EasyPR类似，先提取出待识别目标区域，然后就直接调用Tesseract进行OCR操作了，这个过程中的图像处理参照了<a href="https://github.com/liuruoze/EasyPR" target="_blank" rel="external">EasyPR</a>和<a href="http://www.pyimagesearch.com/2014/03/10/building-pokedex-python-getting-started-step-1-6/" target="_blank" rel="external">Building a Pokedex in Python</a>这两个项目的思路。<br>　　OpenCV的手册整理的还是蛮赞的，C/C++/Python的接口都罗列出来了，所以看着EasyPR然后用Python实现也是极为轻松的事情。</p>
<h1 id="3-1_实现步骤如下:">3.1 实现步骤如下:</h1><p>　　(1) 图像归一化尺寸，因为后面很多的操作是基于大小的，如果这些参数如果输入图像差异过大，参数就会不适用；<br>　　(2) 灰度化图像，然后高斯模糊，计算水平方向Sobel特征子，用OTSU方法提取出二值化图像；<br>下面的图像右边是提取的Sobel特征子，而左边是使用OTSU得到的二值化图像。<br><img src="/post_images/images/201607/c0103665f0eb6adff65ad6a93ca7c348.png" alt="Sobel OTSU"><br>　　(3) 图像膨胀腐蚀操作，然后提取Contours连通区域；<br>　　(4) 对连通区域进行选择，比如依据形状、长宽度、长宽比等参数；<br><img src="/post_images/images/201607/24721cc850baff8a65908af92e22913d.png" alt="候选连通区域"><br>　　(5) 对每一个基本满足条件的连通区域，尝试使用Tesseract进行OCR识别，得出电表读数；<br>　　这里是跟EasyPR项目差异比较大的地方（当然我是简化了处理，所以最终效果还不好）：EasyPR使用SVM对待识别的图像片进行了判断，看是否是车牌图像，这是比较好的优化方式，节省计算量是小，主要是可以提高识别的准确度，一个乱七八糟的图像也可能识别出字符出来再判别就困难了，我是为了省事儿就没做；本文对原始图像进行了一个Transform，归一化成标准长宽矩形的待识别图像供Tesseract识别；图像二值化本文用了自适应OSTU方法，具体可以参照参考文献。另外，对小的图像块再优化操作也是比较容易的哦。<br><img src="/post_images/images/201607/ed4a0c7c149f18abc53d8c151e5ae21f.png" alt="处理后待识别的图像"></p>
<h1 id="3-2_其它问题">3.2 其它问题</h1><p>　　(1) 图像处理技术<br>　　之前说过，这个项目的最大难点在于使用OpenCV进行图片处理，图像处理的好，Tesseract的识别率还是挺高的，如果不是需要手写体等特殊字体，感觉完全可以直接用Tesseract自带的模型数据，比如<a href="http://vbridge.co.uk/2012/11/05/how-we-tuned-tesseract-to-perform-as-well-as-a-commercial-ocr-package/" target="_blank" rel="external">How we tuned Tesseract to perform as well as a commercial OCR package</a>就说，通过图像优化可以让Tesseract达到商用级别的效果。<br><img src="/post_images/images/201607/c3d723da34ea38338541ea752552e458.png" alt="残缺的区域"><br>　　(2) 稍加修改一下，就可以做成一个识别身份证的工具了。<br>　　自己手机拍的图像识别还可以，当然我不会上传自己的身份证给你测试，网上用别人的身份证照又不好，就用了个恶搞的美国总统图，感兴趣的话参数自己调去吧！<br><img src="/post_images/images/201607/989b9e6a195d2c5715f6a8b9dd08ccc1.png" alt="身份证识别"></p>
<p>项目地址：<a href="https://github.com/taozhijiang/dust_repos/tree/master/opencv_tesseract" target="_blank" rel="external">opencv_tesseract</a></p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="https://github.com/liuruoze/EasyPR" target="_blank" rel="external">EasyPR</a></li>
<li><a href="http://www.cnblogs.com/subconscious/p/3979988.html" target="_blank" rel="external">EasyPR–一个开源的中文车牌识别系统</a></li>
<li><a href="http://blog.csdn.net/jinshengtao/article/details/17883075" target="_blank" rel="external">《Mastering OpenCV 读书笔记系列》车牌识别</a></li>
<li><a href="http://www.pyimagesearch.com/2014/03/10/building-pokedex-python-getting-started-step-1-6/" target="_blank" rel="external">Building a Pokedex in Python</a></li>
<li><a href="https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality" target="_blank" rel="external">ImproveQuality</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[TCP链接的建立和关闭过程]]></title>
      <url>https://taozj.org/201607/construct-running-close-of-tcp.html</url>
      <content type="html"><![CDATA[<p>　　TCP/IP是现代互联网的基础，而TCP/IP三次握手似乎也是经久不衰的问题。这次就着抓包，把TCP/IP建立连接和拆除连接抓了个包，仔细看看到底是怎么回事儿。</p>
<p>　　Windows下面数据流量太多了，于是滚到Linux下面，命令行curl url后用Wireshark抓包，就得到了下面一张图（默认Wireshark显示的序列号是相对序列号）。<br><img src="/post_images/images/201607/a098ae3ff7d1b002631fc2c8a77a8214.png" alt="TCP-IP"><br><a id="more"></a></p>
<h1 id="一、三次握手(three-way_handshake)">一、三次握手(three-way handshake)</h1><p>　　(1) 客户端向服务端指明端口发送一个SYNC报文段，同时包含初始序列号C_ISN；<br>　　(2) 服务端返回包含客户端初始序列号S_ISN的SYNC报文段，同时包含确认序列号（C_ISN+1）；<br>　　(3) 客户端对服务器的初始序列号进行确认，确认序列号为S_ISN+1；</p>
<p>　　上面客户端第一个发送SYNC的，称为主动打开，而服务端是接收到SYNC然后再发送SYNC的，称为被动打开，建立连接发送SYNC的时候，必须选择一个初始ISN，这个值一般是一个32bit的计数器，每4ms自动加1。</p>
<p>　　下面这张图是《TCP/IP详解》给出的连接建立的过程图和状态图<br><img src="/post_images/images/201607/a1f67636d67dcd6a0e57784cb2de5647.jpg" alt="TCP-IP详解-1"></p>
<h1 id="二、数据传输">二、数据传输</h1><p>　　服务器和客户端双方不断的收发数据，由于是可靠连接，接收方会根据当前接收到的数据长度加上序列号，发送ACK给对端表示接收到了数据。比如第一幅图客户端向服务端发送GET请求长度是73，所以服务端ACK客户端的序列号是74；服务器返回数据之后，客户端ACK了。<br>　　下面给出一张更清晰的确认状态流程，注意ACK序列号的变化。<br><img src="/post_images/images/201607/132f36d668f5d21542a7deceab8222f9.png" alt="TCP-IP ACK"></p>
<h1 id="三、四次拆连">三、四次拆连</h1><p>　　终止连接需要四次交互，是因为TCP是全双工工作的，所以每个方向必须单独的进行关闭（称为半关闭），就是当一方完成了自己的数据发送任务后，就可以发送一个FIN来终止这个方向的连接，而此时另一方向还是可以进行数据传输的。<br>　　第一个发送FIN的称为主动关闭，而对应的一方称为被动关闭。<br>　　(1) 主动关闭方发送FIN报文段；<br>　　(2) 当对端接到FIN后，会发回一个ACK，且确认序列号为上次FIN序列号+1；</p>
<p>　　下面这张图是《TCP/IP详解》给出的拆除建立的过程图和状态图<br><img src="/post_images/images/201607/f4a73857b6589142f74cc4f116736138.jpg" alt="TCP-IP详解-2"></p>
<p>　　从上面的过程中，还可以看出的是，SYNC、FIN报文是占用1个序列号的（1个字节长度），而ACK是不占用序列号的。</p>
<h1 id="四、TCP/IP开发时候的“槽点”">四、TCP/IP开发时候的“槽点”</h1><p>　　(1) 前面看了TCP的半连接，所以服务端创建socket的时候还是用上SO_KEEPALIVE参数吧；<br>　　(2) 对于某些类型的网络应用，比如之前的代理程序，记得创建完socket之后设置TCP_NODELAY参数；</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/series/12438" target="_blank" rel="external">TCP/IP详解（中文版）</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于memcached原理实现的单机轻量级通用缓存库]]></title>
      <url>https://taozj.org/201607/design-and-impl-of-minicached-base-on-memcached.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　之前拜读过淘宝子柳的《淘宝技术这十年》之大作，深知缓存技术在系统优化中起着一个举足轻重的作用。无论是文件系统静态文件，数据库的访问，乃至网络数据的请求，只要是与内存访问速度相差较大的，都能显著减少IO操作，提高系统的响应速度和吞吐量。<br>　　在企业环境中，memcached和Redis算是最成熟的缓存解决方案，而国内外大型企业将其修改扩展成分布式结构的案例也是相当之很多，memcached出现的事件比较早，相对简单但是方案成熟，而Redis算是在memcached之后开发的后起之秀，改进优化了很多方面。</p>
<h1 id="二、memcached工作原理">二、memcached工作原理</h1><p>　　目前Redis还没有涉及了解过，memcached之前涉及过一点。memcached通常是作为一个单独服务进程启动的，监听来自TCP/UDP/Socket的请求，一般采用ascii协议进行通信。无可厚非，采用网络的方式进行进程间通信，其扩充简单灵活，但是总感觉相对于一般的单机小型程序来说，还是有点杀鸡用牛刀的感觉。如果能有一个微小型的通用缓存库，就可以联合编译链接到应用程序内部，进程间的通信效率提高了，部分数据都可以做到零拷贝了，数据通信协议、同步问题也都很好解决，岂不乐哉？<br><img src="/post_images/images/201607/e02d73dcff1fe8f2afdbeae75a8eacbf.jpg" alt="minicached"><br>　　当然，自己在一个小项目中，用的是libmicrohttpd接收POST请求数据，在不用默认的posthandler的时候，就需要自己手动申请内存，然后供接收数据使用。于是就通过建立一个postbuff的对象池，每当请求来的时候，就阻塞申请对象，用完之后在request_complete回调函数中标记为空闲，供下次使用，这样应该可以大大降低内存的碎片化。不过这个不通用，也没有缓存对象的生命周期、淘汰等特性，这也是本项目的实现目的。<br><a id="more"></a><br>　　如果使用set/get命令追踪一下memcached的执行流程，就会对memcached的内部工作流程清晰很多。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">➜  ~ telnet localhost 11211</div><div class="line">Trying 127.0.0.1...</div><div class="line">Connected to localhost.</div><div class="line">Escape character is <span class="string">'^]'</span>.</div><div class="line"><span class="built_in">set</span> keyname 0 3600 5</div><div class="line">taozj</div><div class="line">STORED</div><div class="line">get keyname</div><div class="line">VALUE keyname 0 5</div><div class="line">taozj</div><div class="line">END</div></pre></td></tr></table></figure></p>
<p>　　之前说过，由于memcached是用Libevent来侦听网络请求的事件的，整个项目很多的代码都是处理网络方面，以及用户命令行交互输入方面的。上面两条数据存取，追踪代码，可以归纳出如下的函数调用路径：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// set keyname 0 3600 5</span></div><div class="line">(<span class="number">1</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">try_read_command</span><span class="params">(conn *c)</span></span>;</div><div class="line">(<span class="number">2</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">process_command</span><span class="params">(conn *c, <span class="keyword">char</span> *command)</span></span>;</div><div class="line">(<span class="number">3</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">process_update_command</span><span class="params">(conn *c, <span class="keyword">token_t</span> *tokens, <span class="keyword">const</span> <span class="keyword">size_t</span> ntokens, <span class="keyword">int</span> comm, <span class="keyword">bool</span> handle_cas)</span></span>;</div><div class="line">(<span class="number">4</span>)<span class="function">item *<span class="title">item_alloc</span><span class="params">(<span class="keyword">char</span> *key, <span class="keyword">size_t</span> nkey, <span class="keyword">int</span> flags, <span class="keyword">rel_time_t</span> exptime, <span class="keyword">int</span> nbytes)</span></span>;</div><div class="line">(<span class="number">5</span>)<span class="function">item *<span class="title">do_item_alloc</span><span class="params">(<span class="keyword">char</span> *key, <span class="keyword">const</span> <span class="keyword">size_t</span> nkey, <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> flags, <span class="keyword">const</span> <span class="keyword">rel_time_t</span> exptime, <span class="keyword">const</span> <span class="keyword">int</span> nbytes, <span class="keyword">const</span> <span class="keyword">uint32_t</span> cur_hv)</span></span>;</div><div class="line"></div><div class="line"><span class="comment">// taozj</span></div><div class="line">(<span class="number">1</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">complete_nread</span><span class="params">(conn *c)</span></span>;</div><div class="line">(<span class="number">2</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">complete_nread_ascii</span><span class="params">(conn *c)</span></span>;</div><div class="line">(<span class="number">3</span>)<span class="function"><span class="keyword">enum</span> store_item_type <span class="title">do_store_item</span><span class="params">(item *it, <span class="keyword">int</span> comm, conn *c, <span class="keyword">const</span> <span class="keyword">uint32_t</span> hv)</span></span>;</div><div class="line"></div><div class="line"><span class="comment">// get keyname</span></div><div class="line">(<span class="number">1</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">try_read_command</span><span class="params">(conn *c)</span></span>;</div><div class="line">(<span class="number">2</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">process_command</span><span class="params">(conn *c, <span class="keyword">char</span> *command)</span></span>;</div><div class="line">(<span class="number">3</span>)<span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">void</span> <span class="title">process_get_command</span><span class="params">(conn *c, <span class="keyword">token_t</span> *tokens, <span class="keyword">size_t</span> ntokens, <span class="keyword">bool</span> return_cas)</span></span>;</div><div class="line">(<span class="number">4</span>)<span class="function">item *<span class="title">item_get</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *key, <span class="keyword">const</span> <span class="keyword">size_t</span> nkey, conn *c)</span></span>;</div><div class="line">(<span class="number">5</span>)<span class="function">item *<span class="title">do_item_get</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *key, <span class="keyword">const</span> <span class="keyword">size_t</span> nkey, <span class="keyword">const</span> <span class="keyword">uint32_t</span> hv, conn *c)</span></span>;</div></pre></td></tr></table></figure></p>
<h1 id="三、minicached设计实现">三、minicached设计实现</h1><p>　　对于实现单机使用的通用内存缓存库的设计需求，上面的命令行处理方面不需要关注，其实底层就是item_alloc、do_store_item、do_item_get这几个函数的作用。缓存可以实现的很简单，也可以做的很精妙复杂。虽然不如Redis现在这么红火，但memcached屹立这么久，还是有很多值得感受和借鉴的地方，那就循着memcached的路子，先慢慢模仿吧。</p>
<h2 id="3-1_内存分配器_slab">3.1 内存分配器 slab</h2><p>　　在Linux内核中slab/slub比较常见。查看了下资料，slab最早是Solaris开发出来的，最初产生的缘由是他们发现，在申请对象的时候，对象的初始化(构造)和销毁(析构)的时间很长，所以开发出slab分配器来缓存对象使用的。而Linux中后来移植过来，但其主要是用于防止内存碎片化，降低操作系统内存回收整理的负担的。<br>　　所以，如果在缓存直接用malloc和free，功能上是没有什么问题的，而且实现也会非常简便容易，但是不断反复malloc和free带来的内存碎片，对长久运行的服务端是很不利的。而slab分配器等于实现了一套自己的内存管理，涉及到对象的分配、回收、同步等操作，自然也大大增加了开发调试的难度了。</p>
<h2 id="3-2_元素查找">3.2 元素查找</h2><p>　　通常快速查找方式有hash方式和二叉树方式查找。在对象比较多的时候hash有着最佳的查找性能，而二叉树在数目有限的元素中也有着很好的性能，这也是这货在当前Linux内核中被大量使用的原因。在memcached中，采用的是hash+链表的典型数据结构，在hash条目少的时候，产生碰撞的元素需要在链表中查询，效率自然会降低，所以memcached设计在一定条件下，会自动进行hash的扩容以保证hash查找的效率。暂时我只用了固定的2^10的hash容量，大多数情况应该都不会是什么严重问题吧。</p>
<h2 id="3-3_元素生命时间">3.3 元素生命时间</h2><p>　　memcached的元素在创建后可以指定其expire生命周期，是一种lazy的模式：就是不会主动扫描查看哪些元素是否过期，而是在(1)访问元素的时候，检查该元素是否超过了生命周期，如果超过了会释放掉；(2)分配新对象而遇到空闲资源紧张的时候，会扫描对象列表，找出过期的对象删除以释放资源。<br>　　LRU是管理了一个链表，在link、store及update操作的时候，会更新对象的time参数，并将其从LRU列表中先删除后再插入到头部，表示最近访问了。当后续申请新的slab对象而不得的时候，会考虑从链表的尾部删除最没被访问的元素用以满足新对象的需求。</p>
<h2 id="3-4_接口操作支持">3.4 接口操作支持</h2><p>　　由于是单机的操作，所以数据通信格式会灵活很多，不用考虑字节序、主机间的ascii通信协议等，而key也可以任何的数据类型，只需要在hash计算的时候传递其对应地址和长度就可以了。<br>　　主要支持的缓存操作接口有：<br>　　(1) new：   创建对象，从slab中取出ITEM_SLABBED空闲对象，对象成为ITEM_PENDING的悬垂状态；<br>　　(2) link：  将对象添加到缓存，变为ITEM_LINKED状态；<br>　　(3) unlink：从缓存中撤出，成为ITEM_PENDING的悬垂状态；<br>　　(4) store： 保存或者更新缓存中指定key对于的value，此时如果对象为ITEM_PENDING状态，则挂入链表中，否则就直接更新其值。由于新的值长度可能大于原来分配slab容量大小，所以这里可能会有slab重新分配的过程；<br>　　(5) remove：释放被unlink对象的资源，对象重新变为ITEM_SLABBED空闲状态；<br>　　(6) update：更新对象的访问时间戳，主要关系涉及到LRU淘汰计算；<br>　　(7) destroy: 删除所有的缓存，重新初始化；<br>　　算是基本覆盖满足了的缓存操作需求了。</p>
<h2 id="3-5_新对象请求的流程">3.5 新对象请求的流程</h2><p>　　内存就是一个空间换时间的操作，理论上内存越大越好，但现实是不可能的。前面说过，缓存对象是通过slab机制管理的，所以请求新对象实际就是请求空闲(ITEM_SLABBED)的slab对象。根据当前slab状态和系统内存状态，请求机制如下：<br>　　(1) 如果请求对应的slab_class的slots上有空闲对象，那么取出后直接返回；<br>　　(2) 否则，遍历当前slab_class对应的LRU链表，查看是否有expired，如果有就释放掉它，然后返回被释放的空闲对象；<br>　　(3) 否则，如果没有超过内存使用限制，则申请一块大(perslab*size)的内存blk，然后创建perslab个空闲的对象，并加入到空闲链表中，取出一个空闲对象返回；<br>　　(4) 否则，遍历其余的slab_class，看是否可以整理已有对象，释放出blk内存供分配使用，如果释放成功就转入(3)步；<br>　　(5) 否则，查看本slab_class的LRU链表，释放最不常用的对象，然后将释放得到的空闲对象返回；<br>　　(6) 否则，返回NULL表示失败。</p>
<h2 id="3-6_线程安全">3.6 线程安全</h2><p>　　memcached本身是线程安全的，其后端用的线程池模型工作的，所以这点是毫无疑问的，与此同时还提供了CAS机制，保证了某些修改在多个进程/主机间也类似原子操作的。缓存中某个对象同时处于hash表，LRU队列，slab队列中，正所谓加锁容易解锁难，对象的申请，释放，移动等操作交迭，很容易就会有死锁的隐患。为此，memcached为hash容器每个对象分配了一个锁，用于hash中元素的增删，修改操作，为每个slab_class生成一个锁，用于LRU队列的访问和修改操作，而对于slabs本身的操作，则用了一个全局的大颗粒锁来保护，这肯定会影响性能，但却是也没想出什么简洁优化的好办法。不过想想也是，缓存最适宜的工作状态是读多修改少才算好的么，如果程序运行一段时间后仍然频繁有slab的修改操作，是不是考虑要增加内存了。<br>　　多个锁的协同作用，其“黄金法则”就是：加锁的顺序要一致，否则就会导致死锁的发生，同时对于非关键部分(比如资源回收)，采用try_lock非阻塞的方式获取锁，增加效率的同时也降低了死锁的概率（我觉得不会死锁，谁能确信地告诉我）。</p>
<h1 id="四、结语">四、结语</h1><p>　　虽然memcached在众多流行的开源项目中算是比较简单的，但是如果需要真正了解，还是需要一定的时间和精力。自己的minicached走着memcached的路子，目前算是简单搭建了出来，但是要稳定可靠运行，还需要大量的测试和验证。<br>　　做他的原因，是本人感觉到确实是一个很有意义的工具库，当然也可能自己重新造轮子了。希望后续能不断完善，在Redis或者其他项目中好的东西也能扩展引入进来。</p>
<div class="github-widget" data-repo="taozhijiang/minicached"></div>

<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/" target="_blank" rel="external">memcache internals</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Libevent学习笔记（三）：内部实现原理初探]]></title>
      <url>https://taozj.org/201606/learn-note-of-libevent-(3)-internel-impl-and-framework.html</url>
      <content type="html"><![CDATA[<p>　　Libevent确实方便了开发人员，对于定时器、信号处理、关心的文件或者套接字，只需要挂载到event_base上面，设置好对应的回调函数和参数就可以了，当对应的事件发生时，Libevent会自动调度相应的回调函数进行处理。<br>　　本文就按照之前在<a href="https://github.com/taozhijiang/sshinner" target="_blank" rel="external">sshinner</a>中使用Libevent的过程，以这些接口函数作为突破点，沿着代码走了一朝，尝试探究一下Libevent的内部工作流程是怎样的。由于本人能力有限，有些东西可能不够详尽或者准确，还望不吝指出。<br><img src="/post_images/images/201605/4ba4cf01515ad01fd5f9403f6460d578.png" alt="libevent"></p>
<h1 id="一、创建event_base">一、创建event_base</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> event_base * main_base = event_base_new(<span class="keyword">void</span>);</div></pre></td></tr></table></figure>
<p>　　主要是根据参数，创建event_base结构体，然后初始化一些数据，如果对默认的参数不满意需要个性化配置的话，可以先创建event_config，然后调用event_base_new_with_config来创建。其中在eventops这个变量中，按照优先级顺序排序罗列了常见的IO复用模型，比如kqueue、epoll、poll、select等，由于Libevent是跨平台的，这些IO复用在有些平台可能是不可用的，同时你还可以在event_config中选择过滤某些不想要的模型。<br>　　当选定了某个IO复用模型之后，其操作结构eventop就被添加到base-&gt;evsel中，然后调用其特定的init初始化函数。这些操作跟文件系统file_operations结构极为的类似。<br>　　那我们接着跟下去，看看大名鼎鼎的epoll类提供了哪些操作吧：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">const</span> <span class="keyword">struct</span> eventop epollops = &#123;</div><div class="line">    <span class="string">"epoll"</span>,</div><div class="line">    epoll_init,</div><div class="line">    epoll_nochangelist_add,</div><div class="line">    epoll_nochangelist_del,</div><div class="line">    epoll_dispatch,</div><div class="line">    epoll_dealloc,</div><div class="line">    <span class="number">1</span>, <span class="comment">/* need reinit */</span></div><div class="line">    EV_FEATURE_ET|EV_FEATURE_O1|EV_FEATURE_EARLY_CLOSE,</div><div class="line">    <span class="number">0</span></div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　在初始化函数epoll_init当中，基本就类似epoll使用时候标准化的准备工作：首先调用epoll_create创建epfd，然后预先创建INITIAL_NEVENT(32)个空间用于存放epoll_event，如果使用了timerfd，则再调用timerfd_create创建对应的timerfd。最后这些fd以及epoll_event都存放在struct epollop当中，然后作为epoll_init函数的返回保存在base-&gt;evbase上。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> epollop &#123;</div><div class="line">    <span class="keyword">struct</span> epoll_event *events;    <span class="comment">//数组</span></div><div class="line">    <span class="keyword">int</span> nevents;</div><div class="line">    <span class="keyword">int</span> epfd;</div><div class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> USING_TIMERFD</span></div><div class="line">    <span class="keyword">int</span> timerfd;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　在创建event_base的最后，还调用了event_base_priority_init进行了一个初始化操作，如果有多个优先级，就有对应的多个等待队列挂靠在base-&gt;activequeues上面，而base-&gt;nactivequeues记录了优先级的数目。<br><a id="more"></a></p>
<h1 id="二、创建listen套接字，并建立connect事件侦听">二、创建listen套接字，并建立connect事件侦听</h1><h2 id="2-1_基本过程">2.1 基本过程</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">listener = evconnlistener_new_bind(srvopt.main_base, accept_conn_cb, <span class="literal">NULL</span>,</div><div class="line">            LEV_OPT_CLOSE_ON_FREE|LEV_OPT_REUSEABLE, <span class="number">-1</span><span class="comment">/*backlog*/</span>,</div><div class="line">            (<span class="keyword">struct</span> sockaddr*)&amp;<span class="built_in">sin</span>, <span class="keyword">sizeof</span>(<span class="built_in">sin</span>));</div></pre></td></tr></table></figure>
<p>　　这个算是个简化版的函数，你可以自己先手动建立和绑定socket，然后再调用evconnlistener_new建立connect事件侦听。这个函数给socket设置了一个高大上的符号SO_KEEPALIVE（SO_KEEPALIVE 保持连接检测对方主机是否崩溃，避免服务器永远阻塞于TCP连接的输入），SOCKET开发还是有很多参数的，比如之前sshinner网络一直出问题，消息不能及时的被发送接收，最后跟踪shadowsockets-libev发现，是要给socket添加TCP_NODELAY参数，问题才得以解决。<br>　　在evconnlistener_new函数中，首先调用listen，然后分配evconnlistener_event这个数据结构，base作为struct evconnlistener类型传递给用户空间，而listener主要作为内部隐藏的数据结构，为通用的struct event数据类型。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> evconnlistener_event &#123;</div><div class="line">    <span class="keyword">struct</span> evconnlistener base;</div><div class="line">    <span class="keyword">struct</span> event listener;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="keyword">struct</span> evconnlistener &#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">struct</span> evconnlistener_ops *ops;</div><div class="line">    <span class="keyword">void</span> *lock;</div><div class="line">    evconnlistener_cb cb;</div><div class="line">    evconnlistener_errorcb errorcb;</div><div class="line">    <span class="keyword">void</span> *user_data;</div><div class="line">    <span class="keyword">unsigned</span> flags;</div><div class="line">    <span class="keyword">short</span> refcnt;</div><div class="line">    <span class="keyword">int</span> accept4_flags;</div><div class="line">    <span class="keyword">unsigned</span> enabled : <span class="number">1</span>;</div><div class="line">&#125;;</div><div class="line"><span class="keyword">struct</span> event &#123;</div><div class="line">    <span class="keyword">struct</span> event_callback ev_evcallback;</div><div class="line">    <span class="comment">/* for managing timeouts */</span></div><div class="line">    <span class="keyword">union</span> &#123;</div><div class="line">        TAILQ_ENTRY(event) ev_next_with_common_timeout;</div><div class="line">        <span class="keyword">int</span> min_heap_idx;</div><div class="line">    &#125; ev_timeout_pos;</div><div class="line">    <span class="keyword">evutil_socket_t</span> ev_fd;</div><div class="line">    <span class="keyword">struct</span> event_base *ev_base;</div><div class="line"> </div><div class="line">    <span class="keyword">union</span> &#123;</div><div class="line">        <span class="comment">/* used for io events */</span></div><div class="line">        <span class="keyword">struct</span> &#123;</div><div class="line">            LIST_ENTRY (event) ev_io_next;</div><div class="line">            <span class="keyword">struct</span> timeval ev_timeout;</div><div class="line">        &#125; ev_io;</div><div class="line"> </div><div class="line">        <span class="comment">/* used by signal events */</span></div><div class="line">        <span class="keyword">struct</span> &#123;</div><div class="line">            LIST_ENTRY (event) ev_signal_next;</div><div class="line">            <span class="keyword">short</span> ev_ncalls;</div><div class="line">            <span class="comment">/* Allows deletes in callback */</span></div><div class="line">            <span class="keyword">short</span> *ev_pncalls;</div><div class="line">        &#125; ev_signal;</div><div class="line">    &#125; ev_;</div><div class="line"> </div><div class="line">    <span class="keyword">short</span> ev_events;</div><div class="line">    <span class="keyword">short</span> ev_res;        <span class="comment">/* result passed to event callback */</span></div><div class="line">    <span class="keyword">struct</span> timeval ev_timeout;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　通过上面的数据结构可以清晰的发现，调用evconnlistener_new_bind函数作为参数提供的回调函数和参数，都被赋值给了evconnlistener_event-&gt;base.cb和base.user_data上面。接下来调用了两个比较重要的函数：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">event_assign(&amp;lev-&gt;listener, base, fd, EV_READ|EV_PERSIST,</div><div class="line">        listener_read_cb, lev);</div><div class="line">evconnlistener_enable(&amp;lev-&gt;base);</div></pre></td></tr></table></figure></p>
<p>　　evconnlistener_enable(&amp;lev-&gt;base)通过追根述源是调用了event_listener_enable，最后调用了event_add(&amp;lev_e-&gt;listener, NULL)。而event_assign和event_add都是比较重要的函数，event_assign类似于event_new的作用，只不过参数是一个已经初始化了的struct event，而event_add则是把event由initialized状态变成pending状态，以便开始接收事件，其实后面可以发现，bufferevent_enable等接口，底层也是调用的event_add实现的。<br>　　接下来把上面这两个函数慢慢品读。</p>
<h2 id="2-2_event_assign调用">2.2 event_assign调用</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">event_assign(&amp;lev-&gt;listener, base, fd, EV_READ|EV_PERSIST,</div><div class="line">        listener_read_cb, lev);</div></pre></td></tr></table></figure>
<p>　　初看上面比较奇怪，在evconnlistener_new这个函数的上半部分已经设置了一个base.cb和base.user_data了，怎么下面又调用一个event_assign来设置一个listener_read_cb回调呢？其实上面是用户提供的callback和args，但是这并没有直接跟某个事件相关联，而下面的event_assign却是设置了&amp;lev-&gt;listener(标准的struct event类型)为固定的listener_read_cb回调函数，当发生了EV_READ就会被自动调用。然后在listener_read_cb中，我们发现：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cb = lev-&gt;cb;    <span class="comment">//</span></div><div class="line">user_data = lev-&gt;user_data;    <span class="comment">//</span></div><div class="line">cb(lev, new_fd, (<span class="keyword">struct</span> sockaddr*)&amp;ss, (<span class="keyword">int</span>)socklen,  user_data);</div><div class="line">errorcb(lev, user_data);</div></pre></td></tr></table></figure></p>
<p>　　所以说，其实Libevent内部根本没有什么诸如LISTEN的事件，还是用的标准EV_READ(因为最最底层的epoll异步只能监听read/write/except事件)，只是做了个封装，当连接之后激活EV_READ(为什么呢？为什么呢？)的回调函数，而出错了就调用err_callback函数，所以accept_conn_cb实际是被手动调用的。</p>
<h2 id="2-3_event_add调用">2.3 event_add调用</h2><p>　　evconnlistener_enable的调用被翻译到event_add函数，其实不光光是这里，后面最常用的bufferevent_enable这类函数，其实也是翻译到底层的event_add函数(event_add_nolock_)上面。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> evconnlistener_event *lev_e =</div><div class="line">        EVUTIL_UPCAST(lev, <span class="keyword">struct</span> evconnlistener_event, base);    <span class="comment">//这个宏比较好看</span></div><div class="line">    <span class="keyword">return</span> event_add(&amp;lev_e-&gt;listener, <span class="literal">NULL</span>);</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> EVUTIL_UPCAST(ptr, type, field)                \</span></div><div class="line">    ((type *)(((char*)(ptr)) - evutil_offsetof(type, field)))</div></pre></td></tr></table></figure></p>
<p>　　event_add有两个参数，后面一个参数是struct timeval的超时参数，如果是NULL就表示无限期等待，这里先就不考虑这种情况。其中最主要做的事情就是调用evmap_io_add_/evmap_signal_add_函数将事件加入到base当中：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 对照上面，返回-1 error, 0 没有实际操作, 1 真实添加了</span></div><div class="line">res = evmap_io_add_(base, ev-&gt;ev_fd, ev);</div><div class="line">res = evmap_signal_add_(base, (<span class="keyword">int</span>)ev-&gt;ev_fd, ev);</div><div class="line"></div><div class="line"><span class="comment">// 上面函数的核心操作</span></div><div class="line">GET_IO_SLOT_AND_CTOR(ctx, io, fd, evmap_io, evmap_io_init,</div><div class="line">                         evsel-&gt;fdinfo_len);</div><div class="line">evsel-&gt;add(base, ev-&gt;ev_fd,</div><div class="line">            old, (ev-&gt;ev_events &amp; EV_ET) | res, extra);</div></pre></td></tr></table></figure></p>
<p>　　首先，由于Libevent的设计是跨平台的，而Windows和Linux对socket和fd的表达和处理方式不同，GET_IO_SLOT_AND_CTOR的行为也有差异：Windows使用的是hashtable维护着struct event_map_entry结构，而Linux平台就直接是用的指针数组（数组，元素类型是指针），用fd作为偏移来索引，指针指向的结构按需分配，十分的简洁高效。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* Used to map signal numbers to a list of events.  If EVMAP_USE_HT is not</span></div><div class="line">   defined, this structure is also used as event_io_map, which maps fds to a</div><div class="line">   list of events.</div><div class="line">*/</div><div class="line"><span class="keyword">struct</span> event_signal_map &#123;</div><div class="line">    <span class="comment">/* An array of evmap_io * or of evmap_signal *; empty entries are</span></div><div class="line">     * set to NULL. */</div><div class="line">    <span class="keyword">void</span> **entries;</div><div class="line">    <span class="comment">/* The number of entries available in entries */</span></div><div class="line">    <span class="keyword">int</span> nentries;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="comment">/** Mapping from file descriptors to enabled (added) events */</span></div><div class="line"><span class="keyword">struct</span> event_io_map io;</div><div class="line"><span class="comment">/** Mapping from signal numbers to enabled (added) events. */</span></div><div class="line"><span class="keyword">struct</span> event_signal_map sigmap;</div></pre></td></tr></table></figure></p>
<p>　　在每一个event_base结构体中，都定义了struct event_signal_map类型的两个成员io和sigmap(Linux平台)，用于信号量和FD与events之间的事件映射。然后看GET_IO_SLOT_AND_CTOR(GET_SIGNAL_SLOT_AND_CTOR)这个宏，查询或者创建fd对应的struct evmap_io对象ctx，将当前的事件和之前的事件进行合并，并调用evsel-&gt;add进行更新(最终反应到底层epoll上面就是epoll_ctl命令进行操作了)，并把当前的event结构体插入到前面找到的ctx-&gt;events链表当中。</p>
<h1 id="三、建立主事件循环">三、建立主事件循环</h1><p>　　无论是主线程，还是对于每个线程池用自己的event_base，最终都会调用这个函数作为主循环进行事件处理。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">event_base_loop(main_base, <span class="number">0</span>);</div></pre></td></tr></table></figure></p>
<p>　　先不考虑那些FLAG(控制何时推出啊啥的)，在event_base_loop主要做的事情是：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* F1 */</span> event_queue_make_later_events_active(base);</div><div class="line"><span class="comment">/* F2 */</span> res = evsel-&gt;dispatch(base, tv_p);</div><div class="line"><span class="comment">/* F3 */</span> timeout_process(base);</div></pre></td></tr></table></figure></p>
<p>　　F1的函数主要是在Libevent中引用了Deferred Callback机制，操作上就是从event_base的active_later_queue队列中将事件取出来，然后添加到activequeues[evcb-&gt;evcb_pri]对应优先级队列上面。<br>　　F2对于epoll类型，就是调用epoll_dispatch函数：首先调用epoll_apply_changes(base);对event_base-&gt;changelist上面挂靠的所有对fd的事件修改都执行底层修改使之生效；然后用res = epoll_wait(epollop-&gt;epfd, events, epollop-&gt;nevents, timeout);获取被激活的事件；对获取到的每个fd的事件，提取被激活的事件类型，然后调用evmap_io_active_(base, events[i].data.fd, ev | EV_ET);函数处理。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">evmap_io_active_(<span class="keyword">struct</span> event_base *base, <span class="keyword">evutil_socket_t</span> fd, <span class="keyword">short</span> events)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">struct</span> event_io_map *io = &amp;base-&gt;io;</div><div class="line">    <span class="keyword">struct</span> evmap_io *ctx;</div><div class="line">    <span class="keyword">struct</span> event *ev;</div><div class="line"></div><div class="line">    GET_IO_SLOT(ctx, io, fd, evmap_io);</div><div class="line"></div><div class="line">    LIST_FOREACH(ev, &amp;ctx-&gt;events, ev_io_next) &#123;</div><div class="line">        <span class="keyword">if</span> (ev-&gt;ev_events &amp; events)</div><div class="line">            event_active_nolock_(ev, ev-&gt;ev_events &amp; events, <span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　执行的结果就是，这个fd对应的evmap_io上的所有事件，以及Deferred Callback事件，都被收集添加到event_base-&gt;activequeues[evcb-&gt;evcb_pri]队列中去。<br>于是乎，最后的好戏就是：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (N_ACTIVE_CALLBACKS(base)) &#123;</div><div class="line">       <span class="keyword">int</span> n = event_process_active(base);</div></pre></td></tr></table></figure></p>
<p>　　在event_process_active中调用了event_process_active_single_queue。当然作者考虑的细节还是比较细腻的：如果当前被调度的活动事件过多，就考虑在timer和maxcb两个维度上限制本轮的事件处理量，而在event_process_active_single_queue中，会不断从事件链表中取出事件处理（包括执行对应的回调函数）。从实现方式上看来，按照优先级从高到低的顺序，每一轮只处理一个最高优先级非空事件队列中的事件，然后就返回了。这样看来，如果高优先级的事件太多太活跃，那么低优先级的事件还是会有被饿死的风险。</p>
<h1 id="四、基于bufferevent的普通socket读写事件">四、基于bufferevent的普通socket读写事件</h1><p>　　bufferevent使得网络的开发变的很方便，无论是从事件还是底层的evbuffer都提供了一套丰富灵活的接口。但是需要注意的是bufferevent目前只能用于TCP连接的类型，对于UDP只能手动建立struct event事件，然后设置事件和回调函数了，而且在回调函数中，一般也只能调用sendto/recvfrom等操作接口。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> event_base *base = evconnlistener_get_base(listener);</div><div class="line"><span class="keyword">struct</span> bufferevent *bev = </div><div class="line">bufferevent_socket_new(base, fd, <span class="number">0</span> <span class="comment">/*BEV_OPT_CLOSE_ON_FREE*/</span>);</div><div class="line">bufferevent_setcb(bev, bufferread_cb, <span class="literal">NULL</span>, bufferevent_cb, <span class="literal">NULL</span>);</div><div class="line">bufferevent_enable(bev, EV_READ|EV_WRITE);</div></pre></td></tr></table></figure></p>
<p>　　上面算是在网络开发中用的最频繁的了，比如在listener的connection回调函数中，接收到一个新的套接字fd，那么就对这个套接字设置bufferevent事件，设置对应的回调函数。<br>在bufferevent_socket_new函数中：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> bufferevent_private *bufev_p;</div><div class="line"><span class="keyword">struct</span> bufferevent *bufev;</div><div class="line"></div><div class="line">bufferevent_init_common_(bufev_p, base, &amp;bufferevent_ops_socket, options);</div><div class="line">bufev_p-&gt;bev;</div><div class="line"></div><div class="line">event_assign(&amp;bufev-&gt;ev_read, bufev-&gt;ev_base, fd,</div><div class="line">    EV_READ|EV_PERSIST|EV_FINALIZE, bufferevent_readcb, bufev);</div><div class="line">event_assign(&amp;bufev-&gt;ev_write, bufev-&gt;ev_base, fd,</div><div class="line">    EV_WRITE|EV_PERSIST|EV_FINALIZE, bufferevent_writecb, bufev);</div><div class="line">evbuffer_add_cb(bufev-&gt;output, bufferevent_socket_outbuf_cb, bufev);</div><div class="line"> </div><div class="line">evbuffer_freeze(bufev-&gt;input, <span class="number">0</span>);</div><div class="line">evbuffer_freeze(bufev-&gt;output, <span class="number">1</span>);</div></pre></td></tr></table></figure></p>
<p>　　跟之前的struct evconnlistener_event一样，这里返回给用户空间可用的struct bufferevent也是struct bufferevent_private的一部分，不过相比listener的单个struct event，这里的bufferevent内容成员要复杂的多，其中我们比较熟悉的有：input、output两个evbuffer，可以调用evbuffer的族函数进行相关的高级处理；此外还设置了be_ops为bufferevent_ops_socket，而enabled使能的时间中默认为EV_WRITE，所以EV_READ需要手动enable；接下来设置bufev_private-&gt;deferred的callback回调函数和调用参数为bufferevent_run_deferred_callbacks_locked和bufev_private。<br>　　最后的两个event_assign分别将ev_read和ev_write两个event的回调函数设置为了bufferevent_readcb/bufferevent_writecb。由于EV_WRITE默认是使能的，所以还调用了evbuffer_add_cb设置其默认的回调函数为bufferevent_socket_outbuf_cb。为了安全，还将两个evbuffer先冻结起来，准备工作还未就绪，所以此时还不允许数据传输。<br>　　其实，正如上面的例子，对于bufferevent，通常的写操作就使用其默认的callback就可以了，实际开发当中我们最关心的是读事件，因为我们要接收数据处理数据（即便只是转发操作），而写数据只要准备好要发送的数据，底层的写就让其自动处理就可以了。<br>　　说到底，这里的bufferevent和evconnlistener类似，也是采用了两段式设计：在bufferevent中的ev_read/write被激活调度的时候，其自动执行的是bufferevent_readcb/writecb函数，在这些标准函数中会做一些的预先处理操作，比如evbuffer_read/evbuffer_write_atmost的读写，到最后通过bufferevent_trigger_nolock_调用用户设定的回调函数。然后你可能感兴趣EV_WRITE默认的bufferevent_socket_outbuf_cb干了啥？查看其代码，其实也就是：检查确保当前ev_write是否是pending的，如果不是就bufferevent_add_event_变成pending状态就好了。我们知道，epoll事件最底层是操作系统直接驱动的，所以如果底层驱动发现socket是可写的，就可以调度底层发送数据了，因此这个函数实际上其实啥都没做。<br>　　最后的bufferevent_enable(bev, EV_READ|EV_WRITE);跟之前的evconnlistener_enable也大差不差的，最终都是通过be_socket_enable-&gt;bufferevent_add_event_-&gt;event_add方式，将event加入到对应的event_base上面去，使之变为pending状态。</p>
<h1 id="五、小结">五、小结</h1><p>　　Libevent的代码实现的十分精妙，注释也比较多，当然也有一些参数和符号尚无注释，自己暂时也没能意会，本文尚有很多需要补充之处。<br>　　哎，想想自己epoll+线程池两个c文件搞定，而Libevent把这个做的如此之精妙（且尚无线程池模型），不得不由衷的让人敬佩：牛人怎么就那么牛呢？这也使得我坚信，初学者和企业应用之间总隔着一条沟沟需要跨越，如果没有项目带着你走，那就可以靠读这些开源项目的代码来弥合，希望大家都能愉快的玩耍和成长！</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Libevent转发的内网端口暴露（四）：添加DNS代理的功能]]></title>
      <url>https://taozj.org/201606/port-expose-based-on-libevent-(4)-dns-proxy-support.html</url>
      <content type="html"><![CDATA[<p>　　之前所说，这应当是这个项目最后一个功能了，到此我觉得个人PC端上网的解决方案都弄完了。<br><img src="/post_images/images/201606/3835a8737168091573fc0932cae0dd96.jpg" alt="sshinner"></p>
<p>　　其实，国内上网环境可以用极度恶劣来形容：DNS投毒、域名劫持、网页串改等，这种环境如果在不走代理的情况下想安心点上网，那么干净的DNS和HTTPS算是可以在基本面上得到一些保证。其实国家一直号召宽带中国、光纤入户，但实际让大家的感受就是上网变得越来越慢，越来越难。<br>　　之前个人上网的DNS使用的是<a href="https://github.com/jedisct1/dnscrypt-proxy" target="_blank" rel="external">dnscrypt-proxy</a>的解决方法，在Linux和Windows平台下都可用，其原理就是在本地建立DNS代理服务器侦听#53号端口，然后把本机的DNS服务器设置成127.0.0.1，代理服务一旦接受到DNS解析请求，就会向远程主机请求解析结果，然后返回给本地。毫无疑问，这个过程中的数据是加密传输的(用的叫什么libsodium库，不过寡人还没怎么听说过)，以此保证你得到的DNS解析结果是干净的。当然个人感觉这也会有缺点，比如大流量网站都会有CDN做优化，根据你访问地址帮你解析到更快的服务器IP，而DNS代理的方式估计享受不到这种优化吧，其利弊全靠个人取舍。<br>　　然后我又有想法了:其实大部分人用8.8.8.8，8.8.4.4这种国外知名的DNS服务器就可以了，但是你在国内直接这样设置到电脑上，由于UDP协议的特性，解析速度和返回的结果都得不到保证。为此，那么我侦听本地#53端口，把本地所有DNS请求的UDP数据包内容进行封装加密发送到国外服务器，远端服务器解析后再将结果加密返回回来，本地代理程序解密后再转成UDP包返回给客户端不就行了？？？<br><a id="more"></a><br>　　好，这个逻辑十分简单，流程也十分清晰，在此简单描述一下：<br>　　1. SRV先启动，CLIENT_DAEMON启动后连接SRV进行认证；<br>　　2. CLIENT_DAEMON建立UDP套接字并绑定侦听本地DNS请求端口(#53是特权端口，需要root权限)，然后建立对应struct event EV_READ事件侦听daemon_ev；<br>　　3. CLIENT_DAEMON连接SRV，发送HD_CMD_DNS请求，SRV将其分配到对应的线程池处理；<br>　　4. 线程池处理请求，建立对应的bufferevent，同时建立UDP socket，并建立对应的struct event EV_READ事件侦听srv_ev，然后向CLIENT_DAEMON发送HD_CMD_DNS_ACT激活；<br>　　5. 客户端收到DNS解析请求后，记录PORT和RequestID对应关系，然后将请求加密后用TCP发送到SRV；SRV接受到数据后，向DNS服务器(8.8.8.8:53)发送该请求；srv_ev异步接收到数据后，加密后返回给CLIENT_DAEMON；<br>　　6. CLIENT_DAEMON解密数据，获取头部的RequestID，通过查表找到本地的请求端口，将数据通过UDP方式返回；</p>
<p>　　此外，在实现上，需要几点说明的是:<br>　　1. 无论国外的互联网环境多么的好，我们都假定DNS的解析是耗费时间的，所以这个过程必定是要异步处理的；<br>　　2. 虽然Libevent含有evdns的库，但是用处跟我们是不一样的，我们只需要转发解析结果就好了，而evdns对结果进行了解析和处理（还记得sockets5代理那里描述的么），所以此处不会用到这个模块；<br>　　3. 当初DNS设计选用UDP可能就是效率方面的考虑，所以这里在DAEMON和SRV之间建立一个专用的TCP长链接，TCP三次握手对于一个DNS请求来说开销有点大，而且如果像之前sockets5代理那样每个请求都拆建一次，那效率肯定会惨不忍睹的；<br>　　4. UDP通信简单的，但是程序处理的流程就复杂一些。目前在客户端记录requestID/Port的方式进行转发的。然后在参考文献中还看到一个有意思的东西，最初的BIND和MS Windows NT都是用的可预测的requestID，每次请求都是之前的requestID+1，那么网络嗅探就可以截获DNS请求或返回包，获取requestID然后就可以预测接下来的requestID进行攻击了（由于DNS是分布式的，所以这种攻击不仅针对客户端，还可以针对本地DNS服务器攻击）。不过现在的requestID都是随机的，下面记录的结果也说明了这一点。目前我这种简单的requestID-Port映射单机没什么问题，如果扩展到局域网为其它多主机做DNS代理，还需要额外的工作才行。</p>
<p>　　运行效果图：<br>　　果真现在requestID是随机产生的了<br><img src="/post_images/images/201606/2428639233aec89ae608bcab0a988970.png" alt="端口记录"></p>
<p>　　客户计算机请求DNS解析的效果<br><img src="/post_images/images/201606/f0cfd1adbb024df123b0f98d7bfffcd6.png" alt="运行效果图"></p>
<p><div class="github-widget" data-repo="taozhijiang/sshinner"></div><br>　　暂时写的比较乱，欢迎指正！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://bak.spc.org/dms/archive/dns_id_attack.txt" target="_blank" rel="external">dns_id_attack</a></li>
<li><a href="http://www.simpledns.com/help/v52/index.html?ht_secure.htm" target="_blank" rel="external">How to secure your server</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[读《清醒思考的艺术》感]]></title>
      <url>https://taozj.org/201606/read-(the-art-of-sober-thinking).html</url>
      <content type="html"><![CDATA[<p>　　这本书最早是在简书上一篇题为《建立逻辑思维，我推荐的三本书》上发现的。其实在文章评论留下邮箱后，作者也把电子版的书发给我了。看着豆瓣的评分不错，书也不贵，于是还是在狗东买了本纸质版的。<br><img src="/post_images/images/201606/ea643e73606a4543bdd3f2c8ec702e89.jpg" alt="清醒思考的艺术"><br>　　看完之后，感触很多，算是直撮痛点吧，第一次让我感触到人性有这么多缺陷，思维有这么多误区。如果说论语是一本道德楷模，像一个温文尔雅的儒仕教你如何去做人处事的话，那么这本书更像一个手持教鞭的教官，毫不保留的指出你的思维缺陷，引导你如何正确看待身边的事事物物。同时，我觉得这本书应该时常带在身边，因为人不仅仅是身体上，思维上也有惰性，许多的视野、逻辑和观点已经习以为常了，如果不曾真正的痛过，是很难留下记忆去修正他的，更何况有些已经随着人类的繁衍持续了成千上万年，深入骨髓了。此外，本书的副标题也很有意思：“你最好让别人去犯的52种思维错误”，其实完全没必要啦，因为大多数人或多或少都有书中罗列的这52条毛病！</p>
<p>　　其实在漫漫进化的长河中，生物体行为无论是先天条件反射还是后天习得，都是让生物体本着趋利避害的方向发展，因为那些大多数不合理的事物，都被大自然所抛弃了，有些由低级神经中枢负责，有些后天由高级神经中枢学习和加强。设想在野外听见狼叫或者熊叫等声音，大多数人第一反应就是躲避或者逃跑，而不是考量对方是什么、会不会对自己造成威胁和伤害等因素，或许那些在这种情况下冷静爱思考的祖先都被吃掉了吧，同时虽然我们没有经历到这些，但是这类思想还是被不断灌输和传承下来。而对于一朝被蛇咬，十年怕井绳，就更不必说了。<br><a id="more"></a><br>　　只是这些看似简单明显的事物和规则，在现代文明当中，有些已经不适用了。虽然现代文明的建设让我们远离了自然的威胁但现实社会中人际交往、社会活动更加的复杂，表面波澜不惊，实际波涛暗涌。不知道是自己小时候不谙世事，还是现今人类进化速度太快了，总感觉现在的人已经没有以前在农村的邻居朋友那单纯了。或许我们不能改变什么，此本教程也非为人处世之道，但是借助这本书能够看清一些现象的本质，在我们做出抉择的时候，能够更加的“清醒”和“理智”。</p>
<p>　　本书的一大特色，还在于列举或者说是揭示了社会生活中常常出现的一些现象，比如：很多店家和商场会送你一些小礼品，然后在你道德平衡感下，他们向你推销的推销会成功的多；现在各大店家喜欢打折或者送券，然后在对比效应下你以为赚到便宜了，而现在大家都知道其实先提价再打折的小伎俩而已；现在中国社会普遍都是万事向钱看，当每个人都想把自己利益最大化的时候，往往群体就会慢慢衰落灭亡，可悲的“公地效应”；“协和效应”、“赌徒谬误”、“团体迷思”等算是对管理决策起着重要影响作用，这本书中也有讲解和论述。</p>
<p>　　有些时候我们欣赏那种“泰山崩于前而色不变，麋鹿兴于左而目不瞬 ”的冷静，有人想来那种说走就走的热情，但往往前者又常常觉得索然无味，后者又有人觉得感情用事。正如我们总是羡慕鸟儿能够翱翔蓝天，殊不知鸟儿也羡慕我们能在地上生活。其实，我们总是追求那么一种状态，那种超脱自然、无所约束和羁盼的状态。如果说我们犯错误了，那么要么是因为迷失自我，要么就是急功近利了，难道不是么？</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于内容推荐的个性化阅读实现（二）：基于SVD的推荐算法]]></title>
      <url>https://taozj.org/201606/personalized-reading-based-on-content-recommendation-(2)-svd-impl.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　SVD前面已经说了好多次了，先不论其信息检索被宣称的各种长处如何如何，在此最主要的作用是将稀疏的term-doc矩阵进行降维，当一篇篇文章变成简短的向量化表示后，就可以用各种科学计算和机器学习算法进行分析处理了。<br>　　之前的推荐算法的设计是用的最大熵估计，他和诸如朴素贝叶斯、逻辑回归等，本质就是根据文章词汇信息把文章作为一个二类归类问题来解决的。根据自己以前的经验，这种方法是最简单，效果也还是比较理想的，而且相比现在设计的越来越复杂的算法，也有坚实的数理做依据的。<br>　　这次，尝试一个新的推荐方式，我的思路是这样的：如果你SVD分解降维后取n_topics=2，那么这些文章最后就都映射成了二维向量，可以把这些二维向量看作平面中的坐标，那么每篇文章其实就是这个平面上的点了。一般来说，文章越相似，那么他们的向量就越相近，然后映射到坐标空间中两者的欧式距离也就越短。反应到我们的推荐阅读中，如果一个人可能有几个兴趣点，那么他喜欢的文章在空间位置就应该聚成以这几个簇的形式展现出来。当然n_topics=2肯定不能用在实践中应用的，否则会丢失大量的特征信息，但是很容易将这个想法推广到多维的超平面上，基本原理都是一样的。<br>　　这个方法在实现中考虑到的缺陷有：浮点向量没法保存到数据库，只能驻留内存和dump到文件系统了；计算速度肯定比贝叶斯要慢很多，但是绝大多数推荐系统不都是定时进行数据线下计算线上加载的么；目前只考虑点赞的，不考虑踩的负样本的影响了，或许这也不是什么优劣势，负样本本来就可以在所有样本中采样来进行平衡。<br><a id="more"></a></p>
<h1 id="二、算法实现流程">二、算法实现流程</h1><p>　　具体实现流程步骤设计如下：<br>　　(1) 设置n_topics参数，然后对历史的文章进行SVD奇异值分解，生成LSI空间参数；<br>　　(2) 针对每一个用户，取出其历史点赞的文章，用LSI浮点向量表示后，把每篇文章两两计算其余弦值相似度，形成各个文章间的相似度矩阵；<br>　　(3) 设定阈值范围factor（比如0.5，其值也可以根据后面的计算结果动态反馈修改），然后遍历所有点赞的文章，如果其阈值范围内的点赞文章数目达到三篇及以上，那么创建其为一个兴趣点，平均化兴趣点中所有文章的特征向量得到中心特征向量，其兴趣权重正比于其兴趣点中所包含的文章的数目；<br>　　(4) 细心的读者可能发现，这样肯定会产生很多个覆盖有重叠的兴趣点。可不是嘛！所以这里还需要一步额外的迭代：选取权重最高的兴趣点，确定之后将包含的所有文章排除掉，然后再在剩余的文章中选择最高权重的兴趣点，依次下来直到没有新的兴趣点或者达到指定要求的兴趣点，迭代结束；<br>　　(5) 每当有当日新的文章到来，通过之前SVD参数计算其在当前空间中的表示向量，然后按照其到各个兴趣点特征向量距离并乘上兴趣点的权重，得到推荐分数，以最高分数作为这篇文章的最终推荐分数。</p>
<h1 id="三、效果评价">三、效果评价</h1><p>　　通常算法的评价一般需要用标注数据和预测推荐进行验证。一天几百篇文章我也懒得过一遍再标注了，就偷点懒，用之前最大熵估计的推荐分数和本文算法的推荐结果进行一个对比吧！<br><img src="/post_images/images/201606/b78dc437c74ef3e4a29bbda557c1ab34.png" alt="RCDSVD"><br>　　感觉效果还不是特别的明显，是数据的原因么？</p>
<h1 id="四、后注">四、后注</h1><p>　　这只是自己凭空想出来的推荐，自我觉得还是有道理的吧。<br>　　因为词ID用gensim的库做了，所以运行新代码前记得删除dump缓存目录所有的缓存数据，同时数据库的site_rcd这个表记得添加double类型的recsvd字段。<br>　　本来打算部署到我的512M的VPS上的，但是上面服务太多已经很慢了，后面居然给我报内存错误，看来MaxEnt和SVD都是消耗内存的大户啊，所以上面的数据是把服务器的数据导下来用本地笔记本跑的结果，当然这些数据我也上传到代码库了，感兴趣的可以自己验证！同时由于荒芜了一段时间（最主要还是移动端UI做烂了，自己都懒得看啊），历史好评数据不够多，所以就产生了一个兴趣点，不排除多个兴趣点的情况下还有Bug，欢迎反馈！</p>
<div class="github-widget" data-repo="taozhijiang/readmeinfo"></div>

<p>　　真心想，如果有足够数据，做个协同过滤CF还是多爽的，不然枉费搞过推荐系统了～</p>
<p>　　针对VPS内存不足的问题，一个偷巧的方法就是添加或者加大交换分区，比如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">➜ dd <span class="keyword">if</span>=/dev/zero of=/var/swapfile bs=1M count=2048</div><div class="line">2048+0 records <span class="keyword">in</span></div><div class="line">2048+0 records out</div><div class="line">2147483648 bytes (2.1 GB) copied, 4.91128 s, 437 MB/s</div><div class="line">➜ /sbin/mkswap swapfile</div><div class="line">Setting up swapspace version 1, size = 2097148 KiB</div><div class="line">no label, UUID=23fbdf6c-1b11-4c75-9ade-c5c43883e60c</div><div class="line">➜ chmod 0644 /var/swapfile</div><div class="line">➜ <span class="built_in">echo</span> <span class="string">"/var/swapfile swap swap defaults 0 0"</span> &gt;&gt;/etc/fstab</div><div class="line">➜ sudo swapon /var/swapfile </div><div class="line">➜ </div><div class="line">➜ /sbin/swapon <span class="_">-s</span>                                         </div><div class="line">Filename                                Type            Size    Used    Priority</div><div class="line">/dev/vda2                               partition       262140  0       -1</div><div class="line">/var/swapfile                           file            2097148 0       -2</div><div class="line">➜</div></pre></td></tr></table></figure></p>
<p>　　特别对于现在有些号称SSD存储的VPS，这一招还是蛮实用的哦。</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Libevent转发的内网端口暴露（三）：添加SS5代理功能]]></title>
      <url>https://taozj.org/201606/port-expose-based-on-libevent-(3)-ss5-proxy-support.html</url>
      <content type="html"><![CDATA[<p>　　比较好奇Shadowsocks代理是怎么工作的：为什么这么流行这么火？而且实际用起来的速度比vpn、https等代理的速度快的多！查了一下，其是基于sockets5（后面简称ss5）的代理，而ss5的规范文档RFC1928/RFC1929就两三页，算是我看到的最简短的RFC文件了。实际数据流上，就是ss_client告诉服务器自己要访问的主机和端口，然后把本地请求的数据发到ss_server，ss_server再请求目标服务器并将得到的结果返回回来。卧槽！这不就是我sshinner做的事情么！！！<br>　　所以在现有的设计上，添加代理支持应该是很简单的：我只需要保证本地应用程序和ss_client通信满足ss5协议之规定，而ss_client和ss_server通信格式完全可以用自己原先设计的一套就好了。其实开始本来想着客户端和服务器的协议也进行模拟，这样就可以直接用Shadowsocks的多个跨平台客户端了，但是后面还是放弃了，因为需要改动的东西太多了。<br>　　如果想要了解ss5协议，除了有上面两个RFC可供参考之外，可以使用wireshark抓包分析（Windows居然没法抓回环网口的包，差评！！！），此外Shadowsocks早期代码也很具有参考价值，只是后来作者引入了Eventloop异步机制，项目显得比较复杂，同时Shadowsocks-libev是基于Libev实现的，我觉得其最强大的是集成了大量的加密解密算法，牛逼啊！</p>
<p><img src="/post_images/images/201606/3835a8737168091573fc0932cae0dd96.jpg" alt="sshinner"></p>
<h1 id="一、概况">一、概况</h1><p>　　前面已经说到了，创建ss5代理比之前我的端口暴露处理在链路上还简单一些，但也有一些挑战。<br>　　端口暴露的程序比如ssh或者mysql，基本都是长链接，所以一旦链路建成就会比较稳定，后面就是不断的数据转发了。<br>　　ss5代理的操作，当我用chrome做测试客户端的时候，发现链接特别多，而且连接拆建特别活跃。这也好理解，因为根据ss5代理协议的规定，在代理之前需要把目标主机和端口号提供给服务器，现在的前端复杂的要死，即使chrome优化的再好：每一个ip:port在所有资源请求完后再关闭连接，也还是会有很多ss5代理的不断建立和释放，而且chrome的请求是多线程并发的，代理请求十分的迅猛。<br>　　这种情况下，对程序的稳定性是一个很大的考验：数据结构操作必须正确，没有严重的内存泄露，没有竞争条件等，不然过不了多久服务就会被拖垮挂掉；客户端也必须由之前的单线程改为多线程的，否则根本发挥不了异步的优势。<br><a id="more"></a></p>
<h1 id="二、数据通信流程">二、数据通信流程</h1><h2 id="2-1_通信流程">2.1 通信流程</h2><p>　　(1) ss_server程序启动，建立套接字侦听；<br>　　(2) ss_daemon程序启动，连接ss_server，进行用户名、ID号等信息的认证，ss_server建立相应的数据结构；同时ss_daemon建立本地代理的套接字侦听（比如127.0.0.1:1083）；<br>　　(3) 应用程序代理请求，ss_daemon采用阻塞的方式进行交互，取得代理程序需要访问的远程主机地址：remote_addr:remote_port；然后将这个连接分配到某个线程池的处理队列中去；<br>　　(4) 线程池调度启动，同时连接ss_server，然后建立两个事件侦听bev_local和bev_srv，但是此时还是未使能的；<br>　　(5) ss_server发送HD_CMD_SS5_ACTIV命令，然后ss_daemon向代理程序返回确认信息，并使能对应的事件侦听bev_local和bev_srv；<br>　　(6) 连接完毕，本地程序和远程服务器交换数据。</p>
<h2 id="2-2_注意事项">2.2 注意事项</h2><p>　　根据协议要求，程序请求的可以是IP地址，也可以是域名的形式，如果是域名的形式，需要做域名解析后才能连接套接字。域名解析是比较花费时间的，所以Libevent支持域名解析的异步模式。<br>　　后面考虑加一个DNS解析代理的功能，国内的DNS环境太恶劣了（防火墙投毒、运营商劫持等），虽然解析得到的IP可能对CDN这样的访问不利，但是起码是干净的吧，用的放心！(本人暂且用的DNSCrypt)</p>
<h1 id="三、数据加密">三、数据加密</h1><p>　　在直接转发的情况下，默认谷歌还是打不开的，所以对数据包的加密还是必须的。正如Shadowsocks作者所说的，这边的加密不需要太强的加密算法，因为不是追求对数据保密，对信息敏感的协议本身链路数据就是加密的（比如ssh、https等等），这里主要是对转发数据进行混淆扰动，可以让防火墙过滤器无法检测包的内容和特征，从而避免被阻断连接。<br>　　Libevent本身支持Bufferevent的SSL接口，但是速度比较慢。相对而言这种情况觉得还是用对称加密比较简单高效，所以思路跟之前<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">st_utils</a>的一样：先用RSA对来传输加密KEY，然后后续数据基于这个KEY进行加密解密。<br>　　数据加密一般分为块加密和流加密，分别有典型的aes-256-cfb以及rc4-md5。大名鼎鼎的<a href="https://www.openssl.org/" target="_blank" rel="external">OpenSSL</a>其实已经提供了各种加密解密的封装接口，对于选择某种算法其实用上层封装接口差异都不是很大。这里用了rc4-md5加密算法，没有深究其原理，感觉就是对某个数据进行“一次异或加密，再次异或解密”这么个意思了，而且每一个会话用一套KEY，每一个连接用一个IV，IV都是双方通过固定的方式计算出来的，因为如果把IV封装到数据包中，而rc4-md5是流加密长度不定，会加大双方通信的复杂度。<br>　　也有人说现在的AES如果新的CPU指令集支持的话，加密解密速度会快很多。呵呵，我觉的现在真正的制约是网速，而不是计算速度（常常都是挂代理反而比不挂代理访问速度更快，我也是日了狗了）。</p>
<p><img src="/post_images/images/201606/0a66d4cbc3775ac189e6d314f251c5a6.png" alt="ss5"></p>
<h1 id="四、小结">四、小结</h1><p>　　到这里，sshinner算是基本完工了，实现了内网端口暴露，以及ss5代理的功能，后面可能有机会再做一个DNS查询代理的功能。从数据包的转发、DNS的查询等充斥着异步操作，而Libevent像个骨架一样支撑着软件的高速运作，各种回调机制方便了程序的开发，真不愧是一款优秀的基于事件的异步开发库，而且维护者写了一份很好的文档，真心赞啊！</p>
<div class="github-widget" data-repo="taozhijiang/sshinner"></div>

<p>　　注意：目前端口暴露工作的不错，而dropbox等简易ss5代理也工作的很好，用proxychains wget有时候速度是Shadowsocks的两倍，但是对于chrome代理，一小段时间后就不能工作了，稳定性不行，等我清醒一下再慢慢Debug吧！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.ietf.org/rfc/rfc1928.txt" target="_blank" rel="external">rfc1928</a></li>
<li><a href="https://wiki.openssl.org/index.php/EVP_Symmetric_Encryption_and_Decryption" target="_blank" rel="external">EVP_Symmetric_Encryption_and_Decryption</a></li>
<li><a href="https://wiki.openssl.org/index.php/Manual:EVP_EncryptInit%283%29" target="_blank" rel="external">Manual:EVP_EncryptInit(3)</a></li>
<li><a href="https://github.com/shadowsocks/shadowsocks-libev.git" target="_blank" rel="external">shadowsocks-libev</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Libevent转发的内网端口暴露（二）：优化重构]]></title>
      <url>https://taozj.org/201606/port-expose-based-on-libevent-(2)-refined-and-improvement.html</url>
      <content type="html"><![CDATA[<p>　　上面一篇文章发了之后，做了一些稍微的改进：添加了会话起始时候帐户信息加密传输，以及服务端线程池初始化的时候等待完成。然后现在清醒的思考了一下（建议效率低的时候不要写BUG），发现最初的设计过于的简单化，将所有的控制包和数据转发都通过客户端和服务端所建立的唯一连接传输，这样的设计不可避免的会带来一些问题：<br>　　(1) 每次传输需要把包头读出来进行解析，找到目标地址、数据包长度以及本地客户端的映射表然后转发，这个过程中数据会被多次的拷贝，所以效率会很低；<br>　　(2) 所有的数据都走一条链路，那么总体的吞吐量是有限的，尤其当数据量大了的时候对交互软件响应极为不利；<br>　　(3) 对于服务端来说，一个客户会话只有一对bufferevent，那么采用的Libevent/epoll的长处根本没发挥出来，可能这样做的效率还不如长连接；<br>　　(4) 所有鸡蛋都放在一个篮子里面，万一这条线路挂了，那么所有的端口都无法工作，对整个系统的可靠性也不利；<br>　　(5) 最要命的是，原先的设计每个侦听端口映射只能建立一条连接，硬伤啊！</p>
<p><img src="/post_images/images/201606/3835a8737168091573fc0932cae0dd96.jpg" alt="sshinner"></p>
<p>　　对于没有经验的“狗驾驶”来说，重构是再所难免的。</p>
<p><img src="/post_images/images/201606/fedc1532e711f526fc2e757f73e72e74.jpg" alt="日了狗了"><br><a id="more"></a><br>　　为此，在原先的<a href="https://github.com/taozhijiang/sshinner" target="_blank" rel="external">仓库</a>中建立了一个新devel分支，打算对整个项目进行相应的重构，稳定后可能会rebase过去。新的设计思路如下：<br>　　(1) 初始流程还是相同的，首先CLT_DAEMON启动后向SRV加密传输账户信息，通过认证（尚未实现）后建立account和activity的数据结构，然后CLT_USR端启动，进行会话信息的校验，这样CLT和SRV的连接就正式建立了，这个过程中为连接的套接字建立bufferevent，分别记作be_main_daemon和be_main_usr，主要作为控制信息发送的通道；<br>　　(2) CLT_USR同样对本地感兴趣的每个端口创建侦听套接字，等待应用程序连接；<br>　　(3) 一旦有应用程序连接CLT_USR之后，首先为这个连接的套接字创建bufferevent，记作be_usr_local(同时记录连接的端口号l_sock作为标识，这样就可以有多个同类型的连接)，然后向SRV发起一个连接请求，将新建立的请求创建bufferevent，记作be_usr_srv，然后通过这个连接向服务器发送HD_CMD_CONN消息；<br>　　(4) 服务器收到HD_CMD_CONN的控制包后，得知这是一个数据通信连接，会取消这个套接字原本在connect事件中建立的bufferevent，然后添加到指定线程待处理队列中；同时将这个包再转发到CLT_DAEMON端，促发CLT_DAEMON端做通信端的准备；<br>　　(5) 线程处理这个请求，建立数据通信的bufferevent，记作be_srv_usr，用l_sock进行标识；<br>　　(6) CLT_DAEMON收到HD_CMD_CONN消息后，会根据端口连接本地的服务，建立bufferevent记为be_daemon_local，然后再类似地向服务器请求连接，建立be_daemon_srv，并通过be_daemon_srv发送HD_CMD_CONN消息；<br>　　(7) SRV处理HD_CMD_CONN消息，建立be_srv_daemon，然后根据l_sock将be_srv_daemon和be_srv_usr进行关联；<br>通过上面的步骤，就为每个链接建立了</p>
<blockquote>
<p>be_usr_local:be_usr_srv &lt;-&gt; be_srv_usr:be_srv_daemon &lt;-&gt; be_daemon_srv:be_daemon_local</p>
</blockquote>
<p>　　这样的一个转发通道。在这个通道中，不必读取解析包头，他们都是要转发的净负荷数据，同时转发采用bufferevent_write_buffer，尽可能的避免了数据的不必要复制。<br>　　(8) 还需要注意的是，上面CLT端的bufferevent(be_usr_srv/local, be_daemon_srv/local)起初都是只建立不使能的，当SRV处理了CLT_DAEMON的HD_CMD_CONN后，整个链路就打通了，然后线程会通过be_main_daemon和be_main_usr分别向两段发送HD_CMD_CONN_ACT包，两个cLT端收到这个包后，启用bufferevent_enable使能EV_READ|EV_WRITE，然后才开始真正的数据传输。</p>
<div class="github-widget" data-repo="taozhijiang/sshinner"></div>

<p>　　测试发现，通信的速度比之前的设计快的多，而且ssh也工作的非常正常！欢迎大家体验，<a href="https://github.com/taozhijiang/sshinner" target="_blank" rel="external">clone的时候</a>注意选择devel分支哦！</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于Libevent转发的内网端口暴露（一）：基本实现]]></title>
      <url>https://taozj.org/201606/port-expose-based-on-libevent-(1)-basic-impl.html</url>
      <content type="html"><![CDATA[<p>　　在写这个程序的时候，报道TeamViewer的服务器被攻陷，黑客借此操控用户的电脑以盗取用户的数据，乃至操控用户的资金账户等敏感信息，然后TeamViewer官方出来辟谣，说是用户自己的弱口令导致的安全漏洞。怎么说呢，TeamViewer用起来确实很方便，而且几乎是全平台支持，不过我不满意的是Linux平台貌似是Wine的，安装的时候还需要安装一大堆的32位的依赖库，作为Gentoo的洁癖佬让我对此无法忍受，所以必要的时候，我愿意用KVM启动一个Windows的虚拟机来应急；而来在Linux上宣称图形界面，浪费带宽，暴殄天物啊！<br>　　内网主机要可以被外网访问，通常实现的路径有：(1)配置内网出口的端口映射表，让内网特定主机的端口暴露出来；(2)在外网主机架设VPN，然后需要通信的主机连接VPN后就在同一个网段了；(3)借助TeamViewer这类的方式，用外网的主机进行数据中转。在现实使用中，(1)比较的难办，除非你在公司很牛逼，或者和网管有非一般的亲密关系才行；(2)用的是比较多的，很多企业WFH(Work From Home)就是这么办的，但是一旦连上VPN，就是一个可信的网段，对于多用户共享十分不安全；于是，(3)这种方式算是最经济最高效的实现方式了。<br>　　其实自己之前写了一个local_forward的小程序来实现这个功能的。现在看看，当时写的真是简单、幼稚啊。正好前面一段时间学了一下Libevent<a href="/201605/learn-note-of-libevent-%281%29-basic-usage.html">Libevent学习笔记（一）：基本使用</a>以及<a href="/201605/learn-note-of-libevent-%282%29-thread-pool-in-memcached.html），这家伙的高效是出了名的，不仅封装了IO复用的细节，而且封装了bufferevent/evbuffer这类数据接口和操作接口，对于网络数据转发正是其用武之地了，于是就谋划着用Libevent这个库写一个通用一点的端口转发框架程序。今天基本完成了，测试FTP(21">Libevent学习笔记（二）：Memcached中Libevent和线程池使用初探</a>、MySQL(3306)工作很好，SSH(22)终端可以工作，但是比较卡顿，而且控制字符异常，80端口用浏览器异常，尚未跟踪结果。</p>
<p><img src="/post_images/images/201606/3835a8737168091573fc0932cae0dd96.jpg" alt="sshinner"></p>
<h1 id="1-_基本原理">1. 基本原理</h1><p>　　整个程序包括SRV/CLT_DAEMON/CLT_USR三个角色，代码由server/client两个部分，配置文件为运行目录下的settings.json，下面模拟场景来说明吧。<br>　　(1) 要下班了，首先在远程服务器192.3.90.76端运行SRV，其读取本地的settings.json文件，决定自己监听在8900端口；<br>　　(2) 把公司内网的电脑启动client -D作为为CLT_DAEMON角色，程序读取settings.json，发现服务器地址为192.3.90.76:8900，读取配置文件中的username、userid，以及本机的mach-uuid信息，连接服务器并发送这些信息；<br>　　(3) 服务器接收到该请求，然后读取数据头和数据体，解析后将该请求添加到某个线程的处理队列，并向该线程发送通知信息；处理线程被激活后检查该会话是否存在，然后建立相应的数据结构和事件侦听；然后向CLT_DAEMON发送OK确认信息；<br>　　(4) CLT_DAEMON接收到服务器确认消息后，就处于等待SRV数据/命令的状态；<br>　　(5) 你吃过饭回家了，想连一下公司的电脑，这时候启动client程序作为CLT_USR，这时候电脑萌逼了，我怎么知道你要跟哪台电脑通信呢？所以你在公司启动的时候，会打印出mach-uuid，你需要把这个记录下来，写到本地的配置文件中再启动；<br>　　(6) CLT_USR带着要会话的mach-uuid连接到服务器。服务器会检查这个mach-uuid是否已经就绪了，如果就绪了就分配到对应的线程，创建bufferevent侦听事件，于是就行成了USR/DAEMON端都被侦听的双工通信管道；接着工作线程向CLT_USR发送OK确认；<br>　　(7) CLT_USR接下来会对每个本地感兴趣的端口都建立listen侦听事件了，然后就默默的“看着你”——你想要做甚？<br>　　(8) 此时的你华丽丽地带端口运行FTP/MySQL/SSH，就会触发USR端的listen事件，在这个时间中会对你连接的套接字添加读事件侦听，同时沿着USR-&gt;SRV-&gt;DAEMON端发送一个特殊的控制帧’T’，触发DAEMON端连接本地的服务，并创建读事件侦听；<br>　　(9) Enjoy yourself。<br><a id="more"></a></p>
<h1 id="2-_实现细节">2. 实现细节</h1><h1 id="2-1_线程池">2.1 线程池</h1><p>　　借鉴之前的Memcached的实现方式。<br>　　Memcached比较简单，就是轮流的分配任务。本任务中由于通信的两端要依靠同一个数据结构，就应该将两端分配在同一个线程中，这里采用了一个简单的方式，将会话的mach-uuid进行hash映射取余映射分配到唯一的一个线程中，之前看了一篇文章，对于负载均衡分配任务方面，还是有不小的讲究的。那么要分配线程需要了解mach-uuid，需要mach-uuid必须客户端传递，所以listen套接字会接受一个数据包，分析得到mach-uuid之后，再将套接字侦听删除，并转移给对应的工作线程。<br>主线程和工作线程采用pipe管道的方式进行通信，而且管道的读取也是采用Libevent来进行事件驱动的哦！</p>
<h1 id="2-2_数据转发">2.2 数据转发</h1><p>　　数据转发的追求无非就是：完整、高效！<br>　　操作接口采用bufferevent_read和bufferevent_write，比较的简单。这里将数据从读到用户空间，然后再写入传输，实际是低效的，但是我需要分析数据包头，得知消息负载的长度等信息，使用这些函数可以精准控制读取长度，bufferevent_read_buffer、bufferevent_write_buffer这些函数虽然更高效，但是没法控制数据包的长度。<br>　　数据完整性，在传输之前会计算负载的CRC32并记录在帧头部，然后接收到的数据包会计算CRC32并比较，如果错误就丢弃数据。这里没有对数据头进行校验，而且也没有校验失败重传机制……<br>　　Libevent传输的最大数据包长度是4096，所以这里每次bufferevent_write的最大长度也是头部+负载=4096。<br>　　在每隔数据包的头部，会记录该数据的daemonport和userport，然后CLT就知道这些包应该被转送给哪些本地的应用程序了。<br>　　这里还需要注意的是，如上面(8)描述的，ssh在三次握手连接之后，是client首先发数据的，所以之前的设计是，在DAEMON接收到USR数据后如果没有连接本地程序，就连接本地程序，然后将套接字添加侦听事件；后来测试MySQL发现没有反应，wireshark抓包发现，在建立连接之后，是服务器先发送信息，然后客户端再发送登陆数据。于是后面的流程改为：一旦USR发现有请求，那么建立连接和事件侦听后，强行向DAEMON端发送一个Trigger事件，DAEMON在接收到这个控制帧后，立即和本地程序请求连接，建立事件侦听，这时候即使服务端先有数据发送，也可以及时传递到USR端了。</p>
<h1 id="3-_测试">3. 测试</h1><p>　　DigitalOcean的服务器装的是Ubuntu 16.04，居然自己的程序编译不过，明明安装了json-c和Libevent的开发库。所以目前还是在本地测试的，如果有好心人在外网部署出错后，请赶紧AT我调试修正哦。<br>　　不同程序的端口工作的效果大同小异，这里贴出工作的效果图吧！</p>
<ul>
<li>服务端启动(包含后面的数据转发消息)<br><img src="/post_images/images/201606/a784c448ac28b64527309e720cbdcbef.png" alt="server"></li>
<li>客户端Daemon启动(接到连接后连接本地服务，创建Event)<br><img src="/post_images/images/201606/3b1d93fcbe89d0cf79cdd4637c4e43d5.png" alt="client daemon"></li>
<li>客户端Usr启动(启动时候打开本地监测端口)<br><img src="/post_images/images/201606/bbea8fc2a19c11fb98a538b335b6d496.png" alt="client usr"></li>
<li>MySQL连接示例<br><img src="/post_images/images/201606/28482216714eb2b4882717ae3b42829a.png" alt="mysql"></li>
</ul>
<h1 id="4-_后续工作(TODO)">4. 后续工作(TODO)</h1><p>　　后面还有很多可以完善的方面，现在想到的有：</p>
<ul>
<li>实现登陆认证接口<br>　　项目本身就有username/userid接口了，可以利用前面的<a href="https://github.com/taozhijiang/readmeinfo" target="_blank" rel="external">readmeinfo</a>项目的前端部分，实现用户注册、认证的形式，那么挂到VPS上面就可以服务广大群众了；</li>
<li>加密数据传输<br>　　如果是SSH的转发还好，因为SSH本身的数据就是加密的，即使这边明文传输也无所谓，但是对于其他未加密的数据还是有危险。之前在<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">st_utils</a>库里面已经调试了SSL加密传输的接口，可以移植过来使用，并且bufferevent本身也有SSL加密传输的接口。</li>
<li>多线程模式<br>　　用Chrome测试的时候，发现这货是多线程建立多个连接。要实现这个功能，就需要在USR端和DAEMON端同时模拟建立这些并发连接，用处不大，闲着可以写的玩玩。</li>
<li>程序的稳定性<br>　　比如DAEMON端和SRV端进行心跳机制，增加DAEMON的容错性和自动重连机制，DAEMON是你接触不到的主机，所以这个改进会很有价值！</li>
</ul>
<p><div class="github-widget" data-repo="taozhijiang/sshinner"></div><br>　　<br>　　上面了。关于这个项目名字，本来是只想做ssh转发的，但是后面发现为啥不把它写的更通用一点呢？然后写是写通用了，但是项目名字就懒得改了，因为我也不知道取什么名字好，凑合着用吧！</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于内容推荐的个性化阅读实现（二）：基本实现]]></title>
      <url>https://taozj.org/201606/personalized-reading-based-on-content-recommendation-(1)-general-impl.html</url>
      <content type="html"><![CDATA[<p>　　这一直是本人想做的一个项目，缘由是现在的信息越来越多，越来越廉价，所以我必须想办法能自动挑出我感兴趣的文章，而不是一打开订阅邮箱堆积着好多好多的订阅文章，想要消化这些文章又不知哪里下手。其实以前好像看到说，Twitter已经着手研究这类问题，今后可能Twitter信息将按照用户的喜好程度，而不是时间排序展列了，国内低效著称的某浪不知道有没有着手这方面的研究，还是坐等着山寨呢？<br>　　同时，国内的今日头条算是当前最大的移动端信息聚合平台了，之前使用见他每个文章都有好几个TAG，所以不知道他的推荐算法是不是简单基于标签计算的。之前的<a href="/201604/recommend-system-algorithm.html">推荐算法介绍</a>中，新闻播客类的推荐应该是基于用户的协同推荐比较合适，奈何没有用户群行为数据，所以也就只能考虑基于内容的推荐方式了。</p>
<p><img src="/post_images/images/201606/18e1c5d3f143d1e224cad1484ff8e34f.png" alt="注册界面"></p>
<h1 id="1-_项目的构成">1. 项目的构成</h1><p>　　该项目算是信息聚集分发类，按照信息流程涉及到抓取、存储、分析、分发等功能。信息源目前是提交feed然后服务器定时抓取，用户行为数据包括用户对消息的喜恶评价，并基于用户历史的行为数据，对当时的每条信息计算出一个喜好程度作为推荐。<br>　　整个项目是使用Python搭建的，具体涉及到的库有：</p>
<ul>
<li>http: <a href="http://www.tornadoweb.org/en/stable/" target="_blank" rel="external">Tornado</a></li>
<li>mysql: <a href="http://torndb.readthedocs.io/en/latest/" target="_blank" rel="external">torndb</a></li>
<li>feed: <a href="https://github.com/kurtmckee/feedparser" target="_blank" rel="external">feedparser</a></li>
<li>科学计算: <a href="http://www.nltk.org/" target="_blank" rel="external">NLTK</a></li>
<li>BeautifulSoup: <a href="http://beautifulsoup.readthedocs.io/zh_CN/latest/" target="_blank" rel="external">bs4</a></li>
<li>wordcut: <a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">Jieba</a><a id="more"></a>
<h1 id="2-_Web前端和数据库">2. Web前端和数据库</h1>　　由于这次会涉及到科学计算，所以后端计划用Python开发，之前的Libmicrohttpd要是调用的话，就必然涉及到CGI，略显麻烦。而且目前对访问量没有要求，搜了一下之后就用上这么个时髦的Tornado的Web微框架。其实Python Web框架很多，但是自己应该不会用太复杂的功能，话说Tornado虽然是单线程的，但是基于底层异步IO，在并发量高的时候性能会好很多（万一做强大了呢，哈哈）。在实际部署中，可以后台开启多个Tornado实例绑定到不同端口，然后前面再套个Nginx做负载均衡，算是Python Web开发的标准了。<br>　　数据库原来想用sqlite的，但后来想想还是用了MySQL，数据库连接器用的是叫做torndb这个库，原本是集成在Tornado里面的，算是对MySQLdb的一个封装，但在后面新版本tornado中被剥离出来了。</li>
</ul>
<h1 id="3-_Feed/Atom内容抓取">3. Feed/Atom内容抓取</h1><p>　　算是非常重要的模块，没有内容不是无米之炊么。由于历史原因，Feed有几个版本，而且不完全兼容，不过我只用到最简单的元素:比如title/link/description这些，所以问题不大，系统会开一个线程定时专门负责扫描feed。<br>　　目前觉得用Feed内容比较单调，后续可能会考虑添加爬虫模块，爬一些主流站点，可以丰富内容。自己之前用的Sina/Twitter机器人，也可以考虑添加进来。还有一点，发现某些文章会在各家网站进行转载，采用自然语言处理去重消息也是后续的一个工作点。</p>
<h1 id="4-_新闻推荐">4. 新闻推荐</h1><p>　　原本是打算用LSI，建立用户的兴趣点进行推荐的，留着后面搞个大新闻吧。<br>　　当前就用了最大熵分类算法：根据用户前五天的好差文章评价用作训练数据，然后对当日爬到的新闻，计算其好/差的概率，依据此排序进行推荐，相关算法已经在之前的<a href="https://github.com/taozhijiang/chinese_nlp" target="_blank" rel="external">chinese_nlp</a>介绍过了，没有什么难处。<br>　　还有，推荐的结果会有一个好/差的排序方式，一方面需要保持后续训练负样本的数量相对平衡（如果用LSI建立兴趣点的话，就没有这个限制了，兴趣中心点可以根据用户对每个文章的好恶进行修正）；此外，本着对用户负责的态度，还是要看看自己不喜欢的文章，防止某些重要或者有趣的信息被推荐引擎过滤掉了（请看<a href="https://www.zhihu.com/question/46480353" target="_blank" rel="external">社交网络为用户进行「个性化推荐」的做法，是否会导致人们「难以接触到意见相左的人」</a>）。<br><img src="/post_images/images/201606/1361693c236125788c62c5911ed0cbbe.png" alt="推荐结果"></p>
<h1 id="5-_前端交互">5. 前端交互</h1><p>　　Tornado可以通过模板快速生成动态网页，而对于请求不同的url也可以路由到不同的处理类中，开发起来十分的方便。但是前端的用户交互行为，比如筛选、排序、点赞等行为，对于一个不懂前端的人，还是比较困难的。靠着强大的谷歌，顺顺利利地抄袭了几段代码简陋的实现了…CSS样式也是丑到家了…前端对大家没啥参考价值，不要学我。</p>
<h1 id="6-_展望">6. 展望</h1><p>　　后续可以把OAuth认证搞进来，Tornado本身是支持的；考虑开放个API，如果有兴趣做移动APP的可以来耍，我本人是没这个精力了；一个完善的LSI推荐实现，乃至后面的协同推荐，算是一个很期待的突破点，所以很期待你们的注册，帮我积累用户行为数据。<br>　　体验地址:<a href="https://r.taozj.org" target="_blank" rel="external">https://r.taozj.org</a>。注意：必须有前几日的评价历史数据，推荐功能才可用哦。   </p>
<p>更新：<br>　　添加了缓存功能，加快浏览速度，同时让你的信息更自由！<br><img src="/post_images/images/201606/182c47bae0c801696b74c673db09fab0.png" alt="缓存"><br>　　如果想体验，可以使用 taozj@live.com  12345678 　这个账号体验！<br>　　<br>　　<div class="github-widget" data-repo="taozhijiang/readmeinfo"></div></p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[互联网OAuth 2.0开放授权原理]]></title>
      <url>https://taozj.org/201605/principle-of-oauth2.html</url>
      <content type="html"><![CDATA[<p>　　OAuth 2.0是一个开放授权协议，是1.0的更新替代版，据说是比1.0简化方便了许多。这个协议是用于授权访问开放资源的，但我觉得对自己最大的方便的是很多网站支持的话，可以方便地用授权账号登陆，而免除注册-激活-登陆这些繁琐的步骤。<br><img src="/post_images/images/201605/6fbb1434f91f270e3d798810f9dc4057.png" alt="OAuth 2.0 图标"></p>
<h1 id="1-_OAuth_2-0_协议介绍">1. OAuth 2.0 协议介绍</h1><h2 id="1-1_OAuth_2-0_授权过程概述">1.1 OAuth 2.0 授权过程概述</h2><p>　　下面，以客户端Web应用程序请求资源的例子(最常见的Authorization Code认证类型)，描述一下OAuth 2.0 授权请求的过程，想必使用过的人(作为Resource Owner)一定很熟悉吧。<br>　　当用户访问这个客户端Web应用程序的时候，会提示选用通过Facebook/Google/Twitter方式登陆；用户点击对应的登陆按钮，然后用户会被导向对应登陆界面，完成登陆后提示是否允许客户端Web应用程序访问自己的某些数据，用户选择允许；接着认证程序将用户导向到redirect URI并附加一个授权码(authentication code)，redirect URI是客户端Web应用注册时候提供的地址，注册时候认证程序会给注册的客户端Web应用client id和client password；用户访问redirect URI，在底层客户端Web应用会将client id，client password和授权码回传给服务器，成功后认证程序返回access token。<br>　　自此，当客户端程序得到了access token，就可以用这个令牌访问申请的资源信息了。<br><a id="more"></a></p>
<h2 id="1-2_OAuth_2-0_角色类型、客户类型和客户属性">1.2 OAuth 2.0 角色类型、客户类型和客户属性</h2><p>　　OAuth 2.0 共有四种角色，分别是：Resource Owner、Client Application、Resource Server、Authorization Server。Resource Owner一般指的拥有资源的用户或者程序，Client Application是请求资源的程序，认证服务器和Resource Server可以是同一台服务器或者不同的服务器构成的。<br>　　协议中，OAuth 2.0有两种客户类型：Confidential和Public，前者是能够保存认证服务器给予的client password，用以让服务器识别客户，常用于Web App；后者用于不能保存client password的情况，比如手机App或者桌面App，以及Javascript应用程序。<br>　　客户属性(Profiles)包括Web Application、User Agent和Native：Web Application通常包括Browser端和Server端，用户密码常常被保存在Server端，因此可以是Confidential的类型；User Agent常常是运行在浏览器中的Javascript小程序或者小游戏；Native通常是运行在移动端或者桌面的应用程序。</p>
<h2 id="1-3_OAuth_2-0_认证">1.3 OAuth 2.0 认证</h2><p>整个认证过程包括：</p>
<h3 id="1-3-1_客户端应用向认证服务器注册">1.3.1 客户端应用向认证服务器注册</h3><p>　　首先，开发的应用程序需要向Facebook/Google/Twitter这类Resource Server的认证服务器进行注册，然后认证服务器会为客户端应用提供唯一的client id和client password，同时客户端程序还需要向认证服务器提供redirect URI，一旦客户端通过了认证服务器的认证，返回客户端之后Resource Owner将被带到这个redirect URI。</p>
<h3 id="1-3-2_认证授权(Grant)">1.3.2 认证授权(Grant)</h3><p>　　主要是客户端程序通过认证服务器的认证之后，Resource Server授权批准给客户端程序的权限。其认证和授权包括四种类型，每一种都包括不同的安全属性：Authorization Code、Implicit、Resource Owner Password Credentials、Client Credentials。</p>
<h4 id="1-3-2-1_Authorization_Code">1.3.2.1 Authorization Code</h4><p>　　如上面概述的过程，是最常见也是最严格的认证模式：</p>
<blockquote>
<p>(1)用户访问应用程序；<br>(2)应用程序提示用户通过Facebook/Google/Twitter方式登陆；<br>(3)用户被重定向到了认证服务器，同时应用程序附加自己的client id给认证服务器；<br>(4)用户在认证服务器上登陆，登陆成功之后提示用户是否Grant应用程序访问资源，用户允许后被重定向到应用程序；<br>(5)当回到应用程序后，认证服务器将用户导向到redirect URI，同时附加authorization code；<br>(6)当redirect URI被访问后，应用程序和认证服务器就直接相连了，应用程序向认证服务器发送authorization code、client id、client password；<br>(7)认证服务器接受这些信息后，返回access token；<br>(8)应用程序之后通过access token访问资源信息；</p>
</blockquote>
<p><img src="/post_images/images/201605/d78950b5d453c9173ab6988ed4c56cff.png" alt="Authorization Code认证过程"></p>
<h4 id="1-3-2-2_Implicit">1.3.2.2 Implicit</h4><p>　　相比 Authorization Code认证方式简化了过程，当用户登录认证服务器完成认证，然后定向到redirect URI，此时认证服务器直接返回access token，而不是上面的authorization code。<br>　　这种情况一般是User Agent和Native的类型，Web Server不会保存client password/access token，当然User Agent或者Native App保存client password/access token在本地也是不安全的。<br><img src="/post_images/images/201605/526ce8aec57f2aa4a395b13d21cd0bce.png" alt="Implicit认证过程"></p>
<h4 id="1-3-2-3_Resource_Owner_Password_Credentials">1.3.2.3 Resource Owner Password Credentials</h4><p>　　通过交付用户账户和密码给应用程序，授权应用程序访问用户资源。这种情况必须极度信任该应用程序才行，想想你交付的可是账户和密码哦！</p>
<h4 id="1-3-2-4_Client_Credentials">1.3.2.4 Client Credentials</h4><p>　　授权应用程序访问公共资源，而不特定针对某个特别的用户情况的。</p>
<h2 id="1-4_OAuth_2-0_请求和响应格式">1.4 OAuth 2.0 请求和响应格式</h2><p>　　针对上面的四种认证授权类型，分别有不同的请求和响应数据格式</p>
<h3 id="1-4-1_Authorization_Code">1.4.1  Authorization Code</h3><p>　　包括两个请求和两个响应</p>
<ul>
<li>认证请求<br>response_type: code<br>client_id: 认证服务器提供的client_id<br>redirect_uri: 应用程序注册的redirect URI<br>scope: 申请的权限、范围</li>
<li>认证响应<br>code: 认证服务器返回的authorization_code</li>
<li>认证错误<br>error: 预先约定的错误码<br>error_description:<br>error_uri: 指向错误详细描述的页面</li>
<li>Token请求<br>client_id:<br>client_secret:<br>grant_type: authorization_code<br>code:返回认证服务器给的authorization_code<br>redirect_uri:</li>
<li>Token响应<br>access_token:<br>token_type:<br>expires_in: access_token失效的时间，用秒计量<br>refresh_token:</li>
</ul>
<h3 id="1-4-2_Implicit">1.4.2  Implicit</h3><p>　　包括一个请求和一个响应</p>
<ul>
<li>请求<br>response_type: code<br>client_id: xxx<br>redirect_uri:<br>scope: </li>
<li>响应<br>access_token:<br>token_type:<br>expires_in:<br>scope:</li>
<li>错误<br>同上。</li>
</ul>
<h3 id="1-4-3_Resource_Owner_Password_Credentials">1.4.3  Resource Owner Password Credentials</h3><p>　　包括一个请求和一个响应</p>
<ul>
<li>请求<br>response_type: password<br>username:<br>password:<br>scope: </li>
<li>响应<br>access_token:<br>token_type:<br>expires_in:<br>refresh_token:</li>
</ul>
<h3 id="1-4-4_Client_Credentials">1.4.4 Client Credentials</h3><p>　　包括一个请求和一个响应</p>
<ul>
<li>请求<br>grant_type: client_credentials<br>scope:</li>
<li>响应<br>access_token:<br>token_type:<br>expires_in:</li>
</ul>
<h1 id="2-_OAuth_2-0_协议举例">2. OAuth 2.0 协议举例</h1><p>　　本着实践的精神，试了一下国内第一大浪的开放平台的OAuth授权。</p>
<h2 id="2-1_注册账户，创建应用">2.1 注册账户，创建应用</h2><p>　　在<a href="http://open.weibo.com/" target="_blank" rel="external">新浪微博开放平台</a>注册开发者账户，然后创建一个应用，得到应用的信息如下：</p>
<blockquote>
<p>应用名称：测试应用的哈<br>App Key(Client ID)：476302957<br>App Secret(Client Password)：1dd5950b4c7165a4203ae9a5b986c105<br>创建时间：2016-05-23<br>回调页面：<a href="http://abc.com/" target="_blank" rel="external">http://abc.com/</a></p>
</blockquote>
<h2 id="2-1_采用新浪提供的授权接口，进行Authorization_Code授权请求">2.1 采用新浪提供的授权接口，进行Authorization Code授权请求</h2><p>　　新浪Authorization Code授权请求的URL格式如下(GET方式)：<br><a href="https://api.weibo.com/oauth2/authorize?client_id=476302957&amp;response_type=code&amp;redirect_uri=http://abc.com/" target="_blank" rel="external">https://api.weibo.com/oauth2/authorize?client_id=476302957&amp;response_type=code&amp;redirect_uri=http://abc.com/</a><br><img src="/post_images/images/201605/71d59b48b077405597414fb88247f968.jpg" alt="授权确认界面"></p>
<h2 id="2-2_获取授权码，换取access_token">2.2 获取授权码，换取access_token</h2><p>　　上面一部授权允许后，会转到redirect URI，并附加授权码<br><img src="/post_images/images/201605/e5e621303de083315bf4ad5309b94742.jpg" alt="获取授权码"></p>
<p>　　然后按照换取access_token的地址，换取access_token。这里需要注意的是，请求方式必须是POST的，否则会返回不支持的请求类型的错误。<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">https://api.weibo.com/oauth2/access_token?client_id=476302957&amp;client_secret=1dd5950b4c7165a4203ae9a5b986c105&amp;grant_type=authorization_code&amp;redirect_uri=http://abc.com/&amp;code=c7502d6f5d015f7ae99b44a9c9d57cd3</div></pre></td></tr></table></figure></p>
<p><img src="/post_images/images/201605/1bd3f4c958ad007086422deec1af4f3b.jpg" alt="换取access_token"></p>
<h2 id="2-3_使用access_token">2.3 使用access_token</h2><p>　　得到了access_token，就可以当作令牌访问用户的授权数据了，比如下面将会得到用户好友的列表：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">https://api.weibo.com/2/friendships/friends.json?screen_name=nicol_tao&amp;access_token=2.00rfgxpB0lJWOW042307510b4MBhGC</div></pre></td></tr></table></figure></p>
<p><img src="/post_images/images/201605/94aed3d6bea233af213ef3cc1e2e37cb.jpg" alt="access_token返回用户好友列表"></p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://tutorials.jenkov.com/oauth2/index.html" target="_blank" rel="external">OAuth 2.0 Tutorial</a></li>
<li><a href="http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="external">理解OAuth 2.0</a></li>
<li><a href="https://github.com/NateFerrero/oauth2lib" target="_blank" rel="external">oauth2lib</a></li>
<li><a href="http://open.weibo.com/wiki/%E6%8E%88%E6%9D%83%E6%9C%BA%E5%88%B6%E8%AF%B4%E6%98%8E" target="_blank" rel="external">授权机制说明</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[MySQL数据类型整理和索引介绍]]></title>
      <url>https://taozj.org/201605/data-type-and-index-of-mysql-database.html</url>
      <content type="html"><![CDATA[<blockquote>
<p>问：数据库有没有建过索引？<br>答：没有。<br>问：居然没有建过索引，查询难道不用索引么！！！<br>答：下一题~~~</p>
</blockquote>
<p>　　数据库的数据库索引对程序员来说是透明的，意味着数据库建立索引之前和之后，你的SQL语句都可以正常运行，索引的运用只是数据库引擎工作时候的优化手段。但是，这不是意味着数据库索引仅仅是数据库设计和运维者的事情，对于一个程序员如果对数据库已有的索引有所了解，还是可以大大优化程序员数据库的查询和修改语句执行效率的，以免你的低效查询语句称为拖累整个系统性能的Black Sheep。<br>　　本文对MySQL/MariaDB数据类型和索引建立、优化进行整理，现在数据库引擎默认都是InnoDB的，而且目前MySQL/MariaDB应用于生产环境时候，应该都是用的这个引擎吧。</p>
<h1 id="一、MySQL的数据类型">一、MySQL的数据类型</h1><h2 id="1-1_数字类型和时间类型">1.1 数字类型和时间类型</h2><p>　　数字类型算是最简单的了，主要差异在于各个类型的取值范围大小限制，和对存储空间字节数的需求。数字类型当然是在满足情况的条件下越短越好，一方面MySQL每行有65535字节长度的限制，同时更宽的数据类型意味着对CPU、内存、磁盘I/O带来压力。</p>
<h3 id="1-1-1_MySQL支持的定点数字类型和占用字节数分别是">1.1.1 MySQL支持的定点数字类型和占用字节数分别是</h3><table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">长度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">TINYINT</td>
<td style="text-align:center">1</td>
</tr>
<tr>
<td style="text-align:center">SMALLINT</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">MEDIUMINT</td>
<td style="text-align:center">3</td>
</tr>
<tr>
<td style="text-align:center">INTEGER</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">BIGINT</td>
<td style="text-align:center">5</td>
</tr>
</tbody>
</table>
<p>　　在数据库设计的时候，常常看到这些整形有个前缀长度，其实这对其类型本身的存储长度和精度没有影响，只会关系到某些交互式工具显示出来的字符个数。</p>
<h3 id="1-1-2_MySQL支持的浮点（实数）类型和占用字节数为">1.1.2 MySQL支持的浮点（实数）类型和占用字节数为</h3><table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">长度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">FLOAT</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">FLOAT(p) [0,24]</td>
<td style="text-align:center">4</td>
</tr>
<tr>
<td style="text-align:center">FLOAT(p) [25,53]</td>
<td style="text-align:center">8</td>
</tr>
<tr>
<td style="text-align:center">DOUBLE,REAL</td>
<td style="text-align:center">8</td>
</tr>
</tbody>
</table>
<p>　　计算机的浮点运算都是不精确的，如果要实现精确浮点运算，就需要使用DECIMAL类型。</p>
<h3 id="1-1-3_时间类型">1.1.3 时间类型</h3><p>　　常被使用的是DATE、DATETIME和TIMESTAMP类型，其表示的范围为：</p>
<blockquote>
<p>DATE：’1000-01-01’ to ‘9999-12-31’<br>DATETIME：’1000-01-01 00:00:00’ to ‘9999-12-31 23:59:59’<br>TIMESTAMP：’1970-01-01 00:00:01’ UTC to ‘2038-01-19 03:14:07’ UTC</p>
</blockquote>
<p>　　TIMESTAMP存储的范围比DATETIME要小，但是空间利用率也最高。MySQL支持的时间精度最高为1s，如果更精确的存储，就必须自己定义存储格式了。<br><a id="more"></a></p>
<h2 id="1-2_字符串类型">1.2 字符串类型</h2><p>　　MySQL中的字符串类型比较多也比较的复杂，各个字符串类型的差别不仅仅在存储时候的空间占用，对存取时候字段某位的strip和padding还有差异。<br>　　对于类型CHAR/VARCHAR/TEXT是跟本地字符集相关的，这会影响到实际占用空间的字节数、字符比较等。</p>
<h3 id="1-2-1_CHAR(M)/VARCHAR(M)">1.2.1 CHAR(M)/VARCHAR(M)</h3><p>　　长度限制参数M表示的是本地字符集的字符个数而不是bytes数目，比如对于UTF8编码，每个本地字符其实际占用的byte长度可能是3或4倍的本地字符长度。比如VARCHAR(255)，如果每个本地字符占用两个字节，那么其需要的存储空间最大为255x2+2。<br>　　CHAR的M被限制在最大255，而VARCHAR的M理论上受限于Row Size的长度(65,535bytes)，且实际存储时候会附加1~2字节的前缀表示数据实际长度。如果strict SQL模式没有被打开，那么当插入数据超过声明长度限制的时候，数据将会被截断并产生警告信息，在strict SQL模式下将会出错。<br>　　CHAR类型在存储的时候，会在右端padding SPACE到指定的M长度，当取该字段的时候，所有末尾的SPACE都将会被strip掉然后返回；VARCHAR不会对进行SPACE进行padding以及strip操作，存储什么样的数据就会返回什么样的数据。<br>　　对于CHAR/VARCHAR/TEXT类型，在进行字符串比较的时候，（SQL语句参数中的字符串）结尾的空格都是不参与比较的，但是对于LIKE语句，检索的时候结尾的空格是考虑在内的。</p>
<h3 id="1-2-2_BINARY(M)/VARBINARY(M)">1.2.2 BINARY(M)/VARBINARY(M)</h3><p>　　BINARY/VARBINARY在操作的时候，参考的是byte streaming而不是charaset streaming，所以其长度限制参数M表示的是byte数目，在比较的时候也是直接的数字大小比较（而非本地字符集方式比较）。<br>　　BINARY在插入的时候，会使用0x00（而非SPACE）padding到长度M，取值的时候不会进行strip尾部空字符的操作（意味着取出来的长度一定是M）；VARBINARY则是保证原样存取的。</p>
<h3 id="1-2-3_BLOB/TEXT">1.2.3 BLOB/TEXT</h3><p>　　分别有TINY/MEDIUM/LONG类型的衍生长度，BLOB是bytes streaming类型的，而TEXT是基于character streaming本地字符集类型的，两者在存取的时候都不会进行padding和strip操作。<br>　　BLOB/TEXT的关系和之前的VARBINARY/VARCHAR是比较相似的，除了：BLOB/TEXT不能够有DEFAULT值；BLOB/TEXT在创建索引的时候必须要有prefix length，而前者是可选的；给予TEXT索引需要有前缀长度，而且建立索引会自动padding SPACE到索引长度，所以如果插入的字符前面一样，只是尾部空字符长度不同，也是会产生相同的索引值。</p>
<h3 id="1-2-4_字符串各个类型占用的空间长度">1.2.4 字符串各个类型占用的空间长度</h3><table>
<thead>
<tr>
<th style="text-align:center">类型</th>
<th style="text-align:center">长度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CHAR(M)</td>
<td style="text-align:center">Mxw bytes</td>
</tr>
<tr>
<td style="text-align:center">BINARY(M)</td>
<td style="text-align:center">M bytes</td>
</tr>
<tr>
<td style="text-align:center">VARCHAR(M), VARBINARY(M)</td>
<td style="text-align:center">L+1/L+2 bytes</td>
</tr>
<tr>
<td style="text-align:center">TINYBLOB, TINYTEXT</td>
<td style="text-align:center">L+1 bytes</td>
</tr>
<tr>
<td style="text-align:center">LOB, TEXT</td>
<td style="text-align:center">L+2 bytes</td>
</tr>
<tr>
<td style="text-align:center">MEDIUMBLOB, MEDIUMTEXT</td>
<td style="text-align:center">L+3 bytes</td>
</tr>
<tr>
<td style="text-align:center">LONGBLOB, LONGTEXT</td>
<td style="text-align:center">L+4 bytes</td>
</tr>
</tbody>
</table>
<p>　　根据官方手册，CHAR/BINARY及其衍生的类型的数据是存储在表的行内部(inline)的，而对于BLOB和TEXT类型，每一个字段只占用该行9-12（1~4+8）个字节（用于数据的地址和长度），实际的数据是存储在Row Buffer之外位置的。所以对于经常访问的字符串类型，而长度又不是特别的大，还是建议用VARCHAR(M)的数据类型，性能会比TEXT快不少。</p>
<h1 id="二、MySQL数据库索引">二、MySQL数据库索引</h1><p>　　数据库索引可以用来快速找到需要的行，否则的话MySQL就需要一行一行的遍历，查询效率自然相当的低。<br>　　MySQL支持的索引包括PRIMARY KEY、UNIQUE、INDEX、FULLTEXT类型的索引。前面说过，FULLTEXT类型的全文索引<a href="/201605/auto-answer-recommend-conclusion.html">在中文下基本是报废的</a>，在此就不予讨论了。<br>　　特别注意的是，对于索引列只能使用单纯的列名，而不能是表达式或者函数的一部分，比如age+2、TO_DAYS(date_col)，引擎在检索的时候才能使用索引。</p>
<h2 id="2-1_索引的类型">2.1 索引的类型</h2><h3 id="2-1-1_PRIMARY_KEY">2.1.1 PRIMARY KEY</h3><p>　　在InnoDB内部，表数据是优化主键快速查询而排列分布的，其查找速度是最快的（相当于聚簇索引：该索引中键值的逻辑顺序决定了表中相应行的物理顺序）。即使表中没有适合做主键的列，也推荐采用一个自动增长的整数主键（代理键），那么这个表在增加数据的时候是顺序存放的，而且后续在别的表参考该外键查询的时候也会得到优化。本身在设计表的时候，也建议常用的数据额不常用的数据分表存放以增加效率。</p>
<h3 id="2-1-2_INDEX">2.1.2 INDEX</h3><p>　　普通索引，对数据没有约束要求，多行记录可以包含相同值。无论对于字符串索引，还是多列组合索引，都以及在查询语句中，都有个最左前缀的原则：</p>
<ul>
<li>对于字符串类型，可以指定索引前缀长度（且对于BLOB/TEXT前缀长度参数是必须的），在InnoDB表中其前缀长度最长是767 bytes，且参数M是用bytes计量的。所以太长的字符串，建立BTree索引浪费比较大，这时候用<a href="/201605/auto-answer-recommend-conclusion.html">手动模拟HASH索引</a>是个方法，不过这种方式对字符串无法灵活的使用前缀方式查询（例如LIKE这类的操作）。</li>
<li>在建立多列索引的时候，必须按照从左到右的顺序使用全部或部分的索引列，才能充分的使用组合索引，比如：(col1, col2, col3)使用(col1)、(col1, col2)、(col1, col2, col3)有效。在查询语句中会一直向右匹配直到遇到范围查询(&gt;,&lt;,BETWEEN,LIKE)就停止匹配，其后的索引列将不会使用索引来优化查找了。</li>
<li>索引不是建立的越多、越长越好，因为索引除了占用空间之外，对后续数据库的增加、删除、修改都有额外的操作来更新索引，所以对索引列和字符串前缀长度，都参考选择性（Selectivity）这个指标来确定：选择性定义为不重复的索引值和数据总记录条数的比值，其选择性越高，那么索引的查询效率也越高，对于性别这种参数，建立索引根本没有意义。<h3 id="2-1-3_UNIQUE">2.1.3 UNIQUE</h3>　　UNIQUE索引要求索引是唯一的。对于单列索引，要求该列所有数据都不相同，但允许有NULL值；对于多列的组合索引，要求这些列的组合是唯一的。UNIQUE索引其本身既可以作为索引，实际中也可以用以产生数据约束，防止增加或者修改后产生相同数据，从而保证数据的完整性。</li>
</ul>
<h2 id="2-2_B+Tree和HASH">2.2 B+Tree和HASH</h2><h3 id="2-2-1_B+Tree">2.2.1 B+Tree</h3><p>　　该类型的索引中，列记录都是按照顺序排列的，可以优化用于比较或者范围查找操作(=, &gt;, &gt;=, &lt;, &lt;=, BETWEEN, IN)，以及用于(GROUP BY, ORDER BY)操作，而且对于字符串类型的索引，最左前缀字符串也可以充分利用索引，比如LIKE ‘Patrick%’会解释成 ‘Patrick’ &lt;= key_col &lt; ‘Patricl’。</p>
<h3 id="2-2-2_HASH">2.2.2 HASH</h3><p>　　速度更快，不过只能用于 =、&lt;=&gt;、IN操作符；优化器不能用于ORDER BY操作；任何查找操作必须是索引的完整列。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/23008813/" target="_blank" rel="external">高性能MySQL</a></li>
<li><a href="http://dev.mysql.com/doc/refman/5.7/en/optimization-indexes.html" target="_blank" rel="external">Optimization and Indexes</a></li>
<li><a href="http://dev.mysql.com/doc/refman/5.7/en/data-types.html" target="_blank" rel="external">Chapter 12 Data Types</a></li>
<li><a href="http://dev.mysql.com/doc/refman/5.7/en/column-count-limit.html" target="_blank" rel="external">C.10.4 Limits on Table Column Count and Row Size</a></li>
<li><a href="http://code.tutsplus.com/tutorials/top-20-mysql-best-practices--net-7855" target="_blank" rel="external">Top 20+ MySQL Best Practices</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[答案自动推荐模块项目小结]]></title>
      <url>https://taozj.org/201605/auto-answer-recommend-conclusion.html</url>
      <content type="html"><![CDATA[<p>　　这段时间一直在写一个小模块，功能上来说，就是根据客服和用户之间的对话记录进行在线记录(原谅我还不敢用在线学习这么专业的术语，因为目前的实现中确实没有用专业的学习算法，只用到信息检索的技术)，为用户的新问题自动推荐答案。目前在线调测的差不多了，不知道上线试用会是怎么样。借此休息的机会，想对项目做个总结，由于还是自己单干，也希望有经验的伙伴能不吝赐教。</p>
<h1 id="1-_权限最小化选择">1. 权限最小化选择</h1><p>　　　其实权限最小化对各方都有积极的意义：对于整个系统来说，权限最小化可以降低系统出错的风险，而对于个人来说，最小的权限也就意味着可以担当最低的责任，目前这个生产的系统已经连续运行了600多天了，很不容易啊。由于个人的检索模块用的是Lucy，并且依赖于Clownfish，而这两个库都比较小众，各大发行版基本都没收录，所以就只能下载代码本地编译，然后将头文件和链接/运行库放到项目本地，修改Makefile编译参数<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-I./include/ApacheLucy -I/home/taozj/root/share/clownfish -L/home/taozj/root/lib/ -llucy -lcfish</div></pre></td></tr></table></figure></p>
<p>　　这样，我的服务如果不是要绑定到1024一下的特权端口，这个服务完全就可以普通用户运行了。</p>
<h1 id="2-_积累代码，统一风格">2. 积累代码，统一风格</h1><p>　　开发的过程是要积累的，这不但包含只是经验的积累，还有自己编写调试好的模块也是。自己之前使用的代码都放到<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">st_utils</a>里面了，这次链表、红黑树、数据库连接池等模块都直接拿来使用了。当然，可能觉得项目集成更好的方式是git submodule，但是这不算是个功能特定的模块，所以此处还是不太合适。<br>　　而外就是个人代码的风格需要一致、统一。就像C函数，有些返回非0表示成功，返回0表示失败；有些返回0表示成功，返回-1表示失败，如果自己的风格不统一的话，很可能写写之后自己都把自己搞晕了。所以模仿Libmicrohttpd的方式，用自己定义的放回类型<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">enum</span> RET_TYPE &#123;</div><div class="line">    RET_YES = <span class="number">1</span>,</div><div class="line">    RET_NO  = <span class="number">0</span>,</div><div class="line">&#125; RET_T;</div></pre></td></tr></table></figure></p>
<p>　　这样，自己约定RET_YES正常返回，RET_NO异常返回；而当返回值不表示函数调用的成败，而是具体的计算结果的时候，再用int类型来作为返回类型。<br><a id="more"></a></p>
<h1 id="3-_多看代码，善于借鉴">3. 多看代码，善于借鉴</h1><p>　　现在深深地觉得作为程序员，读代码是十分重要的。因为很多需求和实现要么是自己凭空臆想出来的，要么是网上搜索出来的，而实际上，很多论坛以及博客的技术方案和实现代码，要么只是浅显涉及到教你怎么用，要么就是实现的低质粗糙，有些作者自己还是一知半解的，甚至还会将你误入歧途。这种情况，如果身边没有大牛给你当百科全书查阅，就自己去看声望较高的开源软件的代码吧，因为那些代码是实实在在运行的，经受大家监督并且久经考验了的。<br>　　比如自己的这个小模块中：(1)数据库连接池设计中，连接的请求操作借鉴了Memcached采用pipefd的阻塞读取，来实现阻塞请求返回；(2)在内存中记录对话内容，由于对话长度是未知的，直接设计固定长度的数组空间利用率会很低，采用strdup保存指针的方式(目前是这样的)容易内存碎片和泄露，那么我觉得Libevent的evbuffer及其evbuffer_chain的设计将是一个很好的范本；(3)这里用的Libmicrohttpd，其本身集成了线程池模型，如果后续用Libmicrohttpd重构的话，线程池可以<a href="/201605/learn-note-of-libevent-%282%29-thread-pool-in-memcached.html">借鉴Memcached</a>的。</p>
<h1 id="4-_模块化，接口化设计">4. 模块化，接口化设计</h1><p>　　这个是构架师的工作内容了，我是控制不了的。但是这次使用看来，用HTTP协议+JSON数据封装的通信，比传统的Socket开发要方便不少，因为HTTP作为应用层的协议，这样就不用考虑传输细节和数据封装，只需要对取得的有效数据进行处理就可以了。不过另一方面说，对于模块和模块之间的通信，而不是开放出去的API，直接用长连接的方式通信可能吞吐量会更大，所以也还需要具体情况具体分析。<br>　　视野越宽，选的路才会更好。不排除会有更高效、更便捷的通信协议适用于相对应的场景。</p>
<h1 id="5-_善用工具，积累经验">5. 善用工具，积累经验</h1><h2 id="5-1_工具类">5.1 工具类</h2><h3 id="5-1-1_SlickEdit">5.1.1 SlickEdit</h3><p>　　如果你不属于Vim+gdb这类的Geeker，想找一个省心的C/C++ IDE工具，那么强烈推荐SlickEdit。其几乎支持所有的平台，支持在线调试跟踪，如果gdb不是很熟练的话，用这家伙绝对是最省心的；</p>
<h3 id="5-1-2_Makefile">5.1.2 Makefile</h3><p>　　Linux的开发者几乎逃脱不了这个东西，上面的SlickEdit说是支持自动Makefile的，当然也有很多工具辅助生成Makefile。目前我开发时候都是手写Makefile，一方面项目比较小，自己添加调教参数方便，二来不用目录下生成很多乱七八糟的文件，当然如果你想自己的软件能发布，自动适应目标环境，可以参见<a href="/201509/generate-makefile-through-autotools.html">利用autotools自动生成项目的Makefile</a>。其实Makefile不算是很复杂，如果不了解的话建议看看Coolshell陈皓的<a href="http://blog.csdn.net/haoel" target="_blank" rel="external">跟我一起写Makefile</a>，入门很实用。而且一旦自己有了一个Makefile模板，后面新的工程基本修改几个参数就可以直接套用了。</p>
<h3 id="5-1-3_Advanced_REST_client/_curl">5.1.3 Advanced REST client/ curl</h3><p>　　HTTP协议的调试，用这两个工具可以快速的构造请求，显示服务端返回信息。Advanced REST client是Chrome的一个程序，跨平台的，而且图形化的操作更加好使。</p>
<h3 id="5-1-4_Python">5.1.4 Python</h3><p>　　最后写个Python，是当自己需要批量导入已有数据的时候，Python的urllib和json库可以方便的进行批操作。</p>
<h3 id="5-1-5_valgrind">5.1.5 valgrind</h3><p>　　算是个神器，建议写完程序上线之前先用这家伙检查一下，可以检测使用未初始化变量、内存泄露等各种不服，如果想服务程序长期稳定运行，不得不考虑这些因素的。</p>
<h2 id="5-2_经验教训">5.2 经验教训</h2><h3 id="5-2-1_MySQL字符串MD5＋索引">5.2.1 MySQL字符串MD5＋索引</h3><p>　　数据库建立索引，其内部可以通过BTREE/HASH的方式，大大加快数据库的检索速度。参见之前的数据库设计，字符串模式直接采用了TEXT的数据类型，而虽然TEXT可以建立索引，但是必须指定前缀长度。这里采用了一个简单的方式，就是添加一个TEXT对应的MD5值字段，然后将TEXT的MD5值放到这个字段中，然后对这个字段建立索引。虽然，相关的文献建议，不要使用MD5/SHA1这类函数作为哈希函数，因为这些是设计的强加密函数，目的是最大程度的消除冲突性，使用之会带来存储和性能的损耗，但是这样使用就可以支持查询MD5不用考虑冲突情况了。<br>　　建议的方式：使用CRC32，或者自设计合理的HASH函数，查询的时候将MD5和原本TEXT域都加入到查询条件中即可。关于MySQL数据类型和索引，将会在后面的文章中做一次学习和整理。<br>　　注：事后发现，我的字符串字段还是使用VARCHAR(M)要比TEXT合适一些。</p>
<h3 id="5-2-2_项目参数配置文件化">5.2.2 项目参数配置文件化</h3><p>　　通过命令行参数+getopt也可以为程序设置参数，但是一旦参数多了，或者参数值比较复杂，用起来就会觉得不方便，此时还是用配置文件的方式比较稳妥，而且参数固化到配置文件后也方便部署。还不清楚开源软件的配置有没有什么解析库，但是既然这里用了json-c库，就把配置文件直接设计成json格式的了。</p>
<h3 id="5-2-3_MySQL的FULLTEXT全文索引">5.2.3 MySQL的FULLTEXT全文索引</h3><p>　　CHAR/VARCHAR/TEXT可以建立FULLTEXT索引，可以用关键字做搜索引擎式的检索，能返回匹配纪录以及score，难道我又画蛇添足了？？？不过InnoDB在5.6版本才引入此特性，而且对中文这类需要分词的语言支持不行，基本都查不到～～～国人，请自强！</p>
<h3 id="5-2-4_程序运行">5.2.4 程序运行</h3><p>　　程序本地控制台运行没有问题，也没啥内存泄漏，到服务器上面后台运行后，大概几个小时就挂掉了，后面用strace跟踪后，发现是“killed by SIGHUP”，这时候想到ss客户端运行的时候用nohup运行的，果真加了这个前缀后，程序跑的HI HI的。是不是要像SIGPIPE一样忽略掉这个信号呢？再或者将其作为守护进程的方式启动运行。<br>　　程序运行有时候需要动态传递给程序一些信息，这时候想到的办法是：寻找一个自定义信号(比如SIGUSR1)及其相应函数，然后把要传递的信息写入固定的文件中，再向运行的程序手动发送该信号，从信号的响应函数中加载这些信息。<br>　　还有就是程序分Debug和Release版本，在Debug中调试信息多一些，关键检查点可以考虑让程序ABORT然后打印出调用栈，这样可以修改让程序更加健壮。</p>
<h3 id="5-2-5_Bug追踪">5.2.5 Bug追踪</h3><p>　　真是程序不上线跑个几天，永远不知道自己挖了多少坑啊：(1)MySQL任何涉及到字符串插入查询的，都要用mysql_real_escape_string处理一下，因为你的用户啥都可能输入，比如可恶的emoji表情等。(2)每当用strncpy你就要格外的小心，当src小于n的时候，des的末尾也会使用’\0’补齐到n长度！</p>
<p>　　当然，说不上有啥干货，很多大神可能觉得还很幼稚。只是自己写出项目过程中的心得感受，望各位大神指正补充。</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Libevent学习笔记（二）：Memcached中Libevent和线程池使用初探]]></title>
      <url>https://taozj.org/201605/learn-note-of-libevent-(2)-thread-pool-in-memcached.html</url>
      <content type="html"><![CDATA[<p>　　这些天想弄一下缓存，减少程序查询数据库的压力，而这方面的王者基本就是memcached和redis了。克隆了一份memcached的源码，发现是基于Libevent+线程池的实现方式，大致看了一下感觉很有启发。正好前两天看的Libevent手册，而且相比自己写的<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">线程池模型</a>，也很好奇企业级线程模型的实现方式，就顺着memcached初始化的流程了解梳理一下了。</p>
<p><img src="/post_images/images/201605/3ff7aa1a8af4a62f0483e7d955872118.jpg" alt="memcached"></p>
<h1 id="1-_main_[memcached-c]">1. main [memcached.c]</h1><p>　　memcached启动时候执行memcached.c中的main函数，在加载了好长的初始化配置之后，定义并初始化event_base；<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">static</span> <span class="keyword">struct</span> event_base *main_base;</div><div class="line">main_base = event_init();</div></pre></td></tr></table></figure></p>
<p>　　然后通过调用memcached_thread_init，创建工作者线程<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">memcached_thread_init(settings.num_threads, main_base);</div></pre></td></tr></table></figure></p>
<p>　　创建定时器clock_handler(0, 0, 0);，这个基于Libevent创建的定时器每一秒钟执行一次，用以更新current_time这个表示自从进程启动后的时间长度。<br>　　然后针对服务端参数指定的侦听(ip:port/unix socket)类型，分别调用server_socket_unix/server_sockets函数，绑定指定地址，并为创建的socket添加connect事件，核心代码如下<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// unix socket</span></div><div class="line">listen_conn = conn_new(sfd, conn_listening, EV_READ | EV_PERSIST, <span class="number">1</span>,</div><div class="line">                                 local_transport, main_base)))</div><div class="line"><span class="comment">// tcp</span></div><div class="line">listen_conn_add = conn_new(sfd, conn_listening, EV_READ | EV_PERSIST, <span class="number">1</span>,</div><div class="line">                                             transport, main_base))</div></pre></td></tr></table></figure></p>
<p>　　这个conn_new不仅仅在这里用以侦听套接字分配资源、创建事件侦听，之后所有客户端连接的套接字也会用这个函数。这个函数最终回调的响应函数是event_handler，然后最终调用一个碉堡了名字的函数drive_machine，这个函数内部是一个复杂的有限状态机，会处理所有与套接字相关的连接、关闭、读写等操作。<br>　　listen套接字当接收到客户请求的时候，如果连接OK，并且没有超过最大连接数目，就调用dispatch_conn_new接收请求。这个函数中，会轮询选择要添加的工作线程，然后创建一个等待item，并添加到对应线程的new_conn_queue队列上去，然后向这个线程的读取队列里面写入’c’一个字节表明有一个新的请求，然后对应线程管道读事件就会被触发，执行处理回调函数。<br>　　主线ain_base进入Libevent事件循环中<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* enter the event loop */</span></div><div class="line"><span class="keyword">if</span> (event_base_loop(main_base, <span class="number">0</span>) != <span class="number">0</span>) &#123;</div><div class="line">	retval = EXIT_FAILURE;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h1 id="2-_memcached_thread_init_[thread-c]">2. memcached_thread_init [thread.c]</h1><p>　　上面我们关注的核心在于调用memcached_thread_init这个函数创建nthreads个工作者线程。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> &#123;</div><div class="line">    <span class="keyword">pthread_t</span> thread_id;        <span class="comment">/* unique ID of this thread */</span></div><div class="line">    <span class="keyword">struct</span> event_base *base;    <span class="comment">/* libevent handle this thread uses */</span></div><div class="line">    <span class="keyword">struct</span> event notify_event;  <span class="comment">/* listen event for notify pipe */</span></div><div class="line">    <span class="keyword">int</span> notify_receive_fd;      <span class="comment">/* receiving end of notify pipe */</span></div><div class="line">    <span class="keyword">int</span> notify_send_fd;         <span class="comment">/* sending end of notify pipe */</span></div><div class="line">    <span class="keyword">struct</span> thread_stats stats;  <span class="comment">/* Stats generated by this thread */</span></div><div class="line">    <span class="keyword">struct</span> conn_queue *new_conn_queue; <span class="comment">/* queue of new connections to handle */</span></div><div class="line">    <span class="keyword">cache_t</span> *suffix_cache;      <span class="comment">/* suffix cache */</span></div><div class="line">&#125; LIBEVENT_THREAD;</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">memcached_thread_init</span><span class="params">(<span class="keyword">int</span> nthreads, <span class="keyword">struct</span> event_base *main_base)</span> </span>&#123;</div><div class="line">...</div><div class="line">    threads = <span class="built_in">calloc</span>(nthreads, <span class="keyword">sizeof</span>(LIBEVENT_THREAD));</div><div class="line"></div><div class="line">    dispatcher_thread.base = main_base;</div><div class="line">    dispatcher_thread.thread_id = pthread_self();</div><div class="line"></div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; nthreads; i++) &#123;</div><div class="line">        <span class="keyword">int</span> fds[<span class="number">2</span>];</div><div class="line">   </div><div class="line">        threads[i].notify_receive_fd = fds[<span class="number">0</span>];</div><div class="line">        threads[i].notify_send_fd = fds[<span class="number">1</span>];</div><div class="line"></div><div class="line">        setup_thread(&amp;threads[i]);</div><div class="line">        <span class="comment">/* Reserve three fds for the libevent base, and two for the pipe */</span></div><div class="line">        stats.reserved_fds += <span class="number">5</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/* Create threads after we've done all the libevent setup. */</span></div><div class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; nthreads; i++) &#123;</div><div class="line">        create_worker(worker_libevent, &amp;threads[i]);</div><div class="line">    &#125;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　上面把非核心的代码剔除掉，就可以看清memcached_thread_init所做的具体工作了。<br>　　(1) 为每个线程创建LIBEVENT_THREAD结构体，并把自我分发线程的信息记录在dispatcher_thread中；<br>　　(2) 对每个线程的结构体LIBEVENT_THREAD初始化，然后通过pipe创建匿名管道，pipefd[0]指向读端，而pipefd[1]指向写端，然后每个线程就通过这个匿名管道同其他线程进行通信；<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">setup_thread</span><span class="params">(LIBEVENT_THREAD *me)</span> </span>&#123;</div><div class="line">...</div><div class="line">    me-&gt;base = event_init();</div><div class="line"></div><div class="line">    <span class="comment">/* Listen for notifications from other threads */</span></div><div class="line">    event_set(&amp;me-&gt;notify_event, me-&gt;notify_receive_fd,</div><div class="line">              EV_READ | EV_PERSIST, thread_libevent_process, me);</div><div class="line">    event_base_set(me-&gt;base, &amp;me-&gt;notify_event);</div><div class="line">    event_add(&amp;me-&gt;notify_event, <span class="number">0</span>);</div><div class="line">    </div><div class="line">    me-&gt;new_conn_queue = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">struct</span> conn_queue));</div><div class="line">    cq_init(me-&gt;new_conn_queue);</div><div class="line"></div><div class="line">    me-&gt;suffix_cache = cache_create(<span class="string">"suffix"</span>, SUFFIX_SIZE, <span class="keyword">sizeof</span>(<span class="keyword">char</span>*),  <span class="literal">NULL</span>, <span class="literal">NULL</span>);</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其中的setup_thread函数中，为每一个线程创建一个event_base，然后添加之前管道的读写时间侦听；同时每个线程还创建了一个等待队列，所有的新请求会添加到这个等待队列上面去。<br>　　在匿名管道的读写事件的相应函数thread_libevent_process上，会尝试读取一个字节,如果是上面写入的’c’，就表明有待处理的请求，然后就从等待队列new_conn_queue中取出一个item，然后处理。处理的方式就是确认这个连接，分配相应的资源，然后再丢到上面的那个event_handler-&gt;drive_machine的状态机中去!<br>　　(3) 调用create_worker(worker_libevent, &amp;threads[i]);实行真正创建线程操作，其内部就是一个pthread_create；</p>
<h1 id="3-总结">3.总结</h1><p>　　Memcached工作方式可以描述如下：<br>　　软件启动的时候，创建event_base，并且根据设置类型创建侦听的tcp/udp socket或者unix socket，然后为这些套接字创建读侦听事件，加入到event_base上，等待客户端连接；<br>　　创建工作线程池，每个工作线程创建自己的event_base；创建一个等待队列，新连接的客户请求都会挂在这个队列上；创建一个匿名管道，并为管道创建读写侦听事件；<br>　　当新的客户端连接上来有请求时候，主线程的侦听事件回调函数会被激活，条件满足后接受这个连接，然后选取一个工作线程，创建等待item挂到其队列上，然后向其管道写入一个c，对应线程管道读事件被激活，读取一个c，并从队列中取出一个请求处理；<br>　　Memcache对所有socket的处理都是event_handler-&gt;drive_machine中处理的。<br>　　可以说，memcached在线程池在等待连接和事件处理中都充分利用了Libevent的异步事件，所以效率是非常之高的。自己的那个线程池，主要是将所有的任务都放到一个链表队列中，当线程发现没有任务的时候，就会用pthread_cond_wait阻塞睡眠，当主线程发现等待的任务太多，就会用pthread_cond_signal唤醒睡眠线程（不会惊群）。总体会让人感觉，把任务事先分给各个队列，吞吐量要大一些，让任务阻塞在select、poll、epoll上，会比自己控制睡眠唤醒要高效可靠！</p>
<p>本文完!</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[对libmicrohttpd添加FastCGI协议支持]]></title>
      <url>https://taozj.org/201605/fastcgi-support-for-http-server-libmicrohttpd.html</url>
      <content type="html"><![CDATA[<p>　　在以前的<a href="/201604/oversee-of-http-based-on-libmicrohttpd.html">《基于libmicrohttpd的HTTP服务器初探》</a>中，libmicrohttpd是可以返回文件系统中的静态网页的，所以挂GitHub Pages的静态博客是没有问题的，但是对于PHP这类动态网页就无能为力了。今天逛V2ex就看见一个家伙把自己简短实现的PHP Web Server挂上来求Star。乍一看用C代码处理HTTP协议，不是很感冒，但是通过FastCGI支持PHP还是挺合寡人口味的。<br><img src="/post_images/images/201605/6c34d4fb192041d50c6d246d1a8e8d90.jpg" alt="FastCGI"><br><a id="more"></a><br>　　基本来说，PHP这类脚本语言需要解释器动态执行生成结果，传统的CGI需要不断启动解释器(fork进程)、加载配置、运行脚本返回结果（通过标准输入、输出、标准错误）、关闭进程，大量的资源用于不断创建销毁进程，效率很低。于是改良版的FastCGI协议出来了，主要是通过Master-Worker进程池的方式，再加上I/O线路多路复用模式，提高了效率。<br>　　之前配置过Nginx Web Server，其实从其配置文件中也猜测出了一些端倪。Nginx的fastcgi_pass可以通过ip:port或者unix套接字方式同php-fpm(FastCGI的一个实现)来进行数据交互，所以Nginx的ngx_http_fastcgi_module.c模块也是一个FastCGI很好的参照模板(只是苦于现在不了解Nginx的数据流,所以看起来很晕乎)！<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">location ~ \.php$ &#123;</div><div class="line"><span class="comment"># Test for non-existent scripts or throw a 404 error</span></div><div class="line"><span class="comment"># Without this line, nginx will blindly send any request ending in .php to php-fpm</span></div><div class="line">try_files <span class="variable">$uri</span> =404;</div><div class="line">fastcgi_pass unix:/run/php-fpm.socket;</div><div class="line"></div><div class="line"><span class="comment"># include /etc/nginx/fastcgi.conf;</span></div><div class="line">fastcgi_param  SCRIPT_FILENAME    <span class="variable">$document_root</span><span class="variable">$fastcgi_script_name</span>;</div><div class="line">fastcgi_param  QUERY_STRING       <span class="variable">$query_string</span>;</div><div class="line">fastcgi_param  REQUEST_METHOD     <span class="variable">$request_method</span>;</div><div class="line">fastcgi_param  CONTENT_TYPE       <span class="variable">$content_type</span>;</div><div class="line">fastcgi_param  CONTENT_LENGTH     <span class="variable">$content_length</span>;</div><div class="line"></div><div class="line">fastcgi_param  SCRIPT_NAME        <span class="variable">$fastcgi_script_name</span>;</div><div class="line">fastcgi_param  REQUEST_URI        <span class="variable">$request_uri</span>;</div><div class="line">fastcgi_param  DOCUMENT_URI       <span class="variable">$document_uri</span>;</div><div class="line">fastcgi_param  DOCUMENT_ROOT      <span class="variable">$document_root</span>;</div><div class="line">fastcgi_param  SERVER_PROTOCOL    <span class="variable">$server_protocol</span>;</div><div class="line">fastcgi_param  HTTPS              <span class="variable">$https</span> <span class="keyword">if</span>_not_empty;</div><div class="line"></div><div class="line">fastcgi_param  GATEWAY_INTERFACE  CGI/1.1;</div><div class="line">fastcgi_param  SERVER_SOFTWARE    nginx/<span class="variable">$nginx_version</span>;</div><div class="line"></div><div class="line">fastcgi_param  REMOTE_ADDR        <span class="variable">$remote_addr</span>;</div><div class="line">fastcgi_param  REMOTE_PORT        <span class="variable">$remote_port</span>;</div><div class="line">fastcgi_param  SERVER_ADDR        <span class="variable">$server_addr</span>;</div><div class="line">fastcgi_param  SERVER_PORT        <span class="variable">$server_port</span>;</div><div class="line">fastcgi_param  SERVER_NAME        <span class="variable">$server_name</span>;</div><div class="line"></div><div class="line"><span class="comment"># PHP only, required if PHP was built with --enable-force-cgi-redirect</span></div><div class="line">fastcgi_param  REDIRECT_STATUS    200;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其实FastCGI是语言无关的,知识一个协议。下文用最常见的PHP及其FastCGI实现php-fpm为例子说明。</p>
<h1 id="一、向FastCGI发送请求">一、向FastCGI发送请求</h1><p>　　总体看来，FastCGI算是很简单的协议了，就是要求Web Server以规定的格式，向php-fpm指定的ip:port或者unix socket连接后发送数据，然后读取php-fpm的返回就可以了。由于socket可以配置成多路复用的模式，所以请求的时候用一个requestId来标示，在会话结束之后requestId失效，可以被后面再次利用。这样也可以感觉到，一个ip:port或者unix socket只能被一个程序使用，否则读到的数据可能是别的程序的回答，但是本程序又处理不了，所以/run/php-fpm。socket启动后都是属于nginx的。<br>　　接着上次的设计，当libmicrohttpd接收请求的url，发现文件名以。php结尾的时候，就连接php-fpm，然后将数据发送给php-fpm程序，接下读取php-fpm的返回结果给客户端就可以了，这也就是Nginx的fastcgi_pass的意义。<br>　　针对HTTP的GET和POST方式，发送给php-fpm有细微的差别，所以这里分开描述。统一说一下FastCGI的数据是要求pad到8字节对其的，在操作的过程中需要注意。<br><img src="/post_images/images/201605/8fc57d40055d3d0f9965f253effe0e44.png" alt="FastCGI flow"></p>
<h2 id="1-1_GET方式">1.1 GET方式</h2><p>　　本身没有消息体，传递的参数位于url上面。发送的过程如下:<br>　　(1) 创建socket或者unix socket，然后连接配置文件指定的ip:port或者unix socket path；<br>　　(2) 创建requestId，发送FCGI_RESPONDER的FCGI_BEGIN_REQUEST请求(其他两类FCGI_AUTHORIZER和FCGI_FILTER暂不考虑)；<br>　　(3) 发送不定个数的FCGI_PARAMS，并以空FCGI_PARAMS为结束标记。这里可以按照Nginx配置文件的参数名传递相应的参数值，很多参数可以从Libmicrohttpd的MHD_Connection连接中提取，对于GET最重要的是传递SCRIPT_FILENAME，其值为请求的文件在服务器文件系统上的绝对路径；然后如果请求的url有参数，将参数部分通过QUERY_STRING传递。这里需要吐槽一下，libmicrohttpd自动将GET的数据都key-value化了，而且貌似还找不回原始表示的参数，难道要我自己手动再连接起来?这里不需要传递CONTENT_LENGTH参数，其它参数能提供最好提供，全的参数名可以查找RFC 3875 CGI规范。<br>　　(4) GET请求类型不需要发送FCGI_STDIN数据，这里可以直接读取php-fpm的返回了。</p>
<h2 id="1-2_POST方式">1.2 POST方式</h2><p>　　url即是访问的路径/文件，要发送的数据放在内部传递过来。所以多了一步将POST数据传递给php-fpm。<br>　　(1) 创建socket或者unix socket，然后连接配置文件指定的ip:port或者unix socket path；<br>　　(2) 创建requestId，发送FCGI_RESPONDER的FCGI_BEGIN_REQUEST请求；<br>　　(3) 发送不定个数的FCGI_PARAMS，并以空FCGI_PARAMS为结束标记。这里重点需要传递CONTENT_LENGTH参数，为POST数据的长度；<br>　　(4) 创建FCGI_STDIN格式的包，将POST数据发送给php-fpm。每次发送的最大长度为FCGI_MAX_LENGTH，所以如果POST的数据太大，可以连续发多个FCGI_STDIN数据包。最后发送空FCGI_STDIN表示结束；<br>　　(5) 读取php-fpm返回；</p>
<h1 id="二、读取FastCGI的结果，并返回给客户">二、读取FastCGI的结果，并返回给客户</h1><p>　　通过上面发送完请求后，就可以直接读socket得到php-fpm的返回了。<br>　　Web Server一般先读取FCGI_HEADER_LEN一个头部的长度，然后解析这个头部，看返回的requestId是不是正确。然后查看返回类型:<br>　　(1) FCGI_STDOUT:正常的php-fpm处理结果。通常第一次返回会添加一个”X-Powered-By: PHP/5。6。20-pl0-gentoo\r\nContent-type: text/html; charset=UTF-8\r\n\r\n”这样的头部信息，Web Server可以选择将这个信息添加到对浏览器的回复头上面。这个头之后的数据就是实际的处理结果，如果返回太长，可能一次读取不玩，多次读取头，然后读取负载大小，直到读取到FCGI_END_REQUEST为止。<br>　　(2) FCGI_STDERR:一般是错误\警告类别的数据。<br>　　(3) FCGI_END_REQUEST:本次请求结束，Web Server可以在这里把收集到的数据汇总返回给浏览器。</p>
<p>　　运行效果如下：<br>　　跑phpinfo()，以及POST提交表单没有问题，但是带参数的GET没有测试，我用的Libmicrohttpd库接受请求的，原因上面说过了。<br><img src="/post_images/images/201605/52f312d5e418f322c65cc8084d1780c4.png" alt="phpinfo"></p>
<h1 id="三、后言">三、后言</h1><p>　　官方网站<a href="http://www.fastcgi.com/" target="_blank" rel="external">fastcgi的网站</a>已经不能访问了，以前很多资料指向的官方实现也找不到了。虽然现在的Apache、Nginx、Lighttpd都有实现fastcgi的模块，只需配置文件几行代码就能正常使用，但是好在FastCGI的协议看似不太复杂，参照别人的修改验证一下，也是挺有意义的。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.mit.edu/~yandros/doc/specs/fcgi-spec.html" target="_blank" rel="external">FastCGI Specification</a></li>
<li><a href="http://andylin02.iteye.com/blog/648412/" target="_blank" rel="external">FastCGI规范</a></li>
<li><a href="http://www.jianshu.com/p/31f61470a325" target="_blank" rel="external">自己动手实现一个web服务器（支持PHP）</a></li>
<li><a href="https://segmentfault.com/q/1010000000256516" target="_blank" rel="external">搞不清FastCgi与PHP-fpm之间是个什么样的关系</a></li>
<li><a href="http://nginx.org/" target="_blank" rel="external">Nginx</a></li>
<li><a href="http://www.php-internals.com/book/?p=chapt02/02-02-03-fastcgi" target="_blank" rel="external">深入理解PHP内核 - 用户代码的执行</a></li>
<li><a href="http://www.faqs.org/rfcs/rfc3875.html" target="_blank" rel="external">RFC 3875 - The Common Gateway Interface (CGI) Version 1.1</a></li>
<li><a href="https://www.hiawatha-webserver.org/files/fastcgi/cgi-fcgi.c.txt" target="_blank" rel="external">cgi-fcgi.c</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Libevent学习笔记（一）：基本使用]]></title>
      <url>https://taozj.org/201605/learn-note-of-libevent-(1)-basic-usage.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　其实，现在高性能网络服务器基本都是异步I/O模式构建的，而Libevent就是对select/poll/epoll这类异步模式接口的封装，通过设置回调函数的方式，在监听文件描述符和套接字读写事件的同时，还兼任定时器和信号接收的管理工作。所以这货对高性能服务器后台开发、跨平台开发、网络开发都具有很大的参考学习价值。官方主页显示很多的项目都用到了Libevent库，而且还可作为主机内部进程间通信和数据交互。这货也考虑到pthread线程模型的同步问题，保证关键数据结构在多线程并行下的数据安全，但是如果能够封装一个线程池模型就更爽了！<br>　　更正：现代服务端的开发，线程池不一定是最合适的服务端模型，像Nginx的实现上，几个进程(当然也可以几个线程)在异步模式下就可以撑起很大的并发量了，协程也是近年来开发的热点，相对来说异步事件的支持下，线程的代价还是略显高了。<br>　　深入了解的第一步就是先学会用它。其实Libevent的主要维护者Nick的博客有一本很好的教程<a href="http://www.wangafu.net/~nickm/libevent-book/" target="_blank" rel="external">libevent book</a>，看完它后再加上Libevent本身附赠的HTTP和DNS服务器的例子sample（Libevent本身封装了evhttp和evdns），基本就可以耍起来啦。看过后会发现，如果对网络开发本身比较熟悉，Libevent还是比较容易理解和上手的。除此之外，Libevent还有一个比较特色的东西，就是封装产生了Bufferevent和evbuffer结构类型，而两者的关系呢，算是Bufferevent是基于evbuffer封装了I/O事件、I/O调度等内容，而evbuffer则是Bufferevent底层的数据承载。<br>　　需要注意的是由于手册的作者就是维护者，所以手册的内容十分的新，有些手册内容在稳定发布版本2.0.22是没有的，代码切换到稳定分支可以使用git branch stable release-2.0.22-stable建立一个稳定分支。<br><img src="/post_images/images/201605/4ba4cf01515ad01fd5f9403f6460d578.png" alt="libevent"></p>
<h1 id="二、服务端使用步骤">二、服务端使用步骤</h1><p>　　这里通过手册描述的过程，对Libevent整个使用过程进行一个梳理。其实，实际使用很多步骤是不用考虑的，因为Libevent在设计上还算是比较智能——当你没有提供参数或者设置的时候，系统会自动给你一个最优的或者常用的配置，比如底层的异步模式。</p>
<h2 id="2-1_配置系统，产生event_base对象">2.1 配置系统，产生event_base对象</h2><p>　　event_base算是Libevent最基础、最重要的对象，因为修改配置、添加事件等，基本都需要将它作为参数传递进去。<br>　　event算是Libevent最常用的元素，对于event在其生命周期有initialized、pending、active这几种状态，当通过event_new创建了事件并关联到event_base上之后，其状态是initialized；然后通过event_add之后，这个事件便是pending的状态，开始侦听了；然后当条件满足之后，其变为active状态，对应的callback函数被调用。<br>　　这个对象通过event_base_new创建，在创建之前还可以设定某些参数：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> event_config *cfg;</div><div class="line"><span class="keyword">struct</span> event_base *base;</div><div class="line"></div><div class="line">cfg = event_config_new();</div><div class="line">event_config_avoid_method(cfg, <span class="string">"select"</span>);   <span class="comment">//避免使用低效率select</span></div><div class="line">event_config_require_features(cfg, EV_FEATURE_ET);  <span class="comment">//使用边沿触发类型</span></div><div class="line"><span class="comment">//event_config_set_flag(cfg, EVENT_BASE_FLAG_PRECISE_TIMER);</span></div><div class="line"><span class="comment">//event_base_new(void); 为简单版本，会根据系统选择最快最合适的类型</span></div><div class="line">base = event_base_new_with_config(cfg);</div><div class="line">event_config_free(cfg);</div><div class="line"><span class="comment">//显示当前使用的异步类型</span></div><div class="line">st_d_print(<span class="string">"Current Using Method: %s"</span>, event_base_get_method(base)); <span class="comment">// epoll</span></div><div class="line"></div><div class="line"><span class="comment">//可选设置优先级数目，然后通过event_priority_set设置事件的优先级</span></div><div class="line"><span class="comment">//0为最高，n_priority-1为最低，此后创建的事件默认优先级为中间优先级</span></div><div class="line">event_base_priority_init(base, <span class="number">3</span>);</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="2-2_针对服务器端和客户端类型的操作">2.2 针对服务器端和客户端类型的操作</h2><p>　　对于网络开发部分，Linux和Windows在网络方面的操作是有差异的，为此Libevent创建了evutil统一的接口来屏蔽两个平台底层的网络开发差异（后悔当时移植程序怎么没有参考这个有价值的东西）。<br>　　由于服务端开发和客户端开发一个主动一个被动，这里分开进行示例。</p>
<h3 id="2-2-1_服务器端操作">2.2.1 服务器端操作</h3><p>　　服务端流程：创建套接字、设置套接字参数(nonblocking等)、绑定地址端口、侦听新连接。<br>　　这么多操作，Libevent封装到了evconnlistener_new_bind中，并创建了连接事件的相应函数accept_conn_cb，同时还可以设置错误回调函数accept_error_cb。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> evconnlistener *listener;</div><div class="line"><span class="keyword">struct</span> sockaddr_in <span class="built_in">sin</span>;</div><div class="line"><span class="built_in">memset</span>(&amp;<span class="built_in">sin</span>, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="built_in">sin</span>));</div><div class="line"><span class="built_in">sin</span>.sin_family = AF_INET;</div><div class="line"><span class="built_in">sin</span>.sin_addr.s_addr = htonl(<span class="number">0</span>);  <span class="comment">//绑定0.0.0.0地址</span></div><div class="line"><span class="built_in">sin</span>.sin_port = htons(<span class="number">8080</span>); <span class="comment">/* Port 8080 */</span></div><div class="line"></div><div class="line">listener = evconnlistener_new_bind(base, accept_conn_cb, <span class="literal">NULL</span>,</div><div class="line">        LEV_OPT_CLOSE_ON_FREE|LEV_OPT_REUSEABLE, <span class="number">-1</span><span class="comment">/*backlog 无限制*/</span>,</div><div class="line">        (<span class="keyword">struct</span> sockaddr*)&amp;<span class="built_in">sin</span>, <span class="keyword">sizeof</span>(<span class="built_in">sin</span>));</div><div class="line">evconnlistener_set_error_cb(listener, accept_error_cb);</div></pre></td></tr></table></figure></p>
<p>　　对于上面引用的两个回调函数，其实现的模板为<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">accept_conn_cb</span><span class="params">(<span class="keyword">struct</span> evconnlistener *listener,</span></span></div><div class="line">    <span class="keyword">evutil_socket_t</span> fd, <span class="keyword">struct</span> sockaddr *address, <span class="keyword">int</span> socklen, <span class="keyword">void</span> *ctx)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">char</span> hbuf[NI_MAXHOST], sbuf[NI_MAXSERV];</div><div class="line"></div><div class="line">    getnameinfo (address, socklen,</div><div class="line">               hbuf, <span class="keyword">sizeof</span>(hbuf),sbuf, <span class="keyword">sizeof</span>(sbuf),</div><div class="line">               NI_NUMERICHOST | NI_NUMERICSERV);</div><div class="line">    st_print(<span class="string">"Welcome (host=%s, port=%s)\n"</span>, hbuf, sbuf);</div><div class="line"></div><div class="line">   <span class="comment">//为新的客户连接socket fd创建Bufferevent事件侦听</span></div><div class="line">    <span class="keyword">struct</span> event_base *base = evconnlistener_get_base(listener);</div><div class="line">    <span class="keyword">struct</span> bufferevent *bev = bufferevent_socket_new(</div><div class="line">            base, fd, BEV_OPT_CLOSE_ON_FREE);</div><div class="line">    bufferevent_priority_set(bev, <span class="number">2</span>);</div><div class="line"></div><div class="line">    bufferevent_setcb(bev, bufferread_cb, <span class="literal">NULL</span>, bufferevent_cb, <span class="literal">NULL</span>);</div><div class="line">    bufferevent_enable(bev, EV_READ|EV_WRITE); <span class="comment">//默认EV_WRITE是使能的，但EV_READ不是</span></div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">accept_error_cb</span><span class="params">(<span class="keyword">struct</span> evconnlistener *listener, <span class="keyword">void</span> *ctx)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">struct</span> event_base *base = evconnlistener_get_base(listener);</div><div class="line">    <span class="keyword">int</span> err = EVUTIL_SOCKET_ERROR();</div><div class="line"></div><div class="line">    st_d_print( <span class="string">"Got an error %d (%s) on the listener. "</span></div><div class="line">            <span class="string">"Shutting down.\n"</span>, err, evutil_socket_error_to_string(err));</div><div class="line">    event_base_loopexit(base, <span class="literal">NULL</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　对于上面的accept_conn_cb函数中，为accept创建的新fd建立EV_READ|EV_WRITE事件侦听。但是上面的回调函数只设置了bufferread_cb和bufferevent_cb，而没有对写设置回调函数。其实这也是现实中常用的情况，程序大多数都阻塞在读的任务上，而一般的写任务也都是基于读到的结果产生对应的写内容，如果为写任务设置回调函数，那么系统检测到输出缓存区可用，便一直调用写回调函数，这可能不是你想要的。<br>　　可以从accept_error_cb中学习Libevent常见的错误处理方式。在Linux中，所有的错误都是通过全局的errno来检测错误信息的，但是Windows使用WSAGetLastError()这种函数得到网络类的错误信息，所以需要使用封装后的EVUTIL_SOCKET_ERROR()和evutil_socket_error_to_string()来实现。<br>　　对于bufferread_cb，就是通用的网络I/O操作，跟服务器端和客户端没有什么差异，这里贴出demo的代码来：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bufferread_cb</span><span class="params">(<span class="keyword">struct</span> bufferevent *bev, <span class="keyword">void</span> *ptr)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">char</span> *msg = <span class="string">"SERVER MESSAGE: WOSHINICOL 桃子大人"</span>;</div><div class="line">    <span class="keyword">char</span> buf[<span class="number">1024</span>]; <span class="keyword">int</span> n;</div><div class="line">    <span class="keyword">struct</span> evbuffer *input = bufferevent_get_input(bev);</div><div class="line">    <span class="keyword">struct</span> evbuffer *output = bufferevent_get_output(bev);</div><div class="line"></div><div class="line">    <span class="keyword">while</span> ((n = evbuffer_remove(input, buf, <span class="keyword">sizeof</span>(buf))) &gt; <span class="number">0</span>)</div><div class="line">    &#123;</div><div class="line">        fwrite(<span class="string">"BUFFERREAD_CB:"</span>, <span class="number">1</span>, <span class="built_in">strlen</span>(<span class="string">"BUFFERREAD_CB:"</span>), <span class="built_in">stderr</span>);</div><div class="line">        fwrite(buf, <span class="number">1</span>, n, <span class="built_in">stderr</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//bufferevent_write(bev, msg, strlen(msg));</span></div><div class="line">    evbuffer_add(output, msg, <span class="built_in">strlen</span>(msg));</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　由上面可以看见，对于evbuffer操作，既可以调用Bufferevent层的封装函数，也可以调用底层的evbuffer的函数接口，Bufferevent接口简单，但是evbuffer类接口比较的底层，但是函数功能很多。具体的细节后文再行描述。</p>
<h3 id="2-2-2_客户端操作">2.2.2 客户端操作</h3><p>　　客户端的开发比较的简单，主要就是建立套接字，连接服务端，就可以进行I/O操作了。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> bufferevent *bev;</div><div class="line"><span class="keyword">struct</span> sockaddr_in <span class="built_in">sin</span>;</div><div class="line"><span class="built_in">memset</span>(&amp;<span class="built_in">sin</span>, <span class="number">0</span>, <span class="keyword">sizeof</span>(<span class="built_in">sin</span>));</div><div class="line"><span class="built_in">sin</span>.sin_family = AF_INET;</div><div class="line">inet_aton(<span class="string">"192.168.1.161"</span>, &amp;<span class="built_in">sin</span>.sin_addr.s_addr);</div><div class="line"><span class="built_in">sin</span>.sin_port = htons(<span class="number">8080</span>); <span class="comment">/* Port 8080 */</span></div><div class="line"></div><div class="line"><span class="comment">//int sockfd = socket(AF_INET, SOCK_STREAM, 0);</span></div><div class="line"><span class="comment">//evutil_make_listen_socket_reuseable(sockfd);</span></div><div class="line"><span class="comment">//evutil_make_socket_nonblocking(sockfd);</span></div><div class="line"><span class="comment">//bev = bufferevent_socket_new(base, sockfd, BEV_OPT_CLOSE_ON_FREE);</span></div><div class="line">bev = bufferevent_socket_new(base, <span class="number">-1</span>, BEV_OPT_CLOSE_ON_FREE);</div><div class="line">bufferevent_setcb(bev, bufferread_cb, bufferwrite_cb, bufferevent_cb, base);</div><div class="line">bufferevent_enable(bev, EV_READ|EV_WRITE);</div><div class="line">bufferevent_socket_connect(bev, (<span class="keyword">struct</span> sockaddr *)&amp;<span class="built_in">sin</span>, <span class="keyword">sizeof</span>(<span class="built_in">sin</span>))</div></pre></td></tr></table></figure></p>
<p>　　如上面注释的代码，对客户端的操作，有两个方法：<br>　　(1)首先创建套接字，然后设置套接字参数，在将这个套接字传递给bufferevent_socket_new函数创建Bufferevent事件，并调用bufferevent_socket_connect链接客户端。<br>　　(2)直接调用bufferevent_socket_new并将套接字参数设置为-1，那么系统会自动创建套接字并完成相应的设置。</p>
<h2 id="2-3_侦听信号事件">2.3 侦听信号事件</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">ct event *ev_signal;</div><div class="line"><span class="comment">//evsignal_new(base, signum, cb, arg)为简洁版本</span></div><div class="line">ev_signal = event_new(base, SIGUSR1, EV_SIGNAL|EV_PERSIST, sigusr1_cb, base);</div><div class="line">event_priority_set(ev_signal, <span class="number">2</span>);</div><div class="line">event_add(ev_signal, <span class="literal">NULL</span>);</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">sigusr1_cb</span><span class="params">(<span class="keyword">evutil_socket_t</span> fd, <span class="keyword">short</span> what, <span class="keyword">void</span> *arg)</span></span>;</div></pre></td></tr></table></figure>
<p>　　对于信号事件，手册说明：对于一个进程，如果有多个event_base，那么请只使用一个event_base处理所有的信号事件，一个程序只有一个event_base能接收到信号事件。</p>
<h2 id="2-4_建立定时器回调">2.4 建立定时器回调</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">struct event *ev_timer;</div><div class="line">struct timeval one_sec = &#123; 1, 0 &#125;; //1s</div><div class="line">int n_calls = 0;</div><div class="line">//evtimer_new(base, callback, arg)为简洁版本</div><div class="line">//EV_TIMEOUT的参数实际是可被忽略的，不传递也是可以的</div><div class="line">ev_timer = event_new(base, -1, EV_PERSIST, timer_cb, &amp;one_sec);</div><div class="line">event_priority_set(ev_timer, 2);</div><div class="line">event_add(ev_timer, &amp;one_sec);</div><div class="line"></div><div class="line">void timer_cb(evutil_socket_t fd, short what, void *arg)；</div></pre></td></tr></table></figure>
<p>　　对于上面的signal和timer事件，其实都没有关联到某一个具体的socket或者fd，其实可以公用同一个callback，然后在处理的callback中，使用what参数来区分到底是由于信号、定时器哪个事件激活了这个回调函数。</p>
<h1 id="2-5_进入事件循环">2.5 进入事件循环</h1><p>　　就像是通常的epoll_wait在一个大的循环里，Libevent提供如下函数进行事件循环检测<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">event_base_loop(base, <span class="number">0</span>);　<span class="comment">//进入事件循环直到没有pending的事件就返回</span></div><div class="line"><span class="comment">//EVLOOP_ONCE　   阻塞直到有event激活，执行回调函数后返回</span></div><div class="line"><span class="comment">//EVLOOP_NONBLOCK 非阻塞类型，立即检查event激活，如果有运行最高优先级的那一类，完毕后退出循环</span></div></pre></td></tr></table></figure></p>
<p>　　如果后面的flags参数为0，那么等价于调用event_base_dispatch。<br>　　默认情况下，如果event_base有pending的事件，就不会结束循环，可以通过调用event_base_loopbreak、event_base_loopexit等函数来跳出终止循环。还需要注意的是，event_base_free只会调用event_del接触event和本身的关系，不会释放event相关的资源，所以如果优雅地写代码的话，需要调用event_free、evconnlistener_free等函数来善后。</p>
<h1 id="三、Bufferevent和evbuffer">三、Bufferevent和evbuffer</h1><p>　　如上面介绍的，如果上面的内容是让系统的各类事件和对应回调函数建立关联，助力于整个系统的设计和架构的话，Bufferevent和evbuffer则是关注于整个系统的数据承载，以完成实际的I/O通信。Bufferevent可以看作是基于evbuffer实现对EV_READ|EV_WRITE事件的侦听，而evbuffer是底层实际数据的承载。</p>
<h2 id="3-1_Bufferevent">3.1 Bufferevent</h2><p>　　Bufferevent支持的类型有：socket-based、asynchronous-IO、filtering、paired类型。socket-based算是最常见的类型，asynchronous-IO主要是Windows下的完成端口异步非阻塞通信类型，filtering和paired常常是针对特殊通信需求的情况。<br>　　Bufferevent创建时候支持的重要标志有：BEV_OPT_CLOSE_ON_FREE当bufferevent被释放的时候，底层的传输也会被释放，比如关闭套接字、释放底层bufferevent等；BEV_OPT_THREADSAFE为Bufferevent创建锁结构，以保证线程安全的，当用户提供的回调函数被执行的时候，会持有这个锁结构；BEV_OPT_DEFER_CALLBACKS延迟执行，事件的回调函数会被排队，当常规event回调执行完之后，才会执行其回调函数。<br>　　Bufferevent的操作在上面已经有示例了，这里将其数据接口整理出来<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 将data指向的数据添加到bufev的输出缓冲区尾部</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">bufferevent_write</span><span class="params">(<span class="keyword">struct</span> bufferevent *bufev, <span class="keyword">const</span> <span class="keyword">void</span> *data, <span class="keyword">size_t</span> size)</span></span>;</div><div class="line"><span class="comment">// 将buf的整个数据移除移动到bufev输出缓冲区的尾部</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">bufferevent_write_buffer</span><span class="params">(<span class="keyword">struct</span> bufferevent *bufev, <span class="keyword">struct</span> evbuffer *buf)</span></span>;</div><div class="line"></div><div class="line"><span class="comment">// 将bufev的输入缓冲区的数据移动到目标位置，注意bufferevent_read返回的是实际读取的数目</span></div><div class="line"><span class="keyword">size_t</span> bufferevent_read(<span class="keyword">struct</span> bufferevent *bufev, <span class="keyword">void</span> *data, <span class="keyword">size_t</span> size);</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">bufferevent_read_buffer</span><span class="params">(<span class="keyword">struct</span> bufferevent *bufev, <span class="keyword">struct</span> evbuffer *buf)</span></span>;</div></pre></td></tr></table></figure></p>
<p>　　然后，当创建Bufferevent的时候如果使用了BEV_OPT_THREADSAFE参数的时候，初始化这个bufferevent会给这个结构本身以及input、output、underlying等结构产生锁，而且在读写callback以及defer延迟的callback时候，都会调用_bufferevent_incref_and_lock、_bufferevent_decref_and_unlock等来获得和释放锁。只有当显式指明BEV_OPT_UNLOCK_CALLBACKS的时候，才会在调用BEV_OPT_DEFER_CALLBACKS的时候不加锁结构。或许也这种情况下才是用户空间锁操作锁的时候，为了更小的锁粒度获得效率的提升？<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bufferevent_lock</span><span class="params">(<span class="keyword">struct</span> bufferevent *bufev)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bufferevent_unlock</span><span class="params">(<span class="keyword">struct</span> bufferevent *bufev)</span></span>;</div></pre></td></tr></table></figure></p>
<h2 id="3-2_evbuffer">3.2 evbuffer</h2><p>　　evbuffer是一个被优化为前端删除，后端添加的bytes queue，用于方便高效的网络IO。其代码实现在buffer.c中，而头文件evbuffer-internel.h为其内部数据结构定义的地方，而用户调用接口的声明主要在event2/buffer.h中。结构上，每个evbuffer内部有多个evbuffer_chain结构构成的链表组成，所以数据在其内部不一定是物理连续的。</p>
<h3 id="3-2-1_线程安全">3.2.1 线程安全</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_enable_locking</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">void</span> *lock)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">evbuffer_lock</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">evbuffer_unlock</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf)</span></span>;</div></pre></td></tr></table></figure>
<p>　　多个线程访问evbuffer是不安全的，所以如果要在多个线程中访问，首先需要使用evbuffer_enable_locking来让evbuffer支持锁结构。通过查看文档和代码，对于evbuffer的底层函数(比如evbuffer_read、evbuffer_write)，都是自动加了锁的，如果函数只调用了这些操作一次，那么不需要额外的加锁结构，如果在函数某个阶段有多次的evbuffer操作，那么需要使用上面的evbuffer_lock/evbuffer_unlock来加解锁保护。</p>
<h3 id="3-2-2_evbuffer常用接口罗列">3.2.2 evbuffer常用接口罗列</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">size_t</span> evbuffer_get_length(<span class="keyword">const</span> <span class="keyword">struct</span> evbuffer *buf);</div><div class="line"><span class="keyword">size_t</span> evbuffer_get_contiguous_space(<span class="keyword">const</span> <span class="keyword">struct</span> evbuffer *buf);</div></pre></td></tr></table></figure>
<p>　　evbuffer_get_length返回evbuffer整体保存了的数据的字节数。<br>　　evbuffer_get_contiguous_space返回第一个evbuffer_chain的offset位置，而offset=buffer+misalign+实际负载，实际就是开头空余空间+实际的负载字节数，也就是末尾空闲空间开始的位置。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_add</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">const</span> <span class="keyword">void</span> *data, <span class="keyword">size_t</span> datlen)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_add_printf</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">const</span> <span class="keyword">char</span> *fmt, ...)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_add_vprintf</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">const</span> <span class="keyword">char</span> *fmt, va_list ap)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_prepend</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">const</span> <span class="keyword">void</span> *data, <span class="keyword">size_t</span> size)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_prepend_buffer</span><span class="params">(<span class="keyword">struct</span> evbuffer *dst, <span class="keyword">struct</span> evbuffer* src)</span></span>;</div></pre></td></tr></table></figure>
<p>　　add类函数都是将数据添加到evbuffer结尾的操作，而prepend类函数是将数据添加到evbuffer开始的操作。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_add_buffer</span><span class="params">(<span class="keyword">struct</span> evbuffer *dst, <span class="keyword">struct</span> evbuffer *src)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_remove_buffer</span><span class="params">(<span class="keyword">struct</span> evbuffer *src, <span class="keyword">struct</span> evbuffer *dst, <span class="keyword">size_t</span> datlen)</span></span>;</div></pre></td></tr></table></figure>
<p>　　都是将evbuffer的数据从src移动到dst中，这里的函数都是优化过的，如果可能就只有evbuffer_chain结构的转移，不会有底层实际数据的拷贝。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">char</span> *<span class="title">evbuffer_pullup</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">ev_ssize_t</span> size)</span></span>;</div></pre></td></tr></table></figure>
<p>　　重新排列evbuffer，使得前size个字节保证在同一个evbuffer_chain的连续位置，当size&lt;0的时候，会对所有的数据进行重排，如果size等于0或者大于实际的datalen，不会进行任何操作，返回NULL；否则返回重排后实际数据的开始地址。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_drain</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">size_t</span> len)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_remove</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">void</span> *data, <span class="keyword">size_t</span> datlen)</span></span>;</div><div class="line"><span class="keyword">ev_ssize_t</span> evbuffer_copyout(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">void</span> *data, <span class="keyword">size_t</span> datlen);</div></pre></td></tr></table></figure>
<p>　　evbuffer_remove会从开头将数据拷贝到data指向的位置，evbuffer_drain会从开头直接释放len长度的buf数据。两者当len的参数大于实际的数据长度的时候，会对所有的数据进行操作，返回实际拷贝/删除的字节数。<br>　　evbuffer_copyout会将数据拷贝到data，但是不会drain删除evbuffer的数据。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> evbuffer_eol_style &#123;</div><div class="line">EVBUFFER_EOL_ANY,  <span class="comment">//不建议使用</span></div><div class="line">EVBUFFER_EOL_CRLF,  <span class="comment">//"\r\n"或者"\n"</span></div><div class="line">EVBUFFER_EOL_CRLF_STRICT,  <span class="comment">//"\r\n"</span></div><div class="line">EVBUFFER_EOL_LF  <span class="comment">//"\n" &#125;;</span></div><div class="line"><span class="function"><span class="keyword">char</span> *<span class="title">evbuffer_readln</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">size_t</span> *n_read_out, <span class="keyword">enum</span> evbuffer_eol_style eol_style)</span></span>;</div></pre></td></tr></table></figure>
<p>　　这是基于某些程序基于行处理而设计的，比如HTTP协议的头部信息等。其会从头提取并drain到一行内容，然后通过malloc分配的空间，拷贝出不带换行符的信息出来（换行符会在evbuffer中删除掉），并在结尾添加’\0’结束符，拷贝的数据长度会保存在n_read_out参数中。用完之后，用户记得free返回的内存空间。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> evbuffer_ptr &#123;</div><div class="line">       <span class="keyword">ev_ssize_t</span> pos;</div><div class="line">       <span class="comment">/* Do not alter the values of fields. */</span></div><div class="line">       <span class="keyword">struct</span> &#123;</div><div class="line">          <span class="keyword">void</span> *chain;</div><div class="line">          <span class="keyword">size_t</span> pos_in_chain;</div><div class="line">    &#125; <span class="number">_</span>internal;</div><div class="line">&#125;;</div><div class="line"><span class="function"><span class="keyword">struct</span> evbuffer_ptr <span class="title">evbuffer_search</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">const</span> <span class="keyword">char</span> *what, <span class="keyword">size_t</span> len, <span class="keyword">const</span> <span class="keyword">struct</span> evbuffer_ptr *start)</span></span>;</div><div class="line"><span class="function"><span class="keyword">struct</span> evbuffer_ptr <span class="title">evbuffer_search_range</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">const</span> <span class="keyword">char</span> *what, <span class="keyword">size_t</span> len, <span class="keyword">const</span> <span class="keyword">struct</span> evbuffer_ptr *start, <span class="keyword">const</span> <span class="keyword">struct</span> evbuffer_ptr *end)</span></span>;</div><div class="line"><span class="function"><span class="keyword">struct</span> evbuffer_ptr <span class="title">evbuffer_search_eol</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">struct</span> evbuffer_ptr *start, <span class="keyword">size_t</span> *eol_len_out, <span class="keyword">enum</span> evbuffer_eol_style eol_style)</span></span>;</div></pre></td></tr></table></figure>
<p>　　提供在evbuffer中搜索特定长度len字符串what的功能。Libevent使用了struct evbuffer_ptr这么一个结构，将evbuffer内部离散的evbufferchain的buffer映射成pos这么一个连续的偏移空间。如果搜索到，那么pos为其位置，否则-1表示没有搜索到。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">enum</span> evbuffer_ptr_how &#123;</div><div class="line">        EVBUFFER_PTR_SET,</div><div class="line">        EVBUFFER_PTR_ADD</div><div class="line">&#125;;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_ptr_set</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">struct</span> evbuffer_ptr *pos, <span class="keyword">size_t</span> position, <span class="keyword">enum</span> evbuffer_ptr_how how)</span></span>;</div><div class="line">evbuffer_ptr_set(buf, &amp;p, <span class="number">0</span>, EVBUFFER_PTR_SET);</div></pre></td></tr></table></figure>
<p>　　类似文件系统seek的方式来操作pos位置，由于evbuffer内部不一定是连续的位置，所以不能简单的修改pos的位置，只能通过这种方式，将pos的更改更新到内部结构的evbufferchain和偏移上去。返回0表示修改成功，否则-1。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> evbuffer_iovec &#123;</div><div class="line">        <span class="keyword">void</span> *iov_base;</div><div class="line">        <span class="keyword">size_t</span> iov_len;</div><div class="line">&#125;;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_peek</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">ev_ssize_t</span> len, <span class="keyword">struct</span> evbuffer_ptr *start_at, <span class="keyword">struct</span> evbuffer_iovec *vec_out, <span class="keyword">int</span> n_vec)</span></span>;</div><div class="line"></div><div class="line">n = evbuffer_peek(buf, <span class="number">4096</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</div><div class="line">v = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">struct</span> evbuffer_iovec)*n);</div><div class="line">n = evbuffer_peek(buf, <span class="number">4096</span>, <span class="literal">NULL</span>, v, n);</div></pre></td></tr></table></figure>
<p>　　高速网络的一个关键就是避免数据的拷贝，为此，Libevent创建了一个evbuffer_iovec的结构，然后通过evbuffer_peek，可以将evbuffer内部的evbuffer_chain结构的数据位置暴露到evbuffer_iovec，用户可以直接访问读取evbuffer的内部数据了。需要注意的是这里只作读取，修改数据会导致不可预料的结果。<br>　　evbuffer_peek会在要么指定的字节数都映射了，或者传递evbuffer_iovec使用完了就会返回。通常使用方式如上文，是先调用evbuffer_peek决定需要多少个evbuffer_iovec结构数目，然后再进行映射操作，保证需要的字节数目都能映射完成。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_reserve_space</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">ev_ssize_t</span> size, <span class="keyword">struct</span> evbuffer_iovec *vec, <span class="keyword">int</span> n_vecs)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_commit_space</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">struct</span> evbuffer_iovec *vec, <span class="keyword">int</span> n_vecs)</span></span>;</div></pre></td></tr></table></figure>
<p>　　这是一个evbuffer高速写入的方式，因为先前的evbuffer_add实际也是先将数据准备好，然后再memcpy拷贝到evbuffer内部的，而这里先通过evbuffer_reserve_space在evbuffer的结尾先预留出需要写的数据空间，然后将空间的地址通过evbuffer_iovec返回，应用程序就可以直接操作这些地址，最后通过evbuffer_commit_space提交就可以了。这里n_vecs可用的只有1、2两个数字，通常推荐2，因为1很有可能会导致数据的重排，降低效率。<br>　　evbuffer_commit_space成功返回0，失败返回-1。<br>使用这些函数的时候必须格外的小心，在调用evbuffer_reserve_space之后和evbuffer_commit_space之前，不能调用任何重排或者追加evbuffer的操作，那样会导致之前evbuffer_reserve_space返回的地址不一致了。在多线程中也要注意用锁保护相应的数据。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_write</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">evutil_socket_t</span> fd)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_write_atmost</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">evutil_socket_t</span> fd, <span class="keyword">ev_ssize_t</span> howmuch)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_read</span><span class="params">(<span class="keyword">struct</span> evbuffer *buffer, <span class="keyword">evutil_socket_t</span> fd, <span class="keyword">int</span> howmuch)</span></span>;</div></pre></td></tr></table></figure>
<p>　　实际的I/O网络操作，注意如果evbuffer被关联到了bufferevent，那么网络I/O是自动触发的，用户不需要使用这些函数。他们会返回实际读取或者写入的字节数目，需要注意的是，如果fd是非阻塞的套接字/文件描述符，需要检查错误的类型来决定是因为I/O当前无法完成还是别的错误类型。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_add_file</span><span class="params">(<span class="keyword">struct</span> evbuffer *output, <span class="keyword">int</span> fd, <span class="keyword">ev_off_t</span> offset, <span class="keyword">size_t</span> length)</span></span>;</div></pre></td></tr></table></figure>
<p>　　直接将打开的文件描述符fd作为参数，然后将文件中的数据用于读取、网络发送等操作。其内部运用sendfile/mmap等机制，避免数据拷贝到用户空间再拷贝到内核空间，增加了操作的效率。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_freeze</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">int</span> at_front)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">evbuffer_unfreeze</span><span class="params">(<span class="keyword">struct</span> evbuffer *buf, <span class="keyword">int</span> at_front)</span></span>;</div></pre></td></tr></table></figure>
<p>　　会禁止对evbuffer的头部/尾部的修改操作，通常在内部使用。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.wangafu.net/~nickm/libevent-book/" target="_blank" rel="external">Fast portable non-blocking network programming with Libevent</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Apache Lucy的全文检索引擎的使用]]></title>
      <url>https://taozj.org/201605/usage-of-apache-lucy-fulltext-index.html</url>
      <content type="html"><![CDATA[<h1 id="一、前言">一、前言</h1><p>　　给定个需求：如果当客户提的问题在问题库中没有精确检索到，怎么推荐出最相近的问题呢？<br>　　其实，本来想用之前的那个LSI来实现的，就是当SVD分解后得到特征矩阵和特征值，那么任何一个新的问题输入，就可以先计算得到降维的特征表示，然后根据向量相似距离就可以找出来了。用gensim的计算库工程是可以实现的，因为具有增量计算方法，可以不断新加新文本，淘汰文本就直接把相关问题的降维向量剔除就可以了。不过其主要遇到的问题还是SVD的计算量很复杂，而且当文本短而term极为稀疏的时候，如果要让检索有效，topic_num值必须设置很大才行。<br>　　然后曲折另外一个解决方案：使用现有的全文检索引擎，将待选答案建立索引，有新查询语句，将其分词后在索引中查找即可，这等于把搜索全部外包出去了。不过这样也有缺点：没有了语义检的特性，不过语料有限情况下这种特性并不明显，明文检索已经可以；没有降纬减噪的功能，可以通过去除停留词达到部分减噪效果。<br>　　当前开源的全文检索引擎很多，比如Lucene、Solr、Sphinx、Xapian等等。考虑到语言、项目集成等因素，最终选择了Apache Lucy，这个家伙算是KinoSearch的继任者，算是对Lucene的C/Perl语言的简洁移植版本，所以C语言可以很方便的在现有的项目中调用。</p>
<p><img src="/post_images/images/201605/b2b52063d6234b4d1b118a107d76b6e8.png" alt="Apache Lucy"></p>
<h1 id="二、使用方法和注意事项">二、使用方法和注意事项</h1><p>　　Lucy的使用方法、接口感觉跟之前我使用的Whoosh(一个全Python实现的全文检索引擎)十分的相似，由于接触到的还不是很多，不知道是不是大多数的搜索引擎思路都是一致的。</p>
<h2 id="2-1_使用步骤">2.1 使用步骤</h2><p>　　(1) 创建检索信息的表（Schema）结构（主要是各个索引列的名字、类型等信息）；<br>　　(2) 指明文件系统存储路径，然后调用Indexer_new创建索引（Indexer）；<br>　　(3) 针对每条记录/文档，创建成一个Doc对象，然后通过Indexer_Add_Doc将文档添加到索引中<br>　　(4) Indexer_Commit提交计算生成索引数据；<br>　　(5) 如果需要检索数据，使用IxSearcher_new方法创建IndexSearcher对象，然后使用IxSearcher_Hits检索遍历结果，而分别调用HitDoc_Get_Doc_ID和HitDoc_Get_Score可以得到文档ID和Rank Score；<br>　　(6) 如果需要修改数据（比如增加或者删除Doc），就需要用Indexer_new创建索引，然后使用Indexer_Add_Doc、Indexer_Delete_By_Doc_ID等方法来实现。<br><a id="more"></a></p>
<h2 id="2-2_注意事项：">2.2 注意事项：</h2><p>　　(1) Lucy的索引是基于文件系统的，所以使用Indexer更新、修改索引的时候会有锁结构。所以如果数据可以分类并且各类之间独立性比较强的话，建议按类别分别建立索引，这样可以提高并发量；<br>　　(2) Lucy的字段有FullTextType类型和StringType类型，前者可以被检索，而后者只能全文匹配，对于需要精确查找和删除的需求的话，可以针对每个文档分别建立这两个类型的列，以方便精确查找操作。<br>　　(3) 长时间的修改索引会导致分片，从而影响到后续检索的性能。<a href="http://lucy.apache.org/docs/c/Lucy/Docs/Cookbook/FastUpdates.html" target="_blank" rel="external">Background merging</a>的机制还是不错的，不过我还没看明白到底怎么个使用方法。</p>
<h2 id="2-3_槽点">2.3 槽点</h2><p>　　(1) 不知道Lucy挂着ClownFish的原因是什么，这让代码十分晦涩，连个字符串也要创建和DECREF。本来想瞄一眼内部原理的，一瞅底层代码——巨坑，放弃了。<br>　　(2) Lucy官方支持十几种语言，但中文不支持，不过也不能怪人家老外，国人当自强。不支持中文不会影响到使用，只是Snowball功能没法使用，这个Snowball就是将同个字进行合并的，比如将horse、horses、horsing变成hors，fishing、fished、fisher变成fish，argue、argued、argues、arguing、argus变成argu，其实中文也没有这么个概念吧，但是如果有人能把中文的同义词归类做进去，会是个刻骨铭心的贡献啊！（别找我，我没时间～）<br>　　(3) 你说他是C API但也不是纯粹的C，当有些函数调用出错的时候，不是返回而是给你抛出和异常(Clownfish是不是就搞的跟C++似的)，你还必须注意和捕获这些异常，否则程序就直接挂掉了。据称异常的捕获还是用的setjmp/longjmp来实现的，较为的不安全，可以参见附录的<a href="http://grokbase.com/t/lucy/dev/153ypam587/lucy-dev-trapping-errors-in-c" target="_blank" rel="external">Trapping errors in C.</a>。</p>
<h1 id="三、操作效果">三、操作效果</h1><p>　　对数据库11773条语句建立索引，包括数据库查询的消耗，总共耗费墙上时间296ms，很不错了吧，如果用LSI没个七八分钟就不要想，而且还需要不断调优topic_num参数。</p>
<p>　　同时，我在搜索资料的时候，发现<a href="http://www.perlmonks.org/?node_id=1142181" target="_blank" rel="external">一则消息</a>:dmitri使用KinoSearch和Lucy近十年，然后用Lucy去索引PDF/HTML/DOC各类文件，然后结合Linux::Inotify2使用cron计划每隔几个小时更新索引，结果是”Surely impressed my $boss”。<br>　　所以有些东西虽然简单，但是使用合理，也可达到不可思议的效果哦！不过Lucy确实比较的小众，三年多的maillist邮件列表才几百条。。。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://metacpan.org/release/Lucy" target="_blank" rel="external">Lucy – C API Index</a></li>
<li><a href="http://www.perlmonks.org/?node_id=1142181" target="_blank" rel="external">Apache solr vs Apache Lucy</a></li>
<li><a href="http://grokbase.com/t/lucy/dev/153ypam587/lucy-dev-trapping-errors-in-c" target="_blank" rel="external">Trapping errors in C.</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于LSI/LDA的文本检索的原理和操作步骤]]></title>
      <url>https://taozj.org/201604/fulltext-search-based-on-lsi-lda.html</url>
      <content type="html"><![CDATA[<p>　　自从上次写了那个<a href="/201604/how-to-calc-svd.html">SVD的计算步骤</a>之后，一直都想补充这一篇——用SVD进行文本检索，刚好这次需求驱动，着手试了一把，实验结果感觉还行！<br>　　SVD算是线性代数里面的东西，PCA、LSI、LDA这些算是不同应用目的的不同叫法吧，其中LSI全名叫Latent Semantic Indexing，看他的名字就是立志要用在文本信息检索里面，但是SVD的应用可不仅仅如此，比如图像处理、推荐系统、语音处理等等。<br>　　关于LSI的教材，本来Edel Garcia有一系列比较好的教程的，但是不知道为什么后来全部删掉了，附录的两个是可以下载的，内容说的也很清楚明白，推荐阅读。SVD由于原理简单，实现好的库也有很多。本文采用了gensim库已经封装好了，使用教程中有详细的操作步骤，个人将测试代码推送到<a href="https://github.com/taozhijiang/chinese_nlp" target="_blank" rel="external">chinese_nlp</a>库。目前小范围的测试效果还可以，不知道语料多了之后效果怎样，同时需要知道SVD是比较耗费计算量的。</p>
<h1 id="一、计算步骤">一、计算步骤</h1><p>　　参考文档中介绍的具体计算步骤，这里描述下来。<br>　　(1) 文本预处理：中文分词，然后去除停用词、删除低频词词，进行word-&gt;id转换；<br>　　(2) 可选的优化，比如用TF-IDF为词汇加上局部权重；<br>　　(3) 将训练文本用dictionary转换成id表现的形式，这就得到了Term-Document矩阵$A$；<br>　　(4) $A=USV^t$，进行SVD分解，得到$U、S、V$矩阵；<br>　　(5) 降维，将奇异值S减少为k个(topic-mode参数)，当然k是个经验数字，比如200-500，然后$U$选前k列，$V$ 选前k列；$S$选左上角k行k列对角方阵，其实$V’$的低n行就是A第n列（第n个文本）的向量表示，且满足$V=A^TUS^{-1}$，或者任意一个文本$d=d^TUS^{-1}$；<br>　　(6) 对于一个新的查询文本q，其查询向量为$q=q^TUS^{-1}$，那么任意两个文本的相似度就可以计算为<br>$$sim(q,d)=sim(q^TUS^{-1}, d^TUS^{-1})$$<br>　　两个向量相似度的计算常常使用consine余弦相似度。<br><a id="more"></a></p>
<h1 id="二、gensim库的实现与使用">二、gensim库的实现与使用</h1><p>　　gensim是基于python的，其专注在NLP方面，什么TF-IDF、LSI、LDA、word2vec等模型应有尽有。<br>　　本文使用gensim的LSI进行文本检索，其实在使用上除去语料预处理，实现LSI文本检索也就两个重要模块的调用：LsiModel和similarities。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">lsi = models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=int(k_value))</div><div class="line">index = similarities.MatrixSimilarity(lsi[corpus])  <span class="comment"># transform corpus to LSI space and index it</span></div></pre></td></tr></table></figure></p>
<h2 id="2-1_LSI模块">2.1 LSI模块</h2><p>　　主要用于将原始语料投影到LSI的空间上来，通过SVD分解降维之后，将原始稀疏word-id表示，变成各个文本的近似短向量表示。这里需要额外说明的是，gensim在完成SVD的基本计算之外，还参考了很多工程上大数据量的计算情况：其实现支持增量计算，模型参数和检索文档可以在线更新(Streaming流计算)；训练数据分割成chunk分批次运算，不受物理内存的限制；支持分布式计算。<br>　　真正训练操作是从添加文本调用add_documents(corpus)开始，其内部调用结构如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">update = Projection(self.num_terms, self.num_topics, job, extra_dims=self.extra_samples, power_iters=self.power_iters)</div><div class="line">    u, s = stochastic_svd(</div><div class="line">           docs, k, chunksize=sys.maxsize,</div><div class="line">           num_terms=m, power_iters=self.power_iters,</div><div class="line">           extra_dims=self.extra_dims)</div><div class="line">    self.u = u[:, :k].copy()</div><div class="line">    self.s = s[:k].copy()</div><div class="line">self.projection.merge(update, decay=decay)</div></pre></td></tr></table></figure></p>
<p>　　可以见到，针对每一个chunk语料（封装到job中），通过Projection来进行投影(SVD的原理其实也就是个最大方差投影操作)，其内部通过stochastic_svd分解得到u,v矩阵，接着通过调用merge，对每个chunk的计算结果进行合并，然后更新u、s的参数；当然如果语料大小小于chunk大小（默认20000），就能一次计算，上面stochastic_svd计算的u、s就直接返回了。<br>　　projection.merge的合并计算，更新u、s参数还是很复杂的，其参照的是<a href="http://nlp.fi.muni.cz/~xrehurek/nips/rehurek_nips.pdf" target="_blank" rel="external">Fast and Faster: A Comparison of Two Streamed Matrix Decomposition Algorithms</a>描述的流计算增量更新方法。</p>
<h2 id="2-2_similarities模块">2.2 similarities模块</h2><p>　　用于计算查询文本和每个Document的相似度(consine)，排序后就可以作为检索结果了。首先通过下式建立index(其实就是每个Doc降维后向量化表示形式)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">index = similarities.MatrixSimilarity(lsi[corpus])</div></pre></td></tr></table></figure></p>
<p>　　上面的式子lsi[corpus]中的[]运算符(<strong>get_item</strong>)才是关键，通过<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">topic_dist = (vec.T * self.projection.u[:, :self.num_topics]).T　<span class="comment"># (x^T * u).T = u^-1 * x</span></div><div class="line">topic_dist = (<span class="number">1.0</span> / self.projection.s[:self.num_topics]) * topic_dist</div></pre></td></tr></table></figure></p>
<p>　　计算将每个文档用num_topics维度的向量记录下来，就是传说中的检索索引了。<br>　　这时候，当需要进行一个新的query时候，执行下面的步骤:(1)中文分词，然后使用dictionary.doc2bow将词转换成ID，如含有未登录词舍弃；(2)采用上面的<a href="__get_item__"></a>计算符，将查询语句的word-id转换成LSI空间的文本短向量；(3)用生成的向量与index中的每个文本向量计算余弦相似度，返回结果；(4)对相似度进行排序，推荐Top-N最佳检索结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">result = numpy.dot(self.index, query.T).T</div></pre></td></tr></table></figure></p>
<p>　　gensim模块的实现中有着大量的density,sparse,CCS的变换，在此就不纠结这些细节了，否则自己很容易就被绕晕了，还有那个在线merge更新的，如果有时间还要好好看看论文，不然理解不了。</p>
<h1 id="三、结果显示">三、结果显示</h1><p>　　测试使用的16000条的问题语料，ｋ大约1300的时候生成文档索引，然后测试文档检索。总体来看还是比较靠谱的，似乎隐约感受到那些LSI声称的语意搜索了。<br><img src="/post_images/images/201604/8669f40f90bc8638ca7077b5f981732c.jpg" alt="LSI问题检索"></p>
<h1 id="四、总结">四、总结</h1><p>　　既然名字叫Latent Semantic Indexing，实际隐藏的那个变量就是topic，通过topic将word和doc关联起来。<br>　　另外，如果计算的文本语料数量比较少的时候，那个１频次去词的步骤就不要要了，否则很多的检索词汇没有，反而导致检索精度的下降。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="/201604/how-to-calc-svd.html">SVD的计算步骤</a></li>
<li><a href="http://www.apluswebservices.com/wp-content/uploads/2012/05/latent-semantic-indexing-fast-track-tutorial.pdf" target="_blank" rel="external">Latent Semantic Indexing (LSI) A Fast Track Tutorial</a></li>
<li><a href="http://manuel.midoriparadise.com/public_html/svd-lsi-tutorial.pdf" target="_blank" rel="external">SVD and LSI Tutorial 4: Latent Semantic Indexing (LSI) How-to Calculations</a></li>
<li><a href="http://blog.csdn.net/zhongkejingwang/article/details/43083603" target="_blank" rel="external">SVD在推荐系统中的应用详解以及算法推导</a></li>
<li><a href="http://nlp.fi.muni.cz/~xrehurek/nips/rehurek_nips.pdf" target="_blank" rel="external">Fast and Faster: A Comparison of Two Streamed Matrix Decomposition Algorithms</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux环境开发（二）：IO复用之select/poll/epoll之原理和差异分析]]></title>
      <url>https://taozj.org/201604/linux-env-program-(2)-difference-select-poll-epoll.html</url>
      <content type="html"><![CDATA[<p>　　select/poll/epoll算是Linux中最常用的IO复用形式了，select是POSIX的标准，所以在Windows平台也是支持的。通常来说，select相对于poll和epoll的限制比较的多，但是在连接数小流量大的时候，select的性能表现也不见得比poll/epoll要差，而epoll对于侦听大量描述符，同时只有少量描述符活跃的时候更为的有效。<br>　　其实这几个IO复用的内部实现，select和poll比较接近，但epoll跟前几两者已经完全不同了，在此做一个总结吧。</p>
<p>　　这些函数都是系统调用，其中select/pselect/poll/ppoll定义在fs/select.c当中，而epoll被单独定义在了fs/eventpoll.c文件当中。</p>
<h1 id="一、select">一、select</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">select</span><span class="params">(<span class="keyword">int</span> nfds, fd_set *readfds, fd_set *writefds,</span></span></div><div class="line">                  fd_set *exceptfds, <span class="keyword">struct</span> timeval *timeout);</div></pre></td></tr></table></figure>
<p>　　select主要是通过三个fd_set记录要监测的read/write/except事件的文件描述符，fd_set的大小被__FD_SETSIZE这个宏所限制，如果要增加这个值势必要重新编译系统内核，这也是select最大的诟病：监听的事件个数是有限的（1024）。外边通过FD_SET、FD_CLR等操作宏，实际内部是将这1024个文件描述符映射成1024bit=128byte=32long(32位系统)中的比特位的。<br>　　在进入系统调用后，接着：<br>　　(1) 调用core_sys_select，对于每个描述符read/write/except以及输入和输出，内核需要为这些描述符申请6倍的映射空间，然后将select输入的参数拷贝进内核空间，然后调用do_select；<br>　　(2) do_select中，按照bit扫描看是否需要r/w/ex的检查，如果需要，就调用文件系统file_operations-&gt;poll函数，检测POLLIN_SET/POLLOUT_SET/POLLEX_SET，并标志保存位图的对应位置;<br>　　(3) do_select调用返回到core_sys_select，将结果拷贝到用户空间（复用传参的地址），调用结束返回；</p>
<p>　　对于socket或者文件系统fd的poll调用，都会调用注册文件系统提供的poll函数，比如对于网络socket的poll，底层的poll函数是定义在net/ipv4/tcp.c中的tcp_poll()，调用过程如下：<br>　　a. fs/select.c: 在do_select开始的时候，会调用poll_initwait()函数，这个函数会将poll_wqueues.poll_table的_qproc设置为__pullwait函数；<br>　　b. fs/select.c：在下面遍历检测的时候，会调用文件系统/网络系统的poll函数(*f_op-&gt;poll)(f.file, wait)，这里调用参数f.file是每个文件描述符，wait是上面的poll_table；<br>　　c. 映射到socket上面，就是调用的net/sock.c中的sock_poll；<br>　　d. 如果是TCP，那么就映射到底层的net/tcp.c中的tcp_poll；<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">sock_poll</span><span class="params">(<span class="keyword">struct</span> file *file,</span></span></div><div class="line">                  <span class="keyword">struct</span> poll_table_struct *wait);</div><div class="line"><span class="function"><span class="keyword">unsigned</span> <span class="keyword">int</span> <span class="title">tcp_poll</span><span class="params">(<span class="keyword">struct</span> file *file, <span class="keyword">struct</span> socket *sock,</span></span></div><div class="line">              <span class="keyword">struct</span> poll_table_struct *wait);</div></pre></td></tr></table></figure></p>
<p>　　tcp_poll就会根据sk的状态设置各种标志，其中最重要的一条是调用了sock_poll_wait(file, sk_sleep(sk), wait);这里的三个参数都有作用：<br>　　file:跟踪的具体文件描述符；<br>　　sk_sleep(sk):得到一个等待队列wait_address，维持了有阻塞在这个sock上的进程，通知唤醒用户进程就是通过这个等待队列来做的；<br>　　wait:poll_table的等待队列；<br>　　(4) poll_wait(file, wait_address, wait);也就是wait-&gt;_qproc(file, wait_address, wait);<br>　　这个过程比较的绕，就是在程序开始的时候，建立一个poll_wqueue的队列以及poll_table结构，并将__poll_wait注册为回调函数，然后遍历每个文件描述符的时候调用对应文件系统的底层poll函数，在文件系统驱动中去调用这个回调函数（主要就是把current当前进程挂载到设备的等待队列上去），设置相应的标志，并且返回。如果驱动程序的数据可用了，就会唤醒挂载到这个等待队列上的进程（没有区分到底是IN/OUT/EX事件触发的唤醒哦）。<br><a id="more"></a><br>　　小结:<br>　　由此可见，select系统调用就是依照顺序检索1024个文件描述符，直观明了。但是缺点是：每次调用需要将侦听的fd_set拷贝到内核态，结果也需要从内核态拷贝到用户态；select内部需要线性扫描每个文件描述符，如果有侦听需求，就需要调用文件系统的poll调用，返回后，用户态也需要用FD_ISSET来依次检测到底是那个文件描述符被设置了，如果fd_set侦听的描述符比较多的话，开销是比较大的；调用要求传递max_fd+1，系统检测当前打开文件最大描述符等，无时不在拷贝数据和扫描检查上面优化。<br>　　此外，select内部是一个忙等待，睡眠时间介于本进程slack和100ms之间，根据超时时间（如果传递了的话）的0.1%~0.5%之间，如果唤醒发展超时、有fd就绪、出错、接收到信号这些事件就返回，否则继续睡眠。当然，如果设备支持唤醒队列的话，数据可用后select系统调用的进程会被重新唤醒，系统调用只需要重新扫描所有的文件描述符就可以了。<br>　　当select返回的时候，会把自己从所有设备的唤醒队列中移除掉，不再接受唤醒事件。<br>　　此外，select是跨平台的，在某些情况下算是比较重要的特性的，使得libevent这种跨平台的异步库得以可能实现。</p>
<h1 id="二、poll">二、poll</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">poll</span><span class="params">(<span class="keyword">struct</span> pollfd *fds, <span class="keyword">nfds_t</span> nfds, <span class="keyword">int</span> timeout)</span></span>;</div></pre></td></tr></table></figure>
<p>　　poll机制使用的是结构体struct pollfd<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> pollfd &#123;</div><div class="line">   <span class="keyword">int</span>   fd;         <span class="comment">/* file descriptor */</span></div><div class="line">   <span class="keyword">short</span> events;     <span class="comment">/* requested events */</span></div><div class="line">   <span class="keyword">short</span> revents;    <span class="comment">/* returned events */</span></div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　然后将要侦听的描述符建立成struct pollfd的数组传递给poll系统调用，这样就没有1024的限制了，只要修改系统打开文件的限制，能打开多少文件就可以创建多少个struct pollfd来侦听。<br>　　(1) 首先调用do_sys_poll函数，也需要将整个fds的用户态结构数组拷贝到内核态中，然后调用do_poll；<br>　　需要注意的是这时候系统内核用了一个新的结构体poll_list来保存,这时候如果256字节的栈空间足够拷贝,那么next为NULL,所有的数据拷贝到entries上面,否则逐个申请GFP_KERNEL页面来拷贝,并以链表的形式组织到poll_list上面.<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> poll_list &#123;</div><div class="line">    <span class="keyword">struct</span> poll_list *next;</div><div class="line">    <span class="keyword">int</span> len;</div><div class="line">    <span class="keyword">struct</span> pollfd entries[<span class="number">0</span>];</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>　　(2) do_poll中依次对每个entries调用do_pollfd处理；<br>　　(3) do_pollfd一样调用file_operations-&gt;poll检查POLLIN_SET/POLLOUT_SET/POLLEX_SET,然后将结果保存在内核态的revents上面；<br>　　(4) 函数调用依次返回,到达do_sys_poll的时候,将结果拷贝到用户空间，调用结束。</p>
<p>　　小结:<br>　　其实poll和select没有本质的大区别，而且底层很多的数据和函数都是公用的，只是调用时候换了一种新的数据结构，让侦听的描述符个数没有限制了。同时,传递的就是要侦听的数据结构，不会像select会产生很多无效的拷贝和扫描了。<br>　　还需要注意的是，这里的poll和下面的epoll虽然名字比较像，但是事件的宏是不兼容的，不要误用哦。</p>
<h1 id="三、epoll">三、epoll</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">epoll_wait</span><span class="params">(<span class="keyword">int</span> epfd, <span class="keyword">struct</span> epoll_event *events,</span></span></div><div class="line">                  <span class="keyword">int</span> maxevents, <span class="keyword">int</span> timeout);</div></pre></td></tr></table></figure>
<p>　　epoll用户应用层的具体用法样例,可以参见<a href="https://github.com/taozhijiang/st_utils/blob/master/source/st_epoll.c" target="_blank" rel="external">st_epoll.c</a>,增加epoll_create/epoll_ctl（EPOLL_CTL_ADD/EPOLL_CTL_DEL/EPOLL_CTL_MOD）/epoll_wait这些系统调用来操作的，其内部的实现已经非常复杂了（居然还搞嵌套）。<br>　　(1) 在epoll_create的时候，会创建一个eventpoll类型的ep数据结构，然后创建了一个匿名[eventpoll]文件，并占用一个文件描述符返回，而这里返回的target文件描述符，成为了特定进程和内核eventpoll通信的标识；<br>　　(2) epoll_ctl进行ADD/DEL/MOD操作的时候，会进行一次epoll_event用户到内核的拷贝（修改会拷贝，一直侦听不会拷贝），然后调用ep_insert/ep_remove/ep_modify封装好的函数。这里搜索是采用的红黑二叉树结构，所以即使维持了大量的侦听队列，也可以快速的找到特定的对象；<br>还有个关键点在调用ep_insert的时候，同时也调用了ep_item_poll-&gt;epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, pt)，而pt的回调函数设置了ep_ptable_queue_proc，所以跟上面select/poll的情况类似，还是把当前进程注册到了特定设备的等待队列中，然后设备OK之后调用回调函数ep_ptable_queue_proc-&gt;ep_poll_callback，就把自己对应的事件添加到rdllist上面去了；<br>　　(3) epoll_wait，调用ep_poll函数，这个函数直接查询ep结构的rdllist就需链表，如果没有就绪的，就把自己添加到等待队列然后睡眠（可被ep_poll_callback()唤醒）；否则就调用ep_send_events-&gt;ep_send_events_proc，它会收集rdllist中就绪队列，然后使用f_op-&gt;poll(epi-&gt;ffd.file, NULL)去检测收集事件，如果满足要求就会将他拷贝到用户空间。<br>注意这里调用底层的poll的时候，使用了pt-&gt;_qproc=NULL的参数，就是不要求将当前进程加入到设备维持的等待队列上去，不想被通知到(因为此时的epoll_wait只做收集检测工作)。这里的拷贝是有实际事件消息的，算是净拷贝吧！<br>　　(4) 而对于epoll的边沿触发和水平触发，其实就是在检测收集完事件之后，如果是边沿触发就不做，否则再次将这个事件添加到rdllist上面去，那么下次这个事件还会被再次检测直至返回。</p>
<p>　　小结：<br>　　epoll的实现是很复杂的，但是无论select/poll/epoll，他们的思路都是一致的，把自己添加到设备的等待队列上，实现高效的异步通知机制，而优化的思路都是减少每次调用的数据拷贝，提高搜索的效率而已。<br>　　此外，是不是感觉这种处理方式和Linux调度的进化十分相似啊：之前是每轮调度完了，全部重新计算优先级和时间片信息，而现在维持着红黑二叉树和链表结构，同时将每个进程的调度信息分摊到每次切换的计算上，这样就保证了调度性能不会因为进程的数量而被影响。</p>
<h1 id="四、pselect/ppoll/epoll_pwait">四、pselect/ppoll/epoll_pwait</h1><p>　　这些函数主要是用于需要同时侦听socket/fd和信号的情况。这点附录的参考文献说的比较好，要实现它，可能的解决方式是：<br>　　(1) 在select/poll等待之前设置信号的处理函数为空，然后调用select/poll的时候，如果返回的是EINTR，那么说明是接收到信号了。但是设置信号处理函数和select/poll之间不是原子的，如果在调用select/poll之前信号就来了，那么该信号就会丢失掉。<br>　　(2) self-pipe技术，建立一个pipe，写端是信号处理函数，读端让select/poll来监听。的确可以满足需求，信号不会被丢失，但是实现比较复杂。<br>　　(3) pselect/ppoll的产生就是为了解决这个问题的，先屏蔽要侦听的信号，设置该信号的处理句柄（或者NULL），再调用pselect、ppoll（如果还要屏蔽掉其它的信号，就把他们传给pselect/ppoll函数）。这样，只有在调用pselect/ppoll的时候，该信号才会被UNMASK掉，select返回后该信号又会被屏蔽起来，实际的效果就是将要侦听的信号压缩在pselect/ppoll调用之中才不会被屏蔽。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sigprocmask(SIG_SETMASK, &amp;sigmask, &amp;sigsaved);</div><div class="line">ready = select(nfds, &amp;readfds, &amp;writefds, &amp;exceptfds, timeout);</div><div class="line">sigprocmask(SIG_SETMASK, &amp;sigsaved, <span class="literal">NULL</span>);</div></pre></td></tr></table></figure></p>
<p>　　上面的C模拟了这个逻辑，实际系统调用基本也是这么实现的，虽然两者之间还可能被抢占式内核抢占，但是只要不返回用户态，这个信号就不会被消耗掉，仍然能够导致select/poll因为有信号pend而返回。</p>
<p>　　最后，还需要描述一下在非阻塞模式下IO操作所需要注意的事项：<br>　　(1). 对于读来说，select、poll以及epoll(LT)都是水平触发的，即使已经读了一些数据，只要fd底层仍然有数据可读，那么下次调用select/poll/epoll_wait还是会返回这个fd。这种方式比较简单，编写程序一般也不容易发生问题，epoll_wait(LT)此时的语义跟前者一样，可以看作是faster的poll；<br>　　(2). 对于epoll(ET)的边缘触发模式，epoll_wait只会在fd的event发生变化的时候才会返回，所以这种情况下一定要确保read/write直到返回EAGAIN，程序才能够正常工作。一个例子比如：客户端发送2Kb的请求，而epoll_wait后服务端只读取了1Kb，下次调用epoll_wait就不会返回这个socket，因此服务端不会再次读取，而客户端还在等待返回，整个程序就会僵持下去；<br>　　(3). 对于写来说，检查write/send的返回结果是很有必要的，尤其是对于非阻塞的socket，因为底层socket的缓冲区大小是有限的，如果发送端太快而接收端比较慢，当缓冲区满了后发送操作会返回EAGAIN，实际的数据并没有发送，发送端需要在while中不断重复。这种情况排除网络因素的话很可能生产者和消费者阻抗不匹配了，需要增加消费者的处理能力了！</p>
<p>本文完!</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://lwn.net/Articles/176911/" target="_blank" rel="external">The new pselect() system call</a></li>
<li><a href="https://www.linuxprogrammingblog.com/code-examples/using-pselect-to-avoid-a-signal-race" target="_blank" rel="external">Using pselect() to avoid a signal race</a></li>
<li><a href="http://www.programmershare.com/3450627/" target="_blank" rel="external">linux the epoll kernel source code analysis of</a></li>
<li><a href="http://blog.csdn.net/21aspnet/article/details/2627662" target="_blank" rel="external">linux下poll和epoll内核源代码剖析</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Linux环境开发（一）：同异步、阻塞的IO模型相关问题]]></title>
      <url>https://taozj.org/201604/linux-env-program-(1)-async-blocking-io-model.html</url>
      <content type="html"><![CDATA[<p>　　其实这几个概念可能在实际的开发中并没有什么需要注意的，因为你调用什么函数就知道接下来需要怎么做了，但是如果要确实分清这几个概念的区别和联系，还是需要动动脑筋的。下面这幅图十分的好：<br><img src="/post_images/images/201604/62da0c7a07594deebfee5e538995fe34.gif" alt="LinuxIO模型矩阵"></p>
<p>　　总结来说，区分的关键点在于：<br>　　(1) 同步-异步：IO资源可用与否是自己去检测，还是依赖于状态、信号、回调等其它机制来通知；<br>　　(2) 阻塞-非阻塞：IO调用的函数在资源不可用时候是否立即返回，还是被挂起状态直到资源可用；</p>
<h1 id="一、同步阻塞IO">一、同步阻塞IO</h1><p>　　算是最简单最容易理解的模型了，且Linux默认的IO模型就是这样的，比如你用open打开文件或者socket创建套接字而没有显式使用O_NONBLOCK/SOCK_NONBLOCK参数的时候，那么后续使用read/write/recv/send等函数的时候，每当资源不可用，应用程序将阻塞在这些调用上面，直到这些调用成功后返回，程序才会继续执行下去。<br>　　这时候的阻塞，内核会将程序进程切换到睡眠的状态，当内核完成IO将数据返回到用户态可用的时候，程序会被切换继续运行下去。</p>
<h1 id="二、同步非阻塞IO">二、同步非阻塞IO</h1><p>　　通常在open和socket调用时候添加了O_NONBLOCK/SOCK_NONBLOCK标志，或者采用ioctl等机制后续设置了这个标志的时候，当调用上面的IO操作函数时候，如果此时资源不可用，调用会立即返回（通常返回EAGAIN/EWOULDBLOCK错误）。<br>　　这个时候应用程序通常的做法是sleep一会儿，或者干点别的事情，然后再次进行IO调用看资源是否可用了。总体来说该方法是比较低效率的，如果忙等待会浪费很多计算资源；且如果休眠时间长或者干别的事情长，那么总体IO响应将会变得很不及时。虽然习惯上称为“异步模式”开发，但本质上还是同步非阻塞的类型，而正规上称为基于事件驱动的开发方式。</p>
<h1 id="三、异步阻塞IO">三、异步阻塞IO</h1><p>　　这其实是一个带阻塞通知的非阻塞IO，是select/poll/epoll函数族的典型情况。从使用上来说，虽然将fd/socket设置为了非阻塞形式，但是select/poll/epoll的调用却是阻塞的，所以这里实际上将阻塞从原先的IO操作转嫁挪动到的资源的侦听操作(epoll_wait)上面了。</p>
<h1 id="四、异步非阻塞IO">四、异步非阻塞IO</h1><p>　　最复杂的情况了，在linux中有aio_xxxx()对应的函数族，其最大的特点是程序的执行和IO操作可以重叠执行：程序调用aio_xxxx()后立即返回，然后程序就执行其它的代码了，而内核完成IO操作之后，会通过状态、信号、回调函数等机制完成IO操作之后对应要处理的内容。<br>　　Windows的完成端口就是典型的异步非阻塞IO模型。而在Linux环境下，感觉异步非阻塞IO不太遭怎么待见，网站基本的构架都是基于epoll这类异步阻塞IO设计的。我想，这可能是因为异步非阻塞IO的优势不是特别的明显，而异步阻塞IO比较符合一般人的思维编程习惯吧。</p>
<p>　　注：后两者的差异，其实就是典型高性能IO设置中常说的Reactor模式和Proactor模式：Reactor中回调通知的是关心的事件或者资源是否就绪了，而真正需要应用程序自己读取或者写入数据；而Proactor模式中，应用程序不需要进行实际的读写过程，操作系统会读取缓存区或者写入缓存区到真正的IO设备，当收到通知的时候，真正的读写事件已经完成了。相比较而言，Proactor需要先分配内存，然后再处理IO操作，可以实现数据的Zero-Copy；同时Reactor模式所有的工作都在回调函数中处理，当回调函数任务繁重的时候，容易导致回调队列拥塞。<br>　　然后据陈硕所言，Linux下面还是Reactor模式较为成熟，Linux下的aio基本没有开发和完善的动力，这些异步操作接口很少使用在网络编程上，而是boost::asio为了跨平台，选取了Proactor模式而已(不过boost.asio也支持Reactor模式操作的)；此外，常用的Libevent就是典型的Reactor模式，而Libevent在Windows下只支持select的异步模式，不过如果是在Windows下的网络开发，可能大部分人还是会直接使用操作系统提供的完成端口机制吧，因为几乎没有看到程序先在Windows平台上开发，然后再兼容到Linux平台的。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.jobbole.com/99765/" target="_blank" rel="external">聊聊同步、异步、阻塞与非阻塞</a></li>
<li><a href="http://www.ibm.com/developerworks/library/l-async/" target="_blank" rel="external">Boost application performance using asynchronous I/O</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/linux/l-async/" target="_blank" rel="external">使用异步 I/O 大大提高应用程序的性能</a></li>
<li><a href="http://blog.jobbole.com/99912/" target="_blank" rel="external">聊聊IO多路复用之select、poll、epoll详解</a></li>
<li><a href="http://xmuzyq.iteye.com/blog/783218" target="_blank" rel="external">高性能IO设计的Reactor和Proactor模式</a></li>
<li><a href="http://www.zhihu.com/question/22064431" target="_blank" rel="external">为何 Boost 的 Asio 要使用 Proactor 模式实现？</a></li>
<li><a href="http://tech.youzan.com/tcp_network_programming/" target="_blank" rel="external">TCP网络编程杂谈</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[基于libmicrohttpd的HTTP服务器初探]]></title>
      <url>https://taozj.org/201604/oversee-of-http-based-on-libmicrohttpd.html</url>
      <content type="html"><![CDATA[<p>　　最近写一个小项目，需要用到HTTP Server来支持一个API操作，正如同现在如火如荼的云API泛滥时代，感觉你不弄个开放接口都不好意思说自己是互联网公司。要求是用POST方式以及JSON数据格式发一个请求，然后服务端返回一个JSON格式的结果。当然用HTTP格式而非Socket方式的好处是显而易见的，HTTP是建立在socket之上的一个应用层协议，虽然性能可能不是最好的，但意味着你不用定义数据包的协议格式、容错以及通信过程中的各种繁琐的细节，只需要关注用户发送的有效负载信息及自己的处理逻辑设计实现就可以了。<br>　　说到HTTP可能最先想到的是Apache和Nginx，然而寡人不是做前端的，也不懂全世界最好的语言（PHP），更不晓得RESTful API，HTTP收到的JSON数据还不晓得怎么和后台的CGI结合起来。于是，这次另辟蹊径找到了libmicrohttpd，话说这个libmicrohttpd是用C写的，GNU旗下产品，支持Linux、Windows、以及andriod、symbian等平台（其定位就是作为一个嵌入式的HTTP库，方便集成到各个程序中去），支持SSL、session等机制，不过每个部分都比较简单，算是简单实现了一个HTTP的框架吧。</p>
<p><img src="/post_images/images/201604/843f0a282190edd9e34aff3cc52e8aa5.jpg" alt="libmicrohttpd"></p>
<h1 id="一、HTTP协议_-_libmicrohttpd">一、HTTP协议 - libmicrohttpd</h1><p>　　libmicrohttpd的文档算是比较的详细，但是用起来还是有点需要注意的：</p>
<h2 id="1-1_处理POST_JSON数据格式的请求">1.1 处理POST JSON数据格式的请求</h2><p>　　libmicrohttpd本身提供了POST数据的处理接口，在新连接到时候使用MHD_create_post_processor创建POST处理器，收到数据后，调用MHD_post_process处理，只不过得到的数据表示为带=的键值对形式，这对我们这种JSON数据显然是不行的。<br>　　如果需要自己收取处理数据，然后自己用JSON库来解析处理，那么我们需要做的是，将完整的数据收上来，然后自己手动处理数据。其思路为：<br>　　(1) 在create_response函数中，调用MHD_lookup_connection_value (connection, MHD_HEADER_KIND, MHD_HTTP_HEADER_CONTENT_LENGTH);，这会解析HTTP头部得到数据的长度，依据这个长度创建接受缓冲区；<br>　　(2) 不断地收数据，直到接受不到数据为止，然后检查收到的数据长度和之前头部报告的长度是否相等；<br>　　(3) 调用自己的数据处理接口。<br><a id="more"></a><br>　　代码的样式如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">const</span> <span class="keyword">char</span>* param = MHD_lookup_connection_value (connection, MHD_HEADER_KIND, MHD_HTTP_HEADER_CONTENT_LENGTH);</div><div class="line">content_len = atoi(param);</div><div class="line"></div><div class="line"><span class="comment">// URL: http://localhost:8080/api</span></div><div class="line"><span class="keyword">if</span> (<span class="number">0</span> == <span class="built_in">strcmp</span> (method, <span class="string">"POST"</span>) &amp;&amp; !strncasecmp(url, <span class="string">"/api"</span>, <span class="number">4</span>)) &#123;</div><div class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == posthandler) &#123; <span class="comment">// new connection</span></div><div class="line">        posthandler = (P_MHD_Data)<span class="built_in">malloc</span> (<span class="keyword">sizeof</span> (MHD_Data));</div><div class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == posthandler)</div><div class="line">            <span class="keyword">return</span> MHD_NO;</div><div class="line"></div><div class="line">        posthandler-&gt;len = <span class="number">0</span>; <span class="comment">//actual data load</span></div><div class="line">        posthandler-&gt;data = <span class="built_in">malloc</span>(content_len + <span class="number">1</span>);</div><div class="line">        <span class="built_in">memset</span>(posthandler-&gt;data, <span class="number">0</span>, content_len+<span class="number">1</span>);</div><div class="line">        *con_cls = (<span class="keyword">void</span> *) posthandler;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> MHD_YES;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">else</span> &#123;</div><div class="line">        <span class="keyword">if</span> (*upload_data_size != <span class="number">0</span>)&#123;</div><div class="line">            <span class="built_in">memcpy</span> (posthandler-&gt;data + posthandler-&gt;len, upload_data, *upload_data_size);</div><div class="line">            posthandler-&gt;len = posthandler-&gt;len + (*upload_data_size);</div><div class="line">            ((<span class="keyword">char</span> *)(posthandler-&gt;data))[posthandler-&gt;len] = <span class="string">'\0'</span>;</div><div class="line">            <span class="comment">/* indicate that we have processed */</span></div><div class="line">            *upload_data_size = <span class="number">0</span>;</div><div class="line"></div><div class="line">            <span class="keyword">return</span> MHD_YES;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (<span class="literal">NULL</span> != posthandler-&gt;data) &#123;</div><div class="line">            <span class="comment">/* done with POST data, serve response */</span></div><div class="line">            <span class="keyword">if</span> (content_len != posthandler-&gt;len)</div><div class="line">                <span class="keyword">goto</span> ERROR_RT;</div><div class="line">﻿</div><div class="line">            <span class="keyword">if</span> (process_post_data(posthandler) != <span class="number">0</span>)</div><div class="line">                <span class="keyword">goto</span> ERROR_RT;</div><div class="line"></div><div class="line">            <span class="keyword">return</span> send_page (connection, (<span class="keyword">const</span> <span class="keyword">char</span>*)posthandler-&gt;data);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h2 id="1-2_服务端运行模式">1.2 服务端运行模式</h2><p>　　在启动libmicrohttpd服务MHD_start_daemon的时候有很多选项，其中最重要的是指定服务器的线程工作模式，大体来说分为以下几类：<br>(1) MHD_USE_THREAD_PER_CONNECTION<br>　　MHD会启动一个线程来进行侦听，当得到一个连接的时候，会生成一个新的线程来处理这个连接，由于连接之间没有通信机制，所以适用于无状态的连接，但是如果创建线程的开销比较大的时候，显然效率不高；<br>(2) MHD_USE_SELECT_INTERNALLY<br>　　创建一个线程来处理侦听和处理，这种情况要被认为响应是不会阻塞，而且能够快速返回的，不然这个线程处于忙等待，系统的吞吐量会被严重影响。<br>(3) MHD_USE_POLL<br>　　包括派生的EPOLL等形式，是I/O+线程池的最佳服务器模式，当使用这些模式的时候，需要使用MHD_OPTION_THREAD_POOL_SIZE来设置使用线程池的大小。然后你可以在处理函数中，打印当前threadid来验证线程池是否工作正常。<br>　　我个人用的是终极MHD_USE_EPOLL_INTERNALLY_LINUX_ONLY模式，然后MHD_OPTION_THREAD_POOL_SIZE线程池设置为6个线程。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">daemon = MHD_start_daemon (MHD_USE_EPOLL_INTERNALLY_LINUX_ONLY|MHD_USE_DEBUG,</div><div class="line">            global_options.http_option.port,</div><div class="line">            <span class="literal">NULL</span>, <span class="literal">NULL</span>,</div><div class="line">            &amp;create_response, <span class="literal">NULL</span>,</div><div class="line">            MHD_OPTION_NOTIFY_COMPLETED, &amp;request_completed,</div><div class="line">            <span class="literal">NULL</span>,</div><div class="line">            MHD_OPTION_THREAD_POOL_SIZE, <span class="number">6</span>,</div><div class="line">            MHD_OPTION_END);</div></pre></td></tr></table></figure></p>
<h2 id="1-3_返回文件系统的资源文件">1.3 返回文件系统的资源文件</h2><p>　　这个部分已经在哥的业务需求之外了。在前面的create_response之中，等于做了个钩子——对于请求的url是/api的时候，就接受数据并进行JSON解析，其实对于其他URL访问，可以返回文件系统中对应文件给客户，就是普通的WebServer模式，于是添加了send_page_from_file(connection, url);这么个函数来处理其他URL请求<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span></span></div><div class="line"><span class="title">send_page_from_file</span> <span class="params">(<span class="keyword">struct</span> MHD_Connection *connection, <span class="keyword">const</span> <span class="keyword">char</span> *filename)</span>&#123;</div><div class="line">    <span class="keyword">int</span> ret;</div><div class="line">    <span class="keyword">struct</span> MHD_Response *response;</div><div class="line">    <span class="keyword">struct</span> stat st;</div><div class="line">    <span class="keyword">char</span> filepath[PATH_MAX];</div><div class="line">    <span class="built_in">strcpy</span>(filepath, global_options.http_option.ROOT_DIR);</div><div class="line">    <span class="built_in">strcat</span>(filepath, filename);</div><div class="line"></div><div class="line">    stat(filepath, &amp;st);</div><div class="line">    <span class="keyword">if</span> ( S_ISDIR(st.st_mode) &amp;&amp; <span class="built_in">strlen</span>(global_options.http_option.PAGE_INDEX)) &#123;</div><div class="line">        <span class="built_in">strcat</span>(filepath,<span class="string">"/"</span>);</div><div class="line">        <span class="built_in">strcat</span>(filepath, global_options.http_option.PAGE_INDEX);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> fd = open(filepath, O_RDONLY);</div><div class="line">    <span class="keyword">if</span>(fd == <span class="number">-1</span>)</div><div class="line">        <span class="keyword">return</span> send_page(connection, err404page);</div><div class="line"></div><div class="line">    FILE *fp = fdopen(fd, <span class="string">"r"</span>);</div><div class="line">    fseek(fp, <span class="number">0</span>, SEEK_END);</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> len = ftell(fp);  <span class="comment">//文件大小</span></div><div class="line">    response = MHD_create_response_from_fd(len, fd);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (!response)</div><div class="line">        <span class="keyword">return</span> MHD_NO;</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(<span class="built_in">strstr</span>(filename, <span class="string">".htm"</span>))</div><div class="line">        MHD_add_response_header(response,<span class="string">"Content-Type"</span>,<span class="string">"text/html; charset=utf-8"</span>);</div><div class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">strstr</span>(filename, <span class="string">".js"</span>))</div><div class="line">        MHD_add_response_header(response,<span class="string">"Content-Type"</span>,<span class="string">"application/x-javascript"</span>);</div><div class="line"></div><div class="line">    ret = MHD_queue_response (connection, MHD_HTTP_OK, response);</div><div class="line">    MHD_destroy_response (response);</div><div class="line"></div><div class="line">    <span class="comment">//close(fd);   //此处不能关闭</span></div><div class="line">    <span class="keyword">return</span> ret;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　其实上面的函数核心就是MHD_create_response_from_fd，当然你也可以把整个文件读出来，然后调用MHD_create_response_from_data来发送，官方的手册上说data函数对于小的可以放到内存上的数据或者文件（比如静态页面）比较合适，后者适用于不知道发送数据的具体大小或者数据过大不能放到内存的情况，不过觉得上面这样用也挺方便的。（不知道是不是要保存这个handle，然后在request_completed中关闭，如果后续发现描述符泄露再改吧。）<br>　　然后顺便模拟了DocumentRoot、Indexes等特性，配置过apache的应当很熟悉。</p>
<h1 id="二、JSON数据处理_-_json-c">二、JSON数据处理 - json-c</h1><p>　　JSON库网络一搜一大把，甚至有个专门评测的列出几十个JSON库测试支持的标准以及性能。由于是用C写的，那么C++的库就被PASS掉了，目前用的json-c库，感觉比较清爽，而且时间比较久了也究竟考验，用起来不错。<br>　　如果后面使用C++开发程序，推荐使用json11，但是如果环境比较的老旧不支持C++11，那么可以使用RapidJson也是不错的。<br>　　配置文件也用json的方式设置，然后程序启动的时候，用这个库就可以加载配置文件了。大名鼎鼎的Sublime编辑器就是这么干的哦！</p>
<h1 id="三、数据库_-_MySQL_C_API">三、数据库 - MySQL C API</h1><p>　　MySQL的C API算是最底层的比较裸的数据库操作接口了吧。当编译连接的时候有线程安全的版本(mysqlclient_r)，官方说明在多线程的情况下可以保证线程安全的，只是需要遵守一些<a href="https://dev.mysql.com/doc/refman/5.7/en/c-api-threaded-clients.html" target="_blank" rel="external">初始化和使用约定</a>，比如在mysql_query()和mysql_store_result() 两个调用之间，不允许其他线程使用该连接，而如果涉及到事物、回滚等机制，问题可能会更加的复杂。<br>　　其实，在附录的pdf文件中也提到，对于MySQL数据库，在服务端也有线程池的概念，也是一个连接一个线程处理的，在客户端如果多个线程公用一个连接，除了要考虑额外的同步问题，性能也不会有所提高，所以对于客户端，最好的解决方案是使用连接池。<br>　　自己使用C简单做了个连接池，放到<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">st_utils</a>库当中去了。</p>
<p>　　由于涉及到公司业务，这里就不开源了。这个简单的HTTP服务器我在<a href="http://mail.freesign.net" target="_blank" rel="external">http://mail.freesign.net</a>上部署了，资源占用极少，原来静态的GitHub Pages显示没有什么问题哦，感兴趣的同学可以压一压！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://json-c.github.io/json-c/json-c-0.10/doc/html/json__object_8h.html" target="_blank" rel="external">json-c</a></li>
<li><a href="http://www.gnu.org/software/libmicrohttpd/" target="_blank" rel="external">GNU Libmicrohttpd</a></li>
<li><a href="http://blog.csdn.net/langeldep/article/details/8867059" target="_blank" rel="external">如何直接获取 libmicrohttpd 库中POST上来的整个数据</a></li>
<li><a href="http://dev.mysql.com/doc/refman/5.6/en/c-api.html" target="_blank" rel="external">MySQL C API</a></li>
<li><a href="https://media.readthedocs.org/pdf/mysqldb/latest/mysqldb.pdf" target="_blank" rel="external">MySQLdb Documentation</a></li>
<li><a href="https://dev.mysql.com/doc/refman/5.7/en/c-api-threaded-clients.html" target="_blank" rel="external">Writing C API Threaded Client Programs</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Windows服务端程序向Linux移植经验总结]]></title>
      <url>https://taozj.org/201604/server-prog-port-from-windows-to-linux.html</url>
      <content type="html"><![CDATA[<p>　　前面做了一些Windows服务端程序向Linux服务端程序的移植工作，还是有些收获的，这里整理记录一下，将工作内容和细节方面的东西供大家参考。<br>　　需要说明几点：这里的移植是真的移植，而不是考虑跨平台开发型的；这里的移植是针对无界面形式的程序，主要是服务端程序；那啥wine、mono的太大，就不考虑了。<br><img src="/post_images/images/201604/e7b52d9197604c2914da1244565384bb.jpg" alt="WINDOWS LINUX"></p>
<h1 id="一、数据类型定义">一、数据类型定义</h1><h2 id="1-1_数据类型的差异">1.1 数据类型的差异</h2><p>　　Windows和Linux的数据类型定义完全是两个风格，而且Windows的类型定义喜欢用大写字母，Windows的数据类型主要是定义在windef.h这个头文件里面的，可以将简单的数据类型按照目标机器翻译过来，当然也有些定义比较的复杂，不过很多却是没用的，可以安全的删掉。</p>
<h2 id="1-2_函数接口的差异">1.2 函数接口的差异</h2><p>　　Windows也是支持POSIX标准的，所以大多数的底层函数还是可以用的，但是某些函数的名字和参数签名等还是有些差异(比如stricmp/strcasecmp)，如果要在这个头文件里面处理，可以内联封装加进去。</p>
<h1 id="二、进程间的通信">二、进程间的通信</h1><h2 id="2-1_创建线程">2.1 创建线程</h2><p>　　Windows使用CreateThread创建线程，而Linux通常使用pthread线程库来实现多线程。</p>
<h2 id="2-2_多线程以及进程间同步">2.2 多线程以及进程间同步</h2><p>　　在Windows上面，除了CriticalSection是仅限线程间的同步之外，其他Mutex、Event、filemap，在使用的时候，只要设定了lpName，那么就可以在其他进程中用这个名字打开，就算是进程间的同步和通信了，否则的话就是线程间的同步。<br>　　不仅仅在这里，其实进程间通信Linux一般都有POSIX和SYS V两套接口，实际经验和感受来说POSIX的接口更加习惯好用一些。</p>
<table>
<thead>
<tr>
<th>Windows</th>
<th>Linux(线程)</th>
<th>Linux(进程)</th>
</tr>
</thead>
<tbody>
<tr>
<td>CriticalSection</td>
<td>pthread_mutex</td>
<td>-</td>
</tr>
<tr>
<td>Mutex</td>
<td>semaphore</td>
<td>semaphore</td>
</tr>
<tr>
<td>Event</td>
<td>semaphore</td>
<td>semaphore</td>
</tr>
<tr>
<td>filemap</td>
<td>shm、mmap</td>
<td>shm、mmap</td>
</tr>
</tbody>
</table>
<p>　　shm和mmap其实都差不多，但是如果有些数据不像映射到硬盘文件系统上（比如处于保密安全考虑），那么就推荐使用shm来实现。<br><a id="more"></a></p>
<h1 id="三、定时器">三、定时器</h1><p>　　在Windows下面，调用SetTimer创建定时器的时候可以指定ID，一个进程中可以创建很多个定时器，但是在Linux下就没有这么方便了。alarm/sleep都是用SIGALRM来实现的，而且代码没法异步执行；timer_create可以指定发送的SIGNUM，然后可以利用调用sigaction提供的参数来区别各个定时器，当然是个候选的方式；同时我找到的网络还有推荐的是使用timerfd+epoll来实现，本库就是按照这个实现封装来模拟SetTimer的操作。<br>　　看似后面两者都可以实现多定时器，实际还是有些差异，前者设定信号处理函数，但是信号处理函数是异步的，所以在这种情况下所做的事情有限，而后者使用一个线程专门检测执行信号处理函数，算是一个进程同步上下文，虽然精度有所欠缺（比如只能按顺序检测没法按照真正时间排序），但是使用更加方便安全。</p>
<h1 id="四、网络IO复用">四、网络IO复用</h1><h2 id="4-1_数据和函数定义细节差异">4.1 数据和函数定义细节差异</h2><p>　　Windows针对自己的异步IO添加了一系列的宏，比如WSAEFAULT、WSANOTINITIALISED等，以及WSAGetLastError等函数（这个直接用errno模拟了）。</p>
<h2 id="4-2_网络IO复用">4.2 网络IO复用</h2><p>　　虽然都是事件驱动的网络IO复用技术，但是算是两者网络风格最大的不同了。</p>
<h3 id="4-2-1_Windows平台">4.2.1 Windows平台</h3><p>　　Windows采用完成端口（Completion Port）的方式，一般的操作步骤是：<br>　　(1) 采用CreateIoCompletionPort创建完成端口；<br>　　(2) 创建bind、listen服务端套接字；<br>　　(3) 根据服务器的CPU数量，创建一定数目的工作线程，然后在每个工作线程中调用GetQueuedCompletionStatus等待完成事件；<br>　　(4) 上面函数返回，说明操作系统IO操作已经完成，就可以直接操作数据了。</p>
<h3 id="4-2-2_Linux平台">4.2.2 Linux平台</h3><p>　　Linux有经典的select、poll，以及后面增强型的epoll方式，目前epoll有很多优点（侦听socket数目多、效率高等），所以没有特殊利用就用epoll吧，epoll的操作步骤是：<br>　　(1) 创建服务器侦听socket并实现bind、listen等操作；<br>　　(2) 设置socket为O_NONBLOCK模式；<br>　　(3) 创建epoll_event结构，首先将listen的socket加入到侦听当中；<br>　　(4) 进入event_loop中，调用epoll_wait，如果listen socket有请求，就accept得到链接的n_socket，并把这个n_socket再次添加到epoll侦听中；<br>　　(5) 以后每次epoll_wait返回，就两种情况：要么listen socket有新连接请求，要么之前连接并侦听的socket有数据到达可供读取。<br>　　内部的实现细节暂不讨论，其中最大的区别就是，Windows的完成端口用起来十分简单，注册之后，你提供数据存储的地址后就等待，一旦返回，说明数据已经接受好并放到指定的位置了，用户只需要专注数据处理了；Linux繁杂但是灵活，而且epoll可以设置Level/Edge触发，应对不同网络负载情况。<br>　　注意：其实现在看来，两者都归并为异步IO，Windows的完成端口是异步非阻塞的，比如接受程序调用IO操作之后就直接返回，执行其它事务了，而别的线程检测到IO完成标志后执行相应操作；而Linux的IO复用确是异步阻塞的，当监听的套接字都不可用的时候，这些函数将处于一直阻塞的状态(体现在epoll_wait的阻塞)。</p>
<h1 id="五、其他方面">五、其他方面</h1><h2 id="5-1_调试技术">5.1 调试技术</h2><p>　　有时候程序写多了，莫名其妙的Segmentfault，如果没有调试信息会让人一脸萌逼不知所措。针对这类情况，可以：<br>　　(1) 编译的时候添加-g调试参数，产生函数符号；<br>　　(2) 系统启动coredump支持，这样产生fatal错误的时候，会生成错误转储，用gdb可以调试之；<br>　　(3) 发生段错误会产生SIGSEGV信号，可以在程序开始的时候，将这个信号处理函数挂靠在特定的处理函数中，在函数中使用backtrace_symbols来回溯调用链。</p>
<h2 id="5-2_单链表">5.2 单链表</h2><p>　　Linux内核有个大名鼎鼎的list_head，可以封装在数据结构中使用，十分方便。但是这东西默认是内核态的，所以做了一点点修改，就可以在用户态方便的使用了。还要的RBTree也从内核中移植出来了，可以保证高性能的访问需求。<br>　　当然，如果不是洁癖的要C的话，还是可以考虑用C++，因为C++标准库和Boost库封装了大量的容器类和算法类，虽然编译出来的可执行程序显得比较的臃肿，不过大多数情况下总比你自己造出的轮子要稳定可靠的多。</p>
<h2 id="5-3_编码问题">5.3 编码问题</h2><p>　　Windows系统下默认编码是GBK，Linux平台下默认编码是UTF8，虽然对于一般的程序源文件编码类型问题不大，最多是注释看起来是乱码而已，但是对于源代码中使用了字符串明文的情况，这个差异就会比较大。<br>　　我移植的程序是做自然语言处理部分的，代码中包含了大量的中文字符串明文，同时程序中还有很多算法也是基于字符串是GBK编码方式假设的。所以移植的时候，就全部保留了源代码文件GBK编码模式，这样程序处理逻辑就可以沿用原来的部分，但是在访问文件系统的时候还需要注意将文件路径编码为UTF8的模式，否则会告之文件和目录找不到的错误。<br>　　程序的编码沿用了传统的GNU libiconv库。Boost包含了一个Boost.locale的库，其中包含各种编码、常规字符和宽字符的互转，虽然表象使用起来方便，但是没有相关文档，就没有使用了。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">charset_convert</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *from_charset, <span class="keyword">const</span> <span class="keyword">char</span> *to_charset,</span></span></div><div class="line">                             <span class="keyword">const</span> <span class="keyword">char</span> *inbuf, <span class="keyword">char</span> *outbuf, <span class="keyword">size_t</span> outlen)</div><div class="line">&#123;</div><div class="line">    <span class="keyword">iconv_t</span> icd;</div><div class="line">    <span class="keyword">size_t</span> inlen = <span class="built_in">strlen</span>(inbuf);</div><div class="line">    <span class="keyword">size_t</span> outleft = outlen;</div><div class="line">    <span class="built_in">memset</span>(outbuf, <span class="number">0</span>, outlen);</div><div class="line"></div><div class="line">    <span class="keyword">if</span> ((<span class="keyword">iconv_t</span>)<span class="number">-1</span> == (icd = iconv_open(to_charset, from_charset)))</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> ((<span class="keyword">size_t</span>)<span class="number">-1</span> == iconv(icd, (<span class="keyword">char</span>**)&amp;inbuf, &amp;inlen, &amp;outbuf, &amp;outleft)) &#123;</div><div class="line">        iconv_close(icd);</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    iconv_close(icd);</div><div class="line">    <span class="keyword">return</span> (<span class="keyword">int</span>)(outlen - outleft);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">gbk2utf</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; str_gbk, <span class="built_in">std</span>::<span class="built_in">string</span>&amp; store)</span></span></div><div class="line">&#123;</div><div class="line">	<span class="keyword">size_t</span> outlen = str_gbk.size() * <span class="number">2</span> + <span class="number">1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">char</span> *outbuf = (<span class="keyword">char</span> *)<span class="built_in">malloc</span>(outlen);</div><div class="line">    <span class="keyword">if</span> (!outbuf)</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> ret = charset_convert(<span class="string">"GBK"</span>, <span class="string">"UTF-8"</span>, str_gbk.c_str(), outbuf, outlen);</div><div class="line">    <span class="keyword">if</span> (ret == <span class="number">-1</span>) &#123;</div><div class="line">        <span class="built_in">free</span>(outbuf);</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    store = <span class="built_in">std</span>::<span class="built_in">string</span>(outbuf);</div><div class="line">    <span class="built_in">free</span>(outbuf);</div><div class="line">    <span class="keyword">return</span> ret;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　此外，如果需要查看程序的输出，默认的UTF8终端可能会显示乱码，必须设置终端的输出字符为GBK编码才可以。汉字的编码由旧到新是GB2312、GBK、GB18030，越新的标准支持的汉字符集越多，而且编码方式都是向下兼容的，GB2312现在来说收录的字符偏少，但GBK已经满足绝大部分需要了。<br>　　如果原来程序是多个部分的，移植目标是生成一个大项目的时候，要记住使用命名空间进行包装，否则可能会产生潜在的名字冲突问题，常量定义尽量使用const代替define，否则名字空间也保护不了你！</p>
<p>　　移植的代码已经托管到<a href="https://github.com/taozhijiang/st_utils" target="_blank" rel="external">st_utils</a>了，欢迎大家测试指正。同时由于工作的时间比较的旧，很多参考文献不能一一列出了，如原作者有需求，请联系我加上！</p>
<p>本文完！</p>
<h1 id="参考文献">参考文献</h1><ul>
<li><a href="http://www.ibm.com/developerworks/systems/library/es-MigratingWin32toLinux.html" target="_blank" rel="external">Migrating Win32 C/C++ applications to Linux on POWER, Part 1: Process, thread, and shared memory services</a></li>
<li><a href="http://www.ibm.com/developerworks/systems/library/es-win32linux.html" target="_blank" rel="external">Migrate Win32 C/C++ application to Linux on POWER, Part 2: Mutexes</a></li>
<li><a href="http://www.ibm.com/developerworks/systems/library/es-win32linux-sem.html" target="_blank" rel="external">Migrate Win32 C/C++ applications to Linux on POWER, Part 3: Semaphores</a></li>
<li><a href="http://blog.csdn.net/wenhm/article/details/1758848" target="_blank" rel="external">Windows下程序向Linux下移植细节</a></li>
<li><a href="http://qiusuoge.com/12451.html" target="_blank" rel="external">手把手教你玩转SOCKET模型：完成端口(Completion Port)详解</a></li>
<li><a href="http://www.graphics-muse.org/wp/?p=868" target="_blank" rel="external">Working with timer_create() to use multiple timers using a single signal</a></li>
<li><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-signalsec/" target="_blank" rel="external">Linux 多线程应用中如何编写安全的信号处理函数</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[推荐系统常用的推荐算法]]></title>
      <url>https://taozj.org/201604/recommend-system-algorithm.html</url>
      <content type="html"><![CDATA[<h1 id="一、推荐系统概述和常用评价指标">一、推荐系统概述和常用评价指标</h1><h2 id="1-1_推荐系统的特点">1.1 推荐系统的特点</h2><p>　　在知乎搜了一下推荐系统，果真结果比较少，显得小众一些，然后大家对推荐系统普遍的观点是：<br>　　(1) 重要性程度UI&gt;数据&gt;算法，就是推荐系统中一味追求先进的算法算是个误区，通常论文研究得到的推荐方法有的带有很多的假设限制，有的考虑工程实现问题较少，推荐系统需要大量的数据整理和转化，同时更需要考虑公司业务特性以及与现有系统的集成，方能形成推荐系统和业务之间的良性循环；<br>　　(2) 推荐系统离线测试很好，上线后要么没有严格的测试结果而只能凭感觉，要么实际效果差强人意，我想主要缘于离线测试比较理想，而在线AB冠军测试无论对于前端还是后台要求都很高，没有雄厚的研发实力难以实现；<br>　　(3) 推荐系统受到的外部干扰因素特别多（季节、流行因素等），整个系统需要不断的迭代更新，没有一劳永逸的事情。<br><img src="/post_images/images/201604/f732c70cc213540804f4220ac672c727.jpg" alt="推荐系统图"></p>
<h2 id="1-2_推荐系统的评价指标">1.2 推荐系统的评价指标</h2><p>　　由于推荐系统比较复杂，所以涉及到的评价指标也很多。当然，用户满意度最为的有效，因为这本来就是推荐系统的最终目标，但是奈何资源有限成本太高，推荐系统还依赖于其它客观评价指标。<br>　　(1) 推荐准确度：<br>　　这个参数可以离线计算所得，而且较为的客观，所以是各大研究论文算法最重要的参考指标。总体来说，推荐系统有两大任务：“预测”和“推荐”，所以推荐系统准确度的评分包括：<br>　　a. 评分预测：学习用户的评价模型，用于预测用户对于未接触事物的评分，其实可以看作是一个回归模型，一般用均方根误差或者绝对误差来衡量；<br>　　b. TopN推荐：给用户一个个性化的推荐列表，其一般通过准确度、召回率等指标评估。其中N也是一个可变参数，可以根据不同的N描绘出对应算法的ROC曲线来进一步评价推荐效果；<br>　　(2) 覆盖率：<br>　　体现了挖掘算法对发掘长尾商品的能力。最简单的定义是，对所有用户推荐出的产品做并集，然后看这个出现的并集产品与总产品数中所占的比例，这种方式比较的粗线条，因为推荐系统中马太效应(马太效应，是指强者越强、弱者越弱的社会现象)频繁，所以好的推荐算法应当是所有商品被推荐的几率差不多，都可以找到各自合适的用户，所以实际中会考虑信息熵、基尼系数等指标。<a id="more"></a><br>　　(3) 多样性：<br>　　其原理可以表述为不在一棵树上吊死。因整个推荐系统涉及到的因素太多，如果只推荐用户一个类别的相似物品，失败风险比较的大，而且也难以实现整个推荐效益的最大化。<br>　　(4) 新颖性：<br>　　原理就是那些用户没有接触过、没有操作过的商品，或者是流行度比较低的商品，对用户来说是比较新鲜的物品，往往会有意外的效果。个人觉得这个指标有点扯~~<br>　　(5) 信任度：<br>　　这个指标比较的主观，就是让用户信任推荐系统做出的推荐是有根据有理由的，以及推荐系统内部是如何运作的。例如亚马逊的商品推荐会给出推荐理由，作为用户的我会觉得很贴心，否则用户会觉得商家的利益驱动而带有抵触心理。<br>　　(6) 健壮性：<br>　　比如针对关联推荐算法，商户恶意下单提高产品的推荐频率，水军恶意评论等。</p>
<h1 id="二、静态数据推荐">二、静态数据推荐</h1><p>　　基本上绝大多数算法都会利用用户-产品的交互数据动态生成个性化的推荐。而静态数据指还没生成用户交互数据的时候，这种情况在系统冷启动的时候尤为的常见，常常使用的静态数据包括：<br>　　(1)用户注册时候的性别、年龄、地域、学历、兴趣等人口统计学信息；<br>　　(2)授权的社交网络账号的好友信息；<br>　　这类基于推荐方法简单，可以根据每类用户预先设置好推送内容，也可以根据同类用户相互之间进行推送，但是这种方法面临着推荐颗粒度较大，对于涉及个人品味爱好的个性化强的商品，参考价值有限，同时在大家隐私意识加强的情况下，这类数据不见得能够轻易得到；第二类社交网络好友信息效果会比较好，但也需要相应的平台授权接入才可以。<br>　　然后这里引申出对于新加入的用户和新加入的商品的冷启动问题：<br>　　(1) 新加入用户：<br>　　推送热门商品；选择用上面人口统计信息进行粗粒度的推送；如果可以得到合作商数据，获取其好友信息，选择接近的好友进行UserCF推荐；向用户展示一些商品（热们常见、具有代表性和区分性、物品要多样性），得到用户的反馈，然后进行学习（Nadav Golbandi算法）；<br>　　(2) 新加入商品：<br>　　UserCF对新加入的物品冷启动不是很敏感，因为只要有用户发现这个新商品，这个新商品就会慢慢扩散开来。对于ItemCF就比较严重，比如可以考虑开始使用基于内容的推荐，等积累数据一定程度后切换成协同过滤推荐。</p>
<h1 id="三、基于内容的推荐">三、基于内容的推荐</h1><p>　　其主要根据用户之前的喜好，推荐相似的物品。该系统包括用户属性和产品属性两方面构成，前者包括用户的固有属性（比如人口统计信息）以及用户的历史商品交互信息（比如对看过电影的评分，然后得到该用户对于喜欢电影的属性描述），后者是对商品的本身属性描述，这样通过简单的余弦相似度就可以实现推荐了。同时也能感觉到，对于同类型的物品描述维度相似，这种算法会工作的比较好，对于电商千奇百怪的商品，可能工作效果一般。<br>　　这个方法核心要解决的问题是推荐是否具有扩张性，如果根据用户之前的爱好只不断推荐同类的产品，显然整个推荐系统的价值就十分有限，但是如果能准确推荐其他不同类别的商品就会很好了。<br>　　Pandora的音乐推荐就是个典型的基于内容的推荐系统，他们把音乐使用各种维度的属性进行描述，然后根据用户之前的兴趣爱好推荐相似属性风格的音乐。</p>
<h1 id="四、协同过滤算法">四、协同过滤算法</h1><p>　　协同过滤算法算是推荐系统中最经典的算法了，也称为基于领域的算法。协同过滤牵涉到用户和商品的交互信息，也就是用户行为，而一般用户对于商品的行为反馈有：<br>　　显性反馈行为——用户明确表现出对某项产品和的喜好，比如用户对商品的打分、评论等信息。<br>　　隐性反馈行为——不能明确代表用户对产品喜好的行为，比如页面浏览行为等，这类数据量的比较多，常常伴有大量的噪音，需要经过处理和转化才可能有实际的用途。</p>
<h2 id="4-1_基于用户的协同过滤算法(UserCF)">4.1 基于用户的协同过滤算法(UserCF)</h2><p>　　其基于的假设是——喜欢类似物品的用户可能有相同或者相似的口味和偏好。UserCF实现的步骤包括：<br>　　(1) 找到与目标用户兴趣相似的用户群；<br>　　假设用户u和v的正反馈的商品集合为N(u)，N(v)，那么两者兴趣相似度可以记为<br>$$w_{u,v}=\frac{|N(u)\cap N(v)|}{|N(u)\cup N(v)|}或w_{u,v}=\frac{|N(u)\cap N(v)|}{\sqrt{|N(u)||N(v)|}}$$<br>　　(2) 找到这个集合中用户喜欢的，而目标用户没有听说过得商品推荐之；<br>　　UserCF提供的一个参数K表示要考虑目标用户兴趣最相似的人的个数，在保证精度的同时，K不宜过大，否则推荐结果会趋向于热门商品，流行度指标和覆盖度指标都会降低。</p>
<h2 id="4-2_基于内容的协同过滤算法(ItemCF)">4.2 基于内容的协同过滤算法(ItemCF)</h2><p>　　目前用的最广泛的推荐算法，不是通过商品本身，而是通过用户对商品的行为来计算商品之间的相似度，其假设能够引起用户兴趣的商品，必定与其之前评分高的商品相似。ItemCF的操作步骤包括：<br>　　(1) 计算商品之间的相似度。<br>　　物品相似度可以表示为（其实跟前面的支持度比较像）<br>$$w_{i,j}=\frac{|N(i)\cap N(v)|}{|N(i)|}或w_{i,j}=\frac{|N(i)\cap N(j)|}{\sqrt{|N(i)||N(j)|}}$$<br>　　第二个式子比第一个式子好在可以惩罚过热产品j。<br>　　(2) 根据商品的相似度和用户的历史行为，给用户生成推荐列表。</p>
<h2 id="4-3_基于模型的协同过滤算法">4.3 基于模型的协同过滤算法</h2><p>　　User-CF和Item-CF合称为memory-based CF，而model-based CF使用一般机器学习的方式，其基于样本的用户喜好信息，训练出一个推荐模型，然后根据实时的用户喜好的信息进行预测和计算推荐。<br>　　常用的模型包括LSI、贝叶斯网络等。</p>
<h2 id="4-4_UserCF和ItemCF之间的比较">4.4 UserCF和ItemCF之间的比较</h2><p>　　在现实的情况中，往往物品的个数是远远小于用户的数量的，而且物品的个数和相似度相对比较稳定，可以离线完成工作量最大的相似性计算步骤，从而大大降低了在线计算量，基于用户的实时性更好一些。但是具体使用的场景，还需要根据具体的业务类型来区分，一般User-CF偏重于反应用户小群体热点，更具社会化，而Item-CF在于维持用户的历史兴趣，比如：<br>　　对于新闻、阅读类的推荐，新闻阅读类的信息是实时更新的，所以ItemCF在这种情况下需要不断更新，而用户对新闻的个性化推荐不是特别的强烈情况，用户有新行为不会导致相似用户的剧烈运动。<br>　　对于电子商务类别的，由于用户消费代价比较高，所以对个性化的精确程度要求也比较高，而一段用户有新的行为，也会导致推荐内容的实时变化。</p>
<p>　　协同过滤的算法缺点也很明显，除了上面的冷启动之外，往往商家的用户数量和产品数量都很多，所以矩阵的计算量会非常的大，但某个具体的用户往往买的东西又有限，所以数据同时也是高度稀疏的。</p>
<h1 id="五、基于标签的推荐方法">五、基于标签的推荐方法</h1><p>　　基于标签的推荐算法也是十分常见的，比如豆瓣网、京东的商品评论等。标签信息一般分为专家、学者类打的标签；一类为普通用户给商品打的标签（UGC, User Generated Content）。而标签的内容一般要么描述商品本身的，比如名字、类别、产地等，也或者用户对商品的观点评价，比如便宜、好用、性能强等，三元组（用户、物品、标签）通过标签将用户和物品进行联系。<br>　　基于标签推荐最简单的例子比如：统计一个用户最常用的标签，统计每个物品最常被打的标签，然后两者通过一定的关系推荐起来；当然也可以展现标签云，让用户点击自己感兴趣的标签，然后依此个性化推荐。<br>　　国内的京东、淘宝、豆瓣都大量使用标签信息。<br><img src="/post_images/images/201604/da65fa0b24cc771e77f3ad16366d7d61.jpg" alt="京东标签"><br><img src="/post_images/images/201604/676dad9d76b3795e78d5302808fa6a99.jpg" alt="豆瓣标签"><br>　　由于标签的评价用户主观性比较强，所以一方面同样意思用户的用语差异性比较大，规范化可以考虑：用户评价的时候提供常用标签，让用户点击可以减少输入差异，而推荐的标签包括该物品描述性较好的标签，以及用户自己常用的标签（用户一致性）；人为或者通过自然语言处理技术对标签进行整理，对于用户积极和消极的评价进行区分；标签也有长尾分布效应，所以除了热门标签外怎么提取那些差异化的有用标签进行更精确的推荐也是应当研究的课题（卡方分布/SVD?）。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy1/index.html" target="_blank" rel="external">探索推荐引擎内部的秘密，第 {1,2,3} 部分</a></li>
<li><a href="https://book.douban.com/subject/10769749/" target="_blank" rel="external">推荐系统实践</a></li>
<li><a href="http://breezedeus.github.io/2015/01/31/breezedeus-review-for-year-2014-tech.html" target="_blank" rel="external">(2011-)2014 年终总结：技术篇</a></li>
<li><a href="http://dsec.pku.edu.cn/~jinlong/publication/wjlthesis.pdf" target="_blank" rel="external">Netflix Prize 中的协同过滤算法</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[推荐系统的典型推荐案例]]></title>
      <url>https://taozj.org/201604/recommend-system-cases.html</url>
      <content type="html"><![CDATA[<p>　　还依稀记得我小的时候，爸爸骑着自行车带我买东西，有时候在小店面，有时候去供销合作社，基本都是跟售货员说：我要一包火柴、3块肥皂、一瓶酱油等等，最多有的时候售货员会问你说要好的、一般的还是便宜的，形式有些像现在的普通药店形式；后来超市开始慢慢走入我们的生活，超市提供的选择和类型就开始多了，而且你还可以逛逛多家超市比较自己喜欢和便宜的，也不用觉得“问了人家或者人家推荐了，不买又不好意思”；现今随着互联网的浪潮，电商变的越来越流行，轰炸式的广告让农村五六十岁的大叔大妈都知道买东西可以找淘宝、京东，而淘宝、亚马逊这些电商的产品目录是绝大多数超大型超市也难以比拟的（当然这之中还有一个国内市场混乱、诚信缺失的因素，导致各类欺诈、假冒伪劣案例频发，所以现今越来越多的人买东西都会选择大型商家自营来挑选了）。<br>　　其实，就是当今社会生产力的发展，导致各行各业的产品过载，越来越多的人患上了选择恐惧症：吃饭不知道吃啥，听歌不知道听啥，打开浏览器不知道干嘛……虽然我在先前的<a href="">文章</a>中告诫大家不要在浩繁的信息海洋中被淹没而让自己的大脑越来越慵懒，遇事要有自己的主见，选择自己的所需所爱，否则你的依赖性会越来越强，但如果对于一个数据挖掘工程师来说，这何尝又不是一个巨大的机遇呢？<br>　　前段时间在搜索资料的时候，偶遇“推荐系统”这个话题，觉得还蛮有意思的。曾经Amazon的老大貌似说过要了解自己的每一个客户，亚马逊能称为全球最大的电商，跟其强大的推荐系统不无关系，不断作为推荐系统研究的经典案例，也为全球各大新兴电商尽相模仿。买了本<a href="https://book.douban.com/subject/26371405/" target="_blank" rel="external">《京东平台数据化运营》</a>，说实话，这本书算是个京东商家后台操作手册，其中基本难寻技术干货，但同时也折射出电商对于数据化运营之重视。国内对于推荐系统的教材寥寥，项亮所著<a href="https://book.douban.com/subject/10769749/" target="_blank" rel="external">《推荐系统实践》</a>算是写的比较早的，内容也还可以。刚看了前两章，其中所著推荐系统案例让我大开眼界、不愿独享，因此摘录下来推荐给大家。</p>
<p>　　正如上文所说的，推荐系统主要是在当前信息和产品过载情况下最为有用，因为如果可供选择的类别的很少，用户完全可以按照自己的喜好、或者收集相关信息做出自己的选择。当前在电商、影视音乐、社交网络、阅读、广告等，算是推荐系统使用最为广泛的领域。</p>
<h1 id="一、电商">一、电商</h1><p>　　电商类的推荐，首推强大的亚马逊了，其讲求的是了解每个客户，针对客户个性化推荐。当打开自己的推荐列表的时候，不仅显示出推荐的内容、评分，还提供了与用户交互反馈式的方式：我拥有了、我不感兴趣、评分，甚至显示出给你推荐的理由，由此可见亚马逊推荐功能之强大，同时对自己的推荐系统之自信。当然我在亚马逊购物的东西还不多，亚马逊可用的信息应当包括购买记录、添加购物车历史、搜索历史、浏览历史等信息，甚至还包括你的购物趋势(Inspired by your shopping trends)，当然还有那些Facebook等社交网络推荐、打包销售等还没能体会到。<br>　　作为海淘一族，下面是Amazon针对自己的推荐信息：<br><img src="/post_images/images/201604/137dcdf3e514a2ca4dd36df276e806ec.jpg" alt="Amazon推荐内容"><br>　　引用亚马逊CEO Jeff Bezos:</p>
<blockquote>
<p>“We have 6.2 million customers, we should have 6.2 million stores. There should be the optimum store for each and every customer.”<br>　　据称推荐系统给亚马逊贡献了20%~30%的收入，可见一个好的推荐系统比一般广告的收益率要高的多！<br>　　国内的京东也在倡导数据化运营，为个人生成的购物基因还是蛮有意思的。<br><img src="/post_images/images/201604/40f368924eafb4b67d4c034aef2fe77e.jpg" alt="京东购物基因"><br><a id="more"></a></p>
<h1 id="二、影视">二、影视</h1><p>　　影视方面Netflix的推荐被传为推荐经典，源于其用100W刀悬赏推荐算法，并为此开放了户行为数据集（40万用户对2万部电影的上亿条评分记录），虽然这个悬赏活动早就结束了，但是开放的数据集吸引了大量机器学习学者，方便了很多推荐算法用于训练和测试模型。<br>　　这个网站在大陆居然可以访问，其原因是没有在大陆开展业务，所以出了个空壳你啥也看不到。YouTube的推荐还是可以体会到的，其根据用户的观看和Subscribe内容，为我推荐了大量生活大爆炸、袁腾飞等视频内容，当然还有很多不符合当地法律规定的内容。</p>
</blockquote>
<h1 id="三、音乐">三、音乐</h1><p>　　音乐电台在国内数<a href="http://douban.fm" target="_blank" rel="external">豆瓣</a>十分的流行，上班的时候可以戴上耳机，当然不会刻意去欣赏和品味某些音乐，只是当作背景音乐罢了。作者介绍了三个典型的音乐电台：Pandora、Last.fm和国内的豆瓣，Pandora基于一个音乐基因工程（Music Genome Project）的项目，针对海量的曲库，让音乐家和工程师对音乐的各种特性（包括旋律、风格、节奏等信息）进行手动标注，称之为音乐基因，然后对用户的收听历史进行基于相似度聚类推荐；Last.fm是基于用户的收听历史和评价反馈，然后对那些相似兴趣的用户歌曲集向目标用户推送不再收听列表中的歌曲，可见Last.fm是使用当前推荐系统最流行的基于用户协同过滤的推荐方法；豆瓣的信息比较的少，使用过程中一方面用户点击喜欢、垃圾桶进行当前曲目的反馈，同时可以收听指定类型频道的音乐电台。<br>　　针对音乐推荐，或许可以考虑优化的因素还会很多，比如：音乐本身有频率、歌词等信息，可以考虑音乐本身属性的自动挖掘聚类；用户在工作、锻炼、休息的时候，心情和状态都不一样，最好能个性化推荐不同风格、节奏的曲目；用户注册的年龄、性别、学历、工作、地域等信息，对用户的品味影响比较大，对也是不错的参考源。</p>
<h1 id="四、社交网络">四、社交网络</h1><p>　　社交网络其实是个十分优质的数据源，因为他是个结构化的网络数据，可以不断地深层次挖掘，同时涉及到的内容也是丰富多彩而不会十分单一，可以从多个维度刻画目标用户的属性。<br>　　国内的新浪微博，一打开就是铺天盖地的广告，用户烦了便纷纷投向微信盆友圈求安宁去了，作为传统内容门户网站的新浪没有这方面的基因，形式太过于简单粗鲁；百度贴吧每隔两三楼就插播一个广告，看的人也是醉了；优酷一分多种的视频广告超过30秒，热点视频甚至更久，所有视频的广告内容基本一样，尤其那种游戏类的广告声响大的要死，直逼用户的心理底线；各大门户网站就更不用说了，什么顶端、底端、侧面都布满了，还要给你来个浮动的，弹窗的。这些网络运营商，或许他们只管卖固定价格的广告位，于是拼命建立更多的广告区域，也没考虑过精细化广告运营和广告实际的转化率。<br>　　这里倒是还有个段子，说是新浪微博的好友推荐系统，对于用户A的好友B和C，系统把B和C进行好友互推，导致的结果就是：A的老婆和A的小三认识了，或者A的女友和A的前任认识了。虽然这种情况在现实中出现的概率不会太高，但是后果很严重，至少也说明了推荐问题可以做的很简单，但是要实现精准的推荐也不是件简单的事情，比如对A和B以及A和C的交流信息做深层次的文本挖掘或许可以解决上面这种尴尬。</p>
<h1 id="五、聚合阅读">五、聚合阅读</h1><p>　　聚合阅读的话，偏执点的程序员会自己搜集个人喜好的RSS订阅（以前自己居然用过USENET），而普通大众手机端最流行的莫过于今日头条了（我的好几个朋友反对，说标题党信息太多）。虽然现在已经卸载了，但基于以前的使用经验，他会给每篇文章打几个TAG，当用户不喜欢的时候，可以选择原因，包括内容性质的TAG(比如某个明星)，或者评价类的TAG(比如内容质量差)，借此实现个性化的推荐。<br>　　目前个人的新闻阅读方法都是讲RSS烧录到<a href="https://blogtrottr.com/" target="_blank" rel="external">blogtrottr</a>，然后他会自动收集新闻然后发送到我的邮箱中，并且是免费使用的。大家不要声张，希望这个好东西能存在的长久点。目前的问题是每日推送的有点多，而且有些是重复的，ThunderBird上要是能搞个插件，排重后优先把我感兴趣的复制一份到某个目录就方便多了。</p>
<h1 id="六、广告">六、广告</h1><p>　　广告投放不得不提Google Ads了，其算是Google的命脉，所以也极为的重视，Google Ads算是一个联盟，你可以选择将Google的广告挂在自己的网站上，当有点击的时候，Google会给你相应的收益。Google Ads对广告把控的算是比较严格的，当时自己作弊点击，被Google发现后取消了广告收益，因此Google对广大广告投放者来说还是比较负责人的。<br>　　这里还有个段子，说的是有个哥们处于好奇在淘宝网<a href="http://news.qq.com/a/20130722/007007.htm" target="_blank" rel="external">搜了一下“棺材”</a>，结果一个多月他打开新浪微博的时候，就给他推介寿衣、骨灰盒寿衣之类的。当然上文的重点偏向了用户隐私和数据贩卖，但在中国应当习以为常了吧，广大网民基本都是裸奔，在国外的话，也有专门做这个的公司，叫做<a href="http://www.oracle.com/us/corporate/acquisitions/bluekai/index.html" target="_blank" rel="external">BlueKai</a>，目前已被Orale收购，针对企业客户，他们会给企业提供的数据做分析，然后给出广告投放的个性化方案。如果只是这个，还不算牛逼的，他做了个数据Market，有客户数据的公司可以把数据卖给他，他们对数据进行清洗（最主要把涉及用户隐私的部分抹掉）、加工之后，对于有需要的公司可以买下和自己胃口的用户，将广告定向投放给他们。想想都是一件不可思议的壮举！<br>　　不过现在国内甚至国外很多网站浏览的时候，也会给出京东或者淘宝的个性化推荐，不知道是由BlucKai这种公司运营的，还是这些网站出售接口给京东、淘宝这样的大客户自行实现的。</p>
<h1 id="七、其它">七、其它</h1><p>　　推荐系统表面看就是给出一些信息，可以做的很粗放，也可以做的很精细，其必须考虑到客户需求和商家（包括第三方商家）利益之间能够最大化。比如长尾效应和马太效应，前者在关注重点客户主流需求的同时，也可以挖掘潜在个性化客户，往往会有的更大的增长空间；后者可以维持公平竞争兼顾扶植一些成长型的客户；对于客户，你可以准确推荐，也可以给用户多样化推荐，甚至给用户“惊喜/尝试”型推荐，总之一切尽在细节之中，没有什么是绝对的好与不好的！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://book.douban.com/subject/10769749/" target="_blank" rel="external">推荐系统实践</a></li>
<li><a href="http://quweiprotoss.blog.163.com/blog/static/408828832013122104343464/" target="_blank" rel="external">计算广告学-受众定向-受众定向概念</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[SVD的数学计算步骤]]></title>
      <url>https://taozj.org/201604/how-to-calc-svd.html</url>
      <content type="html"><![CDATA[<p>涉及到矩阵论相关的东西，这里查资料需要把他彻底搞个明白，幸好找到了参考中的pdf文档，写的很详细很入门，于是就拜读了一下。对于知道的人不要笑话，不知道的赶紧补课吧！</p>
<h1 id="一、线性代数相关基础">一、线性代数相关基础</h1><ul>
<li>点乘/内积: $(\vec{x},\vec{y}) = \vec{x}\cdot\vec{y} = \sum_{i=1}^nx_i+y_i$<br>要求点乘的两个向量的维度相同</li>
<li>正交：$\vec{x}\cdot\vec{y} = 0$<br>两个向量的点乘为0</li>
<li>标准向量：|$\vec{x}| = \sqrt{\sum_{i=1}^nx_i^2} = 1$<br>向量的长度为1</li>
<li>Gram-Schmidt正交化：<br>用于产生一个矩阵的标准正交基，定义为每个列向量的长度为1，不同列向量相互正交，计算过程为：<br>（1）对于第一列，对向量的模长进行标准化；<br>（2）后面的每一列，依次按照公式$\vec{w}_k = \vec{v}_k - \sum_{i=1}^{k-1}\vec{u}_i\cdot\vec{v}_k*\vec{u}_i$进行计算，然后将计算结果$\vec{w}_k$进行标准化。<br>如果标准正交基是方阵，那么叫做正交矩阵，且$\vec{A}\vec{A}^T=\vec{I}$。</li>
<li>矩阵的乘法：<br>如果$\vec{A}$和$\vec{B}$分别是维度为(m,n)和(n,s)的矩阵，那么$\vec{A}\vec{B}$结果的维度就是(m,s)。</li>
<li>对角矩阵：<br>对角线上的元素全不为零，其余元素全部为零的方阵。</li>
<li>单位矩阵：<br>除了对角线上的元素为1，其他元素都为0的方阵，且$\vec{A}\vec{I}=\vec{A}$。</li>
<li>行列式：<br>将一个方阵映射而成的数值，根据其方阵的维度不同，计算如下：<br>（1）$\vec{A} = \begin{bmatrix}a\end{bmatrix}$，$det(\vec{A})=a$;<br>（2）$\vec{A} =\begin{bmatrix}a&amp;b\\c&amp;d\end{bmatrix}$，$det(\vec{A})=ad-bc$;<br>（3）对于更高维度的，按照第一行展开成低纬度的子方阵计算，展开过程中交替改变符号。<br>这里给出一个例子，计算检验看看对不对（$det(\vec{A})=-36$）。<br>$$\vec{A}=\begin{bmatrix}1&amp;2&amp;3&amp;4\\ -1&amp;-2&amp;-7&amp;-4\\2&amp;3&amp;4&amp;5\\ -2&amp;-3&amp;5&amp;4\end{bmatrix}$$</li>
<li>特征值和特征向量：<br>对于方阵$\vec{A}$满足$\vec{A}\vec{v}=\lambda\vec{v}$，那么非0向量$\vec{v}$为特征向量，$\lambda$为特征值。其实可以上面看作是个方程组的解的问题，将$\vec{A}$看成方程组的系数，那么特征向量为方程组的解，比如<br>$\vec{A} =\begin{bmatrix}2&amp;1\\1&amp;2\end{bmatrix}$，那么<br>$$\vec{A}\vec{v}=\lambda\vec{v}=\begin{bmatrix}2&amp;1\\1&amp;2\end{bmatrix}\begin{bmatrix}x_1\\x_2\end{bmatrix}=\lambda\begin{bmatrix}x_1\\x_2\end{bmatrix}$$<br>其整理后就为<br>$$\begin{bmatrix}(2-\lambda)&amp;1\\11&amp;(2-\lambda)2\end{bmatrix}=0$$<br>解得特征值为$\lambda_1=3,\lambda_2=1$，对应的特征向量为$\begin{bmatrix}1,1\end{bmatrix}$和$\begin{bmatrix}1,-1\end{bmatrix}$。</li>
</ul>
<h1 id="二、进行SVD奇异值分解">二、进行SVD奇异值分解</h1><p>SVD的目的，就是将一组相关的变量投射到某个超平面，形成相互无关的变量，用以更好的显示变量之间的差异性，同时还可以根据相关性进行排序，找出哪些属性的差异最明显，可选择的保留差异性大的属性，从而实现了数据的降维。其寻找的超平面具有以下目的：</p>
<ul>
<li>最近重构性：样本点到这个超平面的距离都足够近；</li>
<li>最大可分性：样本在这个超平面上的投影都尽可能的分开；<br>SVD的最简洁表达公式如下<br>$$\vec{A}_{mn}=\vec{U}_{mm}\vec{S}_{mn}\vec{V}_{nn}^T$$<br>其中，$\vec{A}_{mn}$为原始信号，$\vec{U}_{mm}$和 $\vec{V}_{nn}$都是两个正交矩阵，$\vec{V}_{nn}^T$为 $\vec{V}_{nn}$的转置，$\vec{S}$为对角矩阵，那么$\vec{A}_{mn}$就可以用右边的三个公式表示出来。</li>
</ul>
<h2 id="2-1_SVD分解">2.1 SVD分解</h2><p>下面介绍SVD分解的计算过程：</p>
<ul>
<li>给定原始信号$\vec{A}$，计算 $\vec{A}_{mn}\vec{V}_{nm}^T$，得到(m,m)方阵；</li>
<li>计算方阵的特征值和特征向量；</li>
<li>按照特征值从大到小的顺序，依次取其特征向量作为列，组成矩阵$\vec{U}’$；</li>
<li>对$\vec{U}’$进行Gram-Schmidt正交化形成正交矩阵$\vec{U}_{mm}$；</li>
<li>依照上面类似的过程，采用$\vec{A}_{nm}^T\vec{V}_{mn}$进行计算，最终得到正交矩阵$\vec{V}_{nn}$，再行转秩得到$\vec{V}_{nn}^T$；</li>
<li>对于$\vec{S}$，是使用上面的非0特征值按照从大到校的顺序开放形成对角矩阵，对于矩阵维度不满足，右端依次添加0列即可；</li>
<li>用$\vec{U}_{mm}\vec{S}_{mn}\vec{V}_{nn}^T$就可以重构$\vec{A_{mn}}$了。</li>
</ul>
<h2 id="2-2_SVD用于降维的额外操作">2.2 SVD用于降维的额外操作</h2><p>上面是SVD分解，所以最终得到的三个变量是能够完全重构原来的输入信号的。在上面计算的特征值的时候，如果按照从大到小的顺序，实际就是按照属性差异从大到小进行的排列，一般来说可以事先固定设定$\lambda$的个数，或者取总$\lambda$和前95%部分的$\lambda$来决定降维的程度。<br>比如对原始的信号属性从n维降低到r维度，只需要用原始信号乘以前r列的特征向量就可以了。<br>$$\vec{A}_{mn}\vec{U}_{n,1:r}\approx\hat{A}_{mr}$$<br>就可以了。</p>
<p>其实，本质上PCA跟SVD就是一个东西～～<br>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.ling.ohio-state.edu/~kbaker/pubs/Singular_Value_Decomposition_Tutorial.pdf" target="_blank" rel="external">Singular Value Decomposition Tutorial</a></li>
<li><a href="https://zh.wikipedia.org/zh/%E5%A5%87%E5%BC%82%E5%80%BC%E5%88%86%E8%A7%A3" target="_blank" rel="external">奇异值分解</a></li>
<li><a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/01/19/svd-and-applications.html" target="_blank" rel="external">机器学习中的数学(5)-强大的矩阵奇异值分解(SVD)及其应用</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[不带公式的机器学习算法整理]]></title>
      <url>https://taozj.org/201604/conclusion-of-machine-learning-algorithm.html</url>
      <content type="html"><![CDATA[<p>生命不息，奋斗不止。持续更新中…</p>
<p>　　这个题目取得比较奇怪，原因是：虽然号称数学是世界上最简洁的语言，但是太多的公式难免看的人心慌；其次是公式在hexo+mathjax打起来比较的费劲，还有兼容性问题。其实，本意就是想把常用算法罗列一下，用个一两段文字描述一下基本意思和原理，还有用途和局限性，如果看看记不起来了，再去寻求一大堆资料温习一下。其实机器学习常用的算法都比较老了，各种语言的学习库也久经考验，正如越来越多的码农沦为系统集成工程师一样，数据挖掘虽然不用从头实现算法的各个部分，但是如果能对流程和数据特性了如指掌，对各种算法适用范围、优缺点、参数含义烂熟于心，对各种业务指标期望有的放矢，岂不乐哉～<br>　　在此还想啰嗦的一句是，这么多算法无论复杂与简单，大多（统计类的可能有些例外）遵循了给出一个模型—计算误差—修正系统，直到得到最优解或者可以接受的误差为止，由此不得不感叹道维纳“控制论”之伟大！<br><img src="/post_images/images/201604/3dd9457bf78c0383571901dab41eb69f.png" alt="Machine Learning"></p>
<h1 id="一、分类">一、分类</h1><h2 id="1-1_贝叶斯">1.1 贝叶斯</h2><p>　　遵循贝叶斯公式框架的理论，后验概率正比于先验概率与似然度之积。</p>
<h3 id="1-1-1_朴素贝叶斯">1.1.1 朴素贝叶斯</h3><p>　　朴素贝叶斯之所以朴素，是基于“属性条件的独立性假设”而使得模型的计算被简化了。具体来说，就是输入样本有N维的属性，所有属性之间相互独立，每个属性单独独立的对分类结果产生影响。<br>　　对于离散值，就考虑每个属性出现的频率关系得到概率关系，而对于连续的属性，可以考虑其分布类型的概率密度函数。离散属性中，贝叶斯分布一般可以分为Bernoulli /Multinomial，前者是二项式分布，后者是多项式分布。对于统计的元素前者出现与否只有0、1两个状态，后者多项式分布，会记录出每个元素的具体出现频率。一般短文本分类的情况，适用于二项式分布，长文本分析的类似情况，使用多项式分布效果较好。<br>　　在文本分类（情感分析）中，使用过贝叶斯分类，很明显：先验概率就是训练文档各个分类的文档比重，此时你没有观测数据，那么按照这么个比例把握比较大，相似度就统计各个分类中词的出现与否/频率，然后对待测的数据，衡量待测数据中出现的词在各个分类中的比率来计算和各个分类的相似程度，最终修正先验概率得到后验概率。关于伯努利分布和多项式分布，在具体文本测试中两者估计就一个多点的差异，尚不是很明显。<br>　　这两个实现和求解的过程都比较简单，性能还不错，注意建模时候需要平滑处理，防止最终计算概率时候未出现词导致概率为0，其中常用的拉普拉斯修正~“+1”平滑实现简单而且有效。</p>
<h3 id="1-1-2_半朴素贝叶斯">1.1.2 半朴素贝叶斯</h3><p>　　朴素贝叶斯有属性独立性假设，这种假设在现实中并不是总是成立的，所以对属性独立性假设进行放松就形成了版朴素贝叶斯，比如常见的“独依赖估计”(ODE)，其就是假设每个属性在类别之外最多依赖一个其他的属性（如果增加依赖的属性可能计算结果会变好，但是高阶联合概率计算十分复杂），而这个被依赖的属性选择方法就成了这类算法的研究点：比如所有属性都依赖同一个属性，而这个父属性可以通过交叉验证来选择最好的。</p>
<h3 id="1-1-3_贝叶斯网络">1.1.3 贝叶斯网络</h3><p>　　又称为信念网络(Belief Network)，借助于有向无环图(DAG)来刻画属性之间的依赖关系。<br><a id="more"></a></p>
<h2 id="1-2_最大熵估计">1.2 最大熵估计</h2><p>　　在单一机器算法中算是性能上乘的。它基于一个事实：对于我们确信的东西，我们用规则去约束它，对于我们不确定的东西，我们不做任何的假设。新手很容易绕进去，说最大熵不就是最不确定么，我们的目的就是要消除不确定度，让熵降低，那你这个算法让不确定度最大，搞毛线啊。<br>　　其实举个例子，比如投骰子，如果什么不规定，你肯定知道投下去1向上的概率是1/6；然后我告诉你投下去1，2，3向上的概率是2/3，那你就知道1向上的概率就是2/9；然后我再约定3向上的概率为1/3，那么你几就推断出1向上的概率就是1/6了。为什么我要做出这么个判断，缘由我们不知道信息的时候，就让他平均分布，不加入人为的任何假设，这时候相对来说风险最小，但同时也是在满足约束条件下熵最大的时候。<br>　　在文本分类中，最大熵估计准确度确实比贝叶斯估计多4~5个百分点，但是最大熵估计需要不断的迭代约束条件来让他收敛，性能问算是这个算法最大的问题，常用的解法包括GIS(Generalized Iterative Scaling)、IIS(Improved Iterative Scaling)、L-BFGS，前者的计算效率最低，但是原理清晰，适于学习，而后者算法效率较高，适于工程实践。</p>
<h2 id="1-3_决策树">1.3 决策树</h2><p>　　决策树直观上感觉是跟数学关联最小的一种，其实就是建立一个个的判别规则，形似流程图一样，让样本走到最终的叶节点完成分类。但是，决策树在数据挖掘和商业决策中用的情况非常的广泛，同时一个专业的决策树还是有一些技巧的。由于决策树就是从属性集中选择属性来进行样本划分，所以希望决策树的分支节点的样本尽可能是同类别的，称之为纯度。<br>　　决策树的属性有连续和离散之分，对于离散属性，其只会在整个决策树中出现一次，而每个步骤的决策属性不是随便选的，而是基于一定的数学规则来进行，比如ID3使用的信息增益、C4.5使用到的增益率。<br>　　信息增益是先计算这个节点的信息熵，然后对于每一个可选属性，假设该种算法计算其分类后各个节点的信息熵，再根据各个节点数目加权进行整合，计算分类之前的信息熵和这个整合值之间的差异，定义为信息增益，大者说明该属性的划分信息增益大，取之。但是信息增益有个问题，就是比较偏向于可选类型值较多的属性，因此还有个增益率选择法，用之前的信息熵整合值处以“属性固有值”IV，而这个IV对于可选值较多的类型结果会比较大，所以偏向与属性类型值取值较小的属性。通常而言，是使用信息增益率先筛选掉一部分属性，在选择剩余的信息增益大的属性来划分。而CART使用的是Gini值，其表示了样本的分散度。<br>　　决策树还有的处理是剪枝处理，这对于处理过拟合十分的重要。一些情况下决策树学习的过于细致，一些样本的个性也被计算进去了，导致了模型的泛化很弱。剪枝分预剪枝（在生成树的过程中决定是否继续划分）和后剪枝（生成成功之后，从底向上查看非叶节点能否将其子树整合为叶节点）。一般来说，预剪枝有欠拟合的风险，而后剪枝欠拟合风险小，但是计算相对复杂一些。<br>　　对于连续值的预测，可以按照样本的值从小到大进行排序，然后两两去中位数，得到n-1个分类点。然后依次分类点分别计算分类的信息增益，取信息增益大的分类点来决策。还需要注意的是，连续值分类，其属性可以在分类树中使用多次的。<br>　　决策树中常会用到的算法有：ID3、CART、C4.5。</p>
<h1 id="二、回归(Regression)和正则化(Regularization_)">二、回归(Regression)和正则化(Regularization )</h1><p>　　回归问题属于有监督学习范畴，其相对与分类，回归的最大区别是输出变量是连续值，然而这两者没有必然的区分，因为对于回归的结果，也可以设定一个阈值区域用来实现分类效果。</p>
<h2 id="2-1_线性回归(Linear_Regression)">2.1 线性回归(Linear Regression)</h2><p>　　线性回归问题，目的在于得到一个线性模型，使得尽可能的能够让给定的输入能够准确的预测出对应的输出。可以表示为，对于训练数据集D，其每个样本$x^{(i)}$由多个属性所描述，然后我们试图得到函数模型$y=h(x)$，让$y^{(i)} \approx h(x^{(i)})$，然后可以对任意的新样本输入都能给出连续的输入出值，称之为多元线性回归。记为<br>$$h(x) = \sum_i\theta_ix_i = \theta^Tx$$<br>　　上式中每个$x$是一个样本，为了方便添加$x_0=1$和截距$\theta_0$截距。然后实际的输出和模型的输出肯定是有差距的，因此定义代价函数<br>$$J(\theta) = \frac{1}{2} \sum_i \left( h(x^{(i)}) - y^{(i)} \right)^2 = \frac{1}{2} \sum_i \left( \theta^\top x^{(i)} - y^{(i)} \right)^2$$<br>　　然后我们就是要通过训练样本来调整$\theta$，使得$J(\theta)$最小化（1/2为了求导方便）。最常用的方法有：梯度下降法、最小二乘法。</p>
<h3 id="2-1-1_梯度下降法">2.1.1 梯度下降法</h3><p>　　对于梯度下降法，有批量梯度下降法和随机梯度下降法。区别在于批量梯度下降法每次都考虑全部样本，运算量较大；随机梯度下降法在考虑单个样本之后就会更新$\theta$值，所以可以快速收敛。<br>　　批量梯度下降法$\theta$更新公式：$\theta_j := \theta_j + \alpha\sum_{i=1}^m(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}$<br>　　随机梯度下降法$\theta$更新公式：$\theta_j := \theta_j - \alpha\frac{\partial{J(\theta)}}{\partial\theta_j} = \theta_j + \alpha(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}$</p>
<h3 id="2-1-2_最小二乘法">2.1.2 最小二乘法</h3><p>　　相比较梯度下降法需要迭代求取参数$\theta$。</p>
<h2 id="2-2_逻辑回归(Logistic_Regression)">2.2 逻辑回归(Logistic Regression)</h2><p>　　逻辑回归其本质还是在于线性回归，只是对之前无约束的线性输出做了一个映射$g(z)$，对于sigmoid函数输出范围为[0,1]，对tanh函数为[-1,1]，下面假设以sigmoid函数为例，可得<br>$$ h_\theta(x)=g(\theta^Tx)= \frac{1}{1+e^{-\theta^Tx}}$$<br>　　这个得到的结果$h_\theta(x)$就是x分类为1的概率，而$1-h_\theta(x)$就是分类为0的概率，训练的目的就是对于标记为1的样本输出最可能的大，二标记为0的样本输出的值尽可能的小。其误差函数定义为：<br>$$ J(\theta) = \sum_i y^{(i)}log(h_\theta(x^{(i)})) + (1-y^{(i)})log( 1- h_\theta(x^{(i)}))$$<br>　　其用梯度下降法计算同上面的线性回归是一样的。</p>
<h2 id="2-3_Softmax回归">2.3 Softmax回归</h2><p>　　逻辑回归只能用于二分类的情况，而Softmax更像其在多分类情况下的推广，在使用中，如果目标的分类是多分类互斥的，那么用Softmax，否则可以为每个分类建立一个逻辑回归分类器。</p>
<h2 id="2-4_正则化">2.4 正则化</h2><p>　　为了防止模型过拟合的现象，在损失函数中增加一个对每个特征的惩罚因子的过程。过拟合出现的原因往往是特征维度太多，通过去处不重要的特征可以防止过拟合现象，但是去除特征会损失信息，这种情况下采用正则化就比较的方便（个人的直观感受就是增加了一个阻尼项，使得各个特征的表现不像之前那么明显激进）。工程约定中通常不对$\theta_0$进行正则化，同时正则化系数不能选择太大，否则会有欠拟合的风险。<br>　　常见的正则化有L-2范数正则化（岭回归 Ridge Regression）、L-1范数正则化（LASSO）<br>$$min_w\sum_{i=1}^n(y_i - \vec{w}^T\vec{x}_i)^2+\lambda||\vec{w}||_1$$<br>$$min_w\sum_{i=1}^n(y_i - \vec{w}^T\vec{x}_i)^2+\lambda||\vec{w}||_2^2$$<br>　　L-1范数和L-2范数都有助于降低过拟合的风险，而且相比L-2正则化，L-1正则化更容易得到稀疏解，等于起到了特征选择的作用。</p>
<h2 id="2-5_支持向量机_SVM">2.5 支持向量机 SVM</h2><h3 id="2-5-1_支持向量机">2.5.1 支持向量机</h3><h3 id="2-5-2_支持向量回归（SVR）">2.5.2 支持向量回归（SVR）</h3><p>　　其实一看模型$f(\vec{x})=\vec{w}^T\vec{x}+b$就类似于回归模型。SVR同一般的回归模型不同的是，一般的回归模型除非输出和标记完全一样，否则肯定会产生和记录误差，但是对于SVR，相当于在回归线的附近产生了一个缓冲带，在这个缓冲带的误差不计算，超过这个缓冲带的误差才会就算中。</p>
<h3 id="2-5-3_核方法">2.5.3 核方法</h3><p>　　通常的SVM是假设训练样本是线性可分的，就是可以通过超平面将数据正确分类。对于有些不能达到这个要求的样本，就只有想办法将原始特征映射到一个更高维度的特征空间。</p>
<h1 id="三、聚类">三、聚类</h1><p>　　聚类算法中比较核心的是距离的度量，距离近的才会被视为一类。常用的距离是Minkowski距离：<br>$$(\sum_{i=1}^n|x_{i}-y_{i}|^p)^{\frac1p}$$<br>　　当上式的p=2，就退化成了欧拉距离；当p=1，就退化成了麦哈顿距离。当然属性有离散型和连续型之分，连续型的属性计算距离没有什么问题，对于离散型的属性，如果是数值型的，也可以用Minkowski距离计算，而对于{颜色深,颜色浅}等无序属性，可以采用VDM(Value Difference Metric)计算其距离：<br>$$ VDM_p(a,b)=\sum_{i=1}^k|\frac{m_{u,a,i}}{m_{u,a}} - \frac{m_{u,b,i}}{m_{u,b}}|$$<br>　　上面的公式表示，对于k个样本簇，a、b为属性u的两个取值，两个比值表示每个簇中样本a、b占总数的比例。</p>
<h2 id="3-1_K均值算法(K-means)">3.1 K均值算法(K-means)</h2><p>　　其迭代过程表示为：通过对聚得到的每个簇i计算其均值向量$\vec{\mu_{i}}$，然后再将样本集中的每个元素，计算其与各个簇均值向量的距离，找到距离最近的聚类j，再将这个元素添加到j簇中。这样进行过一轮迭代之后，计算每个簇的新均值向量，如果簇均值向量不再更新，那么迭代停止。<br>　　当然K-means也有其缺点：（1）具体K聚类个数不太好把握；（2）初始聚类的种子选择是随机的。</p>
<h2 id="3-2_学习向量化(Learning_Vector_Quantization)">3.2 学习向量化(Learning Vector Quantization)</h2><p>　　要求训练的样本带有标记，算是监督类学习的一种，其目标是对每一个聚类簇学习得到一个属性向量。在训练样本中随机选择带标记的样本，然后计算与各个簇向量的距离，选择距离最近的那个簇，然后比较两者的标记是否一致，如果一致就让簇向量向样本属性向量靠拢；否则就反向远离之。<br>　　当达到最大迭代数目，或者各个簇向量更新很小的时候，就停止迭代。此时可以对任意样本与各个簇向量计算得到所划分的簇。</p>
<h2 id="3-3_层次聚类(Hierarchical_Clustering)">3.3 层次聚类(Hierarchical Clustering)</h2><p>　　试图在不同层次对数据进行划分，形成树形的聚类结构，有自顶向下和自底向上之分。常见的AGNES是一种自底向上的算法。该算法首先将每个样本看作一个初始聚类，然后在运算的每一步中选择距离最近的两个簇进行合并，重复之直到达到要求的聚类数目。这个算法的核心是计算各个簇之间的距离，当然簇也是由元素组成的，其实就映射到两个簇中选择元素进行计算，然后会有最小距离、最大距离、平均距离等方式来决定结果。</p>
<h2 id="3-4_Latent_Dirichlet_Allocation_(LDA)">3.4 Latent Dirichlet Allocation (LDA)</h2><p>　　这个算法最初发表，作者就是研究的文字类的分类，所以注定其在自然语言处理方便应用非常之很多，比如社交媒体热点监控、政府舆论监控等，而其中腾讯的广告系统就是基于这个算法的一个并行化实现。<br>　　本算法是个无指导的分类，只需参数提供聚类的数目即可（该算法还有一个变种，Labelled-LDA，可以实现指导分类）。同时，这个算法还比较有个性的是，其涉及到的数学概念和知识是相当之多。</p>
<h2 id="3-5_Probabilistic_Latent_Semantic_Analysis（PLSA）">3.5 Probabilistic Latent Semantic Analysis（PLSA）</h2><p>　　其实按照出现的顺序来说或，算是PLSA先出来（据说作者搞完这个就去开公司了，也算潇洒），看看PLSA和LDA就感觉是频率派和贝叶斯派的区别：比如在PLSA中在可观测的doc和term之间，隐藏了一个坚信存在的主题变量z，然后用EM方法估计这个z；相比前者LDA添加了个Dirichlet先验分布和一个Gibbs采样。<br>　　理论上人家说LDA由于有先验分布，所以对于超短文本应当可靠性较好，但是在现实的工程实现中，PLSA比较的简单，计算高效而且可以并行化实现，所以PLSA应当更具实用性。</p>
<h1 id="四、数据降维">四、数据降维</h1><p>　　在高纬数据处理中，数据降维和特征选择是两大主流技术。</p>
<h2 id="4-1_主成分分析(Principal_Component_Analysis,_PCA)">4.1 主成分分析(Principal Component Analysis, PCA)</h2><p>　　PCA是最常见的降维方法，常常作为一般算法对于数据的预处理操作。其原理就是将高维属性空间变换为一个低维属性空间，让这个空间中的样本密度大幅提高，因为与学习任务密切相关的信息只是高维属性空间中的某些低维属性，而且通常是各个样本变化比较大的那些属性而应当被保留，而差异比较小的，通常是干扰噪声应当被去除。<br>　　然后PCA跟SVD(Singular Value Decomposition)，很多资料分开讨论，其实算是一个东西：SVD是底层的数学基础，不仅可以降维属性而且可以降维样本数甚至不降维用另外的方式表示数据，PCA算是在统计和机器学习中的一个降低属性维度的约定吧。<br>　　算法的过程：（1）对所有输入样本去直流化，并将数据映射到[0-1]区间；（2）计算样本的协方差矩阵$\vec{X}\vec{X}^T$；（3）对协方差矩阵$\vec{X}\vec{X}^T$做特征值分解；（4）取最大的d个特征值对应的特征向量$\vec{w}_1,\vec{w}_2,…\vec{w}_d$;（5）生成投影矩阵$\vec{W} = \vec{w}_1,\vec{w}_2,…\vec{w}_d$;<br>　　这样生成的投影矩阵$\vec{W}$是正交基向量，$\vec{Y} = \vec{W}^T \vec{X}$就实现了数据的降维。PCA认为一个随机信号最有用的信息体包含在方差里，在投影的时候就希望找到的超平面上各个样本能够经可能的分开，所以上面得到的$\vec{Y}$各个向量不仅是独立的，而且是按照方差从大到小的顺序排列的。同时既然进行了降维，那么必定有些数据信息被舍弃了，舍弃这些信息后能让原本的采样密度更大，同时这些被舍弃的特征向量往往跟噪声有关，PCA此时也起到了降噪的作用。<br>　　同时，PCA还可以有的作用比如：</p>
<ul>
<li>数据压缩，比如对于图片这种数据，如果$\lambda$的选取的比较少，原来的(m,n)二维矩阵就可以用U,S,V三个小矩阵来近似等价存储了；</li>
<li>高维数据的可视化，将数据降维到2~3维就可以可视化了。</li>
</ul>
<h2 id="4-2_特征选择">4.2 特征选择</h2><p>　　特征选择就是对于高维的属性，挑选那些对当前学习有用的“相关特征”作为属性子集，去除那些没什么用的“无关特征”或者“冗余特征”，这样不但降低了计算的复杂度，同时也免除了那些无关特征对计算结果的干扰。<br>　　产生特征集，不能穷举所有的组合类型，因为特征选择本来就是应对高维属性的，穷举的组合类型就会非常的多，因此必须采用合适的子集生成和评价方法。前向搜索方法是：将所有属性分割成单个属性的子集，然后选择单个子集中评价最好的，再依次添加剩余的属性，形成两个元素的属性子集，选择评价最好的，依次类推，直到添加特征后评价还不如不添加，那么添加结束，返回该结果；类似的还有“后向”搜索、“双向”搜索。关于子集的评价，可以使用决策桩形式的信息增益来评价，或者分类准确度等各种评价指标。<br>　　常见的特征选择算法：</p>
<p>###4.2.1 过滤式选择<br>　　主要特点是先进行特征选择，然后进行训练学习，两者是无关的。代表方法是Relief(Relevant Features)，其设计了一个相关统计量来度量特征的重要性，该变量是个向量，每个分量代表了其特征的重要性，选择的时候：对每个样本，在其周围选择最近的同类样本和不同类样本，然后依照如下方法进行更新：<br>$$\delta^j=\sum_i-diff(x_i^j,x_{i,nh}^j)^2+diff(x_i^j,x_{i,nm}^j)^2$$<br>　　前者为同类样本的距离，后者为不同类样本的距离（离散类型根据是否相同为0/1，连续类型归一化到0~1）。</p>
<p>###4.2.2 包裹式选择<br>　　把学习器的最终性能作为属性子集的选择评判标准，所以等于是一种所见即所得的特征选择方法，但是其需要多次训练学习器，因此计算开销比较大。<br>　　最常见的包裹式特征选择法是LVM(Las Vegas Wrapper)算法，其算法的主要概念为：采用随机策略产生特征子集A’，采用交叉验证的方法得到学习误差$\epsilon’$，如果它比当前特征子集A误差更小，或者特征子集包含的特征数量更小，则保留A’。这种算法算是比较简单粗暴的，且其停止条件是迭代次数……</p>
<p>###4.2.3 嵌入式选择<br>　　这其实是L-1范数正则化(LASSO)的副产品，因为对于<br>$$min_w\sum_{i=1}^n(y_i - \vec{w}^T\vec{x}_i)^2+\lambda||\vec{w}||_1$$<br>　　LASSO正则化后$\vec{w}$是稀疏的，而$\vec{w}$中非零的分量特征才会出现在最终的模型中，所以等于在使用了L-1正则化的时候，本身就潜入了特征选择的过程。</p>
<h2 id="4-3_隐形语义分析类(Latent_Semantic_Indexing,_LSI)和潜在语义索引(Latent_Semantic_Analysis,_LSA)">4.3 隐形语义分析类(Latent Semantic Indexing, LSI)和潜在语义索引(Latent Semantic Analysis, LSA)</h2><p>　　这里的方法是基于上面的SVD的，通常应用于文本处理和信息检索之中（LSI将自己定位为Information Retrival）。<br>　　这些方法通过TruncatedSVD（其实就是降维啦），一方面可以去除那些不重要的噪音，还可以带来的好处有：对原始的数据进行了新的表示方式，可以处理Synonymy（同一个语义可以有不同种的表达方式）、Polysemy（对于多义词，他们可能工作的不是很好，因为最终得到的向量是加权平均的，所以会展示为接近平均值的语义项）、Term Dependence（原始的空间是基于独立性假设的，但是这往往是不成立的，但是进过SVD变换后，我们可以轻易的使用这个假设）。<br>　　经过TruncatedSVD之后，新的Doc-Term表示就可以做很多的事情了：如果要作为文本或者话题分类，就可以按照各个Doc的向量来进行聚类；如果要用作信息检索的话，就将要检索的文本计算其投影后向量，然后在这些文档的向量中寻找最接近的即可；不仅仅对文档，词汇也是按照向量表示的，因此还可以对词汇进行研究，比如寻找某个词关系最密切的词汇等。<br>　　对于使用$\vec{A}=word\times docs$的矩阵（与常理的习惯有些差异），进行SVD之后，word以$\vec{U}$的行向量表示，docs以$\vec{V}$的行向量表示（而不是其转置），他们降维之后的版本就是$\vec{U}\vec{S}$和$\vec{V}\vec{S}$。</p>
<h1 id="五、相关学习算法">五、相关学习算法</h1><h2 id="5-1_Apriori_algorithm">5.1 Apriori algorithm</h2><p>　　该算法属于关联分析中的经典算法，用于找到各种集合中频繁出现的项，在商家产品推荐中应用广泛，常常也被称为购物篮分析，用于挖掘常见的商品购买组合。如果产品的数据有限，道可以穷举所有的组合来统计，但是一般商家的产品数目众多，这种笨办法显然是不合适的。<br>　　a. 支持度(support)：表示某个子集合在数据集所有集合中所占的比例；<br>　　b. 置信度/可信度(confidence)：针对A-&gt;B这条规则，可信度表示为 支持度(A,B)/支持度(A)；<br>　　从原理上说，Apriori实际是一个自底到顶的生成算法，Apriori的原理是：如果某个集合是频繁项，那么他的所有子集也是频繁项；反之，如果某个集合是非频繁项，那么他的所有超级肯定也不是频繁项。通过后面的原理，加上支持度的约束，可以省略很多集合项的统计操作。<br>　　其生成步骤描述为：<br>　　a. 首先创建长度为1的子集合，然后扫描数据集计算支持度，去掉支持度不满足的元素；<br>　　b. 将元素组合，生成长度为2的子集合，进行支持度的计算和排除；<br>　　c. 后面对于要生成长度为k的子集合，具有一定的技巧操作——对上一轮的(k-1)长度的子集合，进行两两比较，如果排序后其前(k-2)个元素相同，就取(k-2)|(k-1)~1|(k-1)~2这样组合成长度为k的子集合；（注意，这里有点像Eclat算法）<br>　　d. 依次进行(3)，直到不能产生子集合为止。<br>　　Apriori算法的缺点是：需要产生大量的候选子集合，而且需要不断扫描原始数据集，算法效率比较低。</p>
<h2 id="5-2_FP-growth">5.2 FP-growth</h2><p>　　针对Apriori的缺点，FP不生成候选子集合，同时只需要扫描两遍数据集，将原始数据集压缩成一个频繁模树，然后依据这个频繁模式树生成关联规则，比Apriori算法快一个数量级。</p>
<h2 id="5-3_Eclat_algorithm">5.3 Eclat algorithm</h2><p>　　Eclat算法的思想采用了倒排的概念，一般的数据集都是(TID, items)的形式，而Eclat将数据转换成(item,TIDs)的组织方式。<br>　　子集的元素按照顺序排列，假设其前(k-1)项相同，那么就可以进行或操作得到k项子集了，而同时两个集合的TIDs进行并操作，就得到了新子集的TIDs，所以不需要扫描原始数据集，算法的效率比较的高。<br>　　这个算法的缺点是要保留所有子集合的TID交易集，所以如果数据规模大的话，需要耗费大量的内存。</p>
<h1 id="六、半监督学习">六、半监督学习</h1><p>　　针对标记的样本数量比较的少，未标记样本数目比较大的情况，而假设标记样本和未标记样本都是从数据源中独立同分布采样而得到的，那么就可以考虑使用标记和未标记样本的半监督的学习方法来建立模型。</p>
<h1 id="七、集成学习">七、集成学习</h1><p>　　通过构建多个学习器来完成学习任务，将个体学习器的结果运用某些策略集合产生最终的结果。对于个体学习器，如果是相同的称为同质学习器，如果不同的则称为异质学习器。<br>　　其实在整个集成学习的理论中，追求的就是各个基学习器“好而不同”，其实对每个基学习器的要求不会像平常单个学习方法那么高（当然高更好，可以减少基学习器的数目），关键是各个基学习器之间要有差异，有自己的个性，如果大家对相同的样本做出的判断都一样，其实对最终的准确性和泛化能力没有任何的帮助<br>　　基学习器多样性的方法有：</p>
<ul>
<li>数据样本扰动：基本基于样本采样实现，主要对决策树、神经网络等不稳定基学习器有效，而对线性学习器、支持向量机、朴素贝叶斯等稳定学习器效果很小。</li>
<li>输入属性扰动：当属性比较多的时候推荐，比如随机森林的机制。</li>
<li>输出表示扰动：</li>
<li>算法参数扰动：</li>
</ul>
<p>集成学习的集合策略有：</p>
<ul>
<li>平均法和加权平均法：前者可为后者权重相同时候的一个特例，一般来说，除非各个基学习器之前性能差异十分明显，否则建议蚕蛹平均法集成学习结果。</li>
<li>投票法：可分为绝对多数投票法（只有当投票超过半数才接受，否则不输出结果，用于对可靠性要求高，可以不输出结果的情形）、相对多数投票法、加权投票法。</li>
</ul>
<p>　　根据个体学习器的生成方式，集成学习分为两类：个体学习器之间有强依赖关系，必须串行化生成，代表的有Boosting；个体学习器之间没有强依赖关系，代表有Bagging和随机森林(Random Forest)。</p>
<h2 id="7-1_Boosting及著名代表AdaBoost">7.1 Boosting及著名代表AdaBoost</h2><p>　　如上文的描述，整个模型是串行生成的。算法首先给训练样本权值均匀化，使用一个基分类器训练之，然后根据样本的输出与标记进行对比：如果一致，那么样本的权重会相应降低，如果不一致，那么样本的权重会相应的增加，然后用这些新权重的样本去训练下一个分类器，直到达到指定数目的分类器。这里每一步训练的时候，会对结果的误差$\theta$进行评判，如果小于0.5（还不如随机分布），整个训练以失败结束。<br>　　实践中，有的属性是可以赋值权重的，对于不能赋值权重的，可以通过重采样来实现（估计就是将错误的样本大概率多采集点）。同时，AdaBoost只支持二分类的计算。</p>
<h2 id="7-2_Bootstrapped_Aggregation_(Bagging)">7.2 Bootstrapped Aggregation (Bagging)</h2><p>　　主要是基于自助采样法(bootstrap sampling)，进行有放回的采样得到采样集（初始样本约有63.2%的几率会出现在采样集中），然后用每个采样集训练每个基学习器，再将这些基学习器的结果进行集合（常用简单投票法）就可以了。同时由于对于每个基学习器都有36.8%的样本没有用于训练，所以这些“包外样本”可以用于验证基学习器的泛化性能等。</p>
<h2 id="7-3_随机森林_Random_Forest">7.3 随机森林 Random Forest</h2><p>　　实际是Bagging的一个扩展变体。RF以决策树作为基学习器来构建Bagging集成学习，同时在决策树训练的时候，引入随机属性选择的机制，因为传统的决策树都会按照信息增益、增益率等方式选择出一个最好的属性来用于每一步划分，而随机森林会在这之前每次随机选择一个属性集的子集合，然后在子集和中选择最优属性进行划分，k为随机度——k=1就是完全随机，k=d就是传统的决策树，推荐k=$log_2d$。</p>
<h1 id="八、暴力类">八、暴力类</h1><p>　　之所以这么称，源于这类算法对计算量要求实在是高，网络层数少了模型能力有限（单层神经网络甚至不能执行异或操作），层数深了吧计算量和对训练数据的要求也斗升，所以不搞个Nvdia支持Cuda的GPU，很多样例复现都费劲。深度学习自然是当前机器学习的研究热点，相关论文发布很多，成果也很诱人，同时漫山遍野的深度库使得是个码农都能玩两下——但请谨慎入坑，其毛病也多多：<br>　　训练出来的模型是黑核的，不具备解释性，改进、微调等都比较麻烦，部署风险很高；网络结构，参数设置，训练样本涉及到的因素太多，对开发者经验要求好，而且最终一个工作的模型可能是不断试错最终得出来的；欠拟合、过拟合问题比大多数算法都为的严重（包外数据验证）；最不低碳环保的算法。</p>
<h2 id="8-1_神经网络_BP神经网络">8.1 神经网络 BP神经网络</h2><p>　　早期的神经网络主要以BP网络最为常见和重要。由控制论得知，如果没有BP机制反向传递系统误差用于修正，就很难实现复杂稳定的模型。</p>
<h2 id="8-2_深度学习">8.2 深度学习</h2><h3 id="8-2-1_Convolutional_Neural_Network_(CNN)">8.2.1 Convolutional Neural Network (CNN)</h3><p>　　卷积神经网络，主要适用于固定维度的输入信号，以图像处理最为代表。</p>
<h3 id="8-2-2_Recurrent_Neural_Network_(RNN)">8.2.2 Recurrent Neural Network (RNN)</h3><p>　　表现为这一层网络的那个神经元，除了接受上一层神经元的输出作为输入之外，还接受同层相邻神经元的输出作为输入，这些输入会有个类似开关的东西控制各个输入源的权重。常见的RNN网络有LSTM、GRU。</p>
<p>　　最后，我不得不说——不用公式记录算法根本做不到~~~<br>　　同时，如果有些科学计算不方便，但是有没有装Matlab的，推荐这个<a href="http://octave-online.net/" target="_blank" rel="external">GNU OCTAVE ONLINE</a>，很好用！</p>
<h1 id="参考目录">参考目录</h1><ul>
<li><a href="https://book.douban.com/subject/26708119/" target="_blank" rel="external">机器学习 - 周志华</a></li>
<li><a href="http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/" target="_blank" rel="external">A Tour of Machine Learning Algorithms</a></li>
<li><a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">Machine Learning Library (MLlib) Guide</a></li>
<li><a href="https://github.com/taozhijiang/chinese_nlp" target="_blank" rel="external">中文语言处理工具</a></li>
<li><a href="http://yuedu.baidu.com/ebook/d0b441a8ccbff121dd36839a" target="_blank" rel="external">LDA漫游指南</a></li>
<li><a href="http://www.flickering.cn/nlp/2014/07/lda%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B9%8B%E7%AE%97%E6%B3%95%E7%AF%87-1%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%AD%A3%E7%A1%AE%E6%80%A7%E9%AA%8C%E8%AF%81/" target="_blank" rel="external">[LDA工程实践之算法篇-1]算法实现正确性验证</a></li>
<li><a href="http://scikit-learn.org/stable/index.html" target="_blank" rel="external">scikit-learn docs</a></li>
<li><a href="https://zh.wikipedia.org/zh/%E5%85%88%E9%AA%8C%E7%AE%97%E6%B3%95" target="_blank" rel="external">Apriori算法</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[随机采样方法]]></title>
      <url>https://taozj.org/201604/random-sampling-method.html</url>
      <content type="html"><![CDATA[<p>　　当知道某个模型的概率分布的时候，常常想产生这种概率分布的样本，甚至某些复杂的分布模型，也可以根据这种方式产生大规模样本考察其数学期望等特性，所以随机采样算是一个十分重要的算法。本人最初还是看LDA算法的时候，最初接触到这个Gibbs采样，当初看的也是云里雾里的，乘着这次看徐亦达老师的视频，对随机采样的常见算法做一个归纳整理，包括一些简单的采样方式以及MCMC(Markov Chain Monte Carlo)采样。</p>
<h1 id="一、逆CDF采样">一、逆CDF采样</h1><p>　　对某个分布的CDF曲线（累积分布函数），在Y轴[0,1]的区间上做均匀采样，然后其在曲线上相同y的点映射到X轴(inverse CDF)，即为所采样本。<br>　　但是不是所有分布的inverse CDF都能得到的，所以这种采样方式不太通用。<br><img src="/post_images/images/201604/40ed0a4dc1314e4ec4625822473d3869.jpg" alt="逆CDF采样"></p>
<h1 id="二、接受-拒绝采样（Rejection_Sampling)">二、接受-拒绝采样（Rejection Sampling)</h1><p>　　基本思路就是用一个简单易于抽样的分布类型q(x)，乘以一个大于1的常数值M，使其完全包络待采样分布类型p(x)的PDF（概率密度函数），然后按照Mq(x)进行采样，同时还进行一个选择系数$U~Uniform[0,1]$采样，然后当$Y=Mq(x)U\lt p(x)$的时候，此时采样点被p(x)分布所包围，则接受之，否则拒绝之。<br>　　这种方法确实能进行有效采样，但是主要问题是效率不高，p(x)和q(x)两者的分布越接近，采样效率才会越高，但实际上往往比较难寻十分合适的q(x)。对此有个改进，叫做Adaptive Rejection Sampling（ARS采样），就是让包络分布尽可能的贴近目的采样函数，比较复杂，且前提条件是$log(p(x))$是凸函数的时候才可以用。<br><img src="/post_images/images/201604/fb62147b177f68369b7487c2f147c6cc.jpg" alt="接收拒绝采样"><a id="more"></a></p>
<h1 id="三、重要性采样(Importance_Sampling)">三、重要性采样(Importance Sampling)</h1><p>　　这个采样，感觉主要是用来计算数学期望的，而不是用来真正产生符合原分布的单个样本的。就是原分布f(x)比较难积分且难以采样，那么就无法用积分或者用大数定理采样来估算数学期望，这时候就引入一个辅助的分布q(x)来采样，然后相应的$\frac{f(x)}{q(x)}$就作为了这个采样点对最终数学期望贡献率的权重了，所以叫做重要性采样。<br>　　怎么感觉重要性采样的重要性不大咧～</p>
<h1 id="四、MCMC采样">四、MCMC采样</h1><p>　　说道MCMC采样，就不得不说到马尔科夫链了，其假设了某个随机序列当前的输出，只跟其前N-1个输出相关，叫做N阶马尔科夫链。对于1阶马尔科夫链：<br>$$ P(X_t|X_{t-1},X_{t-2},…,X_1) = P(X_t|X_{t-1})$$<br>　　马尔科夫链最Amazoning的，是对于有限的状态空间，其各个状态的转移概率是固定与t无关的(转移矩阵P)，且任意两个状态是连通的，那么在较长时间后，马尔科夫过程逐渐处于稳定状态，且与初始状态无关，而且这个稳定状态是唯一固定的。而如果能够让这个马尔科夫链的稳定状态恰好是我们所需要采样的f(x)的分布，那么一旦马尔科夫链稳定之后，其所有的输出序列都是我们想要的采样样本了！</p>
<h2 id="4-1_M-H(Metropolis_Hastings)采样">4.1 M-H(Metropolis Hastings)采样</h2><p>　　假设需要采样的分布为f(x)，那么需要找到一个分布k(x)，使得f(x)k(y|x)=f(y)k(x|y)，就是x-&gt;y与y-&gt;x的转换概率是相同的，叫做细致平稳条件(detail balance)，是马尔科夫链平稳的必要条件。所以M-H采样方法，就是要设法找到这个k来实现细致平稳，让马氏链最终收敛后不断产生需要的采样。<br>　　对于M-H中的接受率$\alpha$的表达如下<br>$$\alpha=min\{1,\frac{f(y)q(x|y)}{f(x)q(y|x)}\}$$<br>　　初看来会比较的费解，具体可以查看<a href="http://www.cnblogs.com/xbinworld/p/4266146.html" target="_blank" rel="external">参考文献</a>,其实是在保持细致平稳条件下提交接受率，以方便马尔科夫链快速收敛而操作的。<br>　　所以需要看清楚的是，上文的f(x)q(x|y)通常条件下不满足细致平稳条件，而需要添加一个$\alpha$的接受率之后，$f(x)q(y|x)\alpha’(y|x)$以及和$f(y)q(x|y)\alpha’(x|y)$才是马氏平稳的。而最终采样的时候只看见一个$\alpha$，其实是保持细致平稳增加接受率化简后的结果，然后从$Uniform~(0,1)$中随机采样然后跟接受率比较，判断是否转移到备选点还是停留在远点不转移（但无论如何都是被接受的有效采样点）。<br>　　采样过程摘录如下：<br><img src="/post_images/images/201604/97fe26a8065c2c6f738f40e8f6137c94.jpg" alt="MCMC Metropolis Hastings采样过程"></p>
<h2 id="4-2_Gibbs采样">4.2 Gibbs采样</h2><p>　　首先结论上，Gibbs采样其实是M-H采样的一个特例，就是让其接收率$\alpha$=1最高时候的一种特殊情况，这样在多维度采样的时候，采样效率要高的多。考虑二位MCMC采样，设位于x=x1直线上的两点A(x1,y1)和B(x1,y2)，那么从A转移到B和从B转移到A的概率(就是沿着X轴转移)描述如下：<br>$$p(x1,y1)p(y2|x1)=p(x1)p(y1|x1)p(y2|x1)$$<br>$$p(x1,y2)p(y1|x1)=p(x1)p(y2|x1)p(y1|x1)$$<br>　　因此<br>$$p(x1,y1)p(y2|x1)==p(x1,y2)p(y1,x1)$$<br>　　可以得到<br>$$p(A)p(y2|x1)==p(B)p(y1,x1)$$<br>　　就是在X轴上的任意转移，都满足细致平稳条件，而且这个时候的接受率$\alpha$=1。<br>　　这种情况也可以推广到多维分布，只需要沿着某一个坐标轴${xi}$上做转移，定义$Xi^{-1}=(x1,x2,…,xi-1,xi+1,…,xn)$,那么其转移概率为$p(xi|Xi^{-1})$。</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www-staff.it.uts.edu.au/~ydxu/statistics.htm" target="_blank" rel="external">Statistics, Probability and Machine Learning Short Course</a></li>
<li><a href="http://blog.csdn.net/xianlingmao/article/details/7768833" target="_blank" rel="external">随机模拟的基本思想和常用采样方法</a></li>
<li><a href="http://www.cnblogs.com/xbinworld/p/4266146.html" target="_blank" rel="external">随机采样方法整理与讲解（MCMC、Gibbs Sampling等）</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[统计学之边角料——频率派和贝叶斯派]]></title>
      <url>https://taozj.org/201604/statistics-frequency-bayesian.html</url>
      <content type="html"><![CDATA[<h1 id="第一章_频率学派和贝叶斯学派">第一章 频率学派和贝叶斯学派</h1><p>　　虽然我们在大学的时候概率统计课程只有一门，教材只有一本，在后面查阅资料后发现，其实在概率界一只有两个长期对立的统计学派：频率派和贝叶斯派，两个相持两百年了，还打的水生火热滴。</p>
<h2 id="1-1_频率派">1.1 频率派</h2><p>　　基本依托于大数定律和中心极限定理，其贵在于得到越多越好的样本，然后计算其频率来逼近该事件的真实概率。所以频率派讲求该事件可以被独立重复，因为只有这样才能进行大规模的实验来求取概率逼近真实分布。<br>　　大数定律：对随机变量$X$（比如投硬币100次向上的次数）进行观察不断的n次采样得到$X_1,X_2,……,X_n$，然后求取这n个样本的平均值$\bar{X}$，当样本数目n趋向于无穷大的时候的，其均值$\bar{X}$趋近于其数学期望$E(X)$。<br>　　中心极限定理：大量相互独立的随机变量，其均值/和的分布以正态分布为极限，并且这个定理与随机变量的具体分布类型无关（无论离散还是连续，以及具体的分布类型），也就是各个随机变量的分布类型未知，只需要满足独立同分布的前提就可以，他们的均值总体符合正态分布。</p>
<h2 id="1-2_贝叶斯派">1.2 贝叶斯派</h2><p>　　在课本上最常见的就是条件概率和贝叶斯公式了，可以从如下最常见到的贝叶斯公式来考察。而所谓的贝叶斯框架，就是无论具体是什么样的分布，都可以按照这么样的一个模式来求参数的估计。</p>
<blockquote>
<pre><code>后验概率posterior = (似然度likelihood * 先验概率<span class="built_in">prior</span>)/标准化常量
posterior ∝ likelihood × <span class="built_in">prior</span>
</code></pre></blockquote>
<p>　　贝叶斯讲求引入一个先验概率，表现了对该事件的知识了解，然后再用似然度去修正之前的知识了解，如果当前的观测值越符合我们的先验知识，那么似然度就越大，得到的后验概率也就越大，反之亦然。看似贝叶斯框架比较的完美，而且可以客服一些频率派困难（比如投骰子次数不多，那么计算的频率显然与真实的分布想去甚远，但是贝叶斯的先验知识可以缓和这种极端情况）。但是贝叶斯的先验知识没有具体、规则化的获得方法，每个人的先验知识都可能是不一样的，而不良的先验概率甚至会使得最终的估计偏离真实的值。对此，贝叶斯的先验知识最好是客观计算出来的，抑或者拿不准时候用弱信息甚至无信息的先验假设来尽可能避免这类问题。<br><a id="more"></a></p>
<h2 id="1-3_区别和联系：">1.3 区别和联系：</h2><p>$$p(w|D) = \frac{p(D|w)p(w)}{p(D)}$$<br>　　考量上面的式子，其实似然度 $p(D|w)$在两者都扮演了一个重要的位置，表示了当前的观测与之前的假设所相似的程度。在本质上：频率派认为参数w是一个存在且固定的参数（当然虽然知道他存在但不知道他是多少，不然还估计个毛啊），其可以通过某种方式的估计得到的（比如最大似然估计，就是让观测集D出现的概率最大化时候的w作为估计值，而$-log(p(D|w))$被称为误差函数，和似然度成反比关系）；贝叶斯派认为w是不固定的，在先验知识得到w的时候，用后续的观测D来不断的修正w得到后验估计。</p>
<h2 id="1-4_假设检验（hypothesis_testing）">1.4 假设检验（hypothesis testing）</h2><p>　　在统计中，通过用样本对一个假设进行接受或者拒绝的过程，称之为假设检验，需要注意，假设检验和p是频率派中才使用的东西。一般的假设有Z检验和t检验两种，前者用于样本数目大于30的情况下，目标函数呈正态分布，查询正态分布表得到样本均值在零假设成立的概率，而当样本数量小于30的情况下，目标函数服从t分布，查询t表得到其假设成立的概率。</p>
<ul>
<li>Z-score：描述的是某个采样值$X_i$同总体均值$\mu$所相差的标准方差数，$Z-score= \frac{(X_i-\mu)}{\sigma}$。需要说明的是，Z-score的计算同$X$的具体分布类型无关，只要有均值和方差，就可以计算Z-score；</li>
<li>样本均值抽样分布：其类似于中心极限定理，只是给出了具体的正态分布结果：随着样本数目的增加，样本均值$(\bar{X}-\mu)$符合均值为0，标准方差为远方差除以样本个数开方的正态分布！</li>
</ul>
<p>　　有了上面的预备知识，下面罗列Z-假设和t-假设这两种假设的步骤：</p>
<ul>
<li>先做零假设(null hypothesis)$H_0$和备择假设(alternative hypothesis)$H_1$，比如零假设为药品无效，那么备选假设就是药品有效；</li>
<li>根据上述样本均值抽样分布规律，$F=\frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{N}}}$作为目标函数。当样本数目大于30的时候，F为正态分布，而总体标准方差未知的时候，可以用样本的标准差代替；如果样本数目小于30，F满足t分布规律。</li>
<li>上述目标函数F计算得到$\bar{X}$与$\mu$相距离的标准差个数，然后查表（正态分布表、t分布表），得到零假设成立时候，样本的概率p，然后据此决定是否肯定还是否定零假设。<br><img src="/post_images/images/201604/4c3b57240f358781a05c02b2b7387918.jpg" alt="假设检验"></li>
</ul>
<h2 id="1-5_根据可信度，求置信区间">1.5 根据可信度，求置信区间</h2><p>　　其实跟上面是一个逆运算，知道可行度，就可以查Z/t-表看临界均值相对总体均值的偏移单位数目，带入上面的F公司，就可以求得置信区间的范围了<br><img src="/post_images/images/201604/bf8d073c6b6d42d5ecdbc1cb9f343bfd.jpg" alt="求置信区间"></p>
<h2 id="1-6_举个栗子">1.6 举个栗子</h2><p>　　举个现实点的例子，比如预测明天4月2号的气温，频率派可能抓取历史N年的4月2日的气温数据（为了稳定，可能也会4月2日前后一周的气温数据），然后得到均值和方差，然后得到一个温度范围及其置信度。贝叶斯学派可能根据之前的先验知识（地理位置，经济状况，政策……）估计到一个先验温度分布，然后根据当前这些因素的采样数据，用相似度去修正先验概率，得到一个修正后的后验概率分布。</p>
<h1 id="第二章_置信区间（Confidence）与可信区间（Credible）">第二章 置信区间（Confidence）与可信区间（Credible）</h1><p>　　由于上文的频率派和贝叶斯派的区别——频率派认为真实的参数w是固定的，而显示能得到的w是根据观测集D用各种方式估计得到的w’；贝叶斯派认为w是不确定的，任何随机取的w都是参数的估计，只是有概率衡量他们可能性大小而已。</p>
<h2 id="2-1_频率派">2.1 频率派</h2><p>　　由于相信有真实固定的参数存在，所以置信度表示的意思是，对于置信度p，假如进行100次参数估计，在得到的100个置信区间中，至少有100<em>p个置信区间将真实参数包含在内，就是100次inferences至少有p</em>100次是正确的，而对于某一次具体的实验，只有两种可能：置信区间包含真实参数或者不包含真实参数；<br>　　（95% Confidence Interval: 95% of the time, θ is in the 95% interval that is estimated each time，P(θ ∈ 95% CI) = 0 or 1）</p>
<h2 id="2-2_贝叶斯派">2.2 贝叶斯派</h2><p>　　是假定某种方式得到参数的先验概率分布prior，其可信区间是固定的，然后用观测到的数据得到计算该参数的后验概率posterior，那么得到的后验概率的值，有p的概率落在这个可信区间中。<br>　　（95% Credible Interval: P(θ ∈ 95% CI) = 0.95）</p>
<h1 id="第三章_机器学习模型评估与选择">第三章 机器学习模型评估与选择</h1><h2 id="3-1_训练集、验证集的划分">3.1 训练集、验证集的划分</h2><p>　　为了减少泛化误差，需要将数据集分为训练集合和验证集合，常用的划分方法有：</p>
<ul>
<li>留出法：分层抽取，保证验证数据分布和训练数据分布一致,一般$\frac23$~$\frac45$用于训练；</li>
<li>交叉验证：将数据分为k份，每次用k-1个子集作为训练数据，1份用做训练数据；通常还需要随见用不同的k-1划分p次，称之为p次k折划分；</li>
<li>自助法:将数据放回采样m次(某个数据一次不都不被选中的概率为1/e)得到采样D’作为训练集，D\D’作为测试集；通常勇于数据量小，无法方便拆分训练测试集的时候。</li>
</ul>
<h2 id="3-2_算法性能衡量指标">3.2 算法性能衡量指标</h2><ul>
<li>回归任务<br>　　由于回归任务得到的结果是连续值，如果不将回归转化为分类任务（比如设置域值进行分类），那么常用的指标是均方误差。</li>
<li>分类任务<br>　　错误率 = 分类错误样本数/样本总数<br>　　精度   = 分类正确样本数/样本总数 = 1 - 错误率</li>
</ul>
<table>
<thead>
<tr>
<th>–</th>
<th style="text-align:center">预测结果正例</th>
<th>预测结果反例</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实正例</td>
<td style="text-align:center">TP(真正)</td>
<td>FN(假反)</td>
</tr>
<tr>
<td>真实反例</td>
<td style="text-align:center">FP(假正)</td>
<td>TN(真反)</td>
</tr>
</tbody>
</table>
<p>　　考虑上面的表格，那么<br>　　Precision 查准率 = TP / (TP + FP) ，描述的是预测出为正例中真正为正的比例<br>　　Recall    查全率 = TP / (TP + FN) ，描述的是所有为正例中被检查出来的比例</p>
<ul>
<li>P-R曲线<br>　　如果按照预测为正的概率从高到低排列下来,逐次增加选定正样本的数目,然后查准率、查全率分别为Y、X轴，即可得到P-R曲线。<br>　　由于在通常情况下，P和R是两个需要权衡的指标，当比较两个算法性能的时候，根据P和R的重要性不同，可以计算Fb值:$\frac1{Fb} = \frac1{1+b^2}<em>(\frac1P + \frac{b^2}R)$，重要性 b~R/P。<br>　　当b=1的时候，大名鼎鼎的F1就是$\frac{1}{F_1} = \frac{1}{2}</em>(\frac{1}{P} + \frac{1}{R})$</li>
<li>ROC曲线/受试者工作特征曲线<br>　　TPR 真正率 = TP / (TP + FN)，等同于查全率<br>　　FPR 假正率 = FP / (TN + FP)，描述正式反例中被正确预测为反例的比例<br>　　ROC曲线以TPR为众轴，以FPR为横轴。图形越凸向西北越好。[???与PR的区别联系?]<br><img src="/post_images/images/201603/2f42e3a50fdca79cc8ac5cba693efaf0.jpg" alt="P-R &amp; ROC曲线"></li>
</ul>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.rmki.kfki.hu/~banmi/elte/Bishop%20-%20Pattern%20Recognition%20and%20Machine%20Learning.pdf" target="_blank" rel="external">Pattern Recognition and Machine Learning - Bayesian probabilities</a></li>
<li><a href="http://www.amazon.cn/%E5%9B%BE%E4%B9%A6/dp/B01ARKEV1G?ie=UTF8&amp;keywords=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&amp;qid=1459397227&amp;ref_=sr_1_1&amp;sr=8-1" target="_blank" rel="external">机器学习 - 周志华著</a></li>
<li><a href="https://en.wikipedia.org/wiki/Confidence_interval#Credible_interval" target="_blank" rel="external">Credible interval</a></li>
<li><a href="http://wiki.mbalib.com/wiki/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C" target="_blank" rel="external">假设检验</a></li>
<li><a href="http://open.163.com/movie/2011/6/O/I/M82IC6GQU_M83JCBUOI.html" target="_blank" rel="external">假设检验和p值</a></li>
<li><a href="http://www.aiweibang.com/yuedu/52652665.html" target="_blank" rel="external">贝叶斯vs频率派：武功到底哪家强？</a>  </li>
<li><a href="http://open.163.com/special/Khan/khstatistics.html" target="_blank" rel="external">网易公开课 可汗学院公开课：统计学</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark学习手册（三）：Spark模块学习摘读]]></title>
      <url>https://taozj.org/201603/learn-note-of-spark-(3)-relative-modules.html</url>
      <content type="html"><![CDATA[<p>　　Spark在其基础架构之上支持四大模块，分别是SparkSQL、SparkStreaming、MLlib和GraphX，本文将对这几个模块的手册进行阅读摘录。</p>
<p><img src="/post_images/images/201603/cf8659d1067cbe8d5f3ec06f1a44f3d0.png" alt="Spark 模块"></p>
<h1 id="一、Spark_SQL">一、Spark SQL</h1><h2 id="1-1_简介">1.1 简介</h2><p>　　同Spark SQL的交互方式包括SQL、DataFrames API和Datasets API，但是其内部的执行引擎是一样的，只是对外表现的接口不一样而已。</p>
<ul>
<li>SQL：可以使用基础的SQL语法或HiveQL，当在别的编程语言中执行SQL，返回的是DataFrame格式的结果。SQL的交互方式包括命令行方式，以及JDBC、ODBC对数据库的访问接口。</li>
<li>DataFrame：一种通过命名列组织的分布式数据存储，概念上和关系数据库的表等价，可以接受文件、数据库、RDD等数据源来创建。</li>
<li>Datasets：暂不支持Python，没研究。</li>
</ul>
<h2 id="1-2_从文件创建DataFrame">1.2 从文件创建DataFrame</h2><p>　　基础SQLContext环境创建，并从json文件创建DataFrame<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sqlContext = SQLContext(sc)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df = sqlContext.read.json(<span class="string">"/root/spark-1.6.1-bin-hadoop2.6/examples/src/main/resources/people.json"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.show()</div><div class="line">+----+-------+</div><div class="line">| age|   name|</div><div class="line">+----+-------+</div><div class="line">|null|Michael|</div><div class="line">|  <span class="number">30</span>|   Andy|</div><div class="line">|  <span class="number">19</span>| Justin|</div><div class="line">+----+-------+</div></pre></td></tr></table></figure></p>
<p>DataFrame的常用操作接口(看意思就明白的)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.printSchema()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.select(<span class="string">"name"</span>).show()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.select(df[<span class="string">'name'</span>], df[<span class="string">'age'</span>] + <span class="number">1</span>).show()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.filter(df[<span class="string">'age'</span>] &gt; <span class="number">21</span>).show()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.groupBy(<span class="string">"age"</span>).count().show()</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="1-3_从RDD创建DataFrame">1.3 从RDD创建DataFrame</h2><p>　　将已有的RDD转换为DataFrame有两种方法：一种是映射(reflection)；另外一种是通过变成接口创建表，然后将RDD数据应用到表上面去</p>
<ul>
<li><p>Reflection：通过创建(table_column_name, type)的Row对象，然后通过map将RDD每一行转换成Row，简单但是不够灵活</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext, Row</div><div class="line">sqlContext = SQLContext(sc)</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>lines = sc.textFile(<span class="string">"/root/spark-1.6.1-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>parts = lines.map(<span class="keyword">lambda</span> l: l.split(<span class="string">","</span>))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(people.collect())</div><div class="line">[[<span class="string">'Michael'</span>, <span class="string">' 29'</span>], [<span class="string">'Andy'</span>, <span class="string">' 30'</span>], [<span class="string">'Justin'</span>, <span class="string">' 19'</span>]]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>people = parts.map(<span class="keyword">lambda</span> p: Row(name=p[<span class="number">0</span>], age=int(p[<span class="number">1</span>])))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(people.collect())</div><div class="line">[Row(age=<span class="number">29</span>, name=<span class="string">'Michael'</span>), Row(age=<span class="number">30</span>, name=<span class="string">'Andy'</span>), Row(age=<span class="number">19</span>, name=<span class="string">'Justin'</span>)]</div><div class="line"></div><div class="line"><span class="comment"># 创建schema，并注册成表</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople = sqlContext.createDataFrame(people)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople.registerTempTable(<span class="string">"people"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople.printSchema()</div><div class="line">root</div><div class="line"> |-- age: long (nullable = true)</div><div class="line"> |-- name: string (nullable = true)</div><div class="line"></div><div class="line"><span class="comment"># 访问表内容</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>teenagers = sqlContext.sql(<span class="string">"SELECT name FROM people WHERE age &gt;= 13 AND age &lt;= 19"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(teenagers.collect())  <span class="comment"># teenagers 是RDD的类型，可以常规的访问</span></div><div class="line">[Row(name=<span class="string">'Justin'</span>)]</div></pre></td></tr></table></figure>
</li>
<li><p>编程的方式创建<br>　　这种一般是事先不知道表结构，比如传递过来动态解析的表结构的情况下，就只能这么操作了。<br>下面的例子可以显示出来，其中列名是schemaString是通过动态的字符串创建的，所以在实际使用中可以各种方式指定，灵活性比较的强</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SQLContext, Row</div><div class="line">sqlContext = SQLContext(sc)</div><div class="line"></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>lines = sc.textFile(<span class="string">"/root/spark-1.6.1-bin-hadoop2.6/examples/src/main/resources/people.txt"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>parts = lines.map(<span class="keyword">lambda</span> l: l.split(<span class="string">","</span>))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>people = parts.map(<span class="keyword">lambda</span> p: Row(name=p[<span class="number">0</span>], age=int(p[<span class="number">1</span>])))</div><div class="line"></div><div class="line"><span class="comment"># 创建schema string</span></div><div class="line">schemaString = <span class="string">"name age"</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>fields = [StructField(field_name, StringType(), <span class="keyword">True</span>) <span class="keyword">for</span> field_name <span class="keyword">in</span> schemaString.split()]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schema = StructType(fields)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(fields)</div><div class="line">[StructField(name,StringType,true), StructField(age,StringType,true)]</div><div class="line"></div><div class="line"><span class="comment"># 将创建的schema应用到people数据上去</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople = sqlContext.createDataFrame(people, schema)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople.registerTempTable(<span class="string">"people"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>schemaPeople.printSchema()</div><div class="line">root</div><div class="line"> |-- name: string (nullable = true)</div><div class="line"> |-- age: string (nullable = true)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>results = sqlContext.sql(<span class="string">"SELECT name FROM people"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(results.collect())</div><div class="line">[Row(name=<span class="string">'29'</span>), Row(name=<span class="string">'30'</span>), Row(name=<span class="string">'19'</span>)]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df2 = sqlContext.read.load(<span class="string">"/root/namesAndAgesData.parquet"</span>)  <span class="comment">#default is parquet</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>其中，save支持额外的SaveMode参数，可选的值为”error”、”append”、”overwrite”、”ignore”，类似于普通文件接口，他们在目标文件存在的时候，表现为不同的形式。</p>
<h2 id="1-4_Data_Sources">1.4 Data Sources</h2><ul>
<li><p>文件的加载和保存<br>这里是通用方式的文件加载和保存，意味着parquet和json都能使用。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>df = sqlContext.read.load(<span class="string">"/root/spark-1.6.1-bin-hadoop2.6/examples/src/main/resources/people.json"</span>, format=<span class="string">"json"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(df.collect())</div><div class="line">[Row(age=<span class="keyword">None</span>, name=<span class="string">'Michael'</span>), Row(age=<span class="number">30</span>, name=<span class="string">'Andy'</span>), Row(age=<span class="number">19</span>, name=<span class="string">'Justin'</span>)]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.select(<span class="string">"name"</span>, <span class="string">"age"</span>).write.save(<span class="string">"namesAndAgesData.parquet"</span>, format=<span class="string">"parquet"</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>编程方式加载和访问parquet格式文件的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>parquetFile = sqlContext.read.parquet(<span class="string">"/root/namesAndAgesData.parquet"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>parquetFile.registerTempTable(<span class="string">"parquetFile"</span>); <span class="comment">#可以注册为临时表</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>teenagers = sqlContext.sql(<span class="string">"SELECT name FROM parquetFile WHERE age &gt;= 13 AND age &lt;= 39"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(teenagers.collect())</div><div class="line">[Row(name=<span class="string">'Justin'</span>), Row(name=<span class="string">'Andy'</span>)]</div></pre></td></tr></table></figure>
</li>
<li><p>Json文件格式<br>同上面的parquet一样的，只是对应的接口改成了sqlContext.read.json。同时，json还支持如下方式创建RDD：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>anotherPeopleRDD = sc.parallelize([\</div><div class="line"><span class="meta">... </span><span class="string">'&#123;"name":"Yin1","address":&#123;"city1":"Columbus","state":"Ohios"&#125;&#125;'</span>,\</div><div class="line"><span class="meta">... </span><span class="string">'&#123;"name":"Yin2","address":&#123;"city2":"Columbus","state":"Ohiot"&#125;&#125;'</span>])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>print(anotherPeopleRDD.collect())</div><div class="line">[<span class="string">'&#123;"name":"Yin1","address":&#123;"city1":"Columbus","state":"Ohios"&#125;&#125;'</span>, <span class="string">'&#123;"name":"Yin2","address":&#123;"city2":"Columbus","state":"Ohiot"&#125;&#125;'</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>anotherPeople = sqlContext.jsonRDD(anotherPeopleRDD)</div><div class="line">[Row(address=Row(city1=<span class="string">'Columbus'</span>, city2=<span class="keyword">None</span>, city3=<span class="keyword">None</span>, state=<span class="string">'Ohios'</span>), name=<span class="string">'Yin1'</span>), Row(address=Row(city1=<span class="keyword">None</span>, city2=<span class="string">'Columbus'</span>, city3=<span class="keyword">None</span>, state=<span class="string">'Ohiot'</span>), name=<span class="string">'Yin2'</span>)]</div></pre></td></tr></table></figure>
</li>
<li><p>JDBC/ODBC访问<br>启动的时候，需要指定JDBC的驱动，这个驱动可以在mysql的官方网站下载</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">root@ubuntu1404-node01:~/spark-1.6.1-bin-hadoop2.6<span class="comment"># PYSPARK_PYTHON=python3.4 SPARK_CLASSPATH=mysql-connector-java-5.1.38-bin.jar bin/pyspark</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>然后，就可以操作数据库了<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> *</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sqlContext = SQLContext(sc)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df = sqlContext.read.format(<span class="string">'jdbc'</span>).options(url=<span class="string">'jdbc:mysql://113.106.94.201:3306/n_xxxxx'</span>, dbtable=<span class="string">'v5_xxxxxx'</span>,user=<span class="string">'xxxxx'</span>, password=<span class="string">'xxxxxx'</span>).load()</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>df.take(<span class="number">3</span>)</div></pre></td></tr></table></figure></p>
<h1 id="二、Spark_Streaming">二、Spark Streaming</h1><p>　　Spark Streaming是Spark核心组件对在线流数据处理的扩展。在内部，Spark接受在线输入流数据，将其分成batches，然后再将结果输出，其提供了一个高层次抽象的DStream，表示为一种持续的输入流，其输入可以为（Kafka、Flume、Kinesis……反正我也不懂……）以及其他的DStream，在内部，DStream表示为一系列的RDDs构成。</p>
<h2 id="2-1_一个简单的例子，统计词的个数">2.1 一个简单的例子，统计词的个数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</div><div class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    sc = SparkContext(<span class="string">"local[2]"</span>， appName=<span class="string">"PythonStreamingNetworkWordCount"</span>)</div><div class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)  <span class="comment"># 1s batch interval，为应用需求延迟和系统节点资源的权衡</span></div><div class="line"></div><div class="line">    lines = ssc.socketTextStream(<span class="string">"localhost"</span>,<span class="number">9999</span>) <span class="comment"># 建立Dstream，从TCP获得数据</span></div><div class="line">    counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>))\  <span class="comment">#flatMap，一对多，一个句子分多个词</span></div><div class="line">                  .map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>))\</div><div class="line">                  .reduceByKey(<span class="keyword">lambda</span> a, b: a+b)</div><div class="line">    counts.pprint()   <span class="comment"># 打印最开始的10个元素</span></div><div class="line"></div><div class="line">    ssc.start()   <span class="comment"># 真正从此开始，开始接受输入并计算输出</span></div><div class="line">    ssc.awaitTermination() <span class="comment"># 等待结束（手动停止或者出错，调用streamingContext.stop()）</span></div></pre></td></tr></table></figure>
<p>从两外一个终端开启”nc -lk 9999”不断输入作为数据源；另外一个终端提交任务”PYSPARK_PYTHON=python3.4 bin/spark-submit ../wordc_net.py “。<br> 注意：<br>默认的Spark打印的是INFO，这时候屏幕会不断的滚动消息，将LogLevel设置为WARN才能看的清楚。<br>一旦sc调用start()，就不能添加或者设置新的流计算；<br>一旦sc停止，就不能被重新启动了；<br>同一时刻一个JVM只能有一个活动的sc；<br>当StreamingContext调用stop()的时候，默认也会将SparkContext停止掉，要想保持SparkContext活着，那么stop()的参数请将stopSparkContext设置为false；<br>一个SparkContext可以重用被创建多个StreamingContext，只要之前的StreamingContext关闭停止就可以了。</p>
<h2 id="2-2_Discretized_Streams_(DStreams,离散流)">2.2 Discretized Streams (DStreams,离散流)</h2><p>　　DStream作为Spark Streaming的抽象数据类型，其内部原理就是对于采集到的每隔一个batch interval时间间隔的数据，生成一个该阶段的RDD，然后，上层对于DStream的操作，实际上就映射到底层的RDD的操作了。<br>　　在一个程序中，可以创建多个input DStream，这些数据都会被同时接收和处理，但是需要考虑到实际executor的执行能力。还需要特别注意的是，一个input DStream接收数据是需要占用一个thread的，所以如果有n个输入，需要&gt;2n个执行单元(local[2n])，否则就只能收数据，而收到的数据没有线程来处理了。<br>　　除了上面的TCP输入，还支持textFileStream输入，Spark Streaming会监测指定的文件目录，对于目录中新增的文件（嵌套目录不支持），会被当作新的数据源被处理，但是不支持文件内容的修改和新增等，这就意味着Spark Streaming一旦监测到该新增文件，就只接受一次该文件，因此一般都是别的地方将文件生成后，移动到监测的目录中。由于这种方式不需要使用receiver，所以这种情况不用增加额外的线程数目。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">streamingContext.textFileStream(dataDirectory)</div></pre></td></tr></table></figure></p>
<h2 id="2-3_Transformations">2.3 Transformations</h2><p>　　和之前的支持差不多，这里只列出差异的函数。由于DStream底层就是RDD支撑的，所以这里函数和RDD函数之间的关系还是比较微妙的</p>
<table>
<thead>
<tr>
<th>术语</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>countByValue()</td>
<td style="text-align:center">计数，对于每个元素K，得到（K, Long)</td>
</tr>
<tr>
<td>transform(func)</td>
<td style="text-align:center">对源DStream的每个RDD使用func转换，生成新的DStream，比如增加过滤器等，十分的强大</td>
</tr>
<tr>
<td>updateStateByKey(func)</td>
<td style="text-align:center">通过func将上一个时刻DStream每个key的状态，更新为新的状态，如果上个状态没有该key，其值为None</td>
</tr>
</tbody>
</table>
<p>这里的例子，是动态的对输入流的词频进行累计统计操作<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateFunction</span><span class="params">(newValues, runningCount)</span>:</span></div><div class="line">    <span class="keyword">if</span> runningCount <span class="keyword">is</span> <span class="keyword">None</span>:  <span class="comment">#如果之前不存在，初始值为0</span></div><div class="line">       runningCount = <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> sum(newValues, runningCount) </div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line"></div><div class="line">    sc = SparkContext(appName=<span class="string">"PythonStreamingNetworkWordCount"</span>)</div><div class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)</div><div class="line">    ssc.checkpoint(<span class="string">"checkpoint"</span>) <span class="comment">#必须的</span></div><div class="line"></div><div class="line">    lines = ssc.socketTextStream(<span class="string">"localhost"</span>,<span class="number">9999</span>)</div><div class="line">    counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>))\</div><div class="line">                  .map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>))\</div><div class="line">                  .updateStateByKey(updateFunction)    <span class="comment">#更新在此                 </span></div><div class="line">    counts.pprint()</div><div class="line"></div><div class="line">    ssc.start()</div><div class="line">    ssc.awaitTermination()</div></pre></td></tr></table></figure></p>
<h2 id="2-4_窗口操作">2.4 窗口操作</h2><p>　　需要两个参数：窗口尺寸、滑动间隔，参数值都必须是batch interval的整数倍。其对应的接口函数在下面列出，其中第一个函数用于生成一个新的DStream，其余的都是原有RDD的聚合函数，只是作用于windows窗口模式下的多个RDD而已。</p>
<table>
<thead>
<tr>
<th>术语</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>window(windowLength, slideInterval)</td>
<td style="text-align:center">形成一个新的DStream</td>
</tr>
<tr>
<td>countByWindow(windowLength, slideInterval)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>reduceByWindow(func, windowLength, slideInterval)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks])</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, [numTasks])</td>
<td style="text-align:center">这个函数比较的厉害，有个反向函数invFunc，整个函数的意思就是对进入窗口的新数据用func，而对离开窗口的数据用invFunc</td>
</tr>
<tr>
<td>countByValueAndWindow(windowLength, slideInterval, [numTasks])</td>
</tr>
</tbody>
</table>
<p>　　还有，默认窗口操作的数据都是persist缓存的，而默认的StorageLevel是MEMORY_ONLY_SER，不需要开发者手动调用。对于网络传递进来的数据流，默认的存储是复制到两个不同的节点上以实现容错。</p>
<h2 id="2-5_DStream的输出操作">2.5 DStream的输出操作</h2><p>　　实际类似RDD的actions，一般是现实、保存数据到网络或者文件系统上，从而驱动了真正计算的执行（最后foreachRDD实际是func的操作驱动真正计算）<br>| 术语   | 说明  |<br>| — |:—–:|<br>| pprint() | 打印出最开始的10个元素，主要用于调试 |<br>| saveAsTextFiles(prefix, [suffix]) | 将DStream的数据保存为prefix-TIME_IN_MS[.suffix] |<br>| foreachRDD(func) | 针对每个RDD的操作，这个func是在driver中执行的~rdd.foreachPartition |</p>
<h2 id="2-6_Checkpointing">2.6 Checkpointing</h2><p>　　既然是流数据的，那么程序就理应全天候跑的，Checkpointing就是设计出来应对这种应用的容错机制(系统出错\JVM崩溃等)，用于带有容错机制的文件系统(如HDFS)中。Spark支持的Checkpointing包括</p>
<ul>
<li>Metadata Checkpointing<br>保存了包括创建streaming应用的配置、DStream的操作、正在排队还未完成计算的batches等。这是用于driver programer节点出错时候的恢复。</li>
<li>Data Checkpoint<br>保存生成的RDDs到存储系统中，主要应对的是有状态的transformation，因为要生成新的RDD需要之前的RDD。当然，随着系统的执行，这样的依赖链会越来愈长，所以系统会周期性的将带有状态的transformation的中间RDDs保存到存储系统中。<br>对于程序中用到updateStateByKey/reduceByKeyAndWindow(with inverse function)这类有状态的transformation，以及期望driver programer能从错误中恢复出来，那么就需要使用checkpointing机制。</li>
</ul>
<p>通过<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">streamingContext.checkpoint(checkpointDirectory)</div></pre></td></tr></table></figure></p>
<p>设置Checkpointing目录，可以开启checkpointing机制。然后通常是调用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">context = StreamingContext.getOrCreate(checkpointDirectory, <span class="keyword">function</span>ToCreateContext)</div></pre></td></tr></table></figure></p>
<p>这个函数，当检测checkpointDirectory不存在的时候，说明是第一次执行，functionToCreateContext被调用，当driver programer出错而自动重新启动(由部署的deployment infrastructure支持)的时候，这个目录存在了，就不会再次调用functionToCreateContext函数来创建SparkContext和StreamingContext了。</p>
<h2 id="2-7_实时性">2.7 实时性</h2><p>　　总结来说，Spark Stream实际就是一个时间窗口内的RDD操作，然后通过增加各种函数来关联之前的数据，从本质上来说，算是一个大颗粒的周期性任务，如果时间间隔太大，延迟就严重；间隔太小，反复的提交调度任务，系统的吞吐量降低,负载也会加重。</p>
<h1 id="三、MLlib">三、MLlib</h1><p>　　包括常用的分类、聚类、回归等算法的实现。</p>
<h1 id="四、GraphX">四、GraphX</h1><p>　　这个可不是图形化现实，而是基于图的算法，比如大名鼎鼎的PageRank，此处暂且不论了。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" rel="external">Spark SQL, DataFrames and Datasets Guide</a>   </li>
<li><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" target="_blank" rel="external">Spark Streaming Programming Guide</a>    </li>
<li><a href="http://spark.apache.org/docs/latest/mllib-guide.html" target="_blank" rel="external">Machine Learning Library (MLlib) Guide</a>   </li>
<li><a href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" target="_blank" rel="external">GraphX Programming Guide</a>   </li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark学习手册（二）：Spark官方手册读摘]]></title>
      <url>https://taozj.org/201603/learn-note-of-spark-(2)-read-official-doc.html</url>
      <content type="html"><![CDATA[<p>　　本来想买本Spark的书的，无奈最近买的书有点多超预算了。再看看官方的开发文档写的还是挺全的，就想着自己边读文档边自己做一下记录吧。毕竟，别人网上写的东西都是提纲挈领的没有那么细，看英文虽然繁琐一些，但也好理解一些；但是搞一个完整的手册翻译也太费精力了，这个读摘的定位跟<a href="/201603/learn-note-of-pro-git.html">Pro Git速查笔记</a>一样——适合回顾而不适合学习。<br>　　Spark与HDFS环境的搭建，请参照<a href="/201603/learn-note-of-spark-(1">HDFS支撑下的Spark搭建与尝试</a>-construct-spark-hdfs.html)。个人感觉，理解Spark的核心，是理解其RDD(Resilient Distributed Dataset)的数据模型！同时，以下部分，会尽量用Python(Python3)来测试，不过有些特性或者功能官方还没有支持。<br>　　还有，由于本人对Spark还不太理解，文中的很多术语直接英文，不敢造次。<br><img src="/post_images/images/201603/7aa02b77aa24f8f16e88461c00e086f0.png" alt="Spark"></p>
<h1 id="一、常用术语解释">一、常用术语解释</h1><p>　　Spark中一个Application由1个driver program构成，由程序中的SparkContext定位，SparkContext可以链接各种类型的Cluster Manager(Spark自身的standalone、Mesos、YARN)，然后申请executors，申请到之后将程序代码发送到executors，最终由SparkContext发送tasks到executors以执行之。   </p>
<table>
<thead>
<tr>
<th>术语</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>application</td>
<td style="text-align:center">spark上的用户应用程序，由一个driver program和多个executors组成</td>
</tr>
<tr>
<td>driver program</td>
<td style="text-align:center">运行main并创建SparkContext的进程</td>
</tr>
<tr>
<td>worker node</td>
<td style="text-align:center">任何执行代码的集群节点</td>
</tr>
<tr>
<td>executor</td>
<td style="text-align:center">worker node启动的程序，执行tasks并在内存或者磁盘上保存数据</td>
</tr>
<tr>
<td>task</td>
<td style="text-align:center">每一个executor的执行单元</td>
</tr>
<tr>
<td>job</td>
<td style="text-align:center">由多个tasks构成的并行计算操作，一般由action操作催生</td>
</tr>
<tr>
<td>stage</td>
<td style="text-align:center">并行计算的核心是计算过程中不会产生shuffle，所以stage就是在shuffle边界产生的tasks集合，一个job一般由多个stages组成</td>
</tr>
</tbody>
</table>
<h1 id="二、官方首页显示的Spark的优势">二、官方首页显示的Spark的优势</h1><ul>
<li>速度快，当数据常驻内存会比Hadoop快100倍，即使硬盘访问，速度也会快10倍以上。这同在后面的文档中强调的，可以使用persist将Spark数据常驻内存，同时惰性计算加大了计算的效率和开销有关。将数据保存到内存里面，可以减少磁盘以及HDFS等操作，对于数据挖掘这种常常需要迭代计算的情形尤为适合。</li>
<li>接口简单可用，提供Java/Scala/Python/R的接口，个人比较喜欢Python。</li>
<li>包含Spark SQL，Spark Streaming，MLlib，GraphX模块，可以说从数据源、算法、生成显示的部分都囊括了。</li>
<li>和Hadoop，Mesos等的结合。暂时还没体会，不过用HDFS是刚刚滴，Spark支持本机standalone模式，后面可能会测试跟Hadoop YARN进行集成。<a id="more"></a>
<h1 id="三、Spark启动和实用">三、Spark启动和实用</h1></li>
<li>bin/pyspark会启动一个交互式的shell，并初始化SparkContext和sqlContext（注意查看提示实用的python版本），比如PYSPARK_PYTHON=python3.4 bin/pyspark；<br>–master local/local[4]/spark://host:port….，指定master的地址，当为local的时候在本机执行，不进行分布式操作；</li>
<li>bin/spark-submit提交一个脚本的任务。比如<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  ~  bin/spark-submit /root/wordc.py</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="四、RDD数据表示">四、RDD数据表示</h1><p>　　RDD数据模型会对数据进行分区，可以在各个集群节点上进行并行计算。RDD的数据来源既可以是程序中的数据，也可以是来自外部存储的或者是网路上的数据。</p>
<ul>
<li><p>程序中的数据可以使用sc的parallelize方法，对一个可迭代或者collection的数据进行并行化生成一个可以并行化计算的分布式数据集， 此函数接受一个分区数目参数，一个分区运行一个task，一般是一个CPU分配2～4个分区，系统一般会自动根据集群的规模设置分区数目。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</div><div class="line">distData = sc.parallelize(data)</div></pre></td></tr></table></figure>
</li>
<li><p>外部数据主要是hadoop支持的数据，形式有文本数据，序列文件（SequenceFiles）以及其他Hadoop支持的输入格式；<br>文本文件主要用textFile函数，把文件读入，形成以行为单位的数据集，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">distFile = sc.textFile(<span class="string">"/root/data.txt"</span>)</div><div class="line">print(distFile.collect())</div><div class="line">distFile.map(<span class="keyword">lambda</span> s: len(s)).reduce(<span class="keyword">lambda</span> a, b: a + b) <span class="comment">#计算总的词的个数</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>　　注意：如果指示的文件路径是本地路径，那么在各个work节点上都必须要能在相同的路径访问该文件，比如拷贝过去，或者用网络文件系统共享等到各个work节点的相同路径处；对于输入的文件，可以是路径、含*的通配符、gz压缩文件；函数还支持partition数目的参数，HDFS会把文件分block，默认一个partition对应一个block，也可以设置partition数目大于block数目。<br>　　wholeTextFiles 可以读取一个目录下的所有文件，然后保存成文件名—内容格式；<br>　　RDD.saveAsPickleFile和SparkContext.pickleFile，可以保存RDD以及Python的数据；<br>　　SequenceFiles，比较特殊的，为Hadoop所用二进制形式来存储key-value模式的平面文件，其数据的读写在pyspark中实际上是进行了Python-<pyrolite>-Java数据类型的底层转换的，但是对用户来说是透明的；<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">rdd = sc.parallelize(range(<span class="number">1</span>, <span class="number">4</span>)).map(<span class="keyword">lambda</span> x: (x, <span class="string">"a"</span> * x ))</div><div class="line">rdd.saveAsSequenceFile(<span class="string">"root/aaaa.txt"</span>)</div><div class="line">sc.sequenceFile(<span class="string">"root/aaaa.txt"</span>).collect()</div></pre></td></tr></table></figure></pyrolite></p>
<ul>
<li>Spark SQL；</li>
<li><p>RDD支持两种操作：transformation和action，前者是将一个数据集转换成另外一个数据集，而后者让程序计算并将结果返回给driver程序。前者比如常见的map函数，会将数据集中的每一个元素通过某个函数转换成RDD表示的数据集，而reduce就是把RDD的所有元素通过某些函数聚集起来并返回给driver程序。<br>　　Spark所有的计算都是惰性的，只有在driver程序需要返回而执行action操作时，才会进行真正的计算，这样可以增加Spark的计算效率，减少无用计算和数据传递。<br>　　具体的Transformation函数和Action函数见下文的列表。<br>　　一个map/reduce的例子程序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">lines = sc.textFile(<span class="string">"data.txt"</span>)</div><div class="line">lineLengths = lines.map(<span class="keyword">lambda</span> s: len(s))</div><div class="line">totalLength = lineLengths.reduce(<span class="keyword">lambda</span> a, b: a + b)</div></pre></td></tr></table></figure>
</li>
<li><p>Spark依赖于传奇函数使其节点进行计算任务，函数包含：lamda表达式、文件中定义的局部函数、定义在模块中的函数。<br> 函数模式举例如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#!/usr/bin/python3</span></div><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkConf, SparkContext</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">word_c</span><span class="params">(string)</span>:</span></div><div class="line">        words = string.split()</div><div class="line">        <span class="keyword">return</span> len(words)</div><div class="line"></div><div class="line">    conf = SparkConf().setAppName(<span class="string">"WORD_TEST"</span>).setMaster(<span class="string">"local[2]"</span>)</div><div class="line">    sc = SparkContext(conf=conf)</div><div class="line">    distFile = sc.textFile(<span class="string">"/root/wordc.py"</span>)</div><div class="line">    rest = distFile.map(word_c).reduce(<span class="keyword">lambda</span> a, b: a + b)</div><div class="line">    print(<span class="string">"Total:%d"</span> %(rest))</div></pre></td></tr></table></figure>
</li>
</ul>
<p>　　然后，使用” bin/spark-submit  /root/wordc.py”提交任务。</p>
<ul>
<li><p>Closures<br>　　这个可能是Java中什么闭包的概念。总之，在Spark中被worker节点执行的函数中，不要使用全局变量，如果在本地非分布式环境的话，实际使用的一个JVM虚拟机结果可能是正常的，但是如果是分布式的，那么这个变量会被序列化并传递给每个worker节点一份拷贝，在worker节点上更新的都是自己本地副本而不会反馈回driver程序，所以最终driver程序中的变量压根就没被更新。<br>　　如果要使用全局变量，请使用Broadcasting vars和Accumulators</p>
<ul>
<li><p>Broadcasting vars是共享的只读变量，一般worker节点上执行计算的数据，既可以通过执行函数传递过去，也可以通过这种Broadcasting vars方式传递过去，Broadcasting vars让所有worker节点保持只读的数据拷贝，而且其使用的Broadcasting算法使得这种传递更为的有效率，在使用中一旦被创建就不应当改变其值，以保证各个节点的数据都是一致的，同时也不应当在各个执行节点上被更新。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>arr = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">10</span>]</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>broadcastVar = sc.broadcast(arr)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>broadcastVar.value</div><div class="line">[<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">10</span>]</div></pre></td></tr></table></figure>
</li>
<li><p>Accumulators能够保证在各个worker节点对该变量的更新都能安全的实现，其默认支持数字类型，代码可以继承AccumulatorParam类扩充为其他类型（只需实现zero和addInPlace函数），同时也只能在driver程序中才能读到其值，worker节点只能进行更新操作。此处还需要注意：对于在actions中的更新，系统能保证变量只会被更新一次，所以对于重启的task不会被再次更新；但在transform中的更新操作没有这个保证，重启任务可能会被更新多次，或许可以这么理解：transform自己不会进行实际的计算操作，是由action驱动的计算规则，所以无法保存task计算状态（自己猜的~）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>accum = sc.accumulator(<span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>distFile = sc.textFile(<span class="string">"/root/wordc.py"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>distFile.map(<span class="keyword">lambda</span> s: (s,len(s))).foreach(<span class="keyword">print</span>)  <span class="comment">#查看??</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>distFile.map(<span class="keyword">lambda</span> s: len(s)).foreach(<span class="keyword">lambda</span> x: accum.add(x))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>accum.value</div><div class="line"><span class="number">396</span></div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>　　这里引申出打印数据，每个工作节点的print到的标准输出都是本地的，所以如果要在driver程序的节点上看到打印结果，必须将数据收集起来然后在本地打印显示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">distFile = sc.textFile(<span class="string">"/root/wordc.py"</span>)</div><div class="line">print(distFile.collect())</div><div class="line">print(distFile.take(<span class="number">3</span>))</div></pre></td></tr></table></figure></p>
<h1 id="五、RDD的Transformations和Actions函数">五、RDD的Transformations和Actions函数</h1><ul>
<li>Transformations</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>map(func)</td>
<td style="text-align:center">通过func将源数据的每一个元素进行转换生成RDD</td>
</tr>
<tr>
<td>filter(func)</td>
<td style="text-align:center">通过func选择那些返回为true的数据组成新的数据集</td>
</tr>
<tr>
<td>flatMap(func)</td>
<td style="text-align:center">同map，但是每一个输入元素可能会被映射成0或者多个items</td>
</tr>
<tr>
<td>mapPartitions(func)</td>
<td style="text-align:center">类似map，不过是在RDD各个partition上单独运行的，所以func的参数都是迭代器的（同上面结果可能会有些差异）</td>
</tr>
<tr>
<td>mapPartitionsWithIndex(func)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>sample(withReplacement, fraction, seed)</td>
<td style="text-align:center">取样</td>
</tr>
<tr>
<td>union(otherDataset)</td>
<td style="text-align:center">两个数据集的交集</td>
</tr>
<tr>
<td>intersection(otherDataset)</td>
<td style="text-align:center">两个数据集的并集</td>
</tr>
<tr>
<td>distinct([numTasks]))</td>
<td style="text-align:center">取出不含重复值的数据集</td>
</tr>
<tr>
<td>groupByKey([numTasks])</td>
<td style="text-align:center">集合数据集的(K, V)产生(K, Iterable<v>) ，注意如果是如果可能，reduceByKey/aggregateByKey性能会更好</v></td>
</tr>
<tr>
<td>reduceByKey(func, [numTasks])</td>
<td style="text-align:center">将(K, V)中同K的V通过func方式集合起来</td>
</tr>
<tr>
<td>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>sortByKey([ascending], [numTasks])</td>
<td style="text-align:center">通过K进行排序</td>
</tr>
<tr>
<td>join(otherDataset, [numTasks])</td>
<td style="text-align:center">将(K, V)、(K, W)联合为(K, (V, W))</td>
</tr>
<tr>
<td>cogroup(otherDataset, [numTasks])</td>
<td style="text-align:center">将(K, V)和(K, W)返回(K, (Iterable<v>, Iterable<w>))元祖</w></v></td>
</tr>
<tr>
<td>cartesian(otherDataset)</td>
<td style="text-align:center">笛卡尔，对于T、U数据集，返回(T, U)Pair</td>
</tr>
<tr>
<td>pipe(command, [envVars])</td>
<td style="text-align:center">对每一个partition，通过将每个元素作为command的stdin输入，然后将stdout输出定位到string类型的RDD数据集</td>
</tr>
<tr>
<td>coalesce(numPartitions)</td>
<td style="text-align:center">合并，减少partition数目</td>
</tr>
<tr>
<td>repartition(numPartitions)</td>
<td style="text-align:center">随机的Reshuffle数据</td>
</tr>
<tr>
<td>repartitionAndSortWithinPartitions(partitioner)</td>
<td style="text-align:center">repartition和sort集成的更高效实现</td>
</tr>
</tbody>
</table>
<ul>
<li>Actions</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th style="text-align:center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>reduce(func)</td>
<td style="text-align:center">集合</td>
</tr>
<tr>
<td>collect()</td>
<td style="text-align:center">将数据集的所有元素以数组的方式返回给driver program</td>
</tr>
<tr>
<td>count()</td>
<td style="text-align:center">返回数据集元素的个数</td>
</tr>
<tr>
<td>first()</td>
<td style="text-align:center">返回第一个元素，类似take(1)</td>
</tr>
<tr>
<td>take(n)</td>
<td style="text-align:center">返回前面的n个元素</td>
</tr>
<tr>
<td>takeSample(withReplacement, num, [seed])</td>
<td style="text-align:center">返回随机的num个元素</td>
</tr>
<tr>
<td>takeOrdered(n, [ordering])</td>
<td style="text-align:center">返回通过自然排序或者定制比较器的n个元素</td>
</tr>
<tr>
<td>saveAsTextFile(path)</td>
<td style="text-align:center">将每个元素调用toString方法成为一行，然后保存写入到文件中</td>
</tr>
<tr>
<td>saveAsSequenceFile(path) (Java and Scala)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>saveAsObjectFile(path) (Java and Scala)</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td>countByKey()</td>
<td style="text-align:center">只适用于(K,V)类型，返回(K, Int)计数，默认并行task数为2</td>
</tr>
<tr>
<td>foreach(func)</td>
<td style="text-align:center">对每个元素执行func，通常用于Accumulators等操作</td>
</tr>
</tbody>
</table>
<h1 id="六、Shuffle">六、Shuffle</h1><p>　　主要是数据的重新分配，涉及到执行磁盘IO、数据序列化、网络IO等操作，是十分耗费资源的操作。比如对于reduceByKey操作，系统会读取所有的partition，收集keys形成一个元祖，然后再在所有的partitions中将这些key的值进行搜集整理而得到最终的答案。为了向shuffle组织数据，Spark会产生一些map任务集来负责组织数据，reduce任务集来聚集数据，两者中间会有交互的数据文件，因此会消耗大量的内存，如果内存不够甚至会写入磁盘导致磁盘IO。<br>　　会导致Shuffl的操作有：repartiton(repartition, coalesce)；ByKey(groupByKey, reduceByKey)；join(cogroup, join)</p>
<h1 id="七、RDD_Persistence">七、RDD Persistence</h1><p>　　Spark的缓存是在action触发后，将指定缓存的数据结果保留在某些地方，同时缓存是容错的，当任何一个partition出错数据丢失时候，缓存的数据会重新按照原来的方式计算出来。<br>　　通过persist传递各种Storage Level，可以让缓存在内存与磁盘、平坦与压缩、CPU计算量等方面做出各种妥协和权衡。默认的级别是StorageLevel.MEMORY_ONLY，cache()函数为其缩写。<br>　　Spark会自动跟踪缓存的使用，必要的时候会根据LRU的原则丢弃旧的缓存，当然用户也可以调用 RDD.unpersist()显式地删除某些rdd的缓存。</p>
<p>Spark其他部分待续~</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://spark.apache.org/docs/latest/" target="_blank" rel="external">Spark Doc</a></li>
<li><a href="http://spark.apache.org/docs/latest/cluster-overview.html" target="_blank" rel="external">Spark Cluster Mode Overview</a></li>
<li><a href="http://www.open-open.com/lib/view/open1453249796636.html" target="_blank" rel="external">Spark的性能调优</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Spark学习手册（一）：HDFS支撑的Spark环境搭建与尝试]]></title>
      <url>https://taozj.org/201603/learn-note-of-spark-(1)-construct-spark-hdfs.html</url>
      <content type="html"><![CDATA[<p>﻿﻿﻿﻿　　用于大数据分析的，虽然在前面说过数据分析和数据挖掘的核心贵在算法，但是对于折腾帝来说搭建体验一下还是可以的吧～需要注意的是Spark是可以脱离Hadoop在单机上运行，但总觉得单机跑不出Spark的味道，所以顺便把Hadhoop也搞一份玩玩！　　<br>　　Spark是可以同Hadoop的HDFS和YARN集合到一起玩的，这里先只涉及用Spark跑HDFS方面的东西。</p>
<h1 id="一、LXC集群环境搭建">一、LXC集群环境搭建</h1><p>　　本来想用KVM建立两个DataNode，然后host主机做NameNode的，但根据腿毛兄建议可以用LXC轻量级的虚拟化，想想也是这么回事，这种简单的事搞个虚拟机太浪费了，网上一搜果真还真有。相比较KVM的全虚拟化，LXC基于容器共享一个内核和很多系统组件，当开启多个实例的时候可以大大节约共用的资源，磁盘也类似是host主机文件系统chroot的一个目录，相比完全虚拟化创建一个磁盘镜像完全隔离也显得轻量节省太多了。当然，除了LXC，Docker就是用go语言基于LXC产生的企业级的容器虚拟化方案，但最终偶还是选择了LXC——人嘛，总是要有点追求滴!<br>　　还有，virt-manager+libvirtd是支持链接管理LXC容器的，对于创建应用容器很方便，但是对于系统容器，默认不能创建文件系统；当然你可以用lxc-create的方式进行编译创建，也可以用lxc-create下载官方最新构建好的系统镜像，比如:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">lxc-create -t download -n alpha -- --list</div><div class="line">lxc-create -t download -n debian8_node101 <span class="_">-f</span> /etc/lxc/guest.conf --dir=/home/user/Machines/LXC_ROOTFS/debian8_node101 -- <span class="_">-d</span> debian -r jessie <span class="_">-a</span> amd64</div></pre></td></tr></table></figure></p>
<p>　　但是这种命令行方式创建的容器十分的“裸”，网络参数啥的需要自己手动设定，没耐心的还真需要点功夫，十分的麻烦。于是个人偷了个懒:</p>
<ul>
<li>在<a href="https://images.linuxcontainers.org/images" target="_blank" rel="external">网站</a> 下载好自己想要的发行版的rootfs.tar.xz镜像；</li>
<li>用root权限解压到自己指定的rootfs目录：<br>xz rootfs.tar.xz<br>sudo tar xvfp rootfs.tar #注意root权限解压<br>sudo mv rootfs /home/user/Machines/LXC_ROOTFS/debian8_node101</li>
<li>virt-manager创建系统容器的时候,指定到这个目录来；</li>
<li>默认系统root没有密码,但是virt-manager没密码的话还不让你登陆，丫的只能chroot然后改密码:<br>chroot /home/user/Machines/LXC_ROOTFS/debian8_node101 /bin/bash<br>passwd root</li>
</ul>
<p>　　然后就好了，virt-manager中可以方便的选择网络是NAT模式的，而且公用KVM虚拟机的NAT网段，在WIN7虚拟机里面也可以跟LXC“私通”，很爽吧。<br>　　关于系统镜像，个人反复比较一下，决定用的debian 8(jesse)：fedora的镜像200多M，所以系统比较的臃肿；centos7最小，但是很多软件（比如python3）默认不支持，添加源也比较麻烦；就选择了debian stable算比较折中(又一次背叛了自己的信仰……)。<br>　　PS:Debian和Fedora新版系统在virt-manager下终端登陆有问题，放弃了，目前用的Ubuntu 1404(在此请原谅我的堕落)……<br>　　图1：Virt-Manager关机LXC容器，网络默认是配好的(记住，Virtual-manager还支持链接远程的KVM和LXC的，需要远程主机添加Libvirt的kvm/LXC的相关驱动)<br><img src="/post_images/images/201603/c0db3e83e7ef469b57a5510accd13ff6.png" alt="virt-manager登陆管理LXC容器"><br><a id="more"></a></p>
<h1 id="二、Hadoop环境搭建">二、Hadoop环境搭建</h1><p>　　Hadoop主要由HDFS和MapReduce组成，前者负责一个分布式的文件系统，后者负责计算中的Map和Reduce过程，如果映射到Hadoop具体的机器节点中，那么就是NameNode-DataNode负责HDFS的控制和承载，ResourceManager和NodeManager负责MapReduce的管理和承载，系统中还可以有WebAppProxy(主要是为了安全考虑),JobHistoryServer等节点。这里主要想要HDFS为Spark提供数据，所以只需要NameNode和DataNode就可以了，Hadoop可以折腾的东西很多，看看<a href="http://hadoop.apache.org/" target="_blank" rel="external">项目主页</a>  就知道了，留着以后折腾吧。<br>　　当然，分布式文件系统除了HDFS，还有阿里和腾讯的两个TFS，HDFS大家用的比较多比较主流吧.<br>　　所以在系统中配置了4台主机（不考虑主从备份），安排如下</p>
<blockquote>
<p>ubuntu1404_node01 通用计算节点(Spark)<br>ubuntu1404_node02 NameNode<br>ubuntu1404_node03 DataNode<br>ubuntu1404_node04 DataNode</p>
</blockquote>
<p>图2：Virt-Manager打开的四个计算容器<br><img src="/post_images/images/201603/f7648b86246ce4adb01eb1771913479d.png" alt="四个容器全部开启"></p>
<h2 id="2-1_准备工作">2.1 准备工作</h2><p>准备工作都比较简单，主要是Linux的基础配置，这里就简单罗列下来:</p>
<ul>
<li>在/etc/hostname中设置对应主机名；<br>在主机/etc/network/interfaces设置静态IP，并将主机名和IP映射写入每个机器的/etc/hosts<br>还需要注意的是，在每个主机的/etc/hosts中，把127.0.1.1对应本机hostname的那行注释掉，不然NameNode无法自动启动DataNode。</li>
<li>ssh免密码互通登陆<br>adduser hdfs<br>passwd hdfs #hdfs<br>ssh-keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa<br>cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys<br>chmod 0600 ~/.ssh/authorized_keys<br>然后把各个主机的公钥都整合到同一个authorized_keys文件，拷贝到各个主机，这样各个主机的hdfs用户就可以互通免密码了。</li>
<li>Orace Jave环境安装(Java 1.7,参见<a href="https://ofirm.wordpress.com/2014/01/05/creating-a-virtualized-fully-distributed-hadoop-cluster-using-linux-containers/" target="_blank" rel="external">这里</a>)<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-oracle</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-2_HDFS配置">2.2 HDFS配置</h2><ul>
<li><p>下载最新版本<br>wget <a href="http://mirrors.ustc.edu.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz" target="_blank" rel="external">http://mirrors.ustc.edu.cn/apache/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz</a><br>将其解压到每个节点的/home/hdfs/hadoop目录下，设置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hdfs/hadoop</div><div class="line"><span class="built_in">export</span> HADOOP_PREFIX=/home/hdfs/hadoop</div></pre></td></tr></table></figure>
</li>
<li><p>配置 $HADOOP_HOME/etc/hadoop/下的文件（按照xml格式写）,  各个主机上配置如下</p>
<ul>
<li>NameNode:<br>文件【etc/hadoop/core-site.xml】<br>  fs.defaultFS    hdfs://ubuntu1404_node02:9000<br>文件【etc/hadoop/slave】<br>  ubuntu1404_node03<br>  ubuntu1404_node04<br>文件【etc/hadoop/hdfs-site.xml】<br>  dfs.namenode.name.dir   file:///home/hdfs/hadoopinfra/hdfs/namenode<br>  dfs.permissions.superusergroup    hdfs</li>
<li>DataNode:<br>文件【etc/hadoop/core-site.xml】<br>  fs.defaultFS    hdfs://ubuntu1404_node02:9000<br>文件【etc/hadoop/hdfs-site.xml】<br>  dfs.datanode.data.dir    file:///home/hdfs/hadoopinfra/hdfs/datanode<br>  dfs.permissions.superusergroup    hdfs</li>
</ul>
</li>
<li>相应的，在对应的主机上准备好上面的文件路径<br>  mkdir -p /home/hdfs/hadoopinfra/hdfs/namenode<br>  mkdir -p /home/hdfs/hadoopinfra/hdfs/datanode</li>
<li>设置<br> 在配置文件etc/hadoop/hadoop-env.sh顶部，设置如下环境变量：<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-oracle</div><div class="line"><span class="built_in">export</span> HADOOP_HOME=/home/hdfs/hadoop</div><div class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/home/hdfs/hadoop/etc/hadoop</div><div class="line"><span class="built_in">export</span> HADOOP_PID_DIR=/home/hdfs/hadoop/pids</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="2-3_HDFS测试">2.3 HDFS测试</h2><p>　　hdfs的访问，一种是在命令行的模式下，可以格式化，创建目录等操作，就像传统的linux文件系统的方式。直接文件系统的命令是不行的；还有一种就是API的方式，用于集成到程序当中。<br>　　这里先用命令行的方式来测试验证</p>
<ul>
<li>从NameNode启动服务器<br>　　启动的方式有手动启动，或者自动启动。推荐设置salve文件，把所有DataNode机器的名字都加进去，这样，只需要一条命令就可以启动所有的DataNode节点。<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ hadoop/sbin/stop-dfs.sh <span class="comment">#停止</span></div><div class="line">$ hadoop/sbin/start-dfs.sh <span class="comment">#启动</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>图3：NameNode启动DataNode<br><img src="/post_images/images/201603/8598df1b3ea54bfaf5c30bc00869a15b.png" alt="NameNode启动DataNode"><br>图4：Host主机上开启了大量的Java线程<br><img src="/post_images/images/201603/9f8769f521b27d2c54f48122ad72369c.png" alt="Host主机上开启了大量的Java线程"><br>图5：浏览器打开ubuntu1404-node02:50070，登陆NameNode进行HDFS浏览和管理<br><img src="/post_images/images/201603/ed2176e19b7e19bbe31458475fd4748c.png" alt="网页HDFS浏览和管理"></p>
<ul>
<li>命令行验证<br>内容都是直白，就不解释了：<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs namenode -format</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -mkdir -p testdir</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -ls</div><div class="line">Found 1 items</div><div class="line">drwxr-xr-x   - hdfs hdfs          0 2016-03-23 01:04 testdir</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -put data.csv </div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -put data.csv_2 testdir</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -ls</div><div class="line">Found 2 items</div><div class="line">-rw-r--r--   3 hdfs hdfs       1648 2016-03-23 01:07 data.csv</div><div class="line">drwxr-xr-x   - hdfs hdfs          0 2016-03-23 01:08 testdir</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -ls testdir</div><div class="line">Found 1 items</div><div class="line">-rw-r--r--   3 hdfs hdfs       1648 2016-03-23 01:08 testdir/data.csv_2</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -cat testdir/data.csv_2</div><div class="line">  AAPL,28-01-2011, ,344.17,344.4,333.53,336.1,21144800</div><div class="line">  AAPL,31-01-2011, ,335.8,340.04,334.3,339.32,13473000</div><div class="line">  AAPL,01-02-2011, ,341.3,345.65,340.98,345.03,15236800</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="三、Spark安装与测试">三、Spark安装与测试</h1><h2 id="3-1_Spark安装配置">3.1 Spark安装配置</h2><p>　　安装很简单，就选择和你Hadoop兼容的Pre-build版本就可以了，设置的话，只需要JAVA_HOME配置对了就好了（在/etc/profile添加export JAVA_HOME=/usr/lib/jvm/java-7-oracle）。</p>
<h2 id="3-2_Spark和HDFS联合测试">3.2 Spark和HDFS联合测试</h2><p>　　Spark的RDD数据流据说是Spark的精华所在，这里只是简单的做个测试吧！</p>
<ul>
<li><p>HDFS准备测试数据。这里需要注意的是在最后一行，修改了testdir文件的权限，这是因为之前测试的时候，在计算电脑上保存结果出错，说权限不行，于是这里开放其他用户写权限。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">hdfs@ubuntu1404-node02:~$ wget https://www.kernel.org/doc/Documentation/initrd.txt</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/sbin/start-dfs.sh</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -put initrd.txt</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -ls</div><div class="line">Found 2items</div><div class="line">-rw-r--r--   3 hdfs hdfs      14398 2016-03-23 08:15 initrd.txt</div><div class="line">drwxr-xr-x   - hdfs hdfs          0 2016-03-23 01:08 testdir</div><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -chmod ugo+w /user/hdfs/testdir</div></pre></td></tr></table></figure>
</li>
<li><p>在计算电脑上开启pyspark(spark-1.6.1-bin-hadoop2.6/bin/pyspark)， 然后进行计算操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>text_file = sc.textFile(<span class="string">"hdfs://ubuntu1404-node02:9000/user/hdfs/initrd.txt"</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>counts = text_file.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>)) \</div><div class="line"><span class="meta">... </span>             .map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)) \</div><div class="line"><span class="meta">... </span>             .reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>counts.saveAsTextFile(<span class="string">"hdfs://ubuntu1404-node02:9000/user/hdfs/testdir/wc_initrd"</span>)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>图6：pyspark状态图<br><img src="/post_images/images/201603/aced0e0d3d6d1c2a707a42009adc7997.png" alt="过程截图"></p>
<ul>
<li>在HDFS NameNode电脑商查看计算的结果<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">hdfs@ubuntu1404-node02:~$ hadoop/bin/hdfs dfs -ls /user/hdfs/testdir/wc_initrd/</div><div class="line">Found 3 items</div><div class="line">-rw-r--r--   3 root hdfs          0 2016-03-23 09:03 /user/hdfs/testdir/wc_initrd/_SUCCESS</div><div class="line">-rw-r--r--   3 root hdfs       6650 2016-03-23 09:03 /user/hdfs/testdir/wc_initrd/part-00000</div><div class="line">-rw-r--r--   3 root hdfs       6609 2016-03-23 09:03 /user/hdfs/testdir/wc_initrd/part-00001</div></pre></td></tr></table></figure>
</li>
</ul>
<p><em>当然，这里的测试是比较简单的，从结果得知，还需要手动将节点计算出来的结果进行整合才行。</em><br>这里勘误:上面表述是错误的,这是因为reduceByKey启用了多个task导致的,实际上的结果是合并了的.如果想生成一个文件,可以这样:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">counts.coalesce(<span class="number">1</span>).saveAsTextFile(<span class="string">"hdfs://ubuntu1404-node02:9000/user/hdfs/testdir/wc_initrd"</span>)</div></pre></td></tr></table></figure></p>
<h1 id="四、结语">四、结语</h1><p>　　首先让我对Apache有了一个新的认识，Apache可不仅仅生产Httpd和openOffice，看看<a href="http://mirrors.ustc.edu.cn/apache" target="_blank" rel="external">Apache镜像</a>的庞大规模，可以跟GNU匹配了，你就知道Apache基金会对开源社区的巨大贡献了。<br>　　大数据的工具也不是那么容易的，这里仅仅是一个皮毛的皮毛，不过好在这些东西都很完善和成熟了，我们需要知道的就是怎么配置出我们需要的环境和条件吧。<br>　　为什么这么多企业级的项目都是用的Java？</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://ofirm.wordpress.com/2014/01/05/creating-a-virtualized-fully-distributed-hadoop-cluster-using-linux-containers/" target="_blank" rel="external">Creating a virtualized fully-distributed Hadoop cluster using Linux Containers</a>  </li>
<li><a href="http://blog.csdn.net/jewes/article/details/21998073" target="_blank" rel="external">用Linux Container在单机上部署完全分布式的Hadoop集群</a> </li>
<li><a href="https://wiki.gentoo.org/wiki/LXC" target="_blank" rel="external">Gentoo Wiki LXC</a></li>
<li><a href="https://wiki.archlinux.org/index.php/LXC" target="_blank" rel="external">Archlinux Wiki LXC</a></li>
<li><a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/ClusterSetup.html" target="_blank" rel="external">Apache Hadoop</a></li>
<li><a href="http://www.tutorialspoint.com/hadoop/hadoop_enviornment_setup.htm" target="_blank" rel="external">Hadoop - Enviornment Setup</a></li>
<li><a href="http://blog.csdn.net/renfengjun/article/details/25320043" target="_blank" rel="external">hadoop 启动的时候datanode报错 Problem connecting to server</a></li>
<li><a href="http://spark.apache.org/docs/latest/" target="_blank" rel="external">Apache Spark Doc</a></li>
<li><a href="http://spark.apache.org/examples.html" target="_blank" rel="external">Spark Examples</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Pro Git速查笔记]]></title>
      <url>https://taozj.org/201603/learn-note-of-pro-git.html</url>
      <content type="html"><![CDATA[<h3 id="一、前言">一、前言</h3><p>　　git是个性大神Linus自Linux内核而来的第二大发明。对于这个神器,个人也用了很久，相对其它的版本控制工具,其速度快、性能好、操作智能人性，是开发人员必备之利器；<a href="https://github.com" target="_blank" rel="external">GitHub</a>依托git作为程序员和开源项目代码首选托管网站，俨然同时也已成为全球最大的程序员基佬之交友网站。<br>　　正如Linux下面的大多数命令行程序一样，只有常用的和用的多的才记得住，不常用的即使当时搞得很清晰，事后也容易忘记。这次在假期把<a href="https://git-scm.com/book/zh/v2" target="_blank" rel="external">Pro Git中文版</a>看了一遍，这里打算对常用的命令和参数进行一次整理，方便后续复习查阅。<br><img src="/post_images/images/201603/f17a0279e1e0ec49860ae30ec1dd9bde.png" alt="Pro Git"></p>
<h3 id="二、git常用命令记录">二、git常用命令记录</h3><h6 id="-gitignore文件格式">.gitignore文件格式</h6><ul>
<li>所有空行以及用#开头的注释都会被忽略；</li>
<li>匹配的模式是glob模式，*匹配零个或多个任意字符，[abc]匹配任何一个列在方括号中的字符，?只匹配一个任意字符；</li>
<li>模式后面接/表示要忽略的是目录；</li>
<li>要对某些模式或者目录提出例外情况，使用!进行取反；</li>
<li>doc/<em>.txt只匹配doc直接目录下的</em>.txt,而doc/<em>*/</em>.txt会递归匹配整个目录和子目录的*.txt；</li>
</ul>
<h6 id="git_diff">git diff</h6><ul>
<li>git diff #默认查看的是当前修改的文件和暂存区快照文件的差异；</li>
<li>git diff –cached/–staged #查看暂存区快照文件和上一次提交的对比；</li>
<li>git reset HEAD <filename> #将文件从暂存区撤出来,和当前修改合并；</filename></li>
</ul>
<h6 id="git_rm">git rm</h6><ul>
<li>git rm <filename> #将文件从版本控制中剔除,默认会连同文件系统的文件一通删掉</filename></li>
<li>git rm –cached <filename> #保留文件本身而脱离版本控制(常用于比如忘了添加到.gitignore)</filename></li>
</ul>
<h6 id="git_log">git log</h6><ul>
<li>git log -p   #以补丁的形式显示提交的内容差异</li>
<li>git log -<n>  #显示最近的n次提交</n></li>
<li>git log –word-diff #显示单词(而不是默认行)级别的差异,在处理文本的时候比较有用</li>
<li>git log -U<n> #显示差异的上下文行数,默认是3</n></li>
<li>git log –stat #相比默认显示,添加了修改文件,及其行数信息</li>
<li>git log –pretty=[online,short,full,fuller,format:]<br>git log –pretty=format:”%h %ae %cd %s” #这在提交数目太多的时候,可以方便的显示.</li>
<li>git log –author=xxx –since=”2015-01-12” –before=”2015-03-10” –grep=”CPP” #可以指定单条或者多条过滤格式.默认是满足任何一条就列出,如果需要满足多条,需要额外添加–match-all选项.<a id="more"></a></li>
</ul>
<h6 id="git_commit">git commit</h6><ul>
<li>git commit –amend #对最后一次提交进行覆盖重新提交.(切记对于已经push的commit会引来麻烦)</li>
<li>git reset HEAD <filename> #可以对已经暂存的文件撤出暂存区并同当前目录文件合并</filename></li>
<li>git checkout – <filename> #放弃当前文件的修改,文件内容跟暂存区内容一致.</filename></li>
</ul>
<h6 id="git_remote">git remote</h6><ul>
<li>git remote -v #显示远程仓库的信息</li>
<li>git remote add <remote-name> <a href="https://remote-url" target="_blank" rel="external">https://remote-url</a> #添加远程仓库</remote-name></li>
<li>git fetch <remote-name>  #抓取远程仓库的内容,注意的是fetch只是抓取内容,而不会自动合并内容到本地</remote-name></li>
<li>git push <remote-name> <branch-name> #推送内容到远程的某个分支</branch-name></remote-name></li>
<li>git remote show <remote-name> #显示远程仓库的详细信息(需要联网)</remote-name></li>
<li>git remote rename/rm  #重命名/删除远程仓库</li>
</ul>
<h6 id="git_tag">git tag</h6><ul>
<li>git tag #显示当前仓库已有的标签.</li>
<li>git tag <tag-name> #打轻量级的标签</tag-name></li>
<li>git tag -a <tag-name> -m “tag-message” #打带附注的标签</tag-name></li>
<li>git config –global user.signingKey C0CC5261 #设置默认签名<br>git tag -s <tag-name> -m “tag-message” #打带GPG签名的标签</tag-name></li>
<li>git tag -v <tag-name>  #验证带签名的标签</tag-name></li>
<li>git push origin <tag-name> #默认push不会把tag推送到远程服务器的,可以用这个命令将<tag-name>推送到远程仓库<br>git push origin –tags  #推送本地所有tag到远程仓库</tag-name></tag-name></li>
<li><blockquote>
<p>(1)Git的标签轻量级的和带附注的两种类型.前者其实就是对某个特定提交的引用；而后者是一个实际的标签对象,包含校验信息\标签名\email\日期\GPG校验等信息.</p>
</blockquote>
</li>
</ul>
<h6 id="git_branch">git branch</h6><ul>
<li>git branch <branch-name> #创建分支</branch-name></li>
<li>git checkout <branch-name> #切换到对应分支(切换分支的时候最好保持一个干净的工作空间-stash)</branch-name></li>
<li>git checkout master<br>git merge devel   #将devel分支的更新合并到master分支<br>git branch -d devel #删除无用分支</li>
<li>git branch –merged #查看那些分支已经被并入到当前的分支,也就是那些分支是当前分支的直接上游,因为已经被合并了,所以当前分支已经包含了其所有的数据,可以安全删除这里列出的分支；</li>
<li>git branch –no-merged #与上面相反,包含尚未合并的数据,默认不能简单删除之</li>
<li>git log <master>..<experiment> # 查看所有在[experiment]中而不在<master>分支中的提交,显示的就是git merge <experiment>所用到的存在于<experiment>中的所有提交；</experiment></experiment></master></experiment></master></li>
<li>git log origin/master..HEAD #预览你将会被那些推送给远程仓库;</li>
<li>git log –left-right <master>..<experiment> #查看两个分支各自不同的提交信息</experiment></master></li>
<li><blockquote>
<p>(1)上面这些分支都是本地的分支,跟服务器上的分支没有任何关系,服务器上的分支需要<remote-name>/<branch-name>这样的方式来引用；</branch-name></remote-name></p>
</blockquote>
</li>
<li><blockquote>
<p>(2)合并有快进合并(Fast-forward)和普通合并,当某个分支在被合并分支的下游,就会快进合并；否则在之前的某个提交开始分叉的话,会从两者的共同祖先开始进行一个三方合并；</p>
</blockquote>
</li>
<li><blockquote>
<p>(3)合并冲突:git会自动进行相关合并,如果合并冲突的话,冲突的文件会在Unmerged paths项目下,手动解决这些冲突(git mergetool会调用图形化的合并工具),然后再暂存提交这些修改,提交后合并就结束了；</p>
</blockquote>
</li>
</ul>
<h6 id="git_push">git push</h6><ul>
<li>git push origin master:<new_remote_br> #将本地的master分支推送到远程<new_remote_br>分支(可以新建)上去</new_remote_br></new_remote_br></li>
<li>git fetch origin #通过fetch会把服务器上的分支信息同步下来,<br>git merge origin/<new_remote_br> #然后用将远程<new_remote_br>分支的修改合并到本地分支</new_remote_br></new_remote_br></li>
<li>git checkout -b <new_remote_br> origin/<new_remote_br>  #上面同步得到的origin/<new_remote_br>是一个你不能本地修改的远程分支,如果本地需要基于其修改,就必须依据其创建本地分支；同时此时本地的<new_remote_br>是跟踪远程的origin/<new_remote_br>的,可以简略git pull/push不加远程和分支名进行操作；</new_remote_br></new_remote_br></new_remote_br></new_remote_br></new_remote_br></li>
<li>git push origin :<new_remote_br> #删除远程分支</new_remote_br></li>
</ul>
<h6 id="git_rebase_(衍合)">git rebase (衍合)</h6><ul>
<li>git rebase master <fea_branch> #将特新分支<fea_branch>在master分支上衍合一遍<br>git rebase –continue #如果有冲突会停止,此时手动修改,然后git add,再用这个命令继续衍合<br>git checkout master &amp;&amp; git merge <fea_branch> #衍合后两个分支进行快进合并<br>git branch -d <fea_branch> #不包含其它数据了</fea_branch></fea_branch></fea_branch></fea_branch></li>
<li>git cherry-pick 2faf37cd1e57efacd11581ae1ae1175687c53a6c #只挑选某个感兴趣的提交来衍合</li>
<li><blockquote>
<p>(1)针对两个分支,一种操作是merge,还有就是rebase.rebase的原理就是从两个分支的共同祖先开始,让需要衍合的分支<fea_branch>从此处开始依次后续的提交生成相应的补丁,然后在基底分支(master)最后一个提交开始逐个应用上述补丁,在master之后生成一系列新的提交对象,从而<fea_branch>成为了master的直接下游,master进行一次Fast-Forward就可以了.其好处是master可以看到一个清晰的提交历史,仿佛是在一个分支上的连续操作产生的.</fea_branch></fea_branch></p>
</blockquote>
</li>
<li><blockquote>
<p>(2)如果你要跟别人提交补丁,也最好使用衍合,你的补丁在origin/master最新代码上生成补丁,维护者只需要根据你的提交进行一次快进合并就可以了,将冲突等问题由你自己解决了.   </p>
</blockquote>
</li>
<li><blockquote>
<p>(3)注意:你衍合的应该是你未公布的提交,否则别人之前同步了你的修改,然后你再发布衍合的提交,其实是相同的内容做了两次不同的提交,那么别人不断同步你的更新时候,代码仓库就会乱套.    </p>
</blockquote>
</li>
</ul>
<h6 id="git_stash">git stash</h6><ul>
<li>git stash #保存当前的工作状态(包括跟踪被更改的文件和暂存的文件,未被跟踪的修改不会被保存)</li>
<li>git stash list #查看所有被保存的stash</li>
<li>git stash pop/apply #应用暂存数据,默认的情况是所有的更改被应用到跟踪修改状态,如果想让之前暂存的修改仍然在暂存中,添加使用–index参数.</li>
<li>git stash drop #删除对应的暂存</li>
<li>git stash show -p stash@{0} | git apply -R #取消暂存的修改,相当与unapply的效果</li>
<li>git stash branch <br_name> #可以在你stash save时候的提交开始创建一个分支,然后将存储应用之,并删除存储</br_name></li>
</ul>
<h6 id="git修改提交">git修改提交</h6><ul>
<li><p>git rebase -i HEAD~3 #进入选择的编辑窗口</p>
<ul>
<li>需要修改提交注释的改为edit；</li>
<li>可以重排顺序,就修改了提交顺序；</li>
<li>删除某一项,就删除了那个提交本身；</li>
<li>squash合并到前一个提交,如果有多个要合并,接连用squash；</li>
<li>edit还可以拆分某个修改,git reset HEAD^将修改撤出,然后慢慢添加到暂存区慢慢提交；</li>
<li>然后交互用git commit –amend, git rebase –continue逐步完成(与git log反序显示,实际上是从过去某个点慢慢重新提交这个过程)   </li>
</ul>
</li>
<li><blockquote>
<p>(1)注意,这里修改的提交必须是没有同步到远程仓库的提交,否则会给别人带来困扰</p>
</blockquote>
</li>
</ul>
<h6 id="git_bisect">git bisect</h6><ul>
<li>git bisect start #当前HEAD开始<br>git bisect bad  #设置当前HEAD的bad状态<br>git bisect good [tag-name/commit-id…] #设定之前一个正常提交开始</li>
<li>git bisect start HEAD v1.0 #简化了上面的操作,设置二分查找的范围<br>git bisect run test-error-not-zero.sh #脚本测试,正确返回0,错误返回非0</li>
<li>git bisect reset #切记要恢复HEAD值</li>
</ul>
<h6 id="git_submodule">git submodule</h6><ul>
<li>git submodule add <a href="https://github.com/taozhijiang/st_utils.git" target="_blank" rel="external">https://github.com/taozhijiang/st_utils.git</a> st_utils<br>git commit -m “add submodule st_utils”</li>
<li>git clone <a href="https://github.com/taozhijiang/git_test.git" target="_blank" rel="external">https://github.com/taozhijiang/git_test.git</a><br>git submodule init<br>git submodule update</li>
<li>git fetch origin master  #进入子模块的目录,获取子模块的更新<br>git merge origin master  #合并更新<br>git submodule update    #在顶项目中,更新指针</li>
</ul>
<h6 id="git_svn">git svn</h6><ul>
<li>git svn clone svn://gcc.gnu.org/svn/gcc -T trunk -b branches -t tags<br>git svn clone svn://gcc.gnu.org/svn/gcc -s #与上面等价,注意这里的路径,一般svn的项目根目录会有trunk,branches,tags等目录,如果你对整个项目都有权限的时候,才可以这样,如果你只对trunk某个目录有权限,就不能这么做了</li>
<li>git svn clone svn://gcc.gnu.org/svn/gcc/config #没有项目的根权限</li>
<li>git svn dcommit #向服务器推送更新</li>
<li>git svn rebase  #向服务器拉取更新,时时运行他保证本地代码更新的<br>​</li>
</ul>
<h3 id="三、git其它">三、git其它</h3><h6 id="git_alias">git alias</h6><ul>
<li>git config –global alias.co checkout</li>
<li>git config –global alias.st status</li>
<li>git config –global alias.last ‘log -p -1 HEAD’</li>
</ul>
<h6 id="发布自己的GPG(实际是将公钥信息存储在一个tag中)">发布自己的GPG(实际是将公钥信息存储在一个tag中)</h6><ul>
<li>gpg -a –export C0CC5261 | git hash-object -w –stdin<br>git tag -a maintainer-pgp-pub 687224919a16ae0dcc4fb4aace4b2228a59805f1<br>git push –tags<br>git show maintainer-pgp-pub | gpg –import #别人导入你的公钥</li>
</ul>
<h6 id="代码发布">代码发布</h6><ul>
<li>git archive master –prefix=’git_test’ | gzip &gt; <code>git describe master</code>.tar.gz<br>git archive master –prefix=’git_test’ –format=zip &gt; <code>git describe master</code>.zip </li>
</ul>
<h6 id="git配置">git配置</h6><ul>
<li>git config –global credential.helper cache</li>
<li>git config –global user.signingKey C0CC5261</li>
<li>git config –global color.ui true</li>
<li>git config –global core.autocrlf input</li>
</ul>
<h3 id="四、感言">四、感言</h3><p>　　git作为新生一代版本控制工具的代表，各种概念颠覆了传统的版本控制工具，虽然其看似复杂，但是如果能理解并熟练掌握，则可以大大提高开发和项目管理的效率。一般来说，越是历史悠久、传统保守、对代码掌控越严格的公司，其版本控制工具也越保守，使用如IBM Clearcase、Subversion、SVN等等。现在一般公司用Subversion的比较多，可以试着使用git-svn，虽然不如原生的git那么强大，但基本本地的功能都还能用。</p>
<p>本文完!</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://git-scm.com/book/zh/v2" target="_blank" rel="external">Pro Git中文版</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[深度学习的那些有趣案例]]></title>
      <url>https://taozj.org/201603/interesting-cases-of-machine-learning.html</url>
      <content type="html"><![CDATA[<p>　　随着阿尔法狗(AlphaGo)和李世石那场艺人瞩目的人机围棋大赛落下帷幕，人们对于深度学习的热议和探讨也越发的高涨。其实作为深度学习的基础人工神经网络在上个世纪四五十年代就被提出来了，但是受限于当时的计算能力和数据规模，而且神经网络的”黑盒”不具解释性,导致神经网络的相关研究一直不瘟不火的。<br>　　正如当前积累了大量的电子数据的同时，单点计算能力以及大规模分布式集群研究和实现，让大数据的概念被炒的红红火火，似乎现在嘴边不挂个云计算、大数据，都不好意思跟别的搞IT的说话。内行看门道，外行看热闹，大家可以说可以聊，但不必过于的神话这些概念，就像是我之前听的一个讲座上说的，这些搞云计算和大数据的，其实都是给我们数据挖掘和数据分析提供工具和服务的，如果你是一个在互联网行业的淘金者，那么云计算和大数据就是先进的铲子、筛子这类工具，而对应的互联网公司无谓就是卖或者租这些工具的，甚至有一些为我们扮演者端茶倒水的角色。数据挖掘、分析等核心技术和思路并没有因为大数据和云计算的概念产生很大的变化。<br>　　现今深度学习已经取得了较大的突破，一方面表现为Google Brain、Google驾驶、百度语音Deep Speach等一系列振奋人心的深度学习成果展现出来，传统的语音、图像等机器学习的领域被深度学习一个个攻破；另一方面各家各类的诸如Caffe、Theano、Torch、MXNet等深度学习框架展现出了百花齐放的态势，深度学习作为当今机器学习的热点，给人一种大有可为的景象。</p>
<p>　　首先，为当今深度学习的四大金刚（大牛）致敬，正是他们的存在，使得深度学习不仅在理论上不断的被完善和突破，而且更是把深度学习推向了图像、语音、文字等实用领域，附带着一波波小牛混文凭水文章，一批批专家骗科研混经费。请接受吾等草根屁民一拜。<br><img src="/post_images/images/201603/39dcceecc18348e4907a6e0158061c0e.jpg" alt="深度学习的四大金刚"><br>　　(Yann LeCun，Geoffrey Hinton, Yoshua Bengio, Andrew Ng)<br><a id="more"></a><br>　　之前看过了解过一些深度学习的知识(在NLP上面的使用可以参看拙作<a href="https://github.com/taozhijiang/chinese_nlp/tree/master/DL_python" target="_blank" rel="external">DL_python</a>)，所以针对深度网络在此说个两句，然后面对各个大型公司的深度成果，你没有那么多的训练数据，更没有那么大的计算能力，所以对我们个体户没啥意义，倒是有一些框架和应用可以在我们PC(如果Nvidia显卡支持CUDA,也可以使用独立显卡)上跑，个人可以复现修改，因此这些案例本人摘录下来以飨读者。<br>　　深度神经网络按照原理和结构可以分为两类：CNN(卷积神经网络)和RNN(循环神经网络)，前者一般有固定的输入纬度，各个平行的神经元之间没有直接的联系，其侧重于输入的空间关系，常用于图像这类信息的处理；后者在相邻的神经元之间会有直接的联系，在每个神经元中会有一个控制开关，用于平衡上一个时间序列神经元的输入和当前序列输入对当前神经元输入的权重比例，由于强调的是时间序列，相当于之前序列（历史记忆）会影响到当前神经元，因此对于自然语言这类信息的处理十分的合适。RNN根据神经元内部的设计不同，有可以分为：LSTM、GRU等，大致来说,GRU出现的晚一些,其内部结构稍微简洁一些,且训练收敛的速度比较快,需要的训练数据比较少,而LSTM最终效果会好些。其实在神经网络中,网络深度、神经元个数、训练集合的大小都会影响到最终神经网络的效果,在此两种神经元类型的差异性在一定程度上就不足为道了。同时,我个人感觉后面的文章,都侧重于设计单个神经元的结构,有着让他更加符合生物神经元的原理,包括ReLu等激活函数的设计,以期待更接近生物神经元会得到更好的学习效果。</p>
<h1 id="1-画风合成">1.画风合成</h1><p>　　利用图像让深度网络学习图像对应的画风和色调，在训练过程中各个神经元调整好了参数，然后再使用一幅画作为输入，深度网络就会用这幅画的内容加上之前训练的画风和色调，生成一副新的图像(图片和内容来自于<a href="https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/" target="_blank" rel="external">这里</a>) :<br><img src="/post_images/images/201603/e0f3479779c72c9c35c79df976d71dbd.jpg" alt="梵高式的小猫"><br>　　上面是MXNet的一个案例，当然其图像也不仅限于梵高的《繁星点点》，在原作者文章的案例中还包括透纳的《运输船遇难》， 爱德华·蒙克的《尖叫》，毕加索的《Femme Nue Assise》等(请原谅我借机文艺了一把)，<a href="http://www.boredpanda.com/computer-deep-learning-algorithm-painting-masters/" target="_blank" rel="external">效果</a> 都很和谐唯美。<br>　　如果你不想手动操作,这儿有个现成的<a href="https://deepart.io/" target="_blank" rel="external">网站</a>可以试试看!</p>
<h1 id="2-机器作诗">2.机器作诗</h1><p>　　国内的BosonNLP算是在中文处理方面做的十分深入的一家了，去年上线了一款<a href="http://poem.bosonnlp.com/" target="_blank" rel="external">古体诗生成机器人</a>，发布者说是<a href="https://www.v2ex.com/t/250903" target="_blank" rel="external">使用深度学习的技术</a> ，框架是Theano+Keras，估计是运用LSTM或者GRU对五万首古体唐诗进行训练产生的，较好的生成结果加上古色古香的字体背景，广大V2er的评价还是相当高的。<br><img src="/post_images/images/201603/6169437374145c02aa05b318a4535c30.png" alt="机器作诗"></p>
<h1 id="3-自动文本生成">3.自动文本生成</h1><p>　　上面算是一个本土的文本生成了，国外的研究就更加激动人心了。在<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a> 中，算是对RNN文本生成做的惟妙惟肖了：其不仅可以模仿Paul Graham、Shakespeare写作，甚至还能模仿生成Latex、C语言等结构化的文本。真是逆天了，难道是要革命解放码农的节奏么!!!（代码风格还不错，还知道些注释哈）<br><img src="/post_images/images/201603/c3da17a6367596ec4cd79e7256e8527e.png" alt="机器人码代码"></p>
<h1 id="4-深度学习的图像内容描述">4.深度学习的图像内容描述</h1><p>　　按照作者的<a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" target="_blank" rel="external">综述</a>，其原理就是：通过大量的图像以及图像的文本描述作为训练数据,用CNN网络训练图像部分，然后用双向RNN训练描述文本，然后通过一种方式将两种模型进行对齐，就形成了图像和文本的一种特殊关联。此后再有新的图像输入，就可以用这个模型来生成新的文本描述了。作者的例子图像的描述都是比较贴切的。<br><img src="/post_images/images/201603/5ab3c822022cbbc1cbf4367feb72ada4.png" alt="机器人码代码"></p>
<p>　　就先写到这里了，后面有遇到新的好玩的再整理加进来吧!</p>
<p><strong>更新(20160330)：</strong><br>　　之前发的那个网站，直到现在都没发给我结果，不想花钱的话想必是要排很长很长的队了，不知道要等到猴年马月去了。于是自己用<a href="https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/" target="_blank" rel="external">MXNet的案例</a>，自己在电脑上跑了一个！<br>　　这个库需要下载一个几十兆的VGG模型，算是用的人家的现成的了，然后GeForce 840M 2G显存的显卡报错说内存不足，我也是醉了，果真穷鬼不要玩深度学习~~然后用的CPU计算的，50次迭代大概要十几分钟，这些图来之不易啊。<br>　　原图：<br><img src="/post_images/images/201603/c5925c22c86158757e07e38a40468440.png" alt="原图"></p>
<p>　　不同迭代次数下的效果图（可见迭代次数越多，感觉内容图像的影响就越强，抽象感觉越弱）：<br><img src="/post_images/images/201603/ca7b7a4bb26c7d64f772984f4623abc2.png" alt="迭代次数"></p>
<p>　　不同风格下的效果图：<br><img src="/post_images/images/201603/3d54db5794ff6bd5ce686432ca7fc819.png" alt="不同风格"></p>
<p><strong>更新（20160412）：</strong><br>DeepArt.io的照片其实还是给我了，只是淹没在了邮件中。感觉效果不错啊！<br><img src="/post_images/images/201604/bdf450acdb85914ea55dcceeb97d4bc5.jpg" alt="深度狗"></p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">The Unreasonable Effectiveness of Recurrent Neural Networks</a>   </li>
<li><a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="external">Recurrent Neural Networks Tutorial(1,2,3,4)</a>   </li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="external">Understanding LSTM Networks</a></li>
<li><a href="http://jiwonkim.org/awesome-rnn/" target="_blank" rel="external">Awesome Recurrent Neural Networks</a></li>
<li><a href="http://cs.stanford.edu/people/karpathy/deepimagesent/" target="_blank" rel="external">Deep Visual-Semantic Alignments for Generating Image Descriptions</a> </li>
<li><a href="https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/" target="_blank" rel="external">Deep learning for hackers with MXnet (2): Neural art</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[我的养狗笔记]]></title>
      <url>https://taozj.org/201603/how-to-love-dog.html</url>
      <content type="html"><![CDATA[<p>　　上一篇算是把仔仔的成长历程大概说了一下，也涉及到一些养狗的知识，这一篇就做一个统一的整理和说明，方便自己今后查阅，也方便没有经验的朋友做个参考吧。</p>
<h1 id="一、养狗之前">一、养狗之前</h1><p>　　在把狗狗领回来之前，这里的因素你都要考虑清楚，不然到时候转让或者送养，对财力物力的损失事小，还会对狗狗幼小的心灵产生伤害，对己对狗都是一种不负责任的态度。仔仔有个兄弟叫天虎，开始被预订了，结果四个月了那人不要了，后来一个女孩领回去带了几天，说房东不让养又送回去了，类似这样来来回回五六次，最后八个多月了还在卖狗人家里。虽然狗家对他很好，但在他成长时候这样反复的换主人，是一件多么残忍的事情啊。<br>　　对于深圳租房客来说，房东让不让养是个必要条件，我们还算幸运的，房东只要房租不少她的，基本不干涉我们的生活，但是私自养狗被房东扫地出门的情况是大有案例的。<br>　　虽说人和狗都有穷养富养，你的狗狗可能不需要王可可那样戴苹果表、爱马仕，但必要开销还是少不了的，幼犬的钱在他一生的花费中算是微不足道的。例如：狗狗第一年三针疫苗三百多；每三个月一次体内体外驱虫，每次需要一百多；每个月狗粮好点的四百多，一般的也需要三百左右；成年后每年一次疫苗一百多，两次驱虫三百左右。以上是必须消费，你自己饿着也要出的，平时如果要出门，或者过年回家，寄养一天八十；两周一次澡，如果要别人洗一次70～120；磨牙棒零食你不会不买吧，玩具少买也不可能一个都没有吧。<br>　　或许你是壕，或许钱的问题跟大多数人说的一样，钱的问题都不是问题，那么请准备好，养狗是需要大量的精力的，养他不像是街上的狗狗你看着可爱摸一下就好的，或者在自己空虚无助抑或感情泛滥时候想起了他，而平时可以像玩具一样摆着不闻不问的。否则在狗狗十二年的生命中，除非刮风下雨，否则每早半小时拉屎撒尿，每晚至少一小时的遛狗时间少不了。而且狗狗的生物钟特别准，意味着你可能从此与懒觉无缘了。<br>　　养狗还需要耐心与毅力。不要被网络上的图片视频蒙骗了，即使大家所公认的“大暖男”金毛也不一定狗狗都会成为天使，哈士奇这些就自求多福吧，而且金毛变天使之前还有两年的恶魔期哦。这两年狗的嘴之贱至无敌，啥东西都要咬，基本要报废一两套沙发，各个台子凳子都给你啃成圆角的，领回去的快递比你还高兴，拆个稀巴烂…所以你们高档家具或者房东的好家具，请做好心理准备。仔仔算是比较好的，很快就会定点定时排便了，如果你的狗狗学的迟的话，天天给他捡屎拖地吧。当他不听话甚至闯祸的时候，是对主人最考验的时候，你没法直接告诉他什么是对的，什么是错的，一切都需要你耐心的引导才行，你把他揍个半死也无济于事。<br><a id="more"></a></p>
<h1 id="二、幼犬的选择与培养">二、幼犬的选择与培养</h1><p>　　当你处理好第一条，那才可以继续下面的，切记切记要三思啊。<br>　　狗狗一般按照体型分大型犬、中型犬和小型犬之分，各人爱好品味不同，不做评价，但各个城市有份烈性犬名单，名单中的狗狗不要养，因为出了事基本都理亏，不让你养你养还不是你的责。同时为了狗狗的终生大事考虑，最好选当地流行的犬种，大家的经验积累较多，配种也方便。金毛、拉布拉多、哈士奇、边牧、阿拉斯加、苏牧、喜乐蒂、泰迪、博美都是养的很多的，尤以金毛更为流行，都快被养的烂大街了。<br>　　幼犬的来源有街头贩子、宠物店、犬舍、个人饲养为主，幼犬选择以健康为首要，品格次之。如果个人饲养不要血统，以个人家庭繁殖的狗狗健康可靠，价格实惠首推之，其他渠道鱼龙混杂很容易买到病狗。买家庭狗狗一般可以在当地的宠物群潜伏一段时间，看时间长的成员发自己家狗狗的动态，是比较可靠的，可以联系他们，而58赶集这类网上说自己送养的，99%是假的，他们的套路是：把你的地址是一个宠物店的地址，说自己有事托管在宠物店的，然后宠物店说是送狗，但给你开单收寄养费啥的，而那狗一般都是串串或者病狗，切勿上当！<br>　　狗狗的毛发和皮肤一定要护理好。日常要给他梳理毛发，不仅狗狗看起来比较整洁，而且刺激皮肤会让毛发长的更旺盛。平时可以给狗狗多吃点鸡蛋黄（据说蛋白不好消化，蛋黄的磷脂对毛发很有好处），鸡蛋五块钱一斤，已经算是白菜价了，当然土豪也可以买专业的美毛粉。多晒太阳也是有好处的，特别在阳光下金毛的毛发闪闪发光，甚是好看！<br>　　狗狗的关节是大型犬生长发育中需要特别关注的。这在前面<a href="201603/one-year-old-of-my-zaizai.html">仔仔快要一岁啦</a> 也介绍了，主要就是：小时候不要上下楼梯，不要过于剧烈的运动，搞好伙食适当补钙晒太阳，吃一些葡萄糖胺软骨素之类的保健品。其实身边人养的金毛或多或少在小时候骨骼都有些小问题，仔仔后面两条腿走路外拐过，前面左腿跛了一个月才好，主人按照上面做好就不必过于担心，实在要放心可以让医生一百多块钱拍个片子看看。</p>
<h1 id="三、免疫与常见疾病处理">三、免疫与常见疾病处理</h1><p>　　狗狗的免疫前面也说过了。幼犬45天之后开始第一针疫苗，然后隔19天打第二、第三针，药品推荐卫佳，以卫佳五、五、八为好。这些疫苗最好在医院打，因为需要冷藏保存运输，医院条件较好。狂犬在深圳是免费的，一般在最后一次疫苗一起打。在狗狗打完疫苗之前，不能洗澡，也不能外出。<br>　　狗狗需要定期驱虫，包括体内和体外驱虫，体内用【拜宠清】，每15公斤一片，体外用【福来恩】，都是大家用的口碑比较好的药。拜宠清各个渠道价格差距很大，假货泛滥，建议正归渠道（比如e宠商城）购买，一般少于20块钱一颗的质量堪忧！一岁之前每3个月进行一次，一岁之后每半年一次，驱虫的时候狗狗抵抗力较弱，在此前后两三天不要洗澡。<br>　　人有旦夕祸福，狗狗正常饲养也可能产生这样那样的问题哦。<br>　　在饲养狗狗的过程中，很容易发生各种皮肤病，最常见的就是湿疹。除了上文说的要维持良好的生活环境之外，万一得了湿疹，就需要用药。第一次宠物医院开的是【Candioli 犬用皮康灵乳膏】，用棉签抹在患处，后面觉得用【舒肤】还是可以的，喷雾的使用起来也很方便。用药的时候，需要给狗狗带伊丽萨白头套，不然狗狗会去舔他，让湿疹更难愈合。这个头套还蛮喜感的，他没事爱咬着玩，他咬的话我就给他戴上去。<br><img src="/post_images/images/201603/7bb56a31e76249086a40992047b58fa7.jpg" alt="伊丽萨白狗"><br>　　一次让仔仔吃骨头，结果第二天便血，把我们吓惨了。问卖家原因，应该是骨头把肠胃给划破了，这是需要做的是：给狗狗断食两天，只给少量的水，减少肠胃蠕动从而减轻继发性的损伤，然后服用【庆大霉素】（此药物附作用巨大，不宜多用），给肠道杀菌防止炎症，过个几天排便正常了就可以了。同时有时候正常饲喂的狗狗也会拉稀，可以适当吃一两颗，维持肠道菌落均衡。<br>　　狗狗总是挠痒痒，在正常体外驱虫外，可以买一点外用杀菌止痒药物，比如【犬打】，在狗狗痒的地方和他睡的地方喷喷，会稍微缓解一些。<br>　　扒开狗狗的耳朵，如果有很多黑色或者灰色的烂泥样的，可能还伴随着一些异味，那可能是感染了耳螨了，可以用【法国维克耳漂】，效果比较的好。而且用完之后，耳朵还有一股淡淡的清香味道。<br>　　狗狗吃的东西比较杂，最好还需要给狗狗进行口腔护理。我买的是牙刷牙膏套装，牙膏是牛肉味可以吃的，所以狗狗不抵刷牙（但因为想吃牙膏，也不老实配合，需要用手把嘴巴固定住）。常常刷牙可以保持口气清新，而且牙齿白白的会更漂亮惹人喜欢哦！</p>
<h1 id="四、狗狗训练">四、狗狗训练</h1><p>　　狗狗是需要训练的，人家说不训练的狗恶习很多，在别人面前会显得很没有教养，而且还可能给你的生活添乱和闯祸哦。狗狗的训练一方面需要时间和耐心，当然一些技巧和窍门会让你事半功倍，而且狗狗是小时候比较好教，学习能力强，一些坏习惯也还没有养成。仔仔可能我们小时候没有注重，导致他现在的自我性格很强，不太喜欢粘主人，平时除了喂食和零食挑逗，主动和主人交流有限。<br>　　在此，推荐的一本教材是《狗狗心事》，从狗狗的狼的群居心态来理解狗狗的行为，处理好主人和狗狗的关系，狗狗的很多不听话其实是与狗狗的交流方式不当，也没有处理好在家庭这个群居环境中，主人要作为首领，狗狗要作为普通成员的这个角色关系。视频推荐<a href="http://www.jlpcn.net/vodhtml/121.html" target="_blank" rel="external">《狗语者》</a>，是国家地理的纪录片，共有一百多集，每一集都会解决困扰各个狗狗主人的问题，也很有启发意义。虽然仔仔对于坐下、握手、击掌、看食、趴下、装死都会，但很多都出于食物或者玩具的直接刺激，而且扑人、静坐、随行、唤回都有问题，我们也在学习研究，希望能把他的坏毛病慢慢改掉。</p>
<p>　　最后，说一下大金毛。金毛个性温顺，头脑聪明（主要是耍小聪明啦），除了现在大了会其他大狗会有领地意识之外，对待比自己弱小的伙伴十分有爱心，是一个跟很多人和动物都玩的来的“大暖男”！那些以为金毛体型大而害怕的人，可以借机接触了解一下，而新闻上报道金毛咬人事件的，更是被广大狗民嗤之以鼻。<br><img src="/post_images/images/201603/4e8d9591f40a403287ca7eebf798893e.jpg" alt="大暖男"><br>　　藉此，也希望每一个爱狗人士，都能和自己最忠实的伙伴快乐成长！<br><img src="/post_images/images/201603/3a57177e7320bfbd5bcba0d4ceab0692.jpg" alt="碉堡的仔仔"></p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[我们仔仔快要一岁啦]]></title>
      <url>https://taozj.org/201603/one-year-old-of-my-zaizai.html</url>
      <content type="html"><![CDATA[<p>　　仔仔是4月1日生日，就是下个月就一岁了。虽然和她家里以前都养过狗，但说句实话都没这么上心的养。正如所有的事情一样，快乐总伴随着辛苦，成长总伴随着痛楚，这其中的幸酸苦辣也只有养过的人才能体会到。当你带着他在外的时候，有的人可能躲你远远的，有的人莫名其妙的给你冒出个贱狗，没事干，费钱之类的，当然也有人或是由衷的赞美你的狗狗好乖好听话，或者敷衍一下你的狗狗养的真不错。对于一个把狗养成年的人来说，这都不是事儿，因为能坚持把狗养下来的人，必定是那种意志力无比坚定的人。能有狗狗陪伴成长是一件美好的事情，但这是有巨大的时间、物力和精力付出的。社会上有很多狗狗的美图，狗狗忠于主人感人事迹，狗狗陪伴家人的温馨画面，甚至伴随着神犬小七的热印出现了拉布拉多幼犬价格水涨船高的现象，但是我们在的狗群朋友圈常年都有幼犬因为工作、怀孕等原因转让甚至免费赠送的情况，不排除有特殊情况或者变故，但不少人都是脑门一热买了一只狗，当有伴随着热度的下降和各种养犬问题的暴露，最终放弃他们。负责任的爸爸妈妈或许还会为孩纸找一个好的归宿，而有些直接遗弃狗狗。所以我写这篇文章的目的，一来是看着仔仔慢慢长大，把以前的点点滴滴记录下来，也是传播一下真正狗奴的生活写照，展现每一个狗狗主人背后的付出！<br>　　仔仔的生日是2015年4月1日，所以他的出生就是个笑话。说他太爷是加拿大引进的，不过这也无从考究，总共兄弟姐妹五公三母，排行也不知道了，不过他几个弟兄都长得像他妈妈圆圆，这也就解释了为啥他从小到大长着个男儿身却有着女儿的面容和媚眼。那天下午选他的时候只有三兄弟了，一抱出来后三个全跑出来解我的鞋带。之前网上攻略说要腿粗的，毛量多的，鼻子湿的，耳朵刚好盖住前眼的，挑了半天其实都差不多，最后选了个颜色浅的（关键是兄弟三个都长的丑，个个都是猴子脸）。狗长大的颜色和耳朵的颜色差不多，虽然审美各有所爱，但感觉大多数人还是喜好偏色浅的。然后说说价钱吧，狗家口很紧，这货2200拿下的，平常遛狗交流，这货价格算中上层了，不过也没后悔，确实比那些千吧块钱的狗长的好，其实在十几年的狗生中，这点钱根本排不上位，所以如果喜欢，幼犬贵一点也无所谓。他们家算是专门繁殖狗的，自己打了两针疫苗，给了我们疫苗本，同事送了一包羊奶粉（狗狗对牛奶消化不好，所以幼犬要补充营养，就喂羊奶）。<br>　　去的时候是坐的地铁和公交倒腾的，回来的时候是狗家帮忙找的当地的面包车送回来的。这狗车上直吐白沫，看的心疼啊，三十多公里的路程，估计把他折腾的够呛，到家停车后，这家伙哇哇啦吐了人家一车的。我们估计回来这家伙要缓个两天才精神，没想到回来一会儿，这家伙就家里活动起来到处闻来着了，我们也是醉了。然后他麻麻在家里看着他，我就去超市买狗粮了，偌大个人人乐只有宝路的，而且后来我发现超市一般只卖宝路的，就提了一袋回来，顺便买了袋钙棒和球给他。<br><img src="/post_images/images/201603/53887f5e3b270ce340388fe08f165022.jpg" alt="带回来的仔仔"><a id="more"></a><br>　　第二天是星期天，基本就网上给他买生活必需品了。幼犬需要打三针疫苗，主要是为了预防犬瘟和细小病毒，常用的是英威特和卫佳，但普遍反映后者较好。在打完疫苗之前，幼犬是禁止出门，禁止和其他狗狗接触的，因为幼犬的细小和犬瘟死亡率高，即使治好了花费也昂贵，对狗狗今后的生长发育也会有影响，为了对狗狗负责，一定不能带狗狗出门，同时也不能洗澡！最迫切的是给他买了个围栏，有的人买笼子，其实我个人推荐围栏，主要笼子会让狗狗有压抑感，空间也有限，围栏让狗狗自由些，可以在顶部跟狗狗互动，而且如果家够大的话，可以围很大空间。<br>　　周末一过，就不得不遇到现实的问题了——上班，这家伙得一个人在家了。当时笼子还没到，我就想了个办法，把家里冰箱的盒子翻倒下来，剪一个面把他围在里面。三个月的他已经十多斤了，力气也很大，于是四周用沙发和凳子加固，结果晚上回来：他没憋住尿，箱子一块湿了；箱子一个角被咬了一个洞。<br><img src="/post_images/images/201603/3db54e2c341a9cc3ffe9dee548eefb5b.jpg" alt="箱子中的仔仔"><br>　　这儿还有个插曲，回来我们怎么喊他，怎么叫他都没反应，他自己也不叫不发声音，我们还以为他是聋子哑巴，以为买到个歪狗。关于定点排便，在家里尿了几次，然后骂了几下，看他行为异常（通常在饭后）就把他带到厕所去，过一会儿他就尿了，几次之后他就会自己去厕所尿尿了，这点确实该赞他一个。关于他的名字，本来我想叫他布拉德皮特，希望他也壮壮帅帅的，结果他妈觉得又臭又长，叫他仔仔。我也不知道仔仔怎么来的…同时，我上班近，除了早上晚上各喂他一顿外，中午我还回来喂他吃一顿。那段日子中午12:20下班，然后我十多分钟赶回来，在路上把饭吃了，12：50到家吧，喂它一顿，然后让他在走廊活动一下拉个屎，1：10我在沙发眯个20分钟，然后去公司接着上班。那段时间除了周末都没好好睡过午觉，一直持续两个月后才停止，确实好幸苦。<br>　　回来过不到十天，按照计划给他打最后一针了，算是我们带他第一次出门吧。那是他胆子还是多小的，不怎么愿意走，算是边走，我边抱着吧。在最近的一家康德医院，只有英威特的，那个女院长也建议最开始的三针打一个牌子的，于是就联系了一个稍远的医院，打了个卫佳八——145块大洋！同时也打了个狂犬疫苗，深圳这点做的挺好的，疫苗免费，医院收10块钱的注册费，拿了个免疫本。这个本子还是很有用的，无论后面办狗证还是有啥纠纷，都会对你有所帮助。同时还买了体内驱虫拜宠清和体外驱虫福来恩。那一次花了四百多大洋。<br>　　回来后就盼着，一周后洗澡，两周后遛狗，一来住的屋子小，不是很透气，所以这货味道比较臭，二来很期盼和他分享外边世界的样子。终于，引来的这个周末，带着他去宠物医院洗了个澡，医院的美容师让我们呆在外边，说狗狗看见我们会不太配合他们洗澡，好奇之心还是让我们透过玻璃去看看他第一次洗澡，而且是陌生人的情况下是怎么样的——那是个像是人用的大浴缸，那一小坨放进去都没了，偶尔伸出个布满泡泡的头出来，接着就是抱到一个工作台上，那家伙熟悉地给他用吹水机吹水，剪指甲啥的，大概半个小时吧，这家伙一切搞定了。大概是70块钱吧，出来闻着香蓬蓬，迎着四点多灿烂而又不热烈的太阳，仔仔和我们心情都棒棒的。又过了一周，算是打完疫苗两周了，照理说可以遛了，我吧，算是那种保守小心派，因为网上说狗狗免疫系统有差异，可能会因为狗狗身体或者环境因素免疫失败，于是又带着这货去检查了犬瘟细小两项抗体——180块，免疫是成功的，180送给狗了…<br>　　盼了许久终于盼到这一天了，西丽366大街算是附近狗民的根据地，晚上九点到十点作为遛狗黄金时间的传统由来已久了。我想我们养仔仔，除了我们喜欢狗之外，跟平常接触了这些大量的狗狗也有关系吧（当然只看到狗狗的可爱，当初也没料想养一只狗狗会有这么多的事情）。这家伙如果小时候遛狗的一个字概括，那就是——懒，真的是懒的出了名的：平时带他去遛狗地点，大概两千米左右，这家伙走走停停的，赖在那儿不动，有时候用食物引他走，有时候急了就抱他走一段；到了目的地吧，别的大狗小狗都你追我赶，你打我闹的，这家伙就玩一会儿，然后就趴着或者躺着休息了，我们之后也接触了好多小金毛，都是玩的生龙活虎的，但就是不知道当初他为啥那么不爱动，不过大概八九个月的时候，这家伙就突然转变了，每天似乎精力旺盛的要死，我们反而又觉得嫌弃他闹腾了。<br>　　如果说犬瘟细小是每个狗爸狗妈小时候担惊受怕的事情，那么诸如阿拉斯加、金毛、拉布拉多、德牧这类大型犬成长阶段的骨骼和关节问题，也是让各个狗爸狗妈操碎心的事情，缘由就是这些大型犬的生长速度非常快，一岁不到就接近他们成年时候的体型了，而健康的生长涉及到骨骼，肌肉，关节之间的协调，情况比较复杂。<br>　　骨骼问题涉及到的是补钙问题，这个问题算是有争议的问题吧，有的人说要补，有的人说只要吃的可以的狗粮就不用补，但是对于狗狗来说，如果钙质不够，就会造成骨骼变形，前腿变软，后腿外八，而且一旦成年之后很难矫正，但是如果补钙过量，会导致骨头过早的钙化，影响狗狗长个子，甚至也跟CHD有关，所以如果你有钱而且也想放心的话，建议去医院检查血钙含量和骨密度以决定是否补钙。对于我的个人经历就是，小时候尽量给他吃好一些的狗粮，比如我用的冠能大型犬幼犬犬粮，虽然贵一些，但是对于快速生长发育的狗狗来说，可以补充较为全面的营养；同时对于钙的话，会适量的补一些，我之前用的卫仕乳钙片，别人反应效果一般，我也觉得没啥效果，后面换MAG超能钙鲨鱼软骨粉，这个除了补钙外，对关节和软骨也有很好的保健作用，而量的话，我一般是按照说明的一半来用的，因为仔仔没有表现出明显的缺钙症状。如果狗狗明显缺钙的话，据说液体钙的效果非常的明显，但是普通狗狗慎重使用哈。同时，每天早上七点之前就会把他带下来，让他活动活动并晒个十多二十分钟的太阳，晒太阳对狗狗补钙是最天然最有效的。<br>　　狗狗关节的问题，主要以CHD（髋关节发育不良症）为代表，这种病绝大部分是遗传的，但是平常喂养也需要注意。平常需要控制狗狗的饮食和体重，过重的体型会对关节造成巨大的压力；然后不要盲目过量的补钙（原理可能比较深奥，说不清楚）；再则控制狗狗的活动量，狗狗还小的时候，不要让他过于剧烈的奔跑，否则对关节的磨损会比较的大；最后，小时候千万不要让狗狗上下楼梯，对狗狗的伤害比较大，这也是卖家走的时候反复叮嘱的。我们住在五楼，没有电梯，所以每次都是早上抱下来遛他，完了之后抱上去上班，晚上抱下来和大家遛狗，再抱回去睡觉。随着这家伙长的越来越大越来越重，抱起来也吃力啊，到后面遛完了回来，这家伙直接在楼梯口下面等着我抱他下去，也是坚持了他六个月大左右吧，果断让他自己上下楼梯了，不然他的坏习惯越来越深，而我的手臂也要被抱残了。总体来说，仔仔现在一岁了，架子长起来的，骨头和关节也没有什么明显的缺陷，算是可以松下一口气了，也希望看见的孩子还在成长的狗爸狗妈们能重视起来这个问题。<br>　　当然狗狗也会闯祸。家里的家具基本都留下了他的狗牙签名了，他能接触到的没有一件是完好无损的，而且身边的狗友都是这么个反应。这些问题都是自己的内部问题，基本都不算什么事情，无非扔两件破家具，但是一旦涉及到外边的人，尤其那些不喜欢狗的人，问题就来了，这家伙这么大来，问题多多：</p>
<ul>
<li>最早的时候，是房东打电话，说附近的邻居和清洁的阿姨投诉了，说你们狗狗撒的尿太臭了。唉，其实狗狗已经主动到厕所尿尿，已经很乖了。后来我们就每次狗狗上完测试，就用水把厕所冲一下要好些。</li>
<li>有天早上，带他下来散步，狗绳松了，而正巧前面花坛做了一个老太太在等人，这家伙一下上去把那老太太扑倒了。吓得我连忙跑过去把狗牵来撂倒，当着人家的面把他揍了一顿骂了一通，给那个老太太连忙鞠躬道谦。那老太太叽叽咕咕把我骂了一通，当地的粤语一句没听懂，不过没有找我麻烦，算是万幸了。</li>
<li>还有一次早上在小区中间，我看没什么人就把他放了，然后一个老太晾衣服，手里拿着一个晾衣架和一双袜子，我没太在意，狗慢慢的就走过去了，然后伸着头凑上去闻了一下她的裤子。然后那老太就来劲了，粤语普通话交替得给我骂，怕我听不懂似的。那个年代得人，多会骂人，骂的多难听，我想接触过的人都会有所感觉的。最后她的骂话还上升到地域和阶级斗争了。后来想想也是滑稽，狗就闻了她一下就要跟我这么闹，要是狗扑了她一下，是不是要搞的我倾家荡产啊。总结来说，后面遇到老头老太，还有带小孩的，能离他们多远离开多远，不是说这帮老人都是坏人，但这帮老人绝大多数都是惹不起的人，不跟他们接触为妙。（当然也有和善开明的，在遛狗的地方就有个老头主动带着他的小孩跟我们狗狗玩，我们都劝他带小孩远点，他说没事，这狗温顺，出了啥事也不怨你们。给我的印象很深刻。其实有点常识的人都知道，不是烈性犬的大狗，脾气都比小狗温顺很多的，大狗的真正威胁在于：喜欢你可能把你扑倒，或者玩耍的时候无意把你撞倒 ;) ）</li>
<li>还有一个就是最近发生的。我们住的地方房子比较的旧，楼上楼下的隔音效果很差，这家伙现在70斤左右的，在屋里不说剧烈活动，就是走快点下面都会有动静。这件事情把大家闹的都不愉快，后面我们家里买了垫子铺了一层，为了缓冲这家伙的冲劲，同时也不让仔仔在家大手大脚的耍了，该做的我们也只能这样了。希望出现这种情况的时候，双方都能平静下来，好好协商这种事情该如何的解决。<br><img src="/post_images/images/201603/3521796bfb3109cda1d00048a9355476.jpg" alt="家里减震垫子"><br>　　基本就写这么多吧。养一只狗狗就跟养一个小孩一样，你得负责他吃的喝的、拉屎排尿、洗澡梳毛，保证他健康不生病、开心而不忧郁，带他外出散心，给他买零食玩具，接触认识其他的同伴，跟别人交流养育心得体会，鼓励他什么该做，教训他什么不该做，还得给他闯下的祸担当负责搽屁股……<br>　　养了狗狗，给我们带来的快乐是显而易见的，因为狗狗的世界是单纯、充满活力的。当我们下班回家的时候，他主动叼这个玩具坐在那儿欢迎你归来，每天乐此不疲地欢迎着凯旋归来的骑士；当你偷偷的削个苹果苹果，或者开袋零食的时候，他都会机灵的跑到你的身边，也不会跟你说话也不会跟你抢，口水哗哗地往下流就看你主人怎么办吧；当在散步的时候，听到不明狗叫或者看到比自己凶悍的同类时候，就会躲在你身后，双腿抱着你寻求你的庇护；当他认真的抓蝴蝶、捕苍蝇或者干着其他事情的时候，在某个时间点你们进行了眼神的对视，当你忍俊不禁的笑出来的时候，他就会扑过来感觉自己被嘲弄了似的；当你拿着一块吃的逗他的时候，一只黑黑的大鼻子就伸过来不停的挑逗你，此时的眼神像放电一样的亮……<br><img src="/post_images/images/201603/a268e6022f2242e4eb5fc2db42b236a5.jpg" alt="节操啊节操"><br>　　狗狗也会淘气，也会犯错。当你气急败坏的把他乱骂一通，甚至用皮带狗链把他乱抽一通的话，他不会朝着你吼，不会对着你叫，只会端坐在你的面前，用那副可怜兮兮的小眼神偷瞄你，即使你知道他下次还会再犯，你也忍不住会把他搂在怀里，告诉他下次别在这样了，毕竟他三个月就离开了父母，他只有你唯一的亲人，他长的再大，内心也还是一个年少无知的孩子。有时候你也会想到，自己即使在外面上班再辛苦，但是还是可以和自己朋友联系联系，或者跟身边的同事打打岔的，但是对于他，只能每天早上半个多小时，每天晚上一个多小时能看看外边的世界，在外边太阳灿烂的时候，只能在家里那一米见方的笼子里面默默地等待着主人归来，不禁悲从心来。有时候你很累，工作或者生活很窝火，算了就在家里休息吧，他要不就用无辜的小眼神看着你，要不就趴在窗台默默地看着窗外，此时的你忍心再将他关在家里么——走，儿子，出去耍！！<br><img src="/post_images/images/201603/e2d77cb9cceebcad041729ab1629de05.jpg" alt="我要出去耍"><br>　　幸幸苦苦的走了快一年了，养一只宠物狗确实比较的辛苦，耗费了我们大量的时间和精力。如果你现在再问我，当初再给你一个选择，你还会不会领养仔仔？呵呵，其实我也不知道怎么回答~~<br><img src="/post_images/images/201603/c582b57f67f9fa90885b4ffe2c990a90.jpg" alt="我们开心的一家子"><br>　　在此，还需要感谢366大街的狗友们，谢谢在这份喧闹忙碌的城市里，还有我们这一份淳朴的友情，很难预测没有你们的支持和鼓励，我们和仔仔是否还如同现在这般快乐。即使最终难免分别，愿友谊长存！<br><img src="/post_images/images/201603/591f99d65867dccf29a5c823f6e75061.jpg" alt="群体性遛狗事件"></li>
</ul>
<p>　　更多仔仔的照片，请浏览<a href="https://album.taozj.org/#/places/" target="_blank" rel="external">仔仔的相册</a>页面。</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[面对越来越多的信息我们是怎么了]]></title>
      <url>https://taozj.org/201603/how-to-survive-from-info-ocean.html</url>
      <content type="html"><![CDATA[<p>　　主要是前两天把今日头条给删除了，顿时感觉生活清净了很多。以前在外拿着手机，心中有一种焦虑感和不知所措感，不断的在今日头条/扣扣/微信/什么值得买这些软件之间切换，而平常坐车坐地铁的生活，也看见很多年轻人拿着手机，频繁重复着解锁-维信-朋友圈-锁屏的操作。就像当初看过一部乔布斯的记录片中说到的：乔布斯用手机改变了人类的生活，手机使我们跨越了地域的限制，把我们联系的越来越紧密，也让人与人之间越来越冷漠，越来越孤独。（为此，还有人专门为iPhone开发了APP，强制自己在某一段时间内不去触碰手机！）<br>　　还有就是前段时间Amazon Kindle公布了年度图书销售报告，大数据告诉我们两点信息：（1）在偏远的地区，人们花在阅读上的时间比一线二线城市要多;（2）付费的图书，阅读完成率比免费图书阅读完成率要高的多。<br>　　所以，总结起来说：在人越是多越是喧闹的城市，人表现的明显的焦虑浮躁；如果获得某些信息的代价越低，就越不会被珍惜和重视。针对前者，当然因素很多，比如大城市比较喧闹，生活和工作压力大，节奏太快等，不是单一几个因素所能决定的，倒是对于后者，这个社会产生的信息越来越多，而且获取信息的成本也越来越廉价（甚至免费），而人性天生又比较贪婪，面对这种情况，显得有些不知所措。<a id="more"></a><br>　　曾记得当我小的时候，从亲戚家拿回了两本漫画书，一个是跟猪八戒有关的，一个是跟阿拉丁神灯相关的。这两本书算是我记忆中接触最早的课外书了，当时真是爱不释手，爸妈在田地干活，我就带着这书趴在田埂边看，翻过一遍又一遍，白看不厌。上小学的时候，就爱看动画片，每次放学都是急匆匆的赶回家开电视，那时候自己个头小，够不着电视的开关，就把厨下面的抽屉打开一半，踏着抽屉开电视，累打不动的一天20分钟的动画片，甚是满足。读中学就寄宿学校了，当时随身听十分盛行（当然打着听英语的幌子），同学买了新磁带，总要排着借过来听个几天的，而平时课余最喜欢读的，就是《读者》、《意林》之类的了。上大学之后，虽然有了电脑和手机，但那时候还和同学写过一段时间的书信，那时候流量很少，平常聊短信很多，一个月几百条的短信都数着用，聊QQ的话还事先发短信告诉对方自己什么时候上线，办完事后就电脑候着（当然是大学早期，04/05年左右），平常的娱乐内容就是一天两条手机报。再到后面就跟现在接近了，扣扣24小时挂着，没事就宅到电脑边（其实我还算好的，很多人围着电脑玩游戏、看黄片、海量聊Q，而我是尽情折腾Linux）。<br>　　没经历过啥惊天动地的事情，短短几句话就把自己十几年的光阴概括完了，但是却能感受到这十几年信息变化给我们带来的巨大影响，以至于我们的上一辈对此都难以接受：孩子回家天天抱着个手机；每天面对着电脑忙的手脚冰冷，也不知道有啥好忙的；难得放个假回家，都是忙手机，跟我们也没啥话好说的……<br>　　好了，回忆时光到此打住，然后给自己做一个测试：打开电脑，除了挂QQ、挂微信之外，打开浏览器，然后知道自己干什么不？如果不知道，那么你就是选择恐惧症，因为你不知道自己要干嘛了。电脑可以做的东西很多，但是你却漫无目的，就像是你在一个步行街上，满街的小吃大排档，你却不知道要吃啥要进哪一家，所以你越来越习惯于问别人吃什么，或者习惯于让公司统一订餐，或者爱吃“随便”，就是自己选择太多了。信息也是一样的，网上的门户网站越来越多，而人的精力和时间是有限的，于是，各种手机“头条”APP应运而生，你不是不知道自己看啥么，那我给你推送好了，而且根据数据挖掘，我还会凭着你的喜好推送，于是就造就了越来越多的低头族了。就像当初一个朋友说的一样，现在的人，普遍都是懒——不想动脑子，所以出去要问别人吃啥，出游要问人路线、问人玩啥，现在连娱乐也要别人给你推荐啥。QQ、微信也是一样，以前在学校，每晚还有卧谈，要不讨论明星八卦了，要不讨论班里的哪个哪个了，现在要不就是陌生群里听别人的黄段子，要不就是一大堆基佬讨论装系统啥的。关键，这是个毒品，会让你欲罢不能。如果你拿着个手机，不看点啥，就还会觉得空虚不踏实，越就范就越强化了这种感觉。<br>　　扬扬洒洒的写了这么多，其实无谓就是想说，大家在这个信息泛滥的社会中，不要让信息迷失了自己。要知道自己想要什么，不需要什么，有鉴别力。为此，自己这么做了(有的做到了，有的还在努力)：   </p>
<ul>
<li>让手机卸载微信、QQ不显示，但是要少用。一些有毒的软件建议删除：今日头条、什么值得买、网易新闻，和谐过的新闻没啥好看的，国内当地重要新闻百度都会在首页给你推送，或者每天下班或者午休话20分钟浏览一下网页版就行了。   </li>
<li>IT专业性的消息，建议使用订阅类的，可以去<a href="http://blogtrottr.com/" target="_blank" rel="external">blogtrottr</a>，这样会把信息聚合发给你的邮箱。如上文所列，建议不要太多，少而精，消化足就好了。(个人推荐伯乐在线、月光博客、Solidot等)   </li>
<li>手机安装邮件客户端，没事的时候看上面订阅邮件，比较有营养，同时喜马拉雅听书软件也不错，在看书不方便的时候（比如遛狗散步啥的）可以用耳朵；   </li>
<li>手机尽量放在离自己远一点的地方，然后用智能手环或者智能手表的推送功能，此时应当把手机作为你的敌人对待！   </li>
<li>如果有kindle可以看看电子书，遇到好书看看豆瓣书评论，花点钱买也可以，如上所说的，当你花了钱的话，增加了信息的成本，你就会认真对待，自然收获更大，当然买纸质书更佳，有收藏价值。   </li>
<li>平时多写点东西。IT者的博客不限于软件推荐，系统安装啥的，自己的生活和心灵所感也做些记录，一方面增加你组织表达的能力，二来也作为和别人交流共同的另外一种渠道。   </li>
<li>花点时间研究下科学上网，看看Twitter新闻，让你眼光不再狭隘，知道这个真实的社会和世界。   </li>
</ul>
<p>　　最后告诫大家，千万要记住：人之大忌就是不爱动脑子——脑子越用越灵活，越懒越痴呆。   </p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[请善用GPG安全你的邮件和文件]]></title>
      <url>https://taozj.org/201603/encrypt-safe-your-file-and-email-gpg.html</url>
      <content type="html"><![CDATA[<p>　　虽说在伟大的天朝，互联网无隐私——很多互联网公司有着强大的控制欲和窥探欲（PC软件没事就把你硬盘扫描的吱吱作响，手机一个最简单的软件都要检查一下软件列表，或者拷贝一下通讯录等），要么公司安全意识淡薄（密码不加密不加盐，没防火墙各种端口打开等），同时很多公司又无底线的将这些信息在网上兜售贩卖，ZF以国家安全为由立法强制软件和互联网公司提供后门和协助解密……<br><img src="/post_images/images/201603/335d8df84dc574b3193048d966c98bdb.png" alt="GPG"><br>　　针对这些问题，我们普通庶民还是要提高警觉的，不是说在互联网上支付转账的时候才涉及到网络隐私和安全，互联网的安全无处不在，你的信息任何时候都可能会被滥用于诈骗、恶意推送等，如果你看过一些社会工程学的东西，哪怕泄露最不起眼的一点信息有时候也会让你毛骨悚然。   </p>
<p>　　当然，我们平常在Cyber Life的时候，适当的注意和加强防护意识，还是可以将这些风险大大降低的，比如：   </p>
<ul>
<li>尽量使用开源操作系统和开源软件，比如Linux和FreeBSD，以及各类开源的替代软件。这些系统和软件由于是开源的，所以受到全世界用户的监督，而且不以任何一个国家和政府所牵制。这同时也向大家暗示着：闭源的系统和软件的好用，也是有安全方面的代价的。   </li>
<li>对于没有开源实现的软件，就将这些软件放到虚拟机中隔离起来，比如企鹅和阿里类的软件。   </li>
<li>各种账户和密码即使使用相同的邮箱注册，也不要使用相同的密码，防止某一家泄露造成撞库的危险。推荐<a href="201508/keepass-pass-save.html">个人密码管理器KeePass</a>   </li>
<li>对于网络服务，如果是重要的数据，尽量选择国外的大公司的产品，比如Gmail，Dropbox等。（访问不了的话想办法访问）   </li>
<li>对于重要的数据和邮件，请签名和加密。<a id="more"></a>
最后一点，是本文想介绍的。即使国内的邮箱提供商表述的，邮件在传输过程中是加密的，用户密码也是加密的，内部员工也不可逆的，但即使是这样，你在输入框中输入的是实实在在的账户和密码，谁知道后台会不会记录或者其它猫腻呢。小心使得万年船。</li>
</ul>
<p>　　GPG是GNU实现的一个十分流行的加密解密工具，可以用于文件的加密和签名。其具体的设置和使用在阮一峰的<a href="http://www.ruanyifeng.com/blog/2013/07/gpg.html" target="_blank" rel="external">GPG入门教程</a>中描述很清楚了，这里就不再啰嗦了(另外GPG中还可以添加个人头像哦！)。这里只是想简单的解释一下:   </p>
<ul>
<li>每一份key的产生有公钥和私钥两部分，任何一个数据如果用公钥加密，只能有对应的私钥解密;如果用私钥加密，只能对应的公钥解密。   </li>
<li>公钥是发布到网上的，任何人都可以下载的，私钥是你个人保存的。   </li>
<li>如果你将文件用自己的私钥加密，那么这个文件任何人都可以用你公布的公钥解密，这个过程就是数字签名和验证。   </li>
<li>如果别人用你公布的公钥加密一个文件发送给你，那只有你用自己的私钥解密这个文件，这个过程就是加密和解密。   </li>
</ul>
<p>　　在邮件中，如果你想告诉别人你发的邮件确实是你本人所为，别人接受到的邮件跟你发送的内容是一致的（没有被篡改），那么你需要对你的邮件进行数字签名。如果你发送的内容（或者附件）是不想被别人看见的，那么你需要将该内容用接受邮件的人的公钥进行加密，那么只有真正的接受者才能解密得知邮件的真正内容。   </p>
<p>　　流行的邮件客户端Thunderbird中默认就安装了Enigmail插件，只需要简单的设置，就可以用ThunderBird发送签名和加密邮件了。网络也有很多教程，此处也不详述，系统（本人Gentoo）设置需要注意以下一些内容：   </p>
<ul>
<li><p>很多系统默认使用gnome-keyring-common接管密码输入，而Enigmail明确表示不支持gnome-keyring，所以需要删除(或者转移)/etc/xdg/autostart/gnome-keyring-gpg.desktop，同时在$HOME/.gnupg/gpg-agent.conf中添加如下内容：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pinentry-program /usr/bin/pinentry-gtk-2</div></pre></td></tr></table></figure>
</li>
<li><p>你的passphase可以被缓存一段时间，不用每次都输入，这时候需要使用gpg-agent，请在$HOME/.xprofile添加：   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">eval</span> $(gpg-agent --daemon) &amp;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>然后你就可以用Thunderbird安全的和别人通信啦！<br>发送界面：<br><img src="/post_images/images/201603/359709fe2624a9055f2f999dd4da4856.png" alt="发送界面"></p>
<p>　　接收结果：<br><img src="/post_images/images/201603/65bc46ef02b663008976d316a3667d4b.png" alt="接收结果"></p>
<p>　　最后，我还想说个插曲：<br>　　当时在TP工作的时候，国外安全机构发现了我司路由器的一个漏洞，然后发邮件给我司技术支持的同事，问漏洞的内容是否需要加密传输还是直接传输，结果我司同事回复说直接发过来吧。<br>　　要知道，在安全领域发现漏洞的时候，是最先向厂商报告，等一段时间或者厂商修复后，才可以对外公布的。所以当时这封邮件如果被其他人发现或者截获，后果将不可设想（虽然这种情况的概率比较低）。但这也显现了技术支持的不专业！   </p>
<p>　　如果是macOS的工作环境，想要安装这个建议直接使用brew install gnupg2，因为gnupg2的工作依赖其他部分组件，而这一点homebrew直接帮你做好了。<br>　　再次公布我的GPG指纹：   </p>
<blockquote>
<p>((( A251 3E22 BE65 E709 B1DD  5BE5 D2D3 FB76 C0CC 5261 )))</p>
</blockquote>
<h1 id="参考">参考</h1><ul>
<li><a href="http://www.ruanyifeng.com/blog/2013/07/gpg.html" target="_blank" rel="external">GPG入门教程</a>   </li>
<li><a href="http://irtfweb.ifa.hawaii.edu/~lockhart/gpg/gpg-cs.html" target="_blank" rel="external">Quick’n easy gpg cheatsheet</a></li>
<li><a href="https://ssd.eff.org/en/module/how-use-pgp-mac-os-x" target="_blank" rel="external">How to: Use PGP for Mac OS X</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[我的博客用上HTTPS啦]]></title>
      <url>https://taozj.org/201603/blog-site-under-https.html</url>
      <content type="html"><![CDATA[<p>　　Hexo（或者其它静态网页生成框架）+GitHub一直被认为是博客神器，原因就是，很多IT Geek都有自己的个人博客网站，而且绝大多数的博主都有这几个博客迁移过程：   </p>
<ul>
<li>寻找国内或者国外的免费空间，用提供商的免费三级域名，但是免费也是有条件的：要不不允许绑定自定义域名、要不需要在网站显眼的地方贴出商家广告、要不每个月访问量或者更新量不足就会被关闭。   </li>
<li>然后感觉限制太多了，就用起来付费的空间写。商家把LAMP环境给你弄的妥妥的。   </li>
<li>然后你玩的多了，发现空间价格贵、限制多，自己没折腾的不好玩，于是自己入手一个VPS，从头搞自己的博客系统。   </li>
<li>然后，你可能不小心丢过几次数据，可能各种原因在各家VPS供应商迁移来迁移去，或者被定期备份事情烦扰着……</li>
<li>最终，你就想着要是别人把这些运维、备份等都给做好，我自己只关心写文章，而且最好是免费的，该多好啊！   </li>
</ul>
<p>　　基本上面的路我都走过，我相信很多人也有同样的经历。其实，很多事都有类似的过程，基本都是刚开始从懵懂，再到激情满满，再到最后变懒不想折腾。个人感觉这是成长的过程吧，刚开始什么都想折腾，最后感觉精力有限，把这些繁琐无聊的事情“外包”出去，让自己专心于自己喜欢的或者核心的事情，岂不快哉！<br><a id="more"></a></p>
<p>　　GitHub Pages其实最初是用来托管项目的主页或者项目的文档用的，所以当初就有人在论坛上提问<a href="https://www.zhihu.com/question/20717014" target="_blank" rel="external">在GitHub上搭建个人博客是否道德？</a>，下面也提到了：</p>
<blockquote>
<p>Create a blog and spread your ideas. Whatever you want!  </p>
</blockquote>
<p>　　所以开源世界是很宽容的，即使你的博客会占用他们的空间和带宽，但是只要你能分享你的东西，都可以免费使用GitHub服务，而分享的形式不限与代码哦。</p>
<h1 id="GitHub搭建博客的优点:">GitHub搭建博客的优点:</h1><ul>
<li>GitHub帮忙运营，稳定性有保证。   </li>
<li>当初GitHub被封后，然后在程序员的抗议之下被解封，所以“中国特色稳定性”安全系数较高！   </li>
<li>继承Git的特色，本地保存了完整的repo内容，可以方便部署到任意一台服务端。   </li>
<li>MarkDown语法，简单整洁，即使本地渲染，效果也很好。   </li>
<li>一次配置设置之后，就可以一劳永逸的写文章了，可以愉快的玩耍啦！   </li>
</ul>
<h1 id="GitHub搭建博客的缺点:…">GitHub搭建博客的缺点:…</h1><ul>
<li>由于是静态的，所以相比WordPress功能不够强大，所以有些内容（比如社交评论）需要第三方插件。   </li>
<li>可以绑定自定义域名(包括顶级域名和二级域名)，但是不支持HTTPS加密传输。   </li>
<li>目前用的Hexo插件还不是很多，如果对框架不熟悉，修改会很费劲。博客发布前需要生成静态页面，比较麻烦。   </li>
<li>由于传输是非加密的，所以会被防火墙审查，国内访问速度偏慢。   </li>
<li>由于非加密的，而且不是独立站点，所以搜索引擎排名会很差。   </li>
</ul>
<p>　　当然，这次主要是针对后面两个缺点考虑的。所以在自己的VPS上面，搭建了一个Nginx做反向代理，就可以用HTTPS加密传输了:   </p>
<ul>
<li>将域名freesign.net指向VPS的IP地址;   </li>
<li>删除仓库的CNAME文件，此时只能用taozhijiang.github.io来访问;   </li>
<li>在Nginx添加主机，设置反向代理到GitHub Pages地址;   </li>
</ul>
<p>　　这样，就可以用freesign.net域名来访问博客了。HTTPS加密是没有问题，Google排名可能过一段时间才能看到效果。   </p>
<p>　　后续的玩点还很多，比如手头有几个阿里云的肉机，可以也在上面开代理，然后DNS用智能DNS解析，就实现了CDN的效果，不过站点太小，懒得折腾了。   </p>
<p>　　最后附上一个可用的Nginx服务器配置：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">server &#123;</div><div class="line">        listen 80 default_server;</div><div class="line">        server_name freesign.net;</div><div class="line">        access_<span class="built_in">log</span> /var/<span class="built_in">log</span>/nginx/freesign.access_<span class="built_in">log</span>;</div><div class="line">        error_<span class="built_in">log</span> /var/<span class="built_in">log</span>/nginx/freesign.error_<span class="built_in">log</span>;</div><div class="line">        <span class="built_in">return</span> 301 https://freesign.net;</div><div class="line">&#125;</div><div class="line"></div><div class="line">server &#123;</div><div class="line">        listen 443 default_server;</div><div class="line">        server_name freesign.net;</div><div class="line">        ssl on;</div><div class="line">        ssl_certificate /etc/ssl/1_freesign.net_bundle.crt;</div><div class="line">        ssl_certificate_key /etc/ssl/2_freesign.net.key;</div><div class="line">        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;</div><div class="line">        ssl_ciphers AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:RC4:HIGH:!MD5:!aNULL:!EDH;</div><div class="line">        ssl_prefer_server_ciphers on;</div><div class="line"></div><div class="line">        ssl_session_cache shared:SSL:10m;</div><div class="line">        ssl_session_timeout 10m;</div><div class="line"></div><div class="line">        add_header Strict-Transport-Security max-age=31536000;</div><div class="line">        add_header X-Frame-Options DENY;</div><div class="line"></div><div class="line">        access_<span class="built_in">log</span> /var/<span class="built_in">log</span>/nginx/freesign_ssl.access_<span class="built_in">log</span>;</div><div class="line">        error_<span class="built_in">log</span> /var/<span class="built_in">log</span>/nginx/freesign_ssl.error_<span class="built_in">log</span>;</div><div class="line"></div><div class="line">        client_max_body_size 4m;</div><div class="line"></div><div class="line">        location / &#123;</div><div class="line">                proxy_pass              http://taozhijiang.github.io;</div><div class="line">                proxy_redirect          default;</div><div class="line">                proxy_buffering         off;</div><div class="line">                <span class="comment">#proxy_set_header        Host                    $host;</span></div><div class="line">                proxy_<span class="built_in">set</span>_header        X-Real-IP               <span class="variable">$remote_addr</span>;</div><div class="line">                proxy_<span class="built_in">set</span>_header        X-Forwarded-For         <span class="variable">$proxy_add_x_forwarded_for</span>;</div><div class="line">                proxy_<span class="built_in">set</span>_header        X-Forwarded-Protocol    <span class="variable">$scheme</span>;</div><div class="line">                proxy_pass_header Set-Cookie;</div><div class="line">        &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>　　<strong>2016年03月11日更新</strong>: 个人的<a href="https://srv.freesign.net" target="_blank" rel="external">相册</a>上线啦！挑了很多，发现这个ImageVue效果不错，而且不用挂数据库，备份和迁移都比较的方便，但是为商业软件，授权费用大概40刀，等我财务自由了，一定支持一下。<br>　　PS:这个域名确实比较的挫，但是新建一个域名需要重新颁发证书，比较的麻烦，就凑合着用吧。   </p>
<p>　　<strong>2016-04-04更新</strong>：个人的网站已经关闭了VPS反向代理，所以博客的访问域名为<a href="https://taozj.org">https://taozj.org</a>，个人相册的访问域名为<a href="https://album.taozj.org" target="_blank" rel="external">https://album.taozj.org</a>。<br>　　其中的缘由，直接是因为博文要写数学公式，而mathjax在nginx反向代理后无法解析，但是直接访问原网站却是正常的，所以就觉得把这层代理给关掉了。然后，我的相册也从VPS上面撤下来了，目前放在RedHat Cloud的openShift上面的，也是本地更新，然后用git推送到服务器上面的，同时关于RedHat，我记得在我上大学的时候是不能访问的，但是别人一说现在突然能访问了，估计是数据中心迁移到Amazon的原因吧。<br>　　目前自己的博客、相册、网盘这类东西，都是去中心化的产品，即使远程服务器无法访问，本地也有一份完整的备份。目前看来，互联网服务的最大风险不在于Service Provider的运营水准，而在于因为违反相关法律规定而无法访问。无言～～～<br>　　此外，如果之前访问过小站而再次访问自动跳转到https协议的话，可以打开chrome的chrome://net-internals/#hsts，然后把freesign.net条目清除就可以了。</p>
<p>　　<strong>2016年12月8日更新</strong>：Wosign和其马甲StartSSL的免费证书已经被主流的Chrome和Firefox拉黑了，现在使用的是腾讯云签发的免费赛门铁克单域名证书(虽然七牛、阿里云也提供免费赛门铁克证书申请，但是不提供证书下载，差评)。今后HTTPS必定成为主流，还有一些不可明说的秘密，以及HTTP内容在传输过程中被劫持篡改等因素，建议大家在web server上面开启HSTS机制，让之前已经访问过的浏览器之后能够自动强制进行https访问。不过一旦开启之后你的网站必须一直支持https访问，撤销这个机制是一件非常麻烦的事情。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">// nginx</div><div class="line">add_header Strict-Transport-Security <span class="string">"max-age=2592000; includeSubDomains; preload"</span> always;</div><div class="line">// apache</div><div class="line">Header always <span class="built_in">set</span> Strict-Transport-Security <span class="string">"max-age=10886400; includeSubdomains; preload"</span></div></pre></td></tr></table></figure></p>
<p>本文完！   </p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[NumPy科学计算库学习记录]]></title>
      <url>https://taozj.org/201602/learn-note-of-numpy.html</url>
      <content type="html"><![CDATA[<p>　　Python语言最为流行的科学计算库。主要是在数学计算的时候，使用矩阵的方式可以加速纯粹循环方式计算的速度。而SciPy则是建立在Numpy上的一个库，增加了数值分析、统计等一些函数算法。</p>
<h1 id="一、Numpy基础">一、Numpy基础</h1><p>数组对象(由实际的数据和描述这些数据的元数据组成)   </p>
<ul>
<li><p>产生向量:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.arange(<span class="number">12</span>)</div></pre></td></tr></table></figure>
</li>
<li><p>向量加法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = <span class="number">3</span>; <span class="comment"># broadcast</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>d = numpy,arange(<span class="number">12</span>) ** <span class="number">2</span> <span class="comment"># 指数</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>c = a + b; e = a + d;</div></pre></td></tr></table></figure>
</li>
<li><p>多维数组: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>m = numpy.array([ numpy.arange(<span class="number">3</span>), numpy.arange(<span class="number">3</span>) ** <span class="number">2</span>])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>m.shape  <span class="comment"># (2, 3)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>m[<span class="number">1</span>,<span class="number">2</span>]   <span class="comment"># 4</span></div></pre></td></tr></table></figure>
</li>
<li><p>Numpy支持的数据类型<br>bool(True/False) inti int8 int16 int32 int64 uint8 uint16 uint32 uint64 float16 float32 float complex64 complex</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.arange(<span class="number">3</span>, dtype=float)</div></pre></td></tr></table></figure>
</li>
<li><p>自定义数据类型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>t = numpy.dtype([(<span class="string">'name'</span>, numpy.str, <span class="number">20</span>),(<span class="string">'age'</span>, numpy.int32),(<span class="string">'height'</span>, numpy.float)])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>t</div><div class="line">    dtype([(<span class="string">'name'</span>, <span class="string">'&lt;U20'</span>), (<span class="string">'age'</span>, <span class="string">'&lt;i4'</span>), (<span class="string">'height'</span>, <span class="string">'&lt;f8'</span>)]) </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>items = numpy.array([(<span class="string">'taozhijiang'</span>,<span class="number">29</span>, <span class="number">168</span>),(<span class="string">'YAO'</span>, <span class="number">28</span>, <span class="number">158.999</span>)])</div></pre></td></tr></table></figure>
</li>
<li><p>数组的切片（同Python本身类似）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.arange(<span class="number">9</span>) <span class="comment"># array([0, 1, 2, 3, 4, 5, 6, 7, 8])</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a[:<span class="number">7</span>:<span class="number">2</span>] <span class="comment"># array([0, 2, 4, 6])</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a[::<span class="number">-2</span>] <span class="comment"># array([8, 6, 4, 2, 0])  #反向序列</span></div></pre></td></tr></table></figure>
</li>
<li><p>多维数组的切片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = numpy.arange(<span class="number">24</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)  </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">0</span>,<span class="number">2</span>,<span class="number">2</span>] <span class="comment"># 10</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">1</span>,<span class="number">1</span>,:] <span class="comment"># array([16, 17, 18, 19])</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b[<span class="number">1</span>,<span class="number">1</span>,::<span class="number">2</span>] <span class="comment"># array([16, 18])</span></div></pre></td></tr></table></figure>
</li>
<li><p>修改数组的维度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = numpy.arange(<span class="number">24</span>).reshape(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b.ravel() <span class="comment"># 展开一维数组</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b.flatten() <span class="comment"># 同上面，只是上面得到的是原来数据的View，而下面会重新分配内存存储数据。例如你在View中修改某一个数据，那么b本身也会被修改掉。</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b.transpose() <span class="comment"># 矩阵的转置</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b.resize(<span class="number">3</span>,<span class="number">8</span>) <span class="comment"># reshape函数返回一个新数组，但原数组本身不变；resize在返回一个新数组的同时也改变原数组本身。</span></div></pre></td></tr></table></figure>
</li>
<li><p>组合数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.hstack((a,b)) <span class="comment"># 矩阵的水平组合</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.concatenate((a,b), axis=<span class="number">1</span>) <span class="comment"># 效果同上</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.vstack((a,b)) <span class="comment"># 垂直组合</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.concatenate((a,b), axis=<span class="number">0</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.dstack((a,b)) <span class="comment"># 深度组合</span></div></pre></td></tr></table></figure>
</li>
<li><p>分割数组</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.arange(<span class="number">9</span>).reshape(<span class="number">3</span>,<span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.hsplit(a, <span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.split(a, <span class="number">3</span>, axis=<span class="number">1</span>) <span class="comment"># 垂直分割</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.vsplit(a, <span class="number">3</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.split(a, <span class="number">3</span>, axis=<span class="number">0</span>) <span class="comment"># 水平分割</span></div></pre></td></tr></table></figure>
</li>
<li><p>数组的其它属性</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.ndim <span class="comment"># 维度 2</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.size <span class="comment"># 数据个数 9</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.T <span class="comment"># 转置</span></div></pre></td></tr></table></figure>
</li>
<li><p>类型转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.astype(float)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.tolist() <span class="comment"># 转换成列表类型</span></div></pre></td></tr></table></figure>
</li>
</ul>
<a id="more"></a>
<h1 id="二、Numpy函数">二、Numpy函数</h1><ul>
<li><p>保存和加载数据(常用类型 CSV Comma-Separated Value)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.savetxt(<span class="string">"a.txt"</span>, a)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = numpy.loadtxt(<span class="string">'a.txt'</span>).astype(int64)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>c,v = numpy.loadtxt(<span class="string">'data.csv'</span>, delimiter=<span class="string">','</span>, usecols=(<span class="number">6</span>,<span class="number">7</span>), unpack=<span class="keyword">True</span>) <span class="comment"># unpack用于拆分数据到c,v</span></div></pre></td></tr></table></figure>
</li>
<li><p>各种常用计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>vwap = numpy.average(c, weights=v) <span class="comment"># 成交量加权的平均价格</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.average(c) <span class="comment"># 没有加权，同numpy.mean(c)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.ptp(c) <span class="comment"># 等同于numpy.max(c) - numpy.min(c)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.median(c) <span class="comment"># 中值，如果数目为偶数，那么就是中间相邻两个数的均值</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>sorted_close = numpy.msort(c) <span class="comment"># 排序</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.var(c) <span class="comment"># 方差，等同于计算numpy.mean((c-numpy.mean(c))**2)</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>numpy.diff(c) <span class="comment"># 后面一个减掉前面一个，结果会比c少一个元素</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>returns = numpy.diff(numpy.log(c))</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>post = numpy.where(returns &gt;&gt;&gt; <span class="number">0</span>) <span class="comment"># 获取正收益的下标</span></div><div class="line">(array([ <span class="number">0</span>,  <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">5</span>,  <span class="number">6</span>,  <span class="number">7</span>,  <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">25</span>, <span class="number">28</span>]),)</div></pre></td></tr></table></figure>
</li>
<li><p>加载日期(Python本身支持的)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>datetime.datetime.strptime(a,<span class="string">'%d-%m-%Y'</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>datetime.datetime.strptime(a,<span class="string">'%d-%m-%Y'</span>).date()</div></pre></td></tr></table></figure>
</li>
<li><p>numpy.apply_along_axis 提供函数，然后作用与每一个数组元素上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">my_func</span><span class="params">(a)</span>:</span>  <span class="keyword">return</span> (a[<span class="number">0</span>] + a[<span class="number">-1</span>]) * <span class="number">0.5</span> </div><div class="line"><span class="meta">&gt;&gt;&gt; </span>b = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>], [<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.apply_along_axis(my_func, <span class="number">0</span>, b) <span class="comment"># array([ 4.,  5.,  6.]) # axis同垂直或者竖直方向</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>np.apply_along_axis(my_func, <span class="number">1</span>, b) <span class="comment"># array([ 2.,  5.,  8.])</span></div></pre></td></tr></table></figure>
</li>
<li><p>numpy.maximum(x1, x2[, out]) 两个矩阵取最大值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">numpy.maximum(x1, <span class="number">3</span>) <span class="comment"># 也可以Broadcasting</span></div></pre></td></tr></table></figure>
</li>
<li><p>数组的修剪和压缩</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.arange(<span class="number">6</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.clip(<span class="number">2</span>,<span class="number">4</span>) <span class="comment">#设定最大最小值 array([2, 2, 2, 3, 4, 4])</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.compress( (a%<span class="number">2</span>) ) <span class="comment"># 选出满足条件的元素 array([1, 3, 5])</span></div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.arange(<span class="number">1</span>,<span class="number">5</span>)</div><div class="line"><span class="meta">&gt;&gt;&gt; </span>a.prod()  <span class="comment"># 24 所有元素之积</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>(TO BE CONTINUED!)</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[2015年工作总结——离开TP之路]]></title>
      <url>https://taozj.org/201602/leave-tp-link-at-2015.html</url>
      <content type="html"><![CDATA[<p>　　自从15年上半年离职之后，就再也没写过工作总结了，想到现在也快一年的时间了。感觉这么一段时间中，自己经历了许多，思考了许多，当然也收获了许多。吾本身就是个优柔寡断、多愁善感之人，但也常常告诫自己——人向前看才能走的更远。其实在我低落的时候，真的感觉身边陪伴我的伙伴才是我最宝贵的财富，平常跟他们吃饭出游、天天在群里插科打诨，让日子变的充实欢快了许多。当前，就接着这新年刚过，对去年自己的生活中的点点滴滴做一次回顾吧。   </p>
<p>　　去年最大的一件事情，就是离开了工作近两年的大TP。其实TP真的是个大围城：在里面的人觉得，TP公司传统封闭，做下游的制造链而没有核心技术，在互联网兴起的时代毫无前景，公司官僚主意和平均主义盛行，员工懒散毫无斗志；在外的人对TP工作压力小加班少，平时大小节假日对员工关爱有佳，薪水待遇丰厚而垂涎三尺。在TP员工不断的入职和离职算是司空见惯的事情了，而且TP喜欢“名牌学生”，不是985名校出门研发不要，算是TP招人的一个隐形规则（还有个隐形规则就是不招女研究生），而恰恰这些名牌大学的毕业生志存高远（或者心高气傲，差不多就这个意思），TP的工作内容和企业文化很难HOLD住这帮人，所以等于TP帮深圳的其它企业将这部分人才（或者废材）带到了深圳。曾经有个公司跟我戏说TP就是深圳人才的黄埔军校，即便实际上是这么个意思，我也很不喜欢这么个说法，毕竟跟其他的坑货或者不负责任的公司相比，TP做事还是正正规规、有板有眼的，对于我们这类刚出校园又远赴深圳就职的人来说，其强大的人事处和行政部门帮我们把一切考虑的周周道道，清清爽爽的。   </p>
<p>　　在TP内部当然各个部门也是蛮有意思的，公司上层来说是最重视研发处的（比如研发处的工资涨的飞快，而且有配股分红），但是在实际体验来说研发处是公司最苦逼的部门：没有任何权利，前方被产品部折腾，后方被测试部纠缠，产品部立项就是看看市场再加上自己的奇思妙想，然后就是不断的催进度，催、催、催……测试部要不说自己资源紧张跟你扯皮，要不怀疑你的开发水平说着说那的，技术支持更是黑白无常似的缠着你说前线十万火急赶紧拿方案，平常大家喜欢邮件来邮件去的踢皮球，一下不爽了就抄送对方的领导升级成部门间的斗争。这些事情看似奇葩，不过现在细细品来，还是觉得十分有意思的，正如谈恋爱中说的：打打骂骂才是爱，人与人之间最可怕的不是争执，而是无言的冷漠……<br><a id="more"></a><br>　　然后呢，我肯能是算那一类感觉干的不爽的一类吧。正如我之前说的，TP是一个下游的设备制造商，虽说有自己庞大的研发队伍，但实际上产品的核心技术都是来自各大芯片成熟的解决方案（Atheros、Broadcom、Realtek、MTK……），所以自己的研发队伍基本就是根据这些方案做一些外围、外观、界面的定制这类边角料的事情，大多数的事情繁琐而没有技术含量;其次，不能否定TP中没有牛人，但是感觉身边绝大多数人资质平庸，虽然也是各个方面做技术的，但是没有那种给人深不可测的意味（也可能我眼拙或者没遇到吧）；在我们组遇到了干了八年的秋哥，然后我就觉得，或许我在里面这么干八年的话，应该跟现在也没啥区别，虽然平时也在里面研究研究Linux技术、看看代码，但是毕竟工作和兴趣难以统一起来，当自己的所学不能在付诸于产业化的实现时候，你的知识智能永远停留到书本的深度。   </p>
<p>　　虽然在我出来之前，通过朋友啊啥的，也有几个创业公司联系交流过，但是总感觉团队不太靠谱吧，所以一直呆在公司中。后面自己的前组长G sir找到我，聊了些有邀我出来的意思。其实我对行业不是十分的挑，我一直认为自己要是能做一些企业级的应用开发，将会是一件十分Cool的事情，可能是像《浪潮之巅》这类的书看多了吧，而我最崇拜的公司就是Sun，在互联网的浪潮中开发出许多前瞻的让人惊叹的技术（至今开源社区很多软件工具还在山寨模仿），但一个公司技术再强大，没有高瞻远瞩的领导和适宜的管理，终究是不行的；再则G sir为人敦厚可靠，应该不会有负于我，而且在我生病住院的时候带领其他组员来医院看望过我，让我十分感动，也有一种报答的意思在里面。虽然我提出离职后，时任组长J sir对我百般劝导，也给我时间考虑，我回复说：“人的一生总是要做出选择的，虽然现在的待遇十分的满足，但是还是想到外边去看一看，而且在如此悬殊下能走出去的话，将来面对其它的选择也会从容很多，人是要成长的，即使会为此付出代价。”，所以最终还是出来了。话说J sir为人情商很高，很有领导的范，祝愿将来步步高升。   </p>
<p>　　新公司是做智能客服的。刚进来做了一段时间的数据员的工作，就是按照规则和要求做数据整理，完全是体力活动，工作内容繁重而又索然无味，当时还任性着要走，领导给我谈话说先做做这个了解一下系统，以后的工作会慢慢的安排。后面呢，做的事情就比较杂了，在<a href="https://github.com/taozhijiang" target="_blank" rel="external">我的Github</a>显示的，什么NLP处理（分词、情感分析、归类、NER等），深度学习之类的，也在<a href="/201601/conclusion-of-machine-learning.html">机器学习之总结</a>介绍过，而关于换工作创业的感受经验，有机会后面再写一篇吧。   </p>
<p>　　在这里，让我印象最深刻的，就是参加那次王煜全的《趋势大数据》。他提到，现在很多的公司都掌握了很多的数据（不是吗，手机随便装个软件就要访问这扫描那的），但是拿着这些数据不知道怎么分析、利用、产生价值。这些公司就像是现在的外蒙，守着聚宝盆却挣不到钱，外行看大数据概念被炒的越来越热，其实数据分析早就被很多公司分析用于商业决策、广告投送等领域了。自己研究Linux又不能当饭吃，再说研究生的时候看论文搞过一段时间的机器学习和信号处理，所以想立志今后做一个DG（Data Geeker）。   </p>
<p>　　要问我现在后不后悔？呵呵，多少总会有一些吧，现在的待遇让我不折不扣成了个“月光族”了，账面的直接收入少说也少了十万块了，但是本着对自己将来负责的态度，走出TP是早晚的事。经过这么一折腾，让我想了很多，也成长了很多。至于以后怎么走，随缘吧！   </p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[读《淘宝技术这十年》感]]></title>
      <url>https://taozj.org/201602/read-(i-am-in-taobao-these-ten-years).html</url>
      <content type="html"><![CDATA[<p>　　这本书春节放假的时候就在家里读完了，本来想年初写一下感受总结的，但是没有带电脑回去，也就算是搁置了。感觉整本书还是不错的，以淘宝网的萌生和成长、个人在淘宝的工作经历以及淘宝牛人访谈录三个主要部分组成的。书中虽然没有各个技术的具体实现细节，但是将淘宝和自己的成长例程淋漓尽致地展现在了我们面前，淘宝的实力很强，干货还是有的。   </p>
<p>　　先不论马云私有化的非议，以及众人诟病的淘宝假货和侵权商品肆意横流，就如快播王欣所言：“技术本身并不可耻！”，淘宝网和淘宝技术团队的不断成长，对于整个互联网技术发展和进步还是做出了很大的贡献的：为不断应对淘宝用户规模和数据量的快速增长，从最初购买别人一个现成的LAMP网站改版，到现在能每日处理几十亿个PV访问量、PB级别的数据存储与快速访问，自己改进和开发出各项存储、缓存、中间件、分布文件系统等技术，而且很多技术都以<a href="http://code.taobao.org/project/explore/" target="_blank" rel="external">开源</a>、博文、书籍等形式贡献给了社区。<br><a id="more"></a><br>　　作者在淘宝的这十年，自身伴随着淘宝的成长而成长。正如我所总结的：“对于一个刚入职场的毛头小儿，最幸运也最幸福的事情，莫过于在一个技术积淀深厚的公司，在一群积极向上的牛人的陪伴下好好打磨。”作者的成长免不了其自身的天资聪慧和分发努力，也在于一个较为开放自由的工作环境，也在于一群强者牛人的鼎力配合与关照。   </p>
<p>　　淘宝的技术发展，完全是气自身发展的一个必然结果。从起发展的路程来看，他们最初也是采用LAMP经典的架站方案，然后根据自身业务的不断发展，发现自身的系统的压力不断变大，然后逐步引入各种商业化的成熟技术(Oracle数据库，Sun的Java中间件，NAS和SAN的存储，IBM的小型机等),或许在业务腾飞的那几年，“能用钱解决的问题都不是问题”。但是当淘宝不断成长为一个巨无霸的时候，在资金方面商用方案的成本邹然地攀升，在技术方面很多技术都无法满足淘宝的需求了，甚至淘宝的运营压力在商用方案的公司都没有条件测试和验证的时候，淘宝就不得不自己“创造技术”了。   </p>
<p>　　淘宝是幸运的，因为首先他是一家私企，所以在激烈的市场竞争中如果想吃下这块蛋糕，就必须把上面所面对的问题给解决掉，其次淘宝有幸揽得了这些“人中吕布，马中赤兔”，海量数据分布式存储、数据缓存和高速存取等难题。最终，淘宝的团队还大刀阔斧的进行“五彩石”项目，对整个淘宝的系统进行业务拆分，将一些底层的技术通用化，公用的资源模块化，各司其职就可以让上层业务的开发更加的简单、高效，同时底层资源的维护、升级扩容也更加的方便透明。    </p>
<p>　　这里又让我想起了之前看到的一个笑话：   </p>
<blockquote>
<p>2011年末，京东的图书做促销，活动优惠幅度大吸引了大量的访问和购买着，服务器扛不住出现了”Service is too busy”，然后强东微博说已经紧急采购了10台服务器，明天继续促销一天。然后第二天仍然是”Service is too busy”，老板又微博一篇：“请信息部的同事喝茶！”，旁边的配图照片是：一张大桌子，只有一杯茶，旁边放了一把刀……<br>—-摘自《大型网站技术构架：核心原理与案例分析》</p>
</blockquote>
<p>　　当然，这也让我浮想起，如果淘宝的出生再晚些年，当现在云计算和大数据工具变得较为成熟的时候，淘宝的技术成长之路又会是怎样的呢?   </p>
<p>　　对于本文的作者，如我上文所说的，他是很幸运的。从2003年淘宝项目秘密成立，作者2014年淘宝入职，可以说是伴随着淘宝一块成长的。他在淘宝也从最初的小功能小接口开发，到后面负责大项目，做项目经理，软件测试，员工培训等，不知道他是否是实现了我们所说的程序员的完美华丽的转型。作者算是很优秀的程序员了：能开发项目，解决问题，说明了他技术功底扎实，而不是只会被被动调动的“码农”；能做产品经理，和测部交流协作，说明对项目的流程清楚，跨部门的交流功能能力强；开放设置课程，负责淘宝大学，说明跨部门整合调动资源的能力强。那再想想我们身边，多少人不是缺胳膊少腿呢？   </p>
<p>　　还有，这本书给我技术上的启示，一方面正如大家所公认的：“好的架构是进化来的，而不是设计出来的！”，所以虽然网上很多架构的知识，可以让我们少走很多的弯路，但也不必过于迷恋，适合自己的才是最好的；二来让我接触到一线高压力网站常用的进化方案：异步、缓存、消息中间件、分布式，也让自己有了学习和努力的方向。</p>
<p>本文完！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[终极文件系统ZFS的使用与优化技巧]]></title>
      <url>https://taozj.org/201602/usage-and-optimize-of-zfs.html</url>
      <content type="html"><![CDATA[<p>　　ZFS一直都算是一个神器级别的东西，由于Z是字母表中的最后一个字母，所以很多人将其奉为“终极文件系统”，而我本人对ZFS也是情有独钟，从FreeBSD到Gentoo，都是使用ZFS作为根文件系统。作为文件系统的几个要素来说：ZFS的性能算是中规中矩，对内存要求比较高；稳定性来说，最初是Solaris的文件系统，所以经受过工业环境的考验；而最重要的是ZFS支持相当多的功能特性，告诉我们——文件系统居然可以这样玩。<br>　　当然，由于许可证兼容性的问题，导致ZFS不能集成到Linux内核，所以在Linux下必须是模块的形似使用，这就导致每次更新内核，都需要重新编译安装这些模块。反正都是编译，这让Gentoo的用户感觉不到什么区别，哈哈！</p>
<h1 id="一、ZFS的安装和迁移">一、ZFS的安装和迁移</h1><p>　　新系统安装，可以参照<a href="https://github.com/taozhijiang/gentoo_overlay/blob/master/install_gentoo_zfs.txt" target="_blank" rel="external">ZFS文件系统的Gentoo安装</a>，安装和迁移操作系统涉及到的用法罗列在下文。需要注意的是，ZFS的设计颠覆了传统的文件系统，涉及到存储池的概念，具体的原理可以参考ZFS官方手册。</p>
<h2 id="1-1_创建ZFS存储池和文件系统">1.1 创建ZFS存储池和文件系统</h2><p>　　个人的使用经验，觉得为系统以及Gentoo的编译部分开辟两个单独的文件系统比较好：一方面可以根据两个不同的使用场景进行参数的设置和优化;同时编译部分的数据是没有意义的，那么在快照和备份的时候，可以不为这部分文件系统进行操作；在迁移和重装系统的时候，也可以忽略这部分数据。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">zpool create <span class="_">-f</span> -o ashift=12 -o cachefile=/tmp/zpool.cache -O normalization=formD -m none -R /mnt/gentoo zroot /dev/sda3</div><div class="line">zfs create -o mountpoint=none zroot/ROOT</div><div class="line">zfs create -o mountpoint=/ zroot/ROOT/gentoo  <span class="comment">#根文件系统</span></div><div class="line">zfs create -o mountpoint=none zroot/GENTOO</div><div class="line">zfs create -o mountpoint=/usr/portage/distfiles -o atime=off zroot/GENTOO/portage</div><div class="line">zfs create -o mountpoint=/var/tmp/portage -o sync=disabled zroot/GENTOO/build-dir</div></pre></td></tr></table></figure></p>
<h2 id="1-2_导出和导入ZFS存储池">1.2 导出和导入ZFS存储池</h2><p>　　由于文件系统的信息都包含在了存储池中，所以导出和导入存储池和挂载卸载文件系统的效果是相同的。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">zpool <span class="built_in">export</span> <span class="_">-f</span> zroot</div><div class="line">zpool import <span class="_">-f</span> -o cachefile= -R /mnt/gentoo zroot</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="1-3_系统迁移">1.3 系统迁移</h2><p>　　系统迁移我认为是zfs十分厉害的东西，既可以用作备份，也可以用于恢复系统。这里显示的是保存到固定的存储介质上，其实ZFS是可以在线迁移的，也就是两台电脑只要网络可通，可以在线将一个电脑上的存储池迁移到两外一台电脑上面。同时zfs send的对象是snapshot，就是你可以迁移任意一个之前备份的文件系统状态。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#备份：</span></div><div class="line">zfs snapshot -r zroot@go_to_new</div><div class="line">zfs send -Rv zroot@go_to_new | gzip &gt; /mnt/zroot_go_to_new.gz</div><div class="line"><span class="comment">#迁移：</span></div><div class="line">gzcat /mnt/zroot_go_to_new.gz | zfs receive -Fv zroot</div></pre></td></tr></table></figure></p>
<h1 id="二、ZFS的功能和特性">二、ZFS的功能和特性</h1><h2 id="2-1_文件系统清理，检查数据的完整性">2.1 文件系统清理，检查数据的完整性</h2><p>　　建议一段时间对文件系统进行检查，使用scrub命令即可。该命令以低优先级执行，不会对正在运行的系统有明显的影响。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo zpool scrub zroot</div><div class="line">sudo zpool status -v</div></pre></td></tr></table></figure></p>
<p>然后status会不断的显示scan的进度。   </p>
<blockquote>
<p> scan: scrub in progress since Thu Feb 18 13:12:30 2016<br>   47.7G scanned out of 50.2G at 317M/s, 0h0m to go<br>   0 repaired, 95.09% done   </p>
</blockquote>
<p>当完成的时候，会显示下面的状态。   </p>
<blockquote>
<p> scan: scrub repaired 0 in 0h2m with 0 errors on Thu Feb 18 13:15:15 2016   </p>
</blockquote>
<h2 id="2-2_坏掉的目录和文件修复">2.2 坏掉的目录和文件修复</h2><p>　　ZFS 使用校验和、冗余和自我修复数据来最大限度地减少出现数据损坏的风险。如果status出现错误，可以尝试：scrub进行清理；导出然后重新导入存储池；删掉出错的文件。<br>这么看来，ZFS的最初设计已将容错设计到最大话了，如果运行的ZFS真的出错，基本是无能为力了。所以建议：规定时间进行文件系统快照；规定时间把文件系统备份到其他设备上。<br>个人在FreeBSD和Gentoo上用了两三年的ZFS，都没发生过什么大的问题。</p>
<h1 id="三、文件系统的相关优化和设置">三、文件系统的相关优化和设置</h1><h2 id="3-1_关闭atime">3.1 关闭atime</h2><p>　　这对任何的文件系统都是可用的，可以较为显著地优化系统的性能。<br>手册显示</p>
<blockquote>
<p>除了配额和预留空间外，所有可设置的属性都从父文件系统继承各自的值。   </p>
</blockquote>
<p>所以不用递归地为每个文件系统都进行参数的设置。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">sudo zfs <span class="built_in">set</span> atime=off zroot/ROOT/gentoo</div><div class="line">sudo zfs <span class="built_in">set</span> atime=off zroot/GENTOO  <span class="comment">#可被子文件系统继承</span></div><div class="line">sudo zfs get atime zroot/ROOT/gentoo</div><div class="line">NAME               PROPERTY  VALUE  SOURCE</div><div class="line">zroot/ROOT/gentoo  atime     off    <span class="built_in">local</span></div></pre></td></tr></table></figure></p>
<h2 id="3-2_对某些不常用的目录，可以设置压缩降低数据的写入量">3.2 对某些不常用的目录，可以设置压缩降低数据的写入量</h2><p>　　这样虽然消耗一些CPU和内存，但是不常用的话对系统性能没有太大影响，还可以延长SSD的寿命。该参数设置后，只对新数据有效，原有的数据没有影响。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo zfs <span class="built_in">set</span> compression=lz4 zroot/GENTOO/build-dir</div><div class="line">sudo zfs get compression zroot/GENTOO/build-dir </div><div class="line">NAME                    PROPERTY     VALUE     SOURCE</div><div class="line">zroot/GENTOO/build-dir  compression  lz4       <span class="built_in">local</span></div></pre></td></tr></table></figure></p>
<h2 id="3-3_交换分区">3.3 交换分区</h2><p>　　目前ZFS上的交换分区还不太稳定，不建议使用。<br>单独交换分区不要使用discard挂载命令，因为每次在系统启动的时候，系统会自动TRIM它，而如果手动加上该参数，那么每次在删除文件时候都会进行TRIM，降低系统的性能。<br>修改/etc/sysctl.conf文件，添加</p>
<blockquote>
<p>vm.swappiness = 1</p>
</blockquote>
<p>减少交换分区的使用率。</p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://docs.oracle.com/cd/E26926_01/html/E25826/docinfo.html" target="_blank" rel="external">Oracle Solaris 管理：ZFS 文件系统</a>   </li>
<li><a href="http://wiki.illumos.org/display/illumos/LZ4+Compression" target="_blank" rel="external">LZ4 Compression</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Pebble嵌入式开发环境搭建和开发测试样例]]></title>
      <url>https://taozj.org/201602/setup-dev-env-for-pebble-smartphone.html</url>
      <content type="html"><![CDATA[<p>　　随着Apple Watch和Andriod Wear的兴起，智能手表迅速走到了人们眼前，作为kickstarter上成功的众筹项目，说明很多人对这款手表还是抱有很大期望的。他作为独立于iOS和安卓的智能手表的一个独立阵营而存在着，提供了相应的开发接口和开发包，目前线上的表盘和软件已经成千上万款了。<br>　　也不知道是人们对iOS和安卓已经审美疲倦了，或者是对安卓和iOS设备电池续航太过失望，抑或想追求电纸屏幕的那种古典美而选择了他。在我看来，Pebble手表可以为我记步，提醒我定时喝水和起座，震动电话和闹钟提醒，以及为我推送手机的各种通知，或许你可以说这些功能智能手环已经可以做到了，但是Pebble是开放的，而且目前还在积极的开发中，全球的开发者都在这上面发挥着他们的智慧和创新写出新奇的应用程序，任何时候都可能给你带来惊喜。<br>　　在贴吧和论坛，Pebble已经有自己的铁杆粉丝，他们常常自嘲道：不识货的人都说Pebble是山寨苹果的，而且名字pebble也是山寨apple的。俨然，这种自嘲中流露出了一种优越感，是对自己选择的欣喜和肯定。   </p>
<h1 id="一、开发环境的搭建">一、开发环境的搭建</h1><p>　　官方的开发环境有两类：CouldPebble和本地SDK类别的，前者算是一个云端的开发套件，但是他们租用的亚马逊的云服务，在国内的速度和稳定性都感觉一般吧，而且我们也不是什么时候都有网络可用，所以下面介绍的是用后者，在本地搭建一个开发环境，搭配硬件调试也方便快捷。<br>　　环境搭建步骤如下：   </p>
<ul>
<li><p>下载和安装pebble sdk<br>　　首先下载 <a href="https://developer.getpebble.com/sdk/download/" target="_blank" rel="external">pebble-tools</a>，下载链接显示的是亚马逊的云服务，不加梯子是无法访问的，包括下面安装sdk的时候也是要加VPN的，WEDFD！解压后设置PATH环境变量：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="string">"/home/user/Study/pebble-dev/PebbleSDK/bin"</span></div></pre></td></tr></table></figure>
</li>
<li><p>Python环境安装<br>　　注意的是，Pebble目前只支持python2，所以你的pip必须是python2的pip，有的发行版不是这样的，如果不成功注意检查这一点</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~/Study/pebble-dev/PebbleSDK  sudo pip2 install virtualenv</div><div class="line"> user@localhost  ~/Study/pebble-dev/PebbleSDK  virtualenv --no-site-packages .env</div><div class="line">(.env)  user@localhost  ~/Study/pebble-dev/PebbleSDK  pip install -r requirements.txt</div><div class="line">(.env)  user@localhost  ~/Study/pebble-dev/PebbleSDK  deactivate</div><div class="line"> user@localhost  ~/Study/pebble-dev/PebbleSDK </div></pre></td></tr></table></figure>
</li>
<li><p>安装pebble sdk（需要梯子）   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~/Study/pebble-dev  pebble sdk list</div><div class="line"> user@localhost  ~/Study/pebble-dev  pebble sdk install 3.8.2</div><div class="line"> user@localhost  ~/Study/pebble-dev  pebble sdk list</div><div class="line">Installed SDKs:</div><div class="line">3.8.2 (active)</div></pre></td></tr></table></figure>
</li>
<li><p>pebble是支持qemu虚拟机模拟的，所以你如果没有手表，或者想在硬件调试前用软件模拟，那么可以安装qemu虚拟机(又遇到天才大作qemu)  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/Study/pebble-dev/PebbleSDK  sudo dnf install qemu libpng12 SDL</div></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="二、HelloWorld之WatchFace">二、HelloWorld之WatchFace</h1><p>　　任何语言都是HelloWorld起家的。在Pebble上，如果写一个应用程序比较的麻烦，程序涉及到逻辑，最简单的可以按照官方的例程建立一个简单的watchface表盘。下面将建立表盘的代码罗列下来</p>
<ul>
<li><p>用pebble工具创建表盘的项目</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/GitHub/PebbleFuns/watchfaces   master ●  pebble new-project watchface1</div></pre></td></tr></table></figure>
</li>
<li><p>修改watchfaces/watchface1/appinfo.json文件，最主要的是修改watchface为true，其他的参数根据自己喜好改   </p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="string">"companyName"</span>: <span class="string">"FreeSign"</span>,</div><div class="line"><span class="string">"targetPlatforms"</span>: [<span class="string">"aplite"</span>, <span class="string">"basalt"</span> ],</div><div class="line"><span class="string">"watchapp"</span>: &#123;</div><div class="line">    <span class="string">"watchface"</span>: <span class="literal">true</span></div><div class="line">  &#125;,</div></pre></td></tr></table></figure>
</li>
<li><p>表盘的主要代码在watchfaces/watchface1/src/watchface1.c中修改。都是按照官方抄的，就不罗列了。<br><a href="https://github.com/taozhijiang/PebbleFuns/blob/master/watchfaces/watchface1/src/watchface1.c" target="_blank" rel="external">watchface1.c</a></p>
<a id="more"></a>
</li>
</ul>
<h1 id="三、编译和安装">三、编译和安装</h1><ul>
<li><p>编译，在项目根目录执行pebble build即可   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~/GitHub/PebbleFuns/watchfaces/watchface1   master ●  pebble build</div><div class="line"><span class="string">'build'</span> finished successfully (0.927s)</div></pre></td></tr></table></figure>
</li>
<li><p>模拟器安装，在pebble install添加–emulator参数即可。<br>　　如果是在linux图形下，直接执行就可以了，而如果我这样用的headless虚拟机，需要设置DISPLAY环境变量，同时在Windows机器上安装Xmanager软件，打开Xmanager - Passive   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/GitHub/PebbleFuns/watchfaces/watchface1   master ●  <span class="built_in">export</span> DISPLAY=192.168.91.1:0.0</div><div class="line">user@localhost  ~/GitHub/PebbleFuns/watchfaces/watchface1   master ●  pebble install --emulator basalt</div></pre></td></tr></table></figure>
</li>
</ul>
<p>效果如下：<br><img src="/post_images/images/201602/ad9e96358fb7a5dc9025365179fdaddf.png" alt="image"> <img src="/post_images/images/201602/6cd87f811d0077802adc9b7614e7c149.png" alt="image"></p>
<ul>
<li>手表安装，如果有手表，<a href="https://developer.getpebble.com/guides/publishing-tools/developer-connection/" target="_blank" rel="external">打开手表的调试模式</a>，然后<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/GitHub/PebbleFuns/watchfaces/watchface1   master ●  pebble install --phone 192.168.1.143</div></pre></td></tr></table></figure>
</li>
</ul>
<p>效果如下：<br><img src="/post_images/images/201602/2d09f6ab29415fcbf7a86b8ed6b1dd47.png" alt="image"> <img src="/post_images/master/images/201602/c059d20eb0f5a9c2f07bf3d6974864a8.png" alt="image"></p>
<h1 id="四、总结">四、总结</h1><p>　　相比一般的手环和智能手表，Pebble最大乐趣在于其开放性，对于一般用户可以在应用商店找到各种各样的应用程序和各种样式的表盘，而对于动手能力强的，可以自己写应用软件，甚至发布到官方的应用商店去，据我所知目前其它的手环和智能手表还没有做到这一点。在官方的<a href="https://developer.getpebble.com/examples/" target="_blank" rel="external">例子主页</a>提供了大量的实例，也方便了开发者的学习和模仿。总之，Pebble在我看来还是很有前景，很值得入手的一块智能手表！   </p>
<p>　　2016年12月，Pebble归入Fitbit旗下，前途未卜！</p>
<p>本文完~</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[读《硅谷之谜》感]]></title>
      <url>https://taozj.org/201601/read-(the-mystery-of-silicon-valley).html</url>
      <content type="html"><![CDATA[<p>　　今年一月份出的新书，买回来立马两个多礼拜读完了。吴军博士自从他的《浪潮之巅》一举成名之后，可以说在整个IT界已经达到无人不晓的地步，他的《数学之美》更被奉为每个理工科学生和工作者的必读之物。正如大家所称赞的，一个优秀的工程师很常见，一个优秀有见解的工程师也挺多的，而一个有见解的优秀工程师有个好的文笔就难能可贵了。我想他之所以能深得中国IT从业者之心，一方面是他在中美学习和生活的经历，对中美文化和社会有着深刻的接触和体会；其次就是他深知，在一个相对闭塞保守的中国大陆从事IT底层事业的码农，内心对IT圣殿的欧美有着一种无以言喻的神秘感和窥探欲，深得IT从业者的人性！<br>　　废话不多说了，看完之后想对本书有个总结。其次，作为一个还在深圳打拼漂泊的人，自然不可避免地也会将硅谷和深圳联系起来看吧。  </p>
<h1 id="一、硅谷之谜">一、硅谷之谜</h1><p>　　如果非得要用简单的话来概括，我想说：无为而治，容忍宽容，以人为本，灵活多变，追求卓越！</p>
<h2 id="1-无为而治">1.无为而治</h2><p>　　主要是说给政府听的。为什么我们还是要以市场经济为主体代替计划经济，我想作为中国人在上个世纪对这个体会应该再深刻不过了，同时虽然欧美的市场经济也会有危机和萧条，也有磕磕盼盼，但是从其发展中越来越完善了。中国进行市场经济改革，获得了不小的成功，但当前经济出现了问题，我想最好的情况就是壮士断腕，让不符合客观规律的经济体被淘汰，将空间和资源留给符合条件的生存者。扯多了，闭嘴~<br>　　按照吴军的说法，硅谷的当地政府除了干检查市容这类保姆的事情之外，对硅谷公司的发展没有丝毫影响力：他们没有权利给初创公司划地免税、没钱给公司划拨经费，更没法决定公司和产业的发展方向，一切都由硅谷这个生态圈自己处理。</p>
<h2 id="2-容忍宽容">2.容忍宽容</h2><p>　　如果你看看硅谷的地图，就会惊讶的发现处理微软、亚马逊等少数的公司之外，几乎绝大多数IT公司的总部都坐落在那一小块地方。按照常理这些大公司挤占在这一块，应该没有小的初创公司生存的空间，就像国内的BAT几乎把整个中国的IT养分给瓜分完了，其实不然，在硅谷创业才是整个地区的文化主流，因为旧金山本来就是大家一起淘金的地方，所以引得无数创客在硅谷这块IT浪潮最前沿寻宝。就是这些IT巨头会把自己竞争对象瞄准在跟自己一个界别的对手上，这些小的初创公司会有自己的生存空间，尊重这些公司的Idea；同时在大公司内部，对于多个项目的成败也会抱有很宽容的态度，因为如果要让失败付出代价，那么就不会有创新了。<br>　　其次，我不知道这些创客是不是像我们这儿会面对着巨大的个人生存压力（这一点吴军没有在书中提到），但是这个社会对创业会十分的宽容：表现在学校、社会和风投公司不会因为创业失败而给人贴上一个失败的标签，在这个方面硅谷的创业代价比日本要低得多。</p>
<h2 id="3-以人为本">3.以人为本</h2><p>　　信息时代和机械时代最大的不同是，固定资产在新公司已经不重要了，信息时代最重要的资产是——人才。这表现在，对于硅谷的初创公司的员工算作是一个合作关系而不是传统的雇佣关系，围绕着这么一个基调，公司的发展方向、经营理念、员工的沟通方式等等都会产生翻天覆地的变化；而对于大型公司，公司的管理和经营和传统公司也有区别，公司工程师的地位和待遇会十分的尊重，而不是按资论辈的官僚主义。当然谷歌的工作坏境已经被传为佳话了，在此不表了。<br>　　以人为本还包括他们的产品，吴军说硅谷的产品都是面向全球的，硅谷的人都来自全球各地，所以硅谷本生就有全球化的基因，他们的产品能在全世界风行，我想也是洞察人类的本性，满足和尊重人类最本质的需求所致吧！</p>
<h2 id="4-灵活多变">4.灵活多变</h2><p>　　吴军在最后的“三论”中算是给了一个理论性的解释。<br>　　都说信息社会变化万象，基于我上述的几个总结，只要有好的想法和技术，在硅谷创业的成功率算是比较高的，而且很可能会颠覆到某个行业甚至整个产业。这主要是在信息社会，已经没有了原先工业社会的资产和技术壁垒了，任何几个人拿个笔记本在辛巴克都可以创业。<br>　　对于小公司，包袱小，目的性强，可以为达到自己的目的随时修改方案方向，而对于即使是很大的公司，也会保持一种高度警惕的状态，因为在硅谷叱咤风云的IT巨头瞬间或者慢慢陨落的例子数不胜数：Sun、HP、Yahoo！……所以你如果不观测环境的变化而迅速调整自身、如果不能不断从外部引入信息来消除自身产生的熵，公司的危机随时会到来。</p>
<h2 id="5-追求卓越">5.追求卓越</h2><p>　　主要是硅谷的公司和硅谷人的个人信念吧。我们都能感受到硅谷成功出来的产品，基本都是能经历全球几十亿人考验的杰作，而且公司和公司之间的产品重合度比较低，基本都是各自靠着漂亮的Idea起家，不会恶意仿制和恶意竞争，这和硅谷人不会“以钱为本”，而是追求创新、追求颠覆、追求卓越的信念不无关系。反观国内，一个点子出来，如果没有壁垒门槛，大家都会蜂拥而至，创新者的利益得不到保障，整个产业必然也是死气成成。就像我住的小区，最早见到一个“易速递”进驻的，接下来什么e栈、格格货栈乱七八糟的来了七八个快递自取货柜，甚是反感，而如果这个例子不恰当的话，百度、腾讯、360这些公司对整个中国互联网的作为，应该是广大IT从业者深有体会的。<br><a id="more"></a></p>
<h1 id="二、硅谷和深圳">二、硅谷和深圳</h1><p>　　在一定程度上来说，硅谷和深圳比较的像，深圳算是在整个中国大陆创业氛围最浓厚的地方吧。</p>
<h2 id="1-相同点">1.相同点</h2><ul>
<li>都算是移民城市<br>　　硅谷算是全世界IT从业者向往的天堂和全球IT精英的聚集地，深圳也是国内高校IT类毕业生去的最多的地方。感觉北京和上海的人都没深圳多样化，源自北京和上海本身和周边的高校云集，会占用较多的就业岗位，而深圳本地的高校对人才贡献率几乎为零，所以深圳的IT民工都是全国四面八方的，深圳的饭馆也是多彩多样。</li>
<li>都是以IT为主导的城市<br>　　我也不是特别确定，也没有找到具体统计的数据，但是感觉电子、软件、互联网算是主导产业了。当然层次比起来的话，可能腾讯、华为、中兴这些公司还不错，华强北的低端电子产业跟西方根本没有可比性。</li>
<li>都是生活压力大，竞争激烈的城市<br>　　硅谷的房价和深圳的房价都经历着严酷的增长——深圳的房租、房价，深漂族永远的痛。</li>
</ul>
<h2 id="2-不同点">2.不同点</h2><ul>
<li>产生条件不同<br>　　硅谷的形成算是比较偶然性的，她搭上了整个产业变革的大潮，并一直作为这个工业革命的弄潮儿；而深圳在几个经济特区中，地理位置的优势，再加上政策的扶持，成为改革开放的前沿已是必然。</li>
<li>产业层次不同<br>　　无论怎么强调创新，深圳都是作为整个信息产业的下游而存在着：围绕手机的数据线、保护壳、充电器等低利润低价值周边件；消化西方新技术、新产品而低配、低质、低价化生产后再输出；靠着那个摸不着的墙，国内的软件企业可以将西方的软件和服务本地化，但是BAT的强势，初创软件和互联网公司也是举步维艰。</li>
<li>从业者的心态不同<br>　　深圳的空气还不错，政府钱多，所以现在的基础设施在全国算是比较前列的，但是炎热和湿润的气候显然跟硅谷差远了。对于从业者而言，硅谷应当是各个行业的精英莫名而去，硅谷有着宜人的地中海气候，她聚集了世界最好的大学——斯坦福、加州大学伯克利分校，以及众多的风投公司——凯鹏华盈、红杉资本等。而深圳呢，除了那些少数真正想来深圳打拼的，一部分是挤不上北上广的、一部分是老家没有信息产业的，而这些来深圳的，打拼个两三年，有的负担不起这里高昂的生活成本，有的认为这个所谓中国IT的最前沿其实没那回事，又都慢慢的离开了。所以深圳是中国最年轻的城市！</li>
</ul>
<h1 id="三、总结">三、总结</h1><p>　　说什么能，在中国做IT的都很辛苦，诸君共勉吧！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[机器学习中自然语言处理之总结]]></title>
      <url>https://taozj.org/201601/conclusion-of-machine-learning.html</url>
      <content type="html"><![CDATA[<p>　　出于文本归类和数据处理之需求，这段时间研究了下文本处理类的机器学习方面的东西。也快过年放假了，在此做一个总结和感受吧。<br>附注：<a href="https://github.com/taozhijiang/chinese_nlp/" target="_blank" rel="external">本文的项目地址</a></p>
<h1 id="一、分词">一、分词</h1><p>　　正如绝大多数的科学研究一样，机器学习的算法绝大多数都是西方早在几年、十几年和几十年发布出来，然后再经过西方工程化之后，国内再慢慢跟上路来。在中文和英文处理的最大问题在于中文需要分词。当然可以将单个的汉字作为算法的处理单元，但是由于汉语的词汇比起单词含有多得多的信息，所以分词算是汉语处理的第一步。<br>　　目前汉语分词算法实现的比较好的有：   </p>
<h2 id="中科院张华平博士的ICTCLAS分词：">中科院张华平博士的<a href="http://ictclas.nlpir.org/downloads" target="_blank" rel="external">ICTCLAS分词</a>：</h2><p>　　这个算是国内公认做的最好的分词实现了，在各项评测中指标都比较高，缺点是软件是闭源的，而且挂这个license需要不断更新，比较麻烦。这个还有个人做了个python的<a href="https://github.com/tsroten/pynlpir/" target="_blank" rel="external">调用接口</a>，居然是个老外，想想也比较奇葩，但更多的是羞愧。</p>
<h2 id="结巴分词：">结巴分词：</h2><p>　　口号是做<a href="https://github.com/fxsjy/jieba/" target="_blank" rel="external">最好的 Python 中文分词组件</a>，调用接口可谓是最全面的，各种语言都可以用。由于是开源的，效果也还不错，Python/C都支持，所以在程序中经常用。</p>
<h2 id="其它：">其它：</h2><p>　　我个人也根据HMM原理和深度学习实现了两个分词程序，当然效果肯定没有上面那么成熟，但作为HMM和深度学习练练手还是可以的。此外觉得在汉语的时候，中英文和数字的混排中，设想在第一步处理时候将其独立开来，然后再用纯粹的中文分词处理，当然比较懒，没有去做。<br>　　a. <a href="https://github.com/taozhijiang/chinese_nlp/blob/master/segment/segment.py" target="_blank" rel="external">HMM分词</a><br>　　b. <a href="https://github.com/taozhijiang/chinese_nlp/blob/master/DL_python/dl_segment_v2.py" target="_blank" rel="external">深度学习分词</a></p>
<p>　　个人感觉，中文分词目前已经到了90%以上的分词精度，已经十分满足工程应用了。但是语言是动态不断变化的，而且网络用语越来越多，变化也越来越快，分词程序如果能够快速跟踪这些变化，还是十分有现实价值的。此外，汉语分词的主观性特别的强，尺度和每个人的心里把握都有差异，所以有些分词系统也会提供一个参数，控制分词的颗粒度。   </p>
<h1 id="二、情感分析和归类">二、情感分析和归类</h1><p>　　这里这样列，但是实际上文本归类和情感分析是一个问题，无非就是2类和多类的关系。文本归类分为长文本归类和段文本归类：长文本比如一篇文章、一个博文之类的；短文本比如Twitter和微博之类的。短文本的归类比长文本的归类难得多，长文本字词丰富，一般采用多项式模型（词频统计）；而短文本一般采用伯努利模型（词出现与否）效果会好一些。在实现测试的过程中，以下几种算法效果较好：</p>
<h2 id="贝叶斯网络">贝叶斯网络</h2><p>　　算是最简单的学习算法了，具有理论基础清晰、实现简单、计算量小、效果较好的有点。具有多项式模型和伯努利模型两种实现方式。在实践中，某东语聊好评差评两分类能达到90%的分类精度、sogou分类语聊10分类也能达到70%多的分类精度。<br>　　a. <a href="https://github.com/taozhijiang/chinese_nlp/blob/master/sentiment/sent.py" target="_blank" rel="external">Python实现</a><br>　　b. <a href="https://github.com/taozhijiang/chinese_nlp/tree/master/C_CPP_reimplement/classify" target="_blank" rel="external">C/C++实现</a><br>　　注意，当时Python实现速度比较的慢，但是用C/C++实现后，计算资源和速度都至少有十多倍的提升！！！</p>
<h2 id="最大熵模型">最大熵模型</h2><p>　　这个吴军博士在《数学之美》中有介绍。用几句话来概括就是：如果有先验约束知识，就满足这些约束，否则就不做任何假设，因为不做任何假设是最可靠的，而等概率分布时候的熵最大，称之为最大熵模型。举个例子：如果没有任何条件限制，我问投一个骰子1向上的概率是多大，答案是1/6，然后我告诉你投一次出现3和4的概率之和是1/2，然后你肯定推算出这种约束下1向上的概率是1/8。正是秉着这样的观念，文献说最大熵模型在单一模型算法中效果差不多是最好的。<br>　　最大熵模型提出的比较早了，但是利用起来还不是很悠久，就是传统的GIS迭代求解效率太低，而后面改进使得求解速度大大加快的时候，在实际中才慢慢被利用。代码中是参照nltk的Python实现进行C/C++的移植的。<br>　　a. <a href="https://github.com/taozhijiang/chinese_nlp/tree/master/C_CPP_reimplement/classify_maxent" target="_blank" rel="external">GIS和L-BFGS实现</a>   </p>
<h2 id="LDA(Latent_Dirichlet_Allocation)">LDA(Latent Dirichlet Allocation)</h2><p>　　也是一个比较流行的分类算法，这种算法和上面不同的是，不知道预先的类别种类和数目，有点类似聚类的意思。该算法在Twitter和微博主题分类和主题发现中被广泛使用，同时在广告推荐和信息投放中也被大量应用。还有就是这个算法跟别的算法不同的是，涉及到的数学和统计的知识比较的多，要看明白还是需要些功夫的。<br>　　推荐的文章：<br>　　a. <a href="http://www.flickering.cn/nlp/2015/03/peacock%EF%BC%9A%E5%A4%A7%E8%A7%84%E6%A8%A1%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%85%B6%E5%9C%A8%E8%85%BE%E8%AE%AF%E4%B8%9A%E5%8A%A1%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/" target="_blank" rel="external">Peacock：大规模主题模型及其在腾讯业务中的应用</a><br>　　b. <a href="https://github.com/taozhijiang/chinese_nlp/tree/master/topic_lda" target="_blank" rel="external">本人测试</a>发现效果不是特别的理想，包括一个改进的L-LDA，后面再看吧。<br><a id="more"></a></p>
<h1 id="三、命名实体识别">三、命名实体识别</h1><p>　　命名实体识别（NER）的话，虽然在自然语言处理上一般是列为单独的任务，但个人感觉更是一个同分词关系十分密切的问题，所以在人民日报的标注语料中，都是先分完词，然后将实体标注作为词性标注的一类来进行。机器学习上，NER有字典法、HMM法，但是最常用的是CRF法，而机器学习需要标注语料用于训练，中文目前个人只找到人民日报199801的两万多行训练语料（数量少、偏向书面和官方语），所以做特定行业的语料还需搜集和标注。<br>　　CRF主要是对每一个词的周围开一个窗口，然后根据窗口词的信息给中心词打一个TAG，人家实验当周围词提供的信息越多，对最终的标记结果也就越准确。见<a href="http://blog.csdn.net/felomeng/article/details/4367250" target="_blank" rel="external">条件随机场（CRF）识别命名实体</a><br>　　CRF有透明的开源实现，个人用的是<a href="http://www.chokkan.org/software/crfsuite/" target="_blank" rel="external">crfsuite</a>。在实际中，需要分词效果和人民日报标注语料一致，才会有稍好的实验效果。<br>　　a. <a href="https://github.com/taozhijiang/chinese_nlp/tree/master/crf_ner/" target="_blank" rel="external">本人验证测试</a>   </p>
<h1 id="四、深度学习">四、深度学习</h1><p>　　深度学习在这些年真是越来越火了，随着在图像和语音识别上取得骄人的成绩后，Deep Learning也在尝试席卷NLP这最后一块阵地。自然语言不同于图像和语音部分，属于比较高层次的信号，难度较大，所以很多专家不看好深度学习在自然语言上的处理。但是随着RNN的不断研究和改进，在分词、情感识别、分类、标注、NER方面也有了不小的成就。简单而言，目前我们不能给予深度学习从根本上解决自然语言的各种问题，但是给予以往自然语言的研究成果（比如特征提取等），再加上深度学习的强大建模能力，是会将自然语言处理提上一个新的高度的。<br>　　目前实验的功能：<br>　　a. <a href="https://github.com/taozhijiang/chinese_nlp/blob/master/DL_python/dl_segment_v2.py" target="_blank" rel="external">深度学习分词</a><br>　　b. <a href="https://github.com/taozhijiang/chinese_nlp/blob/master/DL_python/lstm_text_generation.py" target="_blank" rel="external">自然语言生成</a><br>　　第一块的分词结果已经在ReadMe列出来了，还是有些效果的；对于自然语言生成，是用一个语聊去训练它，然后它就会根据语料的“口吻”创作出句子来（我还没大规模训练调试，效果不好）。我猜<a href="http://poem.bosonnlp.com/" target="_blank" rel="external">Bosonnlp作诗</a>应该是这个原理。<br>　　其实深度学习可以产生很多好玩的东西，比如<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">大作-1</a>，<a href="https://no2147483647.wordpress.com/2015/12/21/deep-learning-for-hackers-with-mxnet-2/" target="_blank" rel="external">大作-2</a></p>
<h1 id="五、总结">五、总结</h1><p>　　无论是不是个坑，深度学习都是当前机器学习的热点和主流。让我的最大感受就是：传统的机器学习都是科学家们精妙的设计出各种数学模型和求解算法，而深度学习就是粗鲁地用大数据和巨大计算量拼出一个毕竟训练结果的模型而没有任何理论去支持它。这又让我想起了：</p>
<blockquote>
<p>我们（在考虑图灵测试中的机器时）也应当允许这样一种可能，那就是一些工程师可能会建造一台机器，它能够完成任务（通过图灵测试），但其工作的原理却未必能够被其创造者所完全理解，这是因为他们采用了一种试验的方式（来建造这台机器）。</p>
</blockquote>
<p>　　PS：搞深度学习的话，先换台好点显卡的电脑吧，最好是Nvidia支持CUBA的，集成显卡就不要尝试了，即使是再好的CPU也算不过GPU的！目前很多开源的深度学习库都支持GPU计算的，所以你看看Nvidia的Titan和Tesla价格就知道这东西有多重要了。</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[我的Gentoo Overlay和Linux软件推荐]]></title>
      <url>https://taozj.org/201601/gentoo-overlay-and-software-recommend.html</url>
      <content type="html"><![CDATA[<h1 id="Gentoo_Overlay_(Self)">Gentoo Overlay (Self)</h1><p>　　Gentoo自用的overlay，没有研究怎么public出去，大家如果感兴趣的话，可以将这个仓储clone到/usr/local/，然后将文件etc_portage_repo.postsync.d_local.conf复制到对应的位置，再sync应该就可以了。</p>
<p>　　这里面的ebuild都不是我自己写的，而是在网上收录的，创作权归原来的作者所有。</p>
<p>　　同时，自己系统的使用软件也在此整理，并不定期同步更新（如果有更改的话），供感兴趣的人参考。</p>
<h1 id="系统的桌面贴图">系统的桌面贴图</h1><p><img src="/post_images/images/201601/19b35de7f07e1ecabf21c1364a753c5a.png" alt="image"></p>
<p><img src="/post_images/images/201601/83dfbdb20648e7b0045e3ce007cb4db0.png" alt="image"></p>
<h1 id="软件整理">软件整理</h1><h2 id="内核">内核</h2><p>gentoo的主流内核有三种：sys-kernel/gentoo-sources sys-kernel/ck-sources sys-kernel/vanilla-sources，第一种是gentoo官方打了补丁的内核，优点是menuconfig的时候配置方便，缺点是毕竟改过点东西，不是最稳定的选择；第二种是打了鸡血的内核，主要修改了cpu和硬盘的调度补丁，据说对桌面系统交互相应会好很多，缺点是更不主流；第三种是官方原版的内核，干净的很。<br>我以前用ck-sources，现在用gentoo-sources。<br>分区和引导方式为GPT+EFI，grub被废弃，用的sys-boot/refind帮助引导系统。  </p>
<h2 id="驱动">驱动</h2><p>这个跟每个人的硬件有关系，基本在编译内核的时候，根据自己的情况进行相应的精简。我的电脑用的DELL的无线网卡，内核的开源驱动性能很低，换成net-wireless/broadcom-sta，性能和稳定性好了很多。  </p>
<h2 id="系统美化">系统美化</h2><h3 id="桌面主题">桌面主题</h3><ul>
<li>GNOME SHELL: ZukiShell  </li>
<li>GTK: Numix</li>
</ul>
<h3 id="桌面图标">桌面图标</h3><ul>
<li>Numix-Circle  </li>
</ul>
<h3 id="桌面壁纸：varitey">桌面壁纸：varitey</h3><ul>
<li>variety  这是个壁纸自动替换程序,最初出现在Ubuntu上（已收录），可以自己设置壁纸的源、自动切换的时间等参数。  </li>
</ul>
<h3 id="字体：infinality_+_宋体">字体：infinality + 宋体</h3><p>在行内有一句话，高分屏用什么字体都好看，低分屏用什么字体都渣渣。都这么多年头了，手机都2K屏了，笔记本居然还是720p。低分屏字体需要优化一下，不然太难看了。下面的方案是折腾了很久感觉最耐看、最好效果的。（见图）<br>安装app-eselect/eselect-infinality和media-libs/fontconfig-infinality，然后<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo eselect infinality <span class="built_in">set</span> 2 [infinality]  </div><div class="line">sudo eselect lcdfilter <span class="built_in">set</span> 3 [infinality]  </div><div class="line">sudo eselect fontconfig <span class="built_in">disable</span>/<span class="built_in">enable</span></div></pre></td></tr></table></figure></p>
<p>将fontconfig中除了52-infinality.conf和65-nonlatin.conf两个enable之外，所有的conf都disable掉。<br>再将你windows系统的宋体（simsun.ttc）安装到Linux系统，修改/etc/fonts/conf.d/65-nonlatin.conf，第一个字体用好看的英文字体（宋体的英文显示太难看了，我用的Liberation Sans），然后跟中文宋体（NSimSun），这样在显示的时候，英文会优先使用第一个字体，然后遇到中文没法显示的时候，用下面的宋体显示。然后你GNOME中所有的字体都设置成Liberation Sans就可以了。</p>
<h3 id="GNOME_SHELL插件扩展：">GNOME SHELL插件扩展：</h3><p>Gnome Shell扩展那个之多啊，我启用的都列在下面了，自己没事可以走一下<a href="https://extensions.gnome.org/" target="_blank" rel="external">GNOME插件</a> ，需要注意的是由于接口还是协议的变化，chrome已经不支持了，请用火狐浏览器打开。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">Applications Menu  </div><div class="line">Battery percentage  </div><div class="line">Caffeine  </div><div class="line">Clipboard indicator  </div><div class="line">Dash to dock  </div><div class="line">Focus my window  </div><div class="line">Freon  </div><div class="line">Frippery move clock  </div><div class="line">Frippery panel favorites  </div><div class="line">Impatience  </div><div class="line">Input method panel  </div><div class="line">Lock keys  </div><div class="line">Native window placement  </div><div class="line">Panel-docklet v18  </div><div class="line">Recent(item)s  </div><div class="line">Refresh wifi connections  </div><div class="line">Removable drive menu  </div><div class="line">Show desktop button  </div><div class="line">Status area horizontal spacing  </div><div class="line">Suspend button  </div><div class="line">Topicons  </div><div class="line">Pixel Saver   </div><div class="line">Turn off display</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="应用软件">应用软件</h2><h3 id="文档编辑类:_sublime_wiznote_vim">文档编辑类: sublime wiznote  vim</h3><ul>
<li>sublime：据说很牛逼，不过我只是当notepad++来用了，很惭愧。</li>
<li>wiznote：是一个良心跨平台的笔记解决方案。可能evernote最有名，不过Linux官方没有支持的版本，第三方版本懒得折腾，就选wiznote了。而且还有一点，为知笔记内嵌支持MarkDown语法，用来配合GitHub Pages写博客再合适不过了。</li>
<li>vim：现在只是用来修改系统配置文件了。  </li>
</ul>
<h3 id="输入法类：fcitx_+_sogou拼音">输入法类：fcitx + sogou拼音</h3><ul>
<li>fcitx： 以前都是fcitx+sunpinyin的，感觉fcitx打起字来反应比ibus、scim要快不少。得益于深度和各大软件厂商的合作，sogou拼音支持Linux版本的，这里已经收录了，用的是闭源的fcitx扩展，感觉打字准确度确实要好不少，没有洁癖的可以用。  </li>
</ul>
<h3 id="开发类">开发类</h3><ul>
<li><p>python：Wing IDE<br>Wing IDE：确实是一个优秀的IDE，可以调试、断点、单步运行、查看变量等，方便Python开发调试。  </p>
</li>
<li><p>C/C++：SlickEdit<br>SlickEdit：据说是最贵的编辑器（其实是个IDE），自动补全，很多配置选项。  </p>
</li>
</ul>
<h3 id="网络类">网络类</h3><ul>
<li><p>浏览器：chrome、firefox<br>虽然chrome是最吃资源的，狂占内存，但是作为越来越流行的浏览器是不可否认的。缺点是没法同步，大家都懂得，作为人家说“不扩展不chrome”，就介绍一下自己用的chrome插件吧<br>chromeIPass: KeePass的扩展，见<a href="/201508/keepass-pass-save.html">这篇文档</a>   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Flickr Tab: 每打开一个chrome tab，都会有个新的背景壁纸  </div><div class="line">Google 类似网页: 展现当前相似网页，没怎么用  </div><div class="line">Neat Bookmarks：屏幕太小，标签栏不够用，这个用起来很紧凑，节省空间  </div><div class="line">Proxy SwitchyOmega：科学上网的人都知道，不解释  </div><div class="line">保护眼睛：很赞，自动把你访问的网页转换成“绿豆糕色”  </div><div class="line">百度网盘助手 + YAAW <span class="keyword">for</span> Chrome：可以调用aria2后台下载，还没研究透  </div><div class="line">阅读模式：排除页面干扰，让你专心阅读网页内容</div></pre></td></tr></table></figure>
</li>
<li><p>邮件：thunderbird　ZohoMail<br>thunderbird：用她可能更多的出于情怀了，再次找不到其它好用的邮件客户端了。当然，其强大的扩展功能也十分的赞，比如支持邮件正文的加密和签名，比较可惜的是，网络代理没有认证模式。<br>不过后面用Shadowsocks，本地客户端就是无认证代理的，这就不是问题了，装一个代理插件切换很方便。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">主题：airmail</div><div class="line">CompactHeader: 缩减邮件头，腾出更大的阅读空间</div></pre></td></tr></table></figure>
</li>
</ul>
<p>Zoho Mail:<br>这是个企业邮箱，可以挂靠自己的域名，免费账户的每个邮箱是5G的存储空间，每天流量限制500M，对个人完全是够用了。我弃腾讯企业邮选用他，最主要的是：服务全球一百多个国家，经受住了考验；由于有国内业务，所以暂时不会被墙（建议注册国际版，原因你懂得）；支持两步验证。此外还有很多高级功能，不用不知道。   </p>
<h3 id="网盘：Dropbox">网盘：Dropbox</h3><ul>
<li>Dropbox：行业老大，不解释。虽然百度网盘也有Linux客户端，但是不想把重要的东西给他保管。 国内使用，只能挂socket5代理。<br>正规途径买空间太贵了，淘宝化了十几块钱，半个月帮你刷到最大免费空间18G。 </li>
</ul>
<h3 id="下载类：axel_aria2c">下载类：axel aria2c</h3><ul>
<li>axel： 命令行的下载工具，会开启多线程下载，比wget会快几倍</li>
<li>aria2c：据说是BT等下载利器，当然不是开箱即用的，需要自己摸索配置，然后加上YAAW、百度网盘助手，下东西嗖嗖滴。 </li>
</ul>
<h3 id="Twitter：proxychains_+_corebird">Twitter：proxychains + corebird</h3><ul>
<li>proxychains：这个工具不错，可以为不支持代理设置的软件提供代理服务。安装配置后，proxychains+任意程序名就可以了，但是我想修改desktop启动文件，在Exec前面添加proxychains，但是这样程序启动后就没有了代理效果了。只有命令行执行有效，有没有大神告知为什么。  </li>
<li>Twitter：客户端有好几个，但是这个corebird用起来感觉不错！  </li>
</ul>
<h3 id="DNS:_dnscrypt-proxy">DNS: dnscrypt-proxy</h3><ul>
<li>dnscrypt-proxy: 将DNS的解析进行加密，防止GFW和运营商的DNS劫持和污染，即使解析速度慢一点没关系，关键不要给我垃圾。</li>
</ul>
<h3 id="虚拟机类：">虚拟机类：</h3><ul>
<li>Virt-Manager + Qemu + KVM<br>Linux虚拟机基本就上面方案+VirtualBox+VMware。图省事可以用后面两种，我用第一种，感觉速度还是不错的，本身qemu的启动参数有一大堆，喜欢研究的可以慢慢去考究，特别对做开发的，qemu可以很方便的满足各种需求。因为现在研究方向的原因，不折腾了，所以我就直接用Virt-Manager前端管理虚拟机了。<br>对于Windows虚拟机的话，推荐spice插件，可以用spicy连接运行的虚拟机，支持任意大小的窗口分辨率，效果很赞！  </li>
<li>Oracle VirtualBox也可用的，装黑苹果十分的方便。   </li>
<li>LXC 容器类的轻量级的虚拟化技术，可以用来单机实验搞Hadoop等集群实验。</li>
</ul>
<h3 id="游戏娱乐类：">游戏娱乐类：</h3><ul>
<li>games-action/supertuxkart     </li>
<li>steam CS-GO…  </li>
</ul>
<h3 id="其它杂类：">其它杂类：</h3><ul>
<li>命令行截图工具   <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">alias</span> simg=<span class="string">"scrot -s -e 'curl -F \"name=@\$f\" https://img.vim-cn.com/'"</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>设置simg别名，截图后会自动上传到vim-cn.com图床，然后打印URL地址。这个在freenode聊天中十分常用！   </p>
<p>LAST EDIT：20160324</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[Docker容器技术使用实例]]></title>
      <url>https://taozj.org/201510/docker-examples.html</url>
      <content type="html"><![CDATA[<p>　　本来不想这么快研究这个东西的，实在是<strong>上一个VPS Provider太让人失望和无语</strong>了：服务器无法访问，告诉我服务器配置错误。我问那该怎么办，答复我要VPS要重装。网络不通，数据也无法备份，关键是我重装之后还是不能访问，他们也没找到问题，最后发现是只有某些版本的系统的网络能通，也是无语了。之前运行了近一年了没有出现问题，现在服务器的数据全部没了，很多的额服务器需要重新配置，这也让我对系统的运营和部署产生了足够的重视。<br>　　之前对Docker有一些了解，或许现在正是我这种情况的用武之地了，主要的服务和设置用Docker来部署，而私密的数据毕竟少量，自己按时备份。这样如果下次再出问题，几条命令就可以重新把环境部署回来了。<br>　　对于企业级的部署，docker也是一个很好的解决方案，因为你只需要关心容器特定版本的实现，而不用关系host的环境，就是说你的服务可能只开发了RHEL的版本，但是可以方便的被部署到CentOS、Debian、Ubuntu、CoreOS等各个发行版上去，虽然对原生的性能会有所损耗，但是在现在计算机的配置几乎可以忽略不计了，国外已经有银行用容器部署他们的业务了，可靠性也是得到验证了的，是不是很酷？</p>
<p>下面开工：</p>
<h1 id="1-注册账号">1.注册账号</h1><p>　　<a href="https://hub.docker.com/" title="DockerHub" target="_blank" rel="external">DockerHub</a> 注册用户账号。这个DockerHub相当于GitHub类似的，可以免费帮你存储公有的容器，别人都可以访问和下载（所以前面强调私有的数据要另外保存），然后每个用户可以免费创建一个私有的容器，更多的私有容器就需要花美刀了，跟GitHub是一个运营模式。</p>
<h1 id="2-创建应用容器">2.创建应用容器</h1><h2 id="2-1_安装相应的工具">2.1 安装相应的工具</h2><p>　　我用的是Fedora 22 Server，这些东西默认就给我装上了，其它版本请参照官方的安装手册。(官方文档说的添加docker组可以让docker在非root用户下运行，但是试验发现、改变/var/run/docker.socket权限后会自动变回来，所以fedora是没有办法的，只能sudo了)。此外docker在fedora的官方维持了一个版本，同时docker自己也维持了一个版本，两者差不多。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~  sudo dnf install docker -y</div><div class="line">user@localhost  ~  sudo systemctl <span class="built_in">enable</span> docker</div><div class="line">user@localhost  ~  sudo systemctl restart docker</div><div class="line">user@localhost  ~  sudo docker run hello-world</div><div class="line">user@localhost  ~  sudo docker run -it fedora:22 ping 8.8.4.4</div></pre></td></tr></table></figure></p>
<p>直接使用<strong>docker</strong>可以查看docker的可用命令<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">attach    Attach to a running container</div><div class="line">build     Build an image from a Dockerfile</div><div class="line">commit    Create a new image from a container<span class="string">'s changes</span></div><div class="line">cp        Copy files/folders from a container to a HOSTDIR or to STDOUT</div><div class="line">create    Create a new container</div><div class="line">diff      Inspect changes on a container's filesystem</div><div class="line"><span class="built_in">exec</span>      Run a <span class="built_in">command</span> <span class="keyword">in</span> a running container</div><div class="line"><span class="built_in">history</span>   Show the <span class="built_in">history</span> of an image</div><div class="line">images    List images</div><div class="line">info      Display system-wide information</div><div class="line"><span class="built_in">kill</span>      Kill a running container</div><div class="line">login     Register or <span class="built_in">log</span> <span class="keyword">in</span> to a Docker registry</div><div class="line"><span class="built_in">logout</span>    Log out from a Docker registry</div><div class="line">logs      Fetch the logs of a container</div><div class="line">pause     Pause all processes within a container</div><div class="line">port      List port mappings or a specific mapping <span class="keyword">for</span> the CONTAINER</div><div class="line">ps        List containers</div><div class="line">pull      Pull an image or a repository from a registry</div><div class="line">push      Push an image or a repository to a registry</div><div class="line">rename    Rename a container</div><div class="line">restart   Restart a running container</div><div class="line">rm        Remove one or more containers</div><div class="line">rmi       Remove one or more images</div><div class="line">run       Run a <span class="built_in">command</span> <span class="keyword">in</span> a new container</div><div class="line">save      Save an image(s) to a tar archive</div><div class="line">search    Search the Docker Hub <span class="keyword">for</span> images</div><div class="line">start     Start one or more stopped containers</div><div class="line">stop      Stop a running container</div><div class="line">tag       Tag an image into a repository</div><div class="line">top       Display the running processes of a container</div><div class="line">unpause   Unpause all processes within a container</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="2-2_创建Docker镜像">2.2 创建Docker镜像</h2><p>　　DockerHub官方描述，如果DockerHub有的镜像，可以用上面的方法下载下来直接使用，如果没有的话，有两种方式：<br>(1)下载别人的镜像，然后修改镜像的内容，再提交更改变成自己的镜像；<br>(2)重新修改Dockfile，然后按照自己的规则生成镜像；<br>　　当然两者各有优点<br>第(1)种：简单方便；<br>第(2)种：清晰明了，白盒操作，而且可以持续更新，维护较佳，但是有些配置和修改比较的麻烦，需要用sed等工具来实现；<strong>Dockfile可以托管到GitHub上面，然后DockerHub可以关联GitHub，自动编译镜像</strong>，这个很重要，在国内龟速的出口网络上，上穿上百兆的内容是很困难的！<br>　　所以个人觉得，如果第(2)种能实现的话，虽然麻烦点，建议用第二种；<br>　　Dockfile描述了镜像创建的规则，创建Docker镜像实际就是编写Dockfile的过程，fedora官方提供了很多的<a href="https://github.com/fedora-cloud/Fedora-Dockerfiles" target="_blank" rel="external">Dockfile实例</a>可供参考。Dockerhub约定了各个软件和系统官方所提供的镜像都是不带前缀的，比如“centos:latest”；个人镜像都是带前缀的，比如“taozhijiang/debian-pptpd:v1”这种类型的。</p>
<p>　　这里我们尝试生成一个运行pptpd协议VPN服务的Docker镜像作为例子。</p>
<h3 id="2-2-1_登入Dockhub，修改环境">2.2.1 登入Dockhub，修改环境</h3><p>　　Docker的方便之处就是对运维人员的解脱，将镜像存储在云端，任何在线的服务器都可以轻松的部署。下面就是用Dockfile建立镜像的步骤，其中编写Dockfile是重点！<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~  sudo docker login</div><div class="line">Username: taozhijiang</div><div class="line">Password: </div><div class="line">Email: taozhijiang@gmail.com</div><div class="line">WARNING: login credentials saved <span class="keyword">in</span> /root/.docker/config.json</div><div class="line">Login Succeeded</div><div class="line"> user@localhost  ~  <span class="built_in">cd</span> ~/DockerHub</div><div class="line"> user@localhost  ~/DockerHub  mkdir debian-pptpd</div><div class="line"> user@localhost  ~/DockerHub  <span class="built_in">cd</span> debian-pptpd </div><div class="line"> user@localhost  ~/DockerHub/debian-pptpd  vim Dockerfile </div><div class="line"> user@localhost  ~/DockerHub/debian-pptpd  sudo docker build -t taozhijiang/debian-pptpd .</div></pre></td></tr></table></figure></p>
<p>　　还有一点这里需要列举出来的是，如果你用的systemd，那么<strong>*不要用systemd的networkd来管理的你的网络</strong>，我用地沟油试验的，这种情况container上不了外网，切记切记！<br>　　本来打算用fedora的base image的，但是发现生成的docker image太大了，在768M的VPS上面根本没法运行，内存太小导致docker的进程被杀死。一直以来，fedora和RHEL都感觉比较的臃肿，上次安装系统的时候也是，256M的VPS直接不让装CentOS 7，安装的最低限度是512M……所以现在打算用debian的base image来做这个pptpd的镜像吧。</p>
<h3 id="2-2-2_编写Dockfile文件">2.2.2 编写Dockfile文件</h3> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">FROM debian:latest</div><div class="line">MAINTAINER taozhijiang &lt;taozhijiang@gmail.com&gt;</div><div class="line"></div><div class="line"><span class="comment">#RUN dnf update -y &amp;&amp; dnf install pptpd iptables -y</span></div><div class="line"><span class="comment">#RUN dnf clean all</span></div><div class="line">RUN rm -fr /etc/apt/sources.list</div><div class="line">COPY ./sources.list /etc/apt/sources.list</div><div class="line">RUN apt-get update -y &amp;&amp; apt-get install pptpd iptables rsyslog -y</div><div class="line">RUN apt-get clean </div><div class="line"></div><div class="line">RUN <span class="built_in">echo</span> <span class="string">"\nlocalip 192.168.5.254 \nremoteip 192.168.5.200-230\n"</span> &gt;&gt; /etc/pptpd.conf</div><div class="line">RUN <span class="built_in">echo</span> <span class="string">"\nms-dns 8.8.8.8 \nms-dns 8.8.4.4 \ndebug\n"</span> &gt;&gt; /etc/ppp/pptpd-options</div><div class="line"></div><div class="line">EXPOSE 1723</div><div class="line"></div><div class="line">COPY ./pptpd_start.sh /root/pptpd_start.sh</div><div class="line">RUN chmod u+x /root/pptpd_start.sh</div><div class="line"></div><div class="line">CMD [<span class="string">"/root/pptpd_start.sh"</span>]</div></pre></td></tr></table></figure>
<h3 id="2-2-3_向DockerHub推送镜像">2.2.3 向DockerHub推送镜像</h3><p>　　很简单，登陆之后<strong>sudo docker push debian-pptpd:latest</strong>就可以啦。不过一个镜像少者一两百兆，多着五六百兆，电信的宽带尝试了很多次都没有成功;-( 中国的互联网速度龟、费用贵，出口带宽还得加个墙，无语了。<br>　　我是将Dockfile复制到自己的VPS上面去编译的，国外那个网速那是真的快。</p>
<h3 id="2-2-4_关联GitHub账号，实现自动化编译">2.2.4 关联GitHub账号，实现自动化编译</h3><p>　　DockerHub有一个很靓的功能，就是Automated Build。你可以在你的DockerHub账号设置中，关联GitHub账号或者Bitbucket账号，成功之后你可以新建这种关联与GitHub某个项目的Automated Build的Repo，当GitHub上面的项目有提交更新的话，可以手动或者自动触发这个编译操作去执行生成新的镜像。就不用自己本地生成然后再慢慢上传了，着实的很方便。<br>　　当然，每个GitHub Repo能关联生成一个DockerHub Repo，这对我们没有自己的项目，想用一个GitHub Repo管理所有Dockfile的来说比较的不方便，而且发现Repo的名字不能包含大写字符，应该是一个Bug。</p>
<h3 id="2-2-5_应用服务器部署和调试">2.2.5 应用服务器部署和调试</h3><p>　　在任意一台服务器上，运行<strong>sudo docker pull debian-pptpd:latest</strong>就可以下载存储在DockerHub云端的镜像了。对于上面的文件，我们在部署服务器上面添加VPN用户账户，比如<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#/srv/chap-secrets</span></div></pre></td></tr></table></figure></p>
<p>然后终端运行<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo docker run <span class="_">-d</span> --privileged -p 1723:1723 -v /home/user/GitHub/DockerHub/debian-pptpd/chap-secrets:/etc/ppp/chap-secrets:ro  taozhijiang/debian-pptpd</div></pre></td></tr></table></figure></p>
<p>如果需要调试，可以运行<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo docker <span class="built_in">exec</span> -i -t 5f1c03c7410c62db5edc1d418788ffb982554988c8ced58999590b28436fd978 bash</div></pre></td></tr></table></figure></p>
<h2 id="3-测试验证">3.测试验证</h2><p>　　手机端和PC端，用Docker Host的IP地址和设置的VPN账号密码，可以拨号成功就OK啦！</p>
<h1 id="Reference">Reference</h1><ul>
<li><a href="https://testerhome.com/topics/2648" target="_blank" rel="external">Centos7 下建立 Docker 桥接网络</a></li>
<li><a href="https://docs.docker.com/" target="_blank" rel="external">Welcome to the Docs</a></li>
<li><a href="https://github.com/whuwxl/docker-repos" target="_blank" rel="external">whuwxl/docker-repos</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[搭建基于Postfix和Dovecot的邮件服务器]]></title>
      <url>https://taozj.org/201510/mail-server-based-on-postfix-dovecot.html</url>
      <content type="html"><![CDATA[<p>最近帮飞哥搭建了一个Linux Mail Server，捣鼓了一天终于搞掂了。这里记录下来以备后用，由于时间仓促，很多参数和功能还不知所以然;-(。</p>
<h1 id="1-_服务器环境">1. 服务器环境</h1><p>操作系统：CentOS 7.1<br>环境：apache php mariadb<br>软件：postfix dovecot roundcubemail postfixadmin<br>其它：在域名商添加邮件服务器的A记录和MX记录，这里用的mail.freesign.net<br>     同时请<a href="&#39;https://buy.wosign.com/free/?lan=en#ssl&#39;">申请数字证书</a>，中文版页面的免费申请地址很难看到，估计就是故意不想让人找到的。前段时间还是3年的，现在签发只能管一年了。<br>关于LAMP环境的搭建网络上已经一大堆了，此处不表。Apache推荐开启https，因为postfixadmin和roundcubemail是网页端访问的，这样会比较安全。<br>    添加邮件专用用户vmail:vmail<br>    groupadd -g 5000 vmail<br>    useradd -g vmail -u 5000 vmail -d /home/vmail -m</p>
<h1 id="2-_邮件服务器搭建">2. 邮件服务器搭建</h1><h2 id="2-1_设置服务器">2.1 设置服务器</h2><p>在数据库中专门添加一个邮件的数据库。同时由于邮件服务器涉及到多个软件，这些软件的系统也是通过操作数据库的操作来实现的。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~  mysql -u user -p</div><div class="line"> Enter password: </div><div class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</div><div class="line">Your MariaDB connection id is 3857</div><div class="line">Server version: 5.5.44-MariaDB MariaDB Server</div><div class="line"></div><div class="line">Copyright (c) 2000, 2015, Oracle, MariaDB Corporation Ab and others.</div><div class="line"></div><div class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> help. Type <span class="string">'\c'</span> to clear the current input statement.</div><div class="line"></div><div class="line">MariaDB [(none)]&gt; </div><div class="line">MariaDB [(none)]&gt; create database postfix;</div><div class="line">MariaDB [(none)]&gt; CREATE USER <span class="string">'postfix'</span>@<span class="string">'localhost'</span> IDENTIFIED BY <span class="string">'postfixadmin'</span>;</div><div class="line">MariaDB [(none)]&gt; CREATE USER <span class="string">'postfix'</span>@<span class="string">'localhost.localdomain'</span> IDENTIFIED BY <span class="string">'postfixadmin'</span>;</div><div class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON `postfix` . * TO <span class="string">'postfix'</span>@<span class="string">'localhost'</span>;</div><div class="line">MariaDB [(none)]&gt; GRANT ALL PRIVILEGES ON `postfix` . * TO <span class="string">'postfix'</span>@<span class="string">'localhost.localdomain'</span>;</div><div class="line">MariaDB [(none)]&gt; FLUSH PRIVILEGES;</div></pre></td></tr></table></figure></p>
<p>(把数据库操作过程的输出信息省略了)</p>
<h2 id="2-2_安装roundcubemail和postfixadmin">2.2 安装roundcubemail和postfixadmin</h2><p>postfixadmin没有被打包到库中，所以需要手动下载源代码来安装。roundcubemail是epel中被打包了的，可以直接yum安装。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~  sudo yum install roundcubemail</div><div class="line">user@localhost  ~  <span class="built_in">cd</span> /usr/share </div><div class="line">user@localhost  /usr/share  sudo wget wget http://jaist.dl.sourceforge.net/project/postfixadmin/postfixadmin/postfixadmin-2.93/postfixadmin-2.93.tar.gz</div><div class="line">user@localhost  /usr/share  sudo tar xzvf postfixadmin-2.93.tar.gz</div><div class="line">user@localhost  /usr/share  sudo mv postfixadmin-2.93 postfixadmin</div></pre></td></tr></table></figure></p>
<p>把postfixadmin解压到/usr/share目录，其实这步骤是跟roundcubemail学的。在安装roundcubemail 的时候，会在/etc/httpd/conf.d/roundcubemail.conf产生一个虚拟主机，对这个虚拟主机的别名和目录做如下设置<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">Alias /roundcubemail /usr/share/roundcubemail</div><div class="line">Alias /mail /usr/share/roundcubemail</div><div class="line">Alias /postfixadmin /usr/share/postfixadmin</div><div class="line"></div><div class="line">&lt;Directory /usr/share/roundcubemail/&gt;</div><div class="line">        Options none</div><div class="line">        AllowOverride Limit</div><div class="line">        Require all granted</div><div class="line">&lt;/Directory&gt;</div><div class="line"></div><div class="line">&lt;Directory /usr/share/postfixadmin/&gt;</div><div class="line">        Options none</div><div class="line">        AllowOverride Limit</div><div class="line">        Require all granted</div><div class="line">&lt;/Directory&gt;</div><div class="line"></div><div class="line">&lt;Directory /usr/share/roundcubemail/installer&gt;</div><div class="line">        Options none</div><div class="line">        AllowOverride Limit</div><div class="line">        Require all granted</div><div class="line">&lt;/Directory&gt;</div></pre></td></tr></table></figure></p>
<p>记得重启apache服务器。</p>
<p>postfixadmin算是一个postfix的管理前端，邮件服务器管理域名和用户账户都在这里。解压之后修改config.inc.php文件（官方推荐是创建config.local.php文件，便于后续升级），其实最主要是数据库相关的设置信息(重要的修改列出如下)：<br><figure class="highlight php"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">$CONF[<span class="string">'configured'</span>] = <span class="keyword">true</span>;</div><div class="line">$CONF[<span class="string">'setup_password'</span>] = <span class="string">'abc123def'</span>;</div><div class="line">$CONF[<span class="string">'default_language'</span>] = <span class="string">'cn'</span>;</div><div class="line">$CONF[<span class="string">'database_type'</span>] = <span class="string">'mysqli'</span>;</div><div class="line">$CONF[<span class="string">'database_host'</span>] = <span class="string">'localhost'</span>;</div><div class="line">$CONF[<span class="string">'database_user'</span>] = <span class="string">'postfix'</span>;</div><div class="line">$CONF[<span class="string">'database_password'</span>] = <span class="string">'postfixadmin'</span>;</div><div class="line">$CONF[<span class="string">'database_name'</span>] = <span class="string">'postfix'</span>;</div><div class="line">$CONF[<span class="string">'admin_email'</span>] = <span class="string">'yourmailaddress@126.com'</span>;</div><div class="line">$CONF[<span class="string">'encrypt'</span>] = <span class="string">'dovecot:CRAM-MD5'</span>;</div><div class="line">$CONF[<span class="string">'dovecotpw'</span>] = <span class="string">"/usr/bin/doveadm pw"</span>;</div></pre></td></tr></table></figure></p>
<p>坑点说明：(1)setup_password需要满足密码复杂性要求，不是随便设置的，第一步设置明文，然后在页面生成加密后的密码，再将加密后的密文替换abc123def之后，才能进行添加管理员的操作；(2)encrypt需要修改，要跟后面其它部分设置一样；(3)CentOS7中doveadm打包到了/usr/bin目录，所以这里的路径需要更新；(4)templates_c目录的所属权限需要改为apache；<br>（postfixadmin的DOCUMENTS目录下的内容是个比较好的参考文档）</p>
<p>然后访问<strong><a href="https://mail.freesign.net/postfixadmin/setup.php" target="_blank" rel="external">https://mail.freesign.net/postfixadmin/setup.php</a></strong>进行安装：第一步会生成加密的setup_passwd密码，替换config文件中的明文密码后，会让你创建一个管理账户，创建完成验证能登陆之后就先别做其它操作和设置了，因为很多东西还没有设置，创建域啥的没啥意义；<br>管理员和普通用户的管理路径在下面：<br><a href="https://mail.freesign.net/postfixadmin/login.php" target="_blank" rel="external">https://mail.freesign.net/postfixadmin/login.php</a><br><a href="https://mail.freesign.net/postfixadmin/users/login.php" target="_blank" rel="external">https://mail.freesign.net/postfixadmin/users/login.php</a></p>
<a id="more"></a>
<h2 id="2-3_安装postfix_dovecot">2.3 安装postfix dovecot</h2><p>postfix和dovecot是本文最重要和复杂的两处设置(所以才有人称邮件服务器就是个坑，一点没httpd、ftp这类服务器省心)，postfix的配置文件位于/etc/postfix/下，而dovecot配置文件主要位于/etc/dovecot/下。</p>
<h3 id="2-3-1_postfix的配置信息">2.3.1 postfix的配置信息</h3><p>main.cf重要参数<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">myhostname = mail.freesign.net</div><div class="line">mydomain = freesign.net</div><div class="line"></div><div class="line">inet_interfaces = all</div><div class="line">inet_protocols = ipv4</div><div class="line">mydestination = localhost.localdomain, localhost</div><div class="line">mynetworks = 127.0.0.0/8</div><div class="line"><span class="comment">#以上的参数比较的严格</span></div><div class="line"></div><div class="line">virtual_mailbox_domains = proxy:mysql:/etc/postfix/mysql_virtual_domains_maps.cf</div><div class="line">virtual_<span class="built_in">alias</span>_maps = proxy:mysql:/etc/postfix/mysql_virtual_<span class="built_in">alias</span>_maps.cf</div><div class="line">virtual_mailbox_maps = proxy:mysql:/etc/postfix/mysql_virtual_mailbox_maps.cf</div><div class="line"><span class="comment">#邮件的根目录</span></div><div class="line">virtual_mailbox_base = /aaa/maildata/</div><div class="line"></div><div class="line"><span class="comment">#vmail:vmail的uid和gid</span></div><div class="line">virtual_uid_maps = static:5000</div><div class="line">virtual_gid_maps = static:5000</div><div class="line">virtual_transport = dovecot</div><div class="line">dovecot_destination_recipient_<span class="built_in">limit</span> = 1</div><div class="line">proxy_<span class="built_in">read</span>_maps = <span class="variable">$local_recipient_maps</span> <span class="variable">$mydestination</span> <span class="variable">$virtual_alias_maps</span> <span class="variable">$virtual_alias_domains</span> <span class="variable">$virtual_mailbox_maps</span> <span class="variable">$virtual_mailbox_domains</span> <span class="variable">$relay_recipient_maps</span> <span class="variable">$relay_domains</span> <span class="variable">$canonical_maps</span> <span class="variable">$sender_canonical_maps</span> <span class="variable">$recipient_canonical_maps</span> <span class="variable">$relocated_maps</span> <span class="variable">$transport_maps</span> <span class="variable">$mynetworks</span> <span class="variable">$virtual_mailbox_limit_maps</span></div><div class="line"></div><div class="line"><span class="comment">#smtps 加密发送服务设置</span></div><div class="line">smtpd_tls_cert_file = /etc/pki/dovecot/certs/dovecot.pem</div><div class="line">smtpd_tls_key_file = /etc/pki/dovecot/private/dovecot.pem</div><div class="line">smtpd_use_tls = yes</div><div class="line">smtpd_tls_auth_only = yes</div><div class="line"></div><div class="line">smtpd_sasl_<span class="built_in">type</span> = dovecot</div><div class="line">smtpd_sasl_path = private/auth</div><div class="line">smtpd_sasl_auth_<span class="built_in">enable</span> = yes</div><div class="line">smtpd_sasl_security_options = noanonymous</div><div class="line">smtpd_sasl_<span class="built_in">local</span>_domain = <span class="variable">$myhostname</span></div><div class="line">smtpd_sasl_application_name = smtpd</div><div class="line">smtpd_recipient_restrictions =</div><div class="line">        permit_sasl_authenticated,</div><div class="line">        permit_mynetworks,</div><div class="line">        reject_unauth_destination</div><div class="line"></div><div class="line"><span class="comment">#用户配额，可以后续慢慢优化</span></div><div class="line">message_size_<span class="built_in">limit</span> = 20480000</div><div class="line">virtual_mailbox_<span class="built_in">limit</span>_maps = mysql:/etc/postfix/mysql_virtual_mailbox_<span class="built_in">limit</span>_maps.cf</div><div class="line"></div><div class="line">maximal_queue_lifetime = 1d</div><div class="line">bounce_queue_lifetime = 1d</div></pre></td></tr></table></figure></p>
<p>在master.cf配置文件中，添加dovecot服务支持，同时打开smtps的相关服务smtps和submission，从而支持ssl和tls加密发送<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">submission inet n       -       n       -       -       smtpd</div><div class="line">  -o syslog_name=postfix/submission</div><div class="line">  -o smtpd_tls_security_level=encrypt</div><div class="line">  -o smtpd_sasl_auth_<span class="built_in">enable</span>=yes</div><div class="line">smtps     inet  n       -       n       -       -       smtpd</div><div class="line">  -o syslog_name=postfix/smtps</div><div class="line">  -o smtpd_tls_wrappermode=yes</div><div class="line">  -o smtpd_sasl_auth_<span class="built_in">enable</span>=yes</div><div class="line"></div><div class="line">dovecot   unix  -       n       n       -       -       pipe</div><div class="line">   flags=DRhu user=vmail:vmail argv=/usr/libexec/dovecot/dovecot-lda <span class="_">-f</span> <span class="variable">$&#123;sender&#125;</span> <span class="_">-d</span> <span class="variable">$&#123;recipient&#125;</span></div></pre></td></tr></table></figure></p>
<p>在上文的配置中，同时还需要建立若干mysql_xxx.cf的链接文件，主要用来访问postfixadmin建立的数据库来进行数据交互的，文件的内容基本同参考2种所列出。其中有个mysql_virtual_mailbox_maps.cf漏写了，内容如下：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">user = postfix</div><div class="line">password = postpasswd</div><div class="line">hosts = localhost</div><div class="line">dbname = postfix</div><div class="line">query  = SELECT maildir FROM mailbox WHERE username=<span class="string">'%s'</span> AND active = <span class="string">'1'</span></div></pre></td></tr></table></figure></p>
<h3 id="2-3-2_dovecot的配置信息">2.3.2 dovecot的配置信息</h3><p>这个dovecot的配置就更坑爹了，以前都是搞到一个conf文件的，现在分开到conf.d目录下各个conf文件，显得更难抄袭了。dovecat主要用来收取邮件的，支持pop3/imap/lmtp协议。<br>dovecot.conf的主要内容<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">protocols = imap pop3</div><div class="line">listen = *</div><div class="line"></div><div class="line">passdb &#123;</div><div class="line">    driver = sql</div><div class="line">    args = /etc/dovecot/dovecot-sql.conf.ext</div><div class="line">&#125;</div><div class="line"></div><div class="line">userdb &#123;</div><div class="line">    driver = static</div><div class="line">    args = uid=5000 gid=5000 home=/aaa/maildata/%d/%n allow_all_users=yes</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>上文中dovecot-sql.conf.ext的内容如下，注意到采用的密码加密方式，必须跟前面的设置要一致才行。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">driver = mysql</div><div class="line">connect = host=localhost dbname=postfix user=postfix password=postfixadmin</div><div class="line">default_pass_scheme = CRAM-MD5</div><div class="line">user_query = SELECT CONCAT(<span class="string">'/abc/maildata/'</span>, maildir) AS home, 5000 AS uid, 5000 AS gid, CONCAT(<span class="string">'*:bytes='</span>, quota) as quota_rule FROM mailbox WHERE username = <span class="string">'%u'</span> AND active=<span class="string">'1'</span></div><div class="line">password_query = SELECT username AS user, password, CONCAT(<span class="string">'/webdata/data/maildata/'</span>, maildir) AS userdb_home, 5000 AS userdb_uid, 5000 AS userdb_gid, CONCAT(<span class="string">'*:bytes='</span>, quota) as userdb_quota_rule FROM mailbox WHERE username = <span class="string">'%u'</span> AND active=<span class="string">'1'</span></div></pre></td></tr></table></figure></p>
<p>下面把dovecot最主要的配置列举出来：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#10-mail.conf </span></div><div class="line">mail_location = maildir:/aaa/maildata/%d/%n/Maildir</div><div class="line"><span class="comment">#10-auth.conf </span></div><div class="line"><span class="built_in">disable</span>_plaintext_auth = no</div><div class="line">auth_mechanisms = plain login cram-md5</div><div class="line"><span class="comment">#10-master.conf</span></div><div class="line">service imap-login &#123;</div><div class="line">  inet_listener imap &#123;</div><div class="line">    <span class="comment">#port = 143  关掉非加密访问</span></div><div class="line">  &#125; </div><div class="line">  inet_listener imaps &#123;</div><div class="line">    port = 993</div><div class="line">    ssl = yes</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">service auth &#123;</div><div class="line">unix_listener auth-userdb &#123;</div><div class="line">    mode = 0666</div><div class="line">    user = vmail</div><div class="line">    group =  vmail</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment"># Postfix smtp-auth</span></div><div class="line">  unix_listener /var/spool/postfix/private/auth &#123;</div><div class="line">  mode = 0666</div><div class="line">  user = postfix</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">#10-ssl.conf</span></div><div class="line">ssl = yes</div><div class="line">ssl_cert = &lt;/etc/pki/dovecot/certs/dovecot.pem</div><div class="line">ssl_key = &lt;/etc/pki/dovecot/private/dovecot.pem</div></pre></td></tr></table></figure></p>
<h2 id="2-4_roundcubemail设置">2.4 roundcubemail设置</h2><p>roundcubemail是一个邮件登陆web界面。安装第一步也是需要运行<strong><a href="https://mail.freesign.net/webmail/installer" target="_blank" rel="external">https://mail.freesign.net/webmail/installer</a></strong>访问安装界面。在第(2)步检查各项条件满足后，进入下一步，在第(2)步根据用户的配置，辅助生成配置文件，我们将该文件复制拷贝到/etc/roundcubemail/config.inc.php中，再在第三步(3)进行配置的测试验证。<br>/etc/roundcubemail/config.inc.php的重要配置有：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#数据库访问设置</span></div><div class="line"><span class="variable">$config</span>[<span class="string">'db_dsnw'</span>] = <span class="string">'mysql://postfix:postfixadmin@localhost/postfix'</span>;</div><div class="line"><span class="comment">#IMAP</span></div><div class="line"><span class="variable">$config</span>[<span class="string">'default_host'</span>] = <span class="string">'ssl://mail.freesign.com/'</span>;</div><div class="line"><span class="variable">$config</span>[<span class="string">'default_port'</span>] = 993;</div><div class="line"><span class="comment">#SMTP</span></div><div class="line"><span class="variable">$config</span>[<span class="string">'smtp_server'</span>] = <span class="string">'tls://topcubaircraft.com'</span>;</div><div class="line">// SMTP port (default is 25; use 587 <span class="keyword">for</span> STARTTLS or 465 <span class="keyword">for</span> the</div><div class="line"><span class="variable">$config</span>[<span class="string">'smtp_port'</span>] = 587;</div><div class="line"><span class="variable">$config</span>[<span class="string">'smtp_user'</span>] = <span class="string">'%u'</span>;</div><div class="line"><span class="variable">$config</span>[<span class="string">'smtp_pass'</span>] = <span class="string">'%p'</span>;</div><div class="line"></div><div class="line"><span class="variable">$config</span>[<span class="string">'plugins'</span>] = array(<span class="string">'archive'</span>, <span class="string">'attachment_reminder'</span>, <span class="string">'help'</span>);</div><div class="line"><span class="variable">$config</span>[<span class="string">'sent_mbox'</span>] = <span class="string">'Sent'</span>;</div><div class="line"><span class="variable">$config</span>[<span class="string">'trash_mbox'</span>] = <span class="string">'Trash'</span>;</div><div class="line"><span class="variable">$config</span>[<span class="string">'drafts_mbox'</span>] = <span class="string">'Drafts'</span>;</div><div class="line"><span class="variable">$config</span>[<span class="string">'junk_mbox'</span>] = <span class="string">'Junk'</span>;</div></pre></td></tr></table></figure></p>
<h1 id="3-_验证与测试">3. 验证与测试</h1><h2 id="3-1_建立邮件账户">3.1 建立邮件账户</h2><p>通过访问<strong><a href="https://mail.freesign.net/postfixadmin/" target="_blank" rel="external">https://mail.freesign.net/postfixadmin/</a></strong>，首先添加域mail.freesign.net，然后在域下添加账户nicol，就完成了nicol@mail.freesign.net邮箱账户的注册。</p>
<h2 id="3-2_网页端和手机端验证">3.2 网页端和手机端验证</h2><p>在网页端，访问<strong><a href="https://mail.freesign.net/mail/" target="_blank" rel="external">https://mail.freesign.net/mail/</a></strong><br><img src="/post_images/images/201510/475813caa5928ab75ace87dd55e3bb29.png" alt="网页端测试"></p>
<p>在手机端，用的ssl加密连接，测试OK<br><img src="/post_images/images/201510/9aebb9a30a5095e933da00270394694a.png" alt="邮件客户端连接"></p>
<p>唉，邮件服务器算是最难搭建的服务器了！</p>
<p>本文完！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://www.linode.com/docs/email/postfix/email-with-postfix-dovecot-and-mariadb-on-centos-7" target="_blank" rel="external">Email with Postfix, Dovecot and MariaDB on CentOS 7</a></li>
<li><a href="http://blog.163.com/qiushuhui1989@126/blog/static/2701108920146279368171" target="_blank" rel="external">搭建企业邮件系统</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[RedHat系列软件打包实例（二）]]></title>
      <url>https://taozj.org/201509/rpmbuild-package-example-(2).html</url>
      <content type="html"><![CDATA[<p>　　上一篇算是对RPM软件一个简单的入门介绍。这一篇文章里，将对spec文件的各个参数进行较详细的探究和学习。其次，我们也将对strtest软件包进行改造，让它变的在Linux平台更“专业”像样一点。</p>
<h1 id="1-修改strtest文件">1.修改strtest文件</h1><p>　　这里，我们对strtest的源代码进行修改，让它变成一个类似于后台服务进程一样的。<br>　　当然不想弄一个复杂的服务端出来，因为这里只是进行验证测试：就让strtest心跳2s输出自己还活着的信息。由于现在的系统服务管理经过一段时间无力的抵制和抗议之后，全部屈服成systemd的了，所以这边也添加一个systemd的服务管理单元。<br>　　src/str.cpp的代码内容如下（原谅我一个披着CPP的纯C）<br> <figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SPECS]$ cat ~/dist/strtest<span class="number">-1.0</span><span class="number">.2</span>/src/str.cpp </div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"str.h"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/time.h&gt;</span></span></div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">char</span>* logfile = <span class="string">"/var/log/strtest.log"</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc , <span class="keyword">char</span> **argv)</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">struct</span> timeval tv;</div><div class="line">    <span class="keyword">time_t</span> timet;</div><div class="line">    <span class="keyword">struct</span> tm* timep;</div><div class="line">    FILE* fp = fopen(logfile,<span class="string">"a"</span>);</div><div class="line"></div><div class="line">    <span class="keyword">if</span>(!fp) &#123;</div><div class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>,<span class="string">"Open logfile[%s] failed!\n"</span>, logfile);</div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    time(&amp;timet);</div><div class="line">    timep = localtime(&amp;timet); </div><div class="line">    </div><div class="line">    <span class="built_in">fprintf</span>(fp, <span class="string">"[%d-%d-%d %d:%d:%d]Starting service [%s] ...\n"</span>, timep-&gt;tm_year, timep-&gt;tm_mon, timep-&gt;tm_mday,</div><div class="line">            timep-&gt;tm_hour, timep-&gt;tm_min, timep-&gt;tm_sec, argv[<span class="number">0</span>]);</div><div class="line"></div><div class="line">    <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</div><div class="line">        <span class="built_in">fprintf</span>(fp, <span class="string">"service[%s], I am alive --"</span>, argv[<span class="number">0</span>]);</div><div class="line">        <span class="keyword">if</span>(!gettimeofday(&amp;tv, <span class="literal">NULL</span>)) &#123;</div><div class="line">            <span class="built_in">fprintf</span>(fp, <span class="string">"system time info:%ds-%dus\n"</span>, tv.tv_sec, tv.tv_usec);</div><div class="line">        &#125;</div><div class="line">        fflush(fp);</div><div class="line">        sleep(<span class="number">2</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    fclose(fp);</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h1 id="2-添加strtest的systemd管理单元">2.添加strtest的systemd管理单元</h1><h2 id="2-1编写service文件">2.1编写service文件</h2><p>　　systemd依赖于service文件管理服务，放置在/usr/lib/systemd/目录下，注意的是，systemd管理单元应当是操作系统的一部分，而不是strtest软件代码的一部分，不应当打包到源代码下面，而应该将下面的strtest.service放到和strtest-1.0.2.tar.bz2一样的~/rpmbuild/SOURCES/目录下面。（这个service文件是抄袭的openssh滴！）关于systemd的相关信息，后面可能还会再学习整理，这里先不细究。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SOURCES]$ cat strtest.service </div><div class="line">[Unit]</div><div class="line">Description=Strtest server daemon</div><div class="line"></div><div class="line">[Service]</div><div class="line">ExecStart=/usr/bin/strtest <span class="variable">$OPTIONS</span></div><div class="line">ExecReload=/bin/<span class="built_in">kill</span> -HUP <span class="variable">$MAINPID</span></div><div class="line">KillMode=process</div><div class="line">Restart=on-failure</div><div class="line">RestartSec=42s</div><div class="line"></div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure></p>
<h2 id="2-2_修正spec文件">2.2 修正spec文件</h2><p>　　修改strtest的源代码，对spec文件没有影响（主要是版本号和修改日志等无关紧要的）。目前主要修改使得strtest.service打包进去：<br>　　在%install部分，添加如下内容<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 用于安装systemd服务</span></div><div class="line">install <span class="_">-d</span> -m755 <span class="variable">$RPM_BUILD_ROOT</span>/%&#123;_unitdir&#125;</div><div class="line">install -m644 %&#123;SOURCE1&#125; <span class="variable">$RPM_BUILD_ROOT</span>/%&#123;_unitdir&#125;/strtest.service</div></pre></td></tr></table></figure></p>
<p>然后在%file部分，添加如下内容<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">%&#123;_unitdir&#125;/strtest.service</div></pre></td></tr></table></figure></p>
<p>OK, we all done!<br><a id="more"></a></p>
<h2 id="2-3_演示效果">2.3 演示效果</h2><p>　　打包，然后更新strtest软件后，如预期的，它华丽丽地工作啦！<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~  sudo systemctl start strtest</div><div class="line"> user@localhost  ~  sudo systemctl status strtest</div><div class="line">● strtest.service - Strtest server daemon</div><div class="line">   Loaded: loaded (/usr/lib/systemd/system/strtest.service; disabled; vendor preset: disabled)</div><div class="line">   Active: active (running) since Thu 2015-10-01 23:50:10 CST; 7s ago</div><div class="line"> Main PID: 45603 (strtest)</div><div class="line">   CGroup: /system.slice/strtest.service</div><div class="line">           └─45603 /usr/bin/strtest</div><div class="line"></div><div class="line">Oct 01 23:50:10 localhost.localdomain systemd[1]: Started Strtest server daemon.</div><div class="line">Oct 01 23:50:10 localhost.localdomain systemd[1]: Starting Strtest server daemon...</div><div class="line"> user@localhost  ~  sudo tail <span class="_">-f</span> /var/<span class="built_in">log</span>/strtest.log </div><div class="line">[115-9-1 23:50:10]Starting service [/usr/bin/strtest] ...</div><div class="line">service[/usr/bin/strtest], I am alive --system time info:1443714610s-509937us</div><div class="line">service[/usr/bin/strtest], I am alive --system time info:1443714612s-511546us</div><div class="line">service[/usr/bin/strtest], I am alive --system time info:1443714614s-512393us</div><div class="line">service[/usr/bin/strtest], I am alive --system time info:1443714616s-513700us</div></pre></td></tr></table></figure></p>
<h1 id="3-spec文件的其它特性">3.spec文件的其它特性</h1><h2 id="3-1_patch补丁包">3.1 patch补丁包</h2><p>　　觉得patch功能是这里面最重要的功能，因为你没有办法控制upstream的软件包，所以你的修改需要以补丁的形势和upstream的软件包共存。下面将我们的strtest添加一些补丁信息<br>Patch0</p>
<h2 id="3-2_其它标签">3.2 其它标签</h2><p>BuildArch: noarch<br>BuildRequires:编译软件包所需的依赖包列表，以逗号分隔<br>Requires: 安装软件包时所需的依赖包列表，以逗号分隔(大多数情况下，rpmbuild 会自动探测依赖，所以可能不需要 Requires 标签)<br>prep:<br>file</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[RedHat系列RPM软件打包实例（一）]]></title>
      <url>https://taozj.org/201509/rpmbuild-package-example-(1).html</url>
      <content type="html"><![CDATA[<p>　　对于Linux操作系统，由于软件大部分都是开源软件构成，所以软件打包算是维护一个发行版的绝大多数任务。在Linux那个远古的时代，大家告诉你软件的安装都是下载源码、配置、编译和安装。</p>
<p>　　下面以Fedora 22为例子演示，CentOS可能会有一些差异，暂且不表。且是在本地进行打包的，没有用到Fedora的Koji系统。</p>
<h1 id="1-配置环境">1.配置环境</h1><h2 id="1-1_安装打包软件">1.1 安装打包软件</h2> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~ sudo dnf install fedora-packager @development-tools rpmdevtools</div></pre></td></tr></table></figure>
<h2 id="1-2_配置打包环境">1.2 配置打包环境</h2><p>　　手册强烈建议不要使用root打包，以防破坏系统；也不要使用系统常用用户打包，以防上传一些用户的私密信息；所以建议建立一个专门打包的普通用户。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~ sudo useradd makerpm</div><div class="line"> user@localhost  ~ sudo usermod <span class="_">-a</span> -G mock makerpm</div><div class="line"> user@localhost  ~ sudo passwd makerpm</div><div class="line"> user@localhost  ~ su makerpm</div><div class="line">Password: </div><div class="line">[makerpm@localhost ~]$ rpmdev-setuptree</div><div class="line">[makerpm@localhost ~]$ ls</div><div class="line">rpmbuild</div><div class="line">[makerpm@localhost ~]$</div></pre></td></tr></table></figure></p>
<p>然后打包环境就建立好了。</p>
<h1 id="2-编写spec文件">2.编写spec文件</h1><h2 id="2-1_参考已经打好的包">2.1 参考已经打好的包</h2><p>　　Fedora发布的软件都是包含源代码的，所以可以借鉴这些包的打包脚本，先模仿再创作是最便捷的学习方式。<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost dist]$  dnf download --source p7zip</div><div class="line">[makerpm@localhost dist]$ mkdir p7zip-9.20.1-8.fc22</div><div class="line">[makerpm@localhost dist]$ <span class="built_in">cd</span> p7zip-9.20.1-8.fc22/</div><div class="line">[makerpm@localhost p7zip-9.20.1-8.fc22]$ rpm2cpio ../p7zip-9.20.1-8.fc22.src.rpm | cpio -i</div></pre></td></tr></table></figure></p>
<p>然后慢慢品味p7zip.spec吧！</p>
<h2 id="2-2_准备打包的源代码包">2.2 准备打包的源代码包</h2><p>　　起始环境建立好之后，打包的过程，就是编写spec文件的过程。<br>　　使用的材料是上一次的strtest工程进行打包，注意包的命名规范：name-version.tar.gz<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/Study/project/to_linux  mv strtest strtest-1.0.1</div><div class="line">user@localhost  ~/Study/project/to_linux  tar czvf strtest-1.0.1.tar.gz strtest-1.0.1</div><div class="line">user@localhost  ~/Study/project/to_linux  sudo cp strtest-1.0.1.tar.gz /home/makerpm/rpmbuild/SOURCES/</div><div class="line">user@localhost  ~/Study/project/to_linux  sudo chown makerpm:makerpm /home/makerpm/rpmbuild/SOURCES/strtest-1.0.1.tar.gz</div><div class="line">user@localhost  ~/Study/project/to_linux </div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h2 id="2-3_使用默认模板，修改模板参数">2.3 使用默认模板，修改模板参数</h2> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SPECS]$ <span class="built_in">cd</span> ~/rpmbuild/SPECS</div><div class="line">[makerpm@localhost SPECS]$ rpmdev-newspec strtest</div><div class="line">strtest.spec created; <span class="built_in">type</span> minimal, rpm version &gt;= 4.12.</div><div class="line">[makerpm@localhost SPECS]$</div></pre></td></tr></table></figure>
<p>　　工具会根据提供的程序的名字，来猜测最匹配的模板。<br>　　然后就是修改strtest.spec，填充开始的项目相关资料，几个主要的地方也已经列出了，对于标准的软件包，其%prep %build %install等部分都不需要修改，保持默认就可以了：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SPECS]$ cat strtest.spec </div><div class="line">Name:           strtest</div><div class="line">Version:        1.0.1</div><div class="line">Release:        1%&#123;?dist&#125;</div><div class="line">Summary:        <span class="string">"The strtest program from Nicol TAO"</span></div><div class="line">Summary(zh_CN): <span class="string">"陶治江的strtest测试程序"</span></div><div class="line"></div><div class="line">License:        GPLv3+</div><div class="line">URL:            https://freesign.net</div><div class="line"><span class="comment"># 没有挂到网上的时候，就把软件包直接拷贝到~/rpmbuild/SOURCES/目录下面</span></div><div class="line">Source0:        https://freesign.net/pub//%&#123;name&#125;-%&#123;version&#125;.tar.gz</div><div class="line"></div><div class="line"><span class="comment"># Optional可选项，如果实在没有依赖部分，就将下面的注释掉</span></div><div class="line"><span class="comment">#BuildRequires:  </span></div><div class="line"><span class="comment">#Requires:       </span></div><div class="line"></div><div class="line">%description</div><div class="line">This is the strtest program written by Nicol Tao, used to <span class="built_in">test</span> <span class="keyword">for</span></div><div class="line">the system automake and the rpm format software package.</div><div class="line"></div><div class="line">%description <span class="_">-l</span> zh_CN</div><div class="line"><span class="string">"strtest"</span>程序，用来进行automake的测试，以及rpm系列的系统打包操作。</div><div class="line"></div><div class="line">%prep</div><div class="line">%setup -q</div><div class="line"></div><div class="line"></div><div class="line">%build</div><div class="line">%configure</div><div class="line">make %&#123;?_smp_mflags&#125;</div><div class="line"></div><div class="line"></div><div class="line">%install</div><div class="line">rm -rf <span class="variable">$RPM_BUILD_ROOT</span></div><div class="line">%make_install</div><div class="line"></div><div class="line"></div><div class="line">%files </div><div class="line"><span class="comment">#此处需要添加的，安装的文件、文档列表</span></div><div class="line">%defattr(-,root,root,-)</div><div class="line">%&#123;_bindir&#125;/strtest</div><div class="line">%doc INSTALL</div><div class="line">%license COPYING</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 修改日志的格式要求还是蛮严格的哦！</span></div><div class="line">%changelog</div><div class="line">* Tue Sep 29 2015 Nicol TAO &lt;taozhijiang@gmail.com&gt; - 1.0.1-1</div><div class="line">- First initial release</div></pre></td></tr></table></figure></p>
<p>准备好之后，使用<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SPECS]$ rpmbuild -ba strtest.spec</div></pre></td></tr></table></figure></p>
<p>执行打包，就会生成strtest-1.0.1-1.fc22.x86_64.rpm和对于的debug-info，src.rpm文件！</p>
<p>手册还建议用rpmlint检查打包是否符合规范，那么就跑一下吧！<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost SPECS]$ rpmlint strtest.spec ../SRPMS/strtest* ../RPMS/*/strtest*</div></pre></td></tr></table></figure></p>
<p>结果是<strong>3 packages and 1 specfiles checked; 0 errors, 13 warnings.</strong>我勒个去啊，不管了，检查的还是蛮细致的！</p>
<h1 id="2-4_验证生成的rpm包">2.4 验证生成的rpm包</h1><p>　　检查某个包所打包包含的文件列表<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost x86_64]$ rpm -qpl strtest-1.0.1-1.fc22.x86_64.rpm </div><div class="line">/usr/bin/strtest</div><div class="line">/usr/share/doc/strtest</div><div class="line">/usr/share/doc/strtest/INSTALL</div><div class="line">/usr/share/licenses/strtest</div><div class="line">/usr/share/licenses/strtest/COPYING</div><div class="line">[makerpm@localhost x86_64]$</div></pre></td></tr></table></figure></p>
<p>　　使用<strong>rpm -ivh strtest-1.0.1-1.fc22.x86_64.rpm</strong>安装之后，可以查看软件的其他信息：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[makerpm@localhost x86_64]$ rpm -q --info strtest     </div><div class="line">Name        : strtest</div><div class="line">Version     : 1.0.1</div><div class="line">Release     : 1.fc22</div><div class="line">Architecture: x86_64</div><div class="line">Install Date: Tue 29 Sep 2015 04:45:43 PM CST</div><div class="line">Group       : Unspecified</div><div class="line">Size        : 7216</div><div class="line">License     : GPLv3+</div><div class="line">Signature   : (none)</div><div class="line">Source RPM  : strtest-1.0.1-1.fc22.src.rpm</div><div class="line">Build Date  : Tue 29 Sep 2015 04:44:44 PM CST</div><div class="line">Build Host  : localhost</div><div class="line">Relocations : (not relocatable)</div><div class="line">URL         : https://freesign.net</div><div class="line">Summary     : <span class="string">"The strtest program from Nicol TAO"</span></div><div class="line">Description :</div><div class="line">This is the strtest program written by Nicol Tao, used to <span class="built_in">test</span> <span class="keyword">for</span></div><div class="line">the system automake and the rpm format software package.</div><div class="line">[makerpm@localhost x86_64]$</div></pre></td></tr></table></figure></p>
<p>　　更多的特性请<strong>man rpm</strong>。</p>
<p>　　简单的打包过程就结束了。后面继续更新！</p>
<h1 id="参考">参考</h1><ul>
<li><a href="https://fedoraproject.org/wiki/How_to_create_a_GNU_Hello_RPM_package/zh-cn" target="_blank" rel="external">How to create a GNU Hello RPM package/zh-cn</a></li>
<li><a href="https://fedoraproject.org/wiki/How_to_create_an_RPM_package/zh-cn" target="_blank" rel="external">How to create an RPM package/zh-cn</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[利用autotools自动生成项目的Makefile]]></title>
      <url>https://taozj.org/201509/generate-makefile-through-autotools.html</url>
      <content type="html"><![CDATA[<p>Linux下的软件，大多要不是各个发行版打好包的，要不是源代码下来后，<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./configure &amp;&amp; make &amp;&amp; make install</div></pre></td></tr></table></figure></p>
<p>　　三步曲来完成安装的。对于一个工程，简单的话可以手写Makefile，但是随着项目不断的增长，需要跟踪的文件越来越多的时候，手动维护Makefile会比较的麻烦；同时随着各个发行版和平台的差异性的处理也很尽善尽美；（<strong>当然我主要是对Makefile不太熟悉，用这个工具可以傻瓜生成Makefile，是我最大的动力！</strong>）</p>
<h1 id="1-安装autotools">1.安装autotools</h1><p>　　在我的地沟油下，是被打包成下面两个文件的：<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo dnf install automake  autoconf</div></pre></td></tr></table></figure></p>
<h1 id="2-建立代码目录，添加测试的源代码文件">2.建立代码目录，添加测试的源代码文件</h1><p>　　这里直接无耻地照搬了<a href="http://blog.csdn.net/memoryjs/article/details/7860783" target="_blank" rel="external">这里</a>的两个测试文件str.h和str.cpp<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"> user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project  mkdir include src</div><div class="line"> user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project  cat include/str.h </div><div class="line"><span class="comment">#include &lt;stdio.h&gt;  </span></div><div class="line">int str(char *string);  </div><div class="line"> user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project  cat src/str.cpp </div><div class="line"><span class="comment">#include "str.h"</span></div><div class="line"></div><div class="line">int str(char *string)&#123;</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"\n----PRINT STRING----\n\"%s\"\n"</span>,string);</div><div class="line">        <span class="built_in">return</span> 0;</div><div class="line">&#125;</div><div class="line"></div><div class="line">int main(int argc , char **argv)&#123;</div><div class="line">        char str_<span class="built_in">read</span>[1024];</div><div class="line">        <span class="built_in">printf</span>(<span class="string">"Please INPUT something end by [ENTER]\n"</span>);</div><div class="line">        scanf(<span class="string">"%s"</span>,str_<span class="built_in">read</span>);</div><div class="line">        <span class="built_in">return</span> str(str_<span class="built_in">read</span> );</div><div class="line">&#125;</div><div class="line"> user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project </div></pre></td></tr></table></figure></p>
<h1 id="3-生成configure-ac">3.生成configure.ac</h1><p>　　autoscan工具在给定目录及其子目录树中检查源文件，若没有给出目录，就在当前目录及子目录树中进行检查，并生成一个configure.scan文件。我们将这个文件命名为configure.ac(有的也命名成configure.in文件，但是.ac是新名字，建议用这个哦！)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project  mv configure.scan configure.ac</div></pre></td></tr></table></figure></p>
<p>修改之，添加或者修改如下条目（最终的修改结果会在文末贴出）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">AC_INIT([strtest], [1.0], [taozhijiang@gmail.com])</div><div class="line">AM_INIT_AUTOMAKE</div><div class="line">AC_PROG_CXX</div><div class="line">AC_CONFIG_FILES([Makefile])</div></pre></td></tr></table></figure></p>
<h1 id="4-执行aclocal">4.执行aclocal</h1><h1 id="5-创建Makefile-am">5.创建Makefile.am</h1><p>　　这是另外一个比较讲究的文件。<br>　　一个工程可以创建多个可执行文件，每个可执行文件可以依赖自己的源文件、编译参数等信息。<br>　　AUTOMAKE_OPTIONS提供了三个strictness等级，分别是foreign, gnu(默认), gnits三个，主要差异是对目录下的NEWS、README等要求，以及编译的输出等级等，foreign是最小等级。<br>　　详情请见<strong>info automake  3.2 Strictness</strong></p>
<h2 id="5-1_方案1">5.1 方案1</h2><p>　　我们简单使用的文件如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">AUTOMAKE_OPTIONS = foreign</div><div class="line"></div><div class="line">bin_PROGRAMS = strtest</div><div class="line">strtest_SOURCES = src/str.cpp</div><div class="line">strtest_CPPFLAGS    = -I include/  -include  ./WINTYPES.H</div></pre></td></tr></table></figure></p>
<p>　　下面很明显啦，就是每个执行文件的名字，及其源代码和额外的编译参数。<br><a id="more"></a></p>
<h2 id="5-2_方案2">5.2 方案2</h2><p>　　这样每个源代码添加src比较的麻烦，还以使用SUBDIRS指令。在顶层的Makefile.am的内容为<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">AUTOMAKE_OPTIONS = foreign</div><div class="line">SUBDIRS = src</div></pre></td></tr></table></figure></p>
<p>然后在src目录添加Makefile.am，内容为<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bin_PROGRAMS = strtest</div><div class="line">strtest_SOURCES =  str.cpp</div><div class="line">strtest_CPPFLAGS = -I include/  -include  ./WINTYPES.H</div></pre></td></tr></table></figure></p>
<p>还需要修改之前的configure.ac文件，增加子目录生成Makefile<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">AC_CONFIG_FILES([Makefile src/Makefile])</div></pre></td></tr></table></figure></p>
<p>所以一开始就要规划好！</p>
<h1 id="6-执行autoconf">6.执行autoconf</h1><p>　　生成configure可执行文件，用于检测系统配置等信息。</p>
<h1 id="7-autoheader">7.autoheader</h1><p>　　负责生成configure.ac配置文件中的config.h.in文件。打开看主要是一些包的名字、URL等信息。可能是修改配置configure.ac中的某些参数会生成，对这里的实质性工作没啥作用。</p>
<h1 id="8-automake_–add-missing">8.automake –add-missing</h1><p>　　GNU的要求还是比较规范的，什么INSTALL COPYING 等信息都不能少。添加–add-missing参数自动添加这些丢失的东西!</p>
<h1 id="9-_-/configure_&amp;&amp;_make">9.  ./configure &amp;&amp; make</h1><p>　　这就是通常的编译步骤，完成后就会在根目录或者src目录下生成可执行文件strtest啦！</p>
<h1 id="附录详细的文件清单：">附录详细的文件清单：</h1><p>===================================<br>configure.ac </p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">#                                               -*- Autoconf -*-</span></div><div class="line"></div><div class="line"></div><div class="line"> <span class="comment"># Process this file with autoconf to produce a configure script.</span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"> AC_PREREQ([2.69])</div><div class="line">AC_INIT([strtest], [1.0], [taozhijiang@gmail.com])</div><div class="line">AM_INIT_AUTOMAKE</div><div class="line">AC_CONFIG_SRCDIR([include/str.h])</div><div class="line">AC_CONFIG_HEADERS([config.h])</div><div class="line"></div><div class="line"> <span class="comment"># Checks for programs.</span></div><div class="line">AC_PROG_CC</div><div class="line">AC_PROG_CXX</div><div class="line"></div><div class="line"> <span class="comment"># Checks for libraries.</span></div><div class="line"></div><div class="line"> <span class="comment"># Checks for header files.</span></div><div class="line"></div><div class="line"> <span class="comment"># Checks for typedefs, structures, and compiler characteristics.</span></div><div class="line"></div><div class="line"> <span class="comment"># Checks for library functions.</span></div><div class="line">AC_CONFIG_FILES([Makefile])</div><div class="line"></div><div class="line"> AC_OUTPUT</div><div class="line"> user@localhost  ~/Study/project/to_linux/<span class="built_in">test</span>_project </div><div class="line"></div><div class="line">Makefile.am </div><div class="line"> ```bash</div><div class="line">AUTOMAKE_OPTIONS = foreign</div><div class="line">SUBDIRS = src</div></pre></td></tr></table></figure>
<p>src/Makefile.am<br> <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bin_PROGRAMS = strtest</div><div class="line">strtest_SOURCES = str.cpp</div><div class="line"></div><div class="line">strtest_CPPFLAGS    = -I ../include/  -include  ../WINTYPES.H</div></pre></td></tr></table></figure></p>
<h1 id="参考">参考</h1><ul>
<li><a href="http://blog.csdn.net/memoryjs/article/details/7860783" target="_blank" rel="external"> Makefile自动生成工具—–autotools的使用</a></li>
<li><a href="http://blog.sina.com.cn/s/blog_5f70c7060100gbgy.html" target="_blank" rel="external">GNU make 介绍 -利用工具自动生成makefile</a></li>
</ul>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[开源的个人密码管理器软件KeePass]]></title>
      <url>https://taozj.org/201508/keepass-pass-save.html</url>
      <content type="html"><![CDATA[<p>　　这个文章的标题都建立了好久了，一直没有去写。觉得就是一个软件推荐，十分的没有技术含量啊。但是用了这么久，感觉确实好用，因此整理出来推荐给大家。   </p>
<h1 id="一、KeePass的优点">一、KeePass的优点</h1><h3 id="1-1_主流的密码管理器">1.1 主流的密码管理器</h3><p>　　感觉主流的密码管理器，主要分成两类：保存在网络的和保存在本地的。</p>
<ul>
<li>前者以LastPass作为代表，所有的数据信息加密保存到云端，所以优势就是共享和更新比较的方便，但是缺点就是，万一你的密码或者供应商的数据和加密信息泄漏，你就完全被暴露了。LastPass这家公司曾经是出过此类安全问题的，有兴趣的同学可以扒扒<a href="http://www.freebuf.com/news/11898.html" target="_blank" rel="external">这段历史</a>！</li>
<li>后者主要以1Password和LastPass作为代表。主要区别是1Password是公司的商业产品，需要很多很多美刀，支持主流的平台（Linux除外），所以基本是高帅富的钟爱，这一点在AppStore的排行榜就可以看见。后者是社区化的开源产品，所有平台都支持(<strong>甚至黑莓、WindowsPhone都支持，良心软件啊！</strong>)，Linuxer的首选，但是没有商业支持，所以死活完全自理。这一类是将密码数据库加密存储到本地，不会传递到互联网上，所以理论上是最安全的。你也可以将加密数据库存储到dropbox等网盘中，实现多设备的同步操作。<br>以上列出的管理器，都有浏览器插件支持，后面再叙述。</li>
</ul>
<h3 id="1-2_KeePass的优势">1.2 KeePass的优势</h3><ul>
<li>开源<br>　　虽然我没有精力去查看他的源代码到底安不安全，有没有后门，但是开源的东西公布在网上，我相信大众的智慧会保证产品的质量，同时众目睽睽之下没有人会做这种留后门之类的事情。</li>
<li>支持Linux<br>　　曾经是Linux的忠实拥憋，现在还看见很多人折腾它。虽然现在都在“瘟都死”下学习娱乐，但对这种真正负责任的跨平台印象还是不错的。多平台多软件选择可以参见文档。</li>
<li>免费<br>　　1Password几十上百刀的价格确实把我吓尿了。对于生活在一个“软件不要钱”的国度，我买过的最贵的软件就是Windows序列号RMB10，以及Runtastic二十多块钱折扣时候买的。</li>
<li>保存在本地，安全<br>　　人家说在世界，尤其是天朝，互联网是有国界但是没有隐私的。所以我变得“焦虑、多疑”，我只相信数据在我的手中才是安全的。所以当前我的电脑插了一个SD卡，密码数据文件放在SD卡中，SD卡可以随身携带。<a id="more"></a>   
</li>
</ul>
<h1 id="二、安装设置">二、安装设置</h1><h3 id="2-1_软件安装">2.1 软件安装</h3><p>　　对于PC机，Windows有exe可以直接下载安装，主流的Linux发行版也都响应的被打包好了，Mac我没关注，买不起苹果机的飘过。<br>　　对于移动端，iOS系列和安卓系列请查看<a href="http://www.keepass.info/download.html" target="_blank" rel="external">官方文档</a>，我的iPhone用的是MiniKeePass。然后定期用itunes将SD卡中的数据同步到手机中去。</p>
<h3 id="2-2_浏览器设置">2.2 浏览器设置</h3><p>　　正如其它商业软件的支持一样，KeePass软件也对主流的浏览器(chrome、Firefox等)提供账户密码记录和自动补全功能。详细的过程请参考这篇文档。注意的是，亲测Linux下也是支持的哦！<br>使用KeePass的KeePassHttp插件以及Chrome的ChromeIPass插件！过程可以<a href="http://askubuntu.com/questions/130627/how-to-integrate-keepass-and-chrome-chromium-using-chromipass" target="_blank" rel="external">参照这里</a>。   </p>
<h1 id="三、效果展示">三、效果展示</h1><p>　　别的不说了，教程网上一大把，直接看效果吧！相信你肯定会爱上他的。</p>
<ul>
<li>登陆界面<br><img src="/post_images/images/201508/31779335ec4eb1ba94f021e12e59ee64.png" alt="登陆界面"></li>
<li>工作主界面<br><img src="/post_images/images/201508/e76cfbbd267b26daa260ff578a986f25.png" alt="工作主界面"></li>
<li>浏览器自动填充<br><img src="/post_images/images/201508/a13c26dd786b334f50fd1ba2caca2a85.png" alt="浏览器自动填充"></li>
<li>MiniKeePass界面<br><img src="/post_images/images/201508/c1a0dfa9fcb36bd3da78a694f25f2139.png" alt="MiniKeePass界面"></li>
<li>操作效果<br><img src="/post_images/images/201508/173ecaa819041f8ed7cef40fac6b1147.png" alt="操作效果"></li>
</ul>
<h1 id="四、NOTE">四、NOTE</h1><p>　　在Linux下面，KeePass是基于Mono来实现的，默认中文显示会有问题。需要一点注意的设置是：</p>
<blockquote>
<p>工具–选项–外观–强制使用系统字体   </p>
</blockquote>
<p>这个不要选，否则英文都是方块！</p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[在Windows下通过虚拟机搭建Linux内核的学习和调试环境]]></title>
      <url>https://taozj.org/201508/learning-and-debug-linux-kernel-under-windows.html</url>
      <content type="html"><![CDATA[<p>　　其实，这边文章在我的<a href="https://github.com/taozhijiang/linux/blob/master/start_to_learn_kernel_with_qemu.txt" target="_blank" rel="external">linux的repo</a>里面已经介绍了，此处着重进行归纳和整理。</p>
<h1 id="本文重点">本文重点</h1><ul>
<li>Windows下虚拟机的嵌套</li>
<li>内核编译和ramfs镜像的制作</li>
<li>Qemu使用特定内核启动</li>
</ul>
<h1 id="一、Windows下面VMware虚拟机嵌套KVM虚拟机">一、Windows下面VMware虚拟机嵌套KVM虚拟机</h1><p>　　像我之前用Gentoo，然后搭建个KVM的虚拟机，编译启动内核是十分方便的。但是碍于现在在Windows环境工作的原因，使用Gentoo作为桌面系统，还是有些不方便的。<br>　　此外还有的一个原因，是感觉自己过了那种折腾的年龄了。往昔那种优化美化Linux桌面，寻求各种方式替代Windows的应用软件，对我已经没有任何的吸引力了。（我已老矣）<br>　　在Windows下，至少需要一个Host来交叉编译内核，然后再找个Host启动跟踪这个内核，在一台机器上面如果用虚拟机，势必涉及到虚拟机的嵌套（因为如果开两个虚拟机，我还不知道调试的虚拟机怎么指定内核来启动，除非你将新内核拷贝到测试机覆盖文件系统上的内核，显然很麻烦！！！）Qemu+KVM就是这帮搞Linux的维护开发的，<strong>看看Qemu的启动参数就能吓尿你</strong>，所以用这家伙学内核乃是正道。<br>　　默认的VMware是不支持这种嵌套虚拟化的，需要修改虚拟机的配置文件。我用的VMware Workstation 9，测试添加这些内容可行<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">apic.xapic.enabled = <span class="string">"FALSE"</span>    </div><div class="line">vcpu.hotadd = <span class="string">"FALSE"</span>  </div><div class="line">hypervisor.cpuid.v0 = <span class="string">"FALSE"</span></div></pre></td></tr></table></figure></p>
<p>　　然后在VMware里面安装你的Guest（将来也是Host）的系统吧！（我用的地沟油，贱兔太浪费时间和精力了）<br>　　然后用qemu或者virt-manager再建立一个真正的Guest系统，我同样使用的Fedora。怎么用qemu或者virt-manager装系统，我不想说，你可以去参考archlinux或者gentoo的wiki。<br><a id="more"></a></p>
<h1 id="二、产生内核和initrd文件">二、产生内核和initrd文件</h1><h3 id="2-1_配置和编译内核">2.1 配置和编译内核</h3><p>　　内核我直接Fork的Linus的内核，所以是最upstream的。我想做代码的学习和<a href="https://github.com/taozhijiang/linux" target="_blank" rel="external">注解工程</a>有兴趣的可以联系我一块学习讨论。<br>　　配置编译内核就是<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">make menuconfig</div><div class="line">make</div></pre></td></tr></table></figure></p>
<p>　　两步曲，宇宙人都知道，不再细描。缺的第三步我要在下面说！  </p>
<h3 id="2-2_产生initrd文件">2.2 产生initrd文件</h3><p>　　如果你直接make install，内核会被装到你系统的/boot分区去，在内核的Makefile文件中写道  </p>
<blockquote>
<p># INSTALL_PATH specifies where to place the updated kernel and system map<br># images. Default is /boot, but you can set it to other values</p>
<p># INSTALL_DTBS_PATH specifies a prefix for relocations required by build roots.<br># Like INSTALL_MOD_PATH, it isn’t defined in the Makefile, but can be passed as<br># an argument if needed. Otherwise it defaults to the kernel install path<br>就是说这两个变量可以指定你的安装目录，英语烂的自行机器翻译去吧。  </p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">➜  linux git:(master) mkdir ../INSTALL_PATH</div><div class="line">➜  linux git:(master) make INSTALL_PATH=../INSTALL_PATH install</div><div class="line">sh ./arch/x86/boot/install.sh 4.2.0-rc7+ arch/x86/boot/bzImage \</div><div class="line">        System.map <span class="string">"../INSTALL_PATH"</span></div><div class="line">➜  linux git:(master) make INSTALL_MOD_PATH=../INSTALL_PATH modules_install</div><div class="line">➜  linux git:(master) <span class="built_in">cd</span> ../INSTALL_PATH</div><div class="line">➜  INSTALL_PATH ls</div><div class="line">config-4.2.0-rc7+      lib                        vmlinuz-4.2.0-rc7+</div><div class="line">System.map-4.2.0-rc7+</div></pre></td></tr></table></figure>
<p>　　对于指定了安装目录，那么不用root权限也可以安装的。能不用root权限就不要用，以防对Host主机造成破坏。此外，在地沟油下面会出现</p>
<blockquote>
<p>ln: failed to create symbolic link ‘/boot/System.map’: Permission denied<br>ln: failed to create symbolic link ‘/boot/vmlinuz’: Permission denied<br>ln: failed to create symbolic link ‘/boot/System.map’: Permission denied<br>　　遇见这样的警告，请忽视之。<br>　　对比/boot目录，我们发现少了initramfs文件，这个文件的作用不用说了，没有他多半系统起不来。在Gentoo中是genkernel工具可以自动生成的，在地沟油中，用dracut就可以生成（Gentoo中也可以安装使用dracut的）<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  INSTALL_PATH sudo dracut <span class="_">-f</span> -v -k <span class="string">'./lib/modules/4.2.0-rc7+'</span> initramfs.img 4.2.0-rc7+</div></pre></td></tr></table></figure></p>
</blockquote>
<p>　　如果你对initramfs里面有哪些东东感兴趣，可以使用<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">lsinitrd initramfs.img</div></pre></td></tr></table></figure></p>
<p>　　这个命令查看的。</p>
<h1 id="三、用制定的内核启动嵌套的虚拟机">三、用制定的内核启动嵌套的虚拟机</h1><p>　　上面的准备工作准备好了，就可以用上面出炉的内核以及initrd启动系统了。<br>　　这里啰嗦一句，可能人家对Qemu、KVM有点混乱，这么说吧，Qemu本身是一个天才所作的完整的虚拟机方案，可以虚拟很多种架构，而KVM是底层内核对虚拟化的支持，直接用Qemu也可以建虚拟机，只是速度龟慢，而Qemu+KVM用到内核虚拟化的支持，可以大大提高虚拟机的性能，这时候Qemu就是一个掌管虚拟机的工具了。<br>　　qemu的启动参数很多，下面直接贴出命令出来了，相信都不难理解，这个吧虚拟机的串口输出导出成一个服务端，用网络的方式可以在Host另外一个终端接收<br>　　启动分为两个类别</p>
<h3 id="3-1_使用Xmanager启动图形界面">3.1 使用Xmanager启动图形界面</h3><p>　　安装Xmanager后，打开Xmanager - Passive，同时设置DISPLAY环境变量（IP地址就是VNET8的地址，0.0查看Xmanager系统托盘的显示结果，有时候可能是0.1或者其他的）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">➜  INSTALL_PATH  <span class="built_in">export</span> DISPLAY=192.168.200.1:0.0</div><div class="line">➜  INSTALL_PATH  qemu-system-x86_64 -enable-kvm -cpu host -smp 2,sockets=1 -m 512M -drive file=/home/user/Machines/Fedora.img,<span class="keyword">if</span>=virtio,cache=writethrough   -serial telnet:127.0.0.1:4444,server -kernel ~/GitHub/INSTALL_PATH/vmlinuz-4.2.0-rc7+ -initrd ~/GitHub/INSTALL_PATH/initramfs.img -append <span class="string">"root=/dev/vda1 init=/usr/lib/systemd/systemd console=uart8250,io,0x3f8 debug ignore_loglevel"</span></div></pre></td></tr></table></figure></p>
<p>　　然后打印出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">QEMU waiting for connection on: disconnected:telnet:127.0.0.1:4444,server</div></pre></td></tr></table></figure></p>
<p>　　此时在另外一个终端执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">➜  INSTALL_PATH telnet 127.0.0.1 4444</div></pre></td></tr></table></figure></p>
<h3 id="3-2_Headless启动方法">3.2 Headless启动方法</h3><p>　　如果没有图形界面，就不需要Xmanager和DISPLAY了，直接在qemu的启动参数添加 –nographic参数就可以了。</p>
<h1 id="四、运行效果图">四、运行效果图</h1><p>系统启动界面<br><img src="/post_images/images/201508/4f6cd310dc4959bc35136d85f0d77492.jpg" alt="系统启动界面"><br>系统登陆界面<br><img src="/post_images/images/201508/d7475a78a5cb72fa8c80d177aa733b16.jpg" alt="系统登陆界面"></p>
<p>本文完！</p>
]]></content>
    </entry>
    
  
  
</search>
